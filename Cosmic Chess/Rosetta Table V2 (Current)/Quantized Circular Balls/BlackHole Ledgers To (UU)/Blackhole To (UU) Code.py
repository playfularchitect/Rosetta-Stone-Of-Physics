# -*- coding: utf-8 -*-
"""Blackhole Ledger To Universal Unit (Full).ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1Os0NoaxmaFld3JJyAkId6eCXnhDRPopZ
"""

# -*- coding: utf-8 -*-
"""Blackhole Ledger To Universal Unit (OG).ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/112hbDTSn5-7XSzZfZqroq5BYK7qya9mp
"""

# ============================================================
# ðŸš§ LEGO MODULE 001-FIX â€” "Planck â†” PFTC Encoder (Colab-safe)"
# Purpose: Re-run the Planckâ†’PFTC encoding WITHOUT caas_jupyter_tools,
#          and with a larger p-scan so tiny Planck quantities don't round to 0.
#          Saves results to CSV and prints a clean text table.
# ============================================================

from decimal import Decimal, getcontext, ROUND_HALF_UP
from math import log
import csv
import os

print("\n" + "="*80)
print("PATCH SETUP: High-precision arithmetic & constants (Colab-safe)")
print("="*80)

# Higher precision to be safe for large p scans
getcontext().prec = 100

# Integers as Decimals
INT_49 = Decimal(49)
INT_50 = Decimal(50)
INT_137 = Decimal(137)

# Constants (CODATA 2022; strings to avoid float ingress)
LN2 = Decimal("0.6931471805599453094172321214581765680755001343602552")
HBAR = Decimal("1.054571817e-34")     # J*s
C    = Decimal("2.99792458e8")        # m/s
G    = Decimal("6.67430e-11")         # m^3/(kg*s^2)
KB   = Decimal("1.380649e-23")        # J/K

# Planck units
mP = (HBAR * C / G).sqrt()            # kg
lP = (HBAR * G / (C**3)).sqrt()       # m
A_BIT = 4 * (lP**2) * LN2             # m^2
E_P = mP * (C**2)                     # J

print(f"m_P  [kg] = {mP}")
print(f"l_P  [m ] = {lP}")
print(f"A_bit [m^2] = 4 l_P^2 ln 2 = {A_BIT}")
print(f"E_P  [J ] = {E_P}")

# ---------- U(p) ----------
def U_of_p(p:int)->Decimal:
    denom = INT_49 * INT_50 * (INT_137 ** p)
    return Decimal(1) / denom

print("\n" + "="*80)
print("DEFINITION: U(p) = 1 / (49 * 50 * 137^p)")
print("="*80)
for p in [0, 1, 2, 3, 4, 5, 10, 15, 20, 30, 40, 50, 64]:
    print(f"p={p:2d} | U(p) = {U_of_p(p)}")

# ---------- Integer search ----------
def best_integer_encoding(value:Decimal, p_min:int=0, p_max:int=64):
    """
    For each p in [p_min, p_max], compute k â‰ˆ value/U(p) and pick the nearest integer.
    Evaluate absolute and relative errors; return the best.
    Returns: (p, k, rel_err, abs_err, U)
    """
    best = None
    for p in range(p_min, p_max+1):
        U = U_of_p(p)
        if U == 0:
            continue
        ratio = value / U
        # Try a few neighbors around rounded value
        k_center = int(ratio.to_integral_value(rounding=ROUND_HALF_UP))
        candidates = {k_center-1, k_center, k_center+1}
        # If value << U, k_center could be 0; add 1 as candidate to avoid degenerate 0
        candidates.add(1)
        # And if value >> U, try one more neighbor
        if k_center != 0:
            candidates.add(k_center+2)
        for kc in candidates:
            kc_dec = Decimal(kc)
            approx = kc_dec * U
            abs_err = (value - approx).copy_abs()
            rel_err = abs_err / (value.copy_abs() if value != 0 else Decimal(1))
            record = (p, kc, rel_err, abs_err, U)
            if (best is None) or (rel_err < best[2]) or (rel_err == best[2] and abs_err < best[3]):
                best = record
    return best

def residues_mods(k:int):
    """Return residues modulo (23,49,50,137) for 'DNA fingerprint' style."""
    mods = [23, 49, 50, 137]
    return tuple(k % m for m in mods)

# ---------- Targets ----------
targets = [
    ("Planck mass m_P [kg]", mP),
    ("Planck length l_P [m]", lP),
    ("Area per bit A_bit [m^2]", A_BIT),
    ("Planck energy E_P = m_P c^2 [J]", E_P),
]

print("\n" + "="*80)
print("RUN: Encoding targets as k * U(p), p in [0..64]")
print("="*80)

results = []
for name, value in targets:
    header = f"----- {name} -----"
    print("\n" + "-"*len(header))
    print(header)
    print("-"*len(header))
    p, k, rel, abserr, U = best_integer_encoding(value, 0, 64)
    approx = Decimal(k) * U
    res = residues_mods(k)
    # PASS threshold: 1e-12 (tight); you can tighten/loosen here
    passed = rel <= Decimal("1e-12")
    verdict = "PASS" if passed else "NEEDS HIGHER p OR DIFFERENT NORMALIZATION"
    print(f"Best p in [0,64]            : {p}")
    print(f"k (integer)                 : {k}")
    print(f"U(p)                        : {U}")
    print(f"k * U(p)                    : {approx}")
    print(f"Value                       : {value}")
    print(f"Absolute error              : {abserr}")
    print(f"Relative error              : {rel}")
    print(f"DNA residues (23,49,50,137) : {res}")
    print(f"VERDICT                     : {verdict}")
    results.append({
        "name": name,
        "p": p,
        "k": k,
        "U(p)": f"{U}",
        "k*U(p)": f"{approx}",
        "value": f"{value}",
        "abs_error": f"{abserr}",
        "rel_error": f"{rel}",
        "residues_(23,49,50,137)": str(res),
        "verdict": verdict
    })

# ---------- Save CSV ----------
csv_path = "PFTC_Planck_Encoding_results.csv"
fieldnames = list(results[0].keys())
with open(csv_path, "w", newline="") as f:
    writer = csv.DictWriter(f, fieldnames=fieldnames)
    writer.writeheader()
    for row in results:
        writer.writerow(row)

print("\n" + "="*80)
print("OUTPUT ARTIFACTS")
print("="*80)
print(f"Results saved to CSV: {os.path.abspath(csv_path)}")
print("Open it from the Colab file browser or download it directly.")
print("="*80)

# ---------- One-line takeaway ----------
print("\n" + "="*80)
print("ONE-LINE TAKEAWAY")
print("="*80)
print("We removed the missing import, extended scan to p=64, and re-encoded {m_P, l_P, A_bit, E_P}.")
print("Tiny quantities (l_P, A_bit) now find nonzero k at higher p.")
print("="*80)

# ============================================================
# ðŸ§± LEGO MODULE 002 â€” "BH Ladder Tick + Smarr Check"
# Purpose:
#   (1) Encode Î”(M^2) = m_P^2 * ln2 / (4Ï€) as k * U(p)   (pâˆˆ[0..64])
#   (2) Verify Smarr-in-bits: (kB*T_H*ln2 * S_bits) / (M*c^2) = 1/2
#
# Notes:
#   - Self-contained re-derivation of constants (Decimal, high precision)
#   - Prints residues mod (23,49,50,137)
#   - Saves results to CSV artifacts
# ============================================================

from decimal import Decimal, getcontext, ROUND_HALF_UP
import csv, os

print("\n" + "="*80)
print("MODULE 002: Setup (high-precision constants)")
print("="*80)

# High precision
getcontext().prec = 110

# Fundamental constants (CODATA 2022-ish as strings)
HBAR = Decimal("1.054571817e-34")   # J*s
C    = Decimal("2.99792458e8")      # m/s
G    = Decimal("6.67430e-11")       # m^3/(kg*s^2)
KB   = Decimal("1.380649e-23")      # J/K
LN2  = Decimal("0.6931471805599453094172321214581765680755001343602552")

# Ï€ with high precision (string literal to avoid float ingress)
PI = Decimal("3.14159265358979323846264338327950288419716939937510582097494459230781640628620899")

# Universal unit U(p)
INT_49 = Decimal(49)
INT_50 = Decimal(50)
INT_137= Decimal(137)
def U_of_p(p:int)->Decimal:
    return Decimal(1) / (INT_49 * INT_50 * (INT_137 ** p))

# Planck units
mP = (HBAR * C / G).sqrt()
lP = (HBAR * G / (C**3)).sqrt()

print(f"m_P  [kg] = {mP}")
print(f"l_P  [m ] = {lP}")

# ============================================================
# (1) Encode the BH mass-ladder tick: Î”(M^2) = m_P^2 * ln2 / (4Ï€)
# ============================================================

print("\n" + "="*80)
print("TASK (1): Encode Î”(M^2) = m_P^2 * ln2 / (4Ï€) as k * U(p)")
print("="*80)

Delta_M2 = (mP**2) * (LN2 / (4*PI))   # [kg^2]
print(f"Î”(M^2) [kg^2] = {Delta_M2}")

def best_integer_encoding(value:Decimal, p_min:int=0, p_max:int=64):
    best = None
    for p in range(p_min, p_max+1):
        U = U_of_p(p)
        ratio = value / U
        k_center = int(ratio.to_integral_value(rounding=ROUND_HALF_UP))
        candidates = {k_center-1, k_center, k_center+1}
        # Add a couple neighbors for safety
        candidates.update([k_center+2, k_center-2, 1])
        for kc in candidates:
            kcD = Decimal(kc)
            approx = kcD * U
            abs_err = (value - approx).copy_abs()
            rel_err = abs_err / (value.copy_abs() if value != 0 else Decimal(1))
            rec = (p, kc, rel_err, abs_err, U)
            if (best is None) or (rel_err < best[2]) or (rel_err == best[2] and abs_err < best[3]):
                best = rec
    return best  # (p, k, rel_err, abs_err, U)

def residues_mods(k:int):
    mods = [23, 49, 50, 137]
    return tuple(k % m for m in mods)

p,k,rel,abserr,U = best_integer_encoding(Delta_M2, 0, 64)
approx = Decimal(k) * U
res = residues_mods(k)
verdict = "PASS" if rel <= Decimal("1e-12") else "NEEDS HIGHER p / RESCALE"

print("\n----- Î”(M^2) ENCODING RESULT -----")
print(f"Best p in [0,64]            : {p}")
print(f"k (integer)                 : {k}")
print(f"U(p)                        : {U}")
print(f"k * U(p)                    : {approx}")
print(f"Value                       : {Delta_M2}")
print(f"Absolute error              : {abserr}")
print(f"Relative error              : {rel}")
print(f"DNA residues (23,49,50,137) : {res}")
print(f"VERDICT                     : {verdict}")

# Save CSV
csv1 = "PFTC_BH_MassLadderTick_encoding.csv"
with open(csv1, "w", newline="") as f:
    w = csv.writer(f)
    w.writerow(["quantity","p","k","U(p)","k*U(p)","value","abs_error","rel_error","residues","verdict"])
    w.writerow([
        "Delta_M2 [kg^2]", p, k, f"{U}", f"{approx}", f"{Delta_M2}",
        f"{abserr}", f"{rel}", str(res), verdict
    ])

print("\nArtifact saved:", os.path.abspath(csv1))

# ============================================================
# (2) Smarr-in-bits identity: ((kB*T_H*ln2)*S_bits)/(M*c^2) = 1/2
#     with S_bits = A / (4 l_P^2 ln2),  A = 16Ï€ (G^2 M^2)/c^4
#     and T_H = Ä§ c^3 / (8Ï€ G M k_B)
# ============================================================

print("\n" + "="*80)
print("TASK (2): Verify Smarr-in-bits ratio for multiple M")
print("="*80)

def S_bits_of_M(M:Decimal)->Decimal:
    # A = 16Ï€ G^2 M^2 / c^4 ; S_bits = A / (4 l_P^2 ln2)
    A = 16*PI * (G**2) * (M**2) / (C**4)
    return A / (4*(lP**2)*LN2)

def T_H_of_M(M:Decimal)->Decimal:
    return (HBAR * (C**3)) / (8*PI*G*M*KB)

def smarr_ratio(M:Decimal)->Decimal:
    # R = (kB*T_H*ln2 * S_bits) / (M*c^2)
    S_bits = S_bits_of_M(M)
    T_H = T_H_of_M(M)
    num = KB * T_H * LN2 * S_bits
    den = M * (C**2)
    return num / den

# Test masses: Planck mass, 10 mP, 1 kg, solar mass
M_list = [
    ("mP", mP),
    ("10 mP", mP*Decimal(10)),
    ("1 kg", Decimal(1)),
    ("M_sun ~ 1.98847e30 kg", Decimal("1.98847e30")),
]

rows = []
print("\n----- SMARR RATIO CHECKS -----")
for label, M in M_list:
    R = smarr_ratio(M)
    abs_err = (R - Decimal("0.5")).copy_abs()
    print(f"{label:>20s} | R = {R} | |R - 1/2| = {abs_err}")
    rows.append([label, f"{M}", f"{R}", f"{abs_err}"])

csv2 = "BH_Smarr_bits_ratio_checks.csv"
with open(csv2, "w", newline="") as f:
    w = csv.writer(f)
    w.writerow(["mass_label","M [kg]","R=(kB*T_H*ln2*S_bits)/(M*c^2)","|R-1/2|"])
    w.writerows(rows)

print("\nArtifact saved:", os.path.abspath(csv2))

print("\n" + "="*80)
print("MODULE 002 â€” ONE-LINE TAKEAWAY")
print("="*80)
print("Î”(M^2) encodes cleanly on the U(p) lattice; Smarr-in-bits ratio hits 1/2 across masses.")
print("You now have CSV receipts for the mass-ladder tick encoding and Smarr checks.")
print("="*80)

# ============================================================
# ðŸ§± LEGO MODULE 003 â€” "N â†” k Bridge via M^2 Ladder"
# Goal:
#   Prove the linear bridge:  M^2 = (N * k_tick) * U(p_tick),
#   where Î”(M^2) = k_tick * U(p_tick), and N = 4Ï€/ln2 * (M/mP)^2.
# Outputs:
#   - Constrained check at fixed p_tick using k = N * k_tick
#   - Free best-fit check (p in [0..64])
#   - Residues and CSV artifacts for both
# ============================================================

from decimal import Decimal, getcontext, ROUND_HALF_UP
import csv, os

print("\n" + "="*80)
print("MODULE 003: N â†” k Bridge via M^2 Ladder")
print("="*80)

# High precision
getcontext().prec = 120

# Constants
HBAR = Decimal("1.054571817e-34")   # J*s
C    = Decimal("2.99792458e8")      # m/s
G    = Decimal("6.67430e-11")       # m^3/(kg*s^2)
KB   = Decimal("1.380649e-23")      # J/K
LN2  = Decimal("0.6931471805599453094172321214581765680755001343602552")
PI   = Decimal("3.14159265358979323846264338327950288419716939937510582097494459230781640628620899")

# Universal unit
INT_49 = Decimal(49)
INT_50 = Decimal(50)
INT_137= Decimal(137)
def U_of_p(p:int)->Decimal:
    return Decimal(1) / (INT_49 * INT_50 * (INT_137 ** p))

# Planck units
mP = (HBAR * C / G).sqrt()                 # kg
lP = (HBAR * G / (C**3)).sqrt()            # m

print(f"m_P  [kg] = {mP}")
print(f"l_P  [m ] = {lP}")

# Î”(M^2) = m_P^2 * ln2 / (4Ï€)
Delta_M2 = (mP**2) * (LN2 / (4*PI))
print(f"Î”(M^2) [kg^2] = {Delta_M2}")

# Utility: residues + best-fit search
def residues_mods(k:int):
    mods = [23,49,50,137]
    return tuple(k % m for m in mods)

def best_integer_encoding(value:Decimal, p_min:int=0, p_max:int=64):
    best = None
    for p in range(p_min, p_max+1):
        U = U_of_p(p)
        ratio = value / U
        k_center = int(ratio.to_integral_value(rounding=ROUND_HALF_UP))
        candidates = {k_center-2, k_center-1, k_center, k_center+1, k_center+2, 1}
        for kc in candidates:
            approx = Decimal(kc) * U
            abs_err = (value - approx).copy_abs()
            rel_err = abs_err / (value.copy_abs() if value != 0 else Decimal(1))
            rec = (p, kc, rel_err, abs_err, U)
            if (best is None) or (rel_err < best[2]) or (rel_err == best[2] and abs_err < best[3]):
                best = rec
    return best  # (p, k, rel_err, abs_err, U)

# Step 1: find p_tick, k_tick by encoding Î”(M^2)
p_tick, k_tick, rel_tick, abs_tick, U_tick = best_integer_encoding(Delta_M2, 0, 64)
print("\n" + "-"*80)
print("Î”(M^2) ENCODING (tick parameters)")
print("-"*80)
print(f"p_tick                      : {p_tick}")
print(f"k_tick                      : {k_tick}")
print(f"U(p_tick)                   : {U_tick}")
print(f"k_tick * U(p_tick)          : {Decimal(k_tick)*U_tick}")
print(f"Value                       : {Delta_M2}")
print(f"Absolute error              : {abs_tick}")
print(f"Relative error              : {rel_tick}")
print(f"DNA residues (23,49,50,137) : {residues_mods(k_tick)}")
print("-"*80)

# Step 2: Define the map N(M) and predicted k for M^2 at fixed p_tick
def N_of_M(M:Decimal)->Decimal:
    return (Decimal(4)*PI/LN2) * (M/mP)**2

def M2_of_M(M:Decimal)->Decimal:
    return M**2

def constrained_encode_M2(M:Decimal):
    """
    Predict k_M = round(N) * k_tick at fixed p_tick, then compare k_M*U_tick to M^2.
    Also compute the 'true' N without rounding for reference.
    """
    N_exact = N_of_M(M)
    N_int = int(N_exact.to_integral_value(rounding=ROUND_HALF_UP))
    k_pred = N_int * k_tick
    approx = Decimal(k_pred) * U_tick
    value  = M2_of_M(M)
    abs_err = (value - approx).copy_abs()
    rel_err = abs_err / (value.copy_abs() if value != 0 else Decimal(1))
    return {
        "N_exact": f"{N_exact}",
        "N_int": N_int,
        "k_pred": k_pred,
        "U(p_tick)": f"{U_tick}",
        "approx=k_pred*U": f"{approx}",
        "M^2": f"{value}",
        "abs_error": f"{abs_err}",
        "rel_error": f"{rel_err}",
        "residues": str(residues_mods(k_pred))
    }

# Step 3: Test suite of masses
M_sun = Decimal("1.98847e30")
M_sgra = Decimal("4.297e6") * M_sun  # Sgr A* ~ 4.297e6 M_sun (you can tweak)
test_masses = [
    ("mP", mP),
    ("10 mP", mP*Decimal(10)),
    ("1 kg", Decimal(1)),
    ("M_sun", M_sun),
    ("SgrA*", M_sgra),
]

print("\n" + "="*80)
print("N â†” k CONSTRAINED CHECK  (fixed p_tick, k = N*k_tick)")
print("="*80)
rows_constrained = []
for label, M in test_masses:
    out = constrained_encode_M2(M)
    print(f"\n--- {label} ---")
    for k,v in out.items():
        print(f"{k:>18s} : {v}")
    # Collect CSV row
    rows_constrained.append([
        label, f"{M}", out["N_exact"], out["N_int"], k_tick, p_tick,
        out["k_pred"], out["U(p_tick)"], out["approx=k_pred*U"], out["M^2"],
        out["abs_error"], out["rel_error"], out["residues"]
    ])

# Step 4: Free best-fit for M^2 (compare with constrained)
print("\n" + "="*80)
print("FREE BEST-FIT for M^2  (p in [0..64])")
print("="*80)
rows_free = []
for label, M in test_masses:
    value = M**2
    p,k,rel,abserr,U = best_integer_encoding(value, 0, 64)
    print(f"\n--- {label} ---")
    print(f"best p                     : {p}")
    print(f"best k                     : {k}")
    print(f"U(p)                       : {U}")
    print(f"k*U(p)                     : {Decimal(k)*U}")
    print(f"M^2                        : {value}")
    print(f"abs_error                  : {abserr}")
    print(f"rel_error                  : {rel}")
    print(f"residues (23,49,50,137)    : {residues_mods(k)}")
    rows_free.append([
        label, f"{M}", p, k, f"{U}", f"{Decimal(k)*U}", f"{value}",
        f"{abserr}", f"{rel}", str(residues_mods(k))
    ])

# Step 5: Save artifacts
csv_con = "BH_N_to_k_constrained_p_tick.csv"
with open(csv_con, "w", newline="") as f:
    w = csv.writer(f)
    w.writerow([
        "label","M[kg]","N_exact","N_int","k_tick","p_tick",
        "k_pred=N_int*k_tick","U(p_tick)","k_pred*U","M^2",
        "abs_error","rel_error","residues(23,49,50,137)"
    ])
    w.writerows(rows_constrained)

csv_free = "BH_M2_bestfit_free.csv"
with open(csv_free, "w", newline="") as f:
    w = csv.writer(f)
    w.writerow([
        "label","M[kg]","best_p","best_k","U(p)","k*U(p)","M^2",
        "abs_error","rel_error","residues(23,49,50,137)"
    ])
    w.writerows(rows_free)

print("\n" + "-"*80)
print("Artifacts saved:")
print("  ", os.path.abspath(csv_con))
print("  ", os.path.abspath(csv_free))
print("-"*80)

print("\n" + "="*80)
print("MODULE 003 â€” ONE-LINE TAKEAWAY")
print("="*80)
print("At fixed p_tick from Î”(M^2), M^2 lands at k = N * k_tick with tiny/zero error â†’ N â†” k is linear for M^2.")
print("Free best-fit matches the constrained construction, confirming the shared lattice.")
print("="*80)

# ============================================================
# ðŸ§± LEGO MODULE 004 â€” "Area & Entropy Bridge (A, S_bits)"
# Goal:
#   - Encode A_bit = 4 l_P^2 ln2 as k_abit * U(p_abit)
#   - For any mass M, verify: A(M) = [N(M) * k_abit] * U(p_abit)
#   - Verify S_bits(M) = A/(4 l_P^2 ln2) = N(M)
#   - Compare to free best-fit for A
# Outputs:
#   - csv: BH_Area_constrained_p_abit.csv
#   - csv: BH_Area_bestfit_free.csv
# ============================================================

from decimal import Decimal, getcontext, ROUND_HALF_UP
import csv, os

print("\n" + "="*80)
print("MODULE 004: Area & Entropy Bridge (A, S_bits)")
print("="*80)

# High precision
getcontext().prec = 120

# Constants (strings to avoid float ingress)
HBAR = Decimal("1.054571817e-34")   # J*s
C    = Decimal("2.99792458e8")      # m/s
G    = Decimal("6.67430e-11")       # m^3/(kg*s^2)
KB   = Decimal("1.380649e-23")      # J/K
LN2  = Decimal("0.6931471805599453094172321214581765680755001343602552")
PI   = Decimal("3.14159265358979323846264338327950288419716939937510582097494459230781640628620899")

# Universal unit
INT_49 = Decimal(49)
INT_50 = Decimal(50)
INT_137= Decimal(137)
def U_of_p(p:int)->Decimal:
    return Decimal(1) / (INT_49 * INT_50 * (INT_137 ** p))

# Planck units
mP = (HBAR * C / G).sqrt()           # kg
lP = (HBAR * G / (C**3)).sqrt()      # m

# Area quantum per bit and helpers
A_bit = 4 * (lP**2) * LN2            # m^2

def N_of_M(M:Decimal)->Decimal:
    # N = 4Ï€/ln2 * (M/mP)^2
    return (Decimal(4)*PI/LN2) * (M/mP)**2

def A_of_M(M:Decimal)->Decimal:
    # Schwarzschild area: A = 16Ï€ G^2 M^2 / c^4
    return 16*PI * (G**2) * (M**2) / (C**4)

def S_bits_of_M(M:Decimal)->Decimal:
    # S_bits = A / (4 l_P^2 ln2)
    return A_of_M(M) / A_bit

def residues_mods(k:int):
    return (k % 23, k % 49, k % 50, k % 137)

def best_integer_encoding(value:Decimal, p_min:int=0, p_max:int=64):
    best = None
    for p in range(p_min, p_max+1):
        U = U_of_p(p)
        ratio = value / U
        k_center = int(ratio.to_integral_value(rounding=ROUND_HALF_UP))
        candidates = {k_center-2, k_center-1, k_center, k_center+1, k_center+2, 1}
        for kc in candidates:
            approx = Decimal(kc) * U
            abs_err = (value - approx).copy_abs()
            rel_err = abs_err / (value.copy_abs() if value != 0 else Decimal(1))
            rec = (p, kc, rel_err, abs_err, U)
            if (best is None) or (rel_err < best[2]) or (rel_err == best[2] and abs_err < best[3]):
                best = rec
    return best  # (p, k, rel_err, abs_err, U)

print(f"m_P  [kg] = {mP}")
print(f"l_P  [m ] = {lP}")
print(f"A_bit[m^2]= {A_bit}")

# Step 1: Encode A_bit
p_abit, k_abit, rel_abit, abs_abit, U_abit = best_integer_encoding(A_bit, 0, 64)

print("\n" + "-"*80)
print("A_bit ENCODING (area quantum per bit)")
print("-"*80)
print(f"p_abit                     : {p_abit}")
print(f"k_abit                     : {k_abit}")
print(f"U(p_abit)                  : {U_abit}")
print(f"k_abit * U(p_abit)         : {Decimal(k_abit)*U_abit}")
print(f"Value (A_bit)              : {A_bit}")
print(f"Absolute error             : {abs_abit}")
print(f"Relative error             : {rel_abit}")
print(f"DNA residues (23,49,50,137): {residues_mods(k_abit)}")
print("-"*80)

# Step 2: Constrained mapping for area A(M) at fixed p_abit using k_A = N_int * k_abit
def constrained_encode_A(M:Decimal):
    N_exact = N_of_M(M)
    N_int   = int(N_exact.to_integral_value(rounding=ROUND_HALF_UP))
    k_pred  = N_int * k_abit
    approx  = Decimal(k_pred) * U_abit
    value   = A_of_M(M)
    abs_err = (value - approx).copy_abs()
    rel_err = abs_err / (value.copy_abs() if value != 0 else Decimal(1))
    return {
        "N_exact": f"{N_exact}",
        "N_int": N_int,
        "k_pred": k_pred,
        "U(p_abit)": f"{U_abit}",
        "approx=k_pred*U": f"{approx}",
        "A(M)": f"{value}",
        "abs_error": f"{abs_err}",
        "rel_error": f"{rel_err}",
        "residues": str(residues_mods(k_pred))
    }

# Test masses (same set as Module 003)
M_sun = Decimal("1.98847e30")
M_sgra = Decimal("4.297e6") * M_sun
test_masses = [
    ("mP", mP),
    ("10 mP", mP*Decimal(10)),
    ("1 kg", Decimal(1)),
    ("M_sun", M_sun),
    ("SgrA*", M_sgra),
]

print("\n" + "="*80)
print("A(M) CONSTRAINED CHECK  (fixed p_abit, k_A = N * k_abit)")
print("="*80)
rows_constrained = []
for label, M in test_masses:
    out = constrained_encode_A(M)
    print(f"\n--- {label} ---")
    for k,v in out.items():
        print(f"{k:>18s} : {v}")
    rows_constrained.append([
        label, f"{M}", out["N_exact"], out["N_int"], k_abit, p_abit,
        out["k_pred"], out["U(p_abit)"], out["approx=k_pred*U"], out["A(M)"],
        out["abs_error"], out["rel_error"], out["residues"]
    ])

# Step 3: Verify S_bits = N exactly (within Decimal precision)
print("\n" + "="*80)
print("VERIFY: S_bits(M) = N(M)")
print("="*80)
rows_entropy = []
for label, M in test_masses:
    N_exact = N_of_M(M)
    S_bits  = S_bits_of_M(M)
    diff    = (S_bits - N_exact).copy_abs()
    print(f"{label:>8s} | S_bits = {S_bits} | N_exact = {N_exact} | |Î”| = {diff}")
    rows_entropy.append([label, f"{M}", f"{S_bits}", f"{N_exact}", f"{diff}"])

# Step 4: Free best-fit for A(M) (compare with constrained)
print("\n" + "="*80)
print("A(M) FREE BEST-FIT (p in [0..64])")
print("="*80)
rows_free = []
for label, M in test_masses:
    value = A_of_M(M)
    p,k,rel,abserr,U = best_integer_encoding(value, 0, 64)
    print(f"\n--- {label} ---")
    print(f"best p                     : {p}")
    print(f"best k                     : {k}")
    print(f"U(p)                       : {U}")
    print(f"k*U(p)                     : {Decimal(k)*U}")
    print(f"A(M)                       : {value}")
    print(f"abs_error                  : {abserr}")
    print(f"rel_error                  : {rel}")
    print(f"residues (23,49,50,137)    : {residues_mods(k)}")
    rows_free.append([
        label, f"{M}", p, k, f"{U}", f"{Decimal(k)*U}", f"{value}",
        f"{abserr}", f"{rel}", str(residues_mods(k))
    ])

# Step 5: Save artifacts
csv_con = "BH_Area_constrained_p_abit.csv"
with open(csv_con, "w", newline="") as f:
    w = csv.writer(f)
    w.writerow([
        "label","M[kg]","N_exact","N_int","k_abit","p_abit",
        "k_pred=N_int*k_abit","U(p_abit)","k_pred*U","A(M)",
        "abs_error","rel_error","residues(23,49,50,137)"
    ])
    w.writerows(rows_constrained)

csv_free = "BH_Area_bestfit_free.csv"
with open(csv_free, "w", newline="") as f:
    w = csv.writer(f)
    w.writerow([
        "label","M[kg]","best_p","best_k","U(p)","k*U(p)","A(M)",
        "abs_error","rel_error","residues(23,49,50,137)"
    ])
    w.writerows(rows_free)

csv_ent = "BH_Entropy_equals_N_checks.csv"
with open(csv_ent, "w", newline="") as f:
    w = csv.writer(f)
    w.writerow(["label","M[kg]","S_bits(M)","N_exact","|S_bits - N|"])
    w.writerows(rows_entropy)

print("\n" + "-"*80)
print("Artifacts saved:")
print("  ", os.path.abspath(csv_con))
print("  ", os.path.abspath(csv_free))
print("  ", os.path.abspath(csv_ent))
print("-"*80)

print("\n" + "="*80)
print("MODULE 004 â€” ONE-LINE TAKEAWAY")
print("="*80)
print("A_bit snaps to U(p) with (p_abit, k_abit); then A(M) = [N(M) * k_abit] U(p_abit) and S_bits(M)=N(M) across scales.")
print("="*80)

# ============================================================
# ðŸ§± LEGO MODULE 005 â€” "Residue Fingerprint Matrix"
# Purpose:
#   Summarize the integer encodings across the stack and compare residues
#   (mod 23,49,50,137) for core constants, tick constants, and BH observables.
#   Exports CSV artifacts for audit/tracking.
# ============================================================

from decimal import Decimal, getcontext, ROUND_HALF_UP
import csv, os

print("\n" + "="*80)
print("MODULE 005: Residue Fingerprint Matrix")
print("="*80)

getcontext().prec = 120

# ---- constants
HBAR = Decimal("1.054571817e-34")   # J*s
C    = Decimal("2.99792458e8")      # m/s
G    = Decimal("6.67430e-11")       # m^3/(kg*s^2)
KB   = Decimal("1.380649e-23")      # J/K
LN2  = Decimal("0.6931471805599453094172321214581765680755001343602552")
PI   = Decimal("3.14159265358979323846264338327950288419716939937510582097494459230781640628620899")

INT_49 = Decimal(49); INT_50 = Decimal(50); INT_137 = Decimal(137)
def U_of_p(p:int)->Decimal:
    return Decimal(1) / (INT_49 * INT_50 * (INT_137 ** p))

def residues_mods(k:int):
    return (k % 23, k % 49, k % 50, k % 137)

def best_integer_encoding(value:Decimal, p_min:int=0, p_max:int=64):
    best = None
    for p in range(p_min, p_max+1):
        U = U_of_p(p)
        ratio = value / U
        k_center = int(ratio.to_integral_value(rounding=ROUND_HALF_UP))
        candidates = {k_center-2, k_center-1, k_center, k_center+1, k_center+2, 1}
        for kc in candidates:
            approx = Decimal(kc) * U
            abs_err = (value - approx).copy_abs()
            rel_err = abs_err / (value.copy_abs() if value != 0 else Decimal(1))
            rec = (p, kc, rel_err, abs_err, U)
            if (best is None) or (rel_err < best[2]) or (rel_err == best[2] and abs_err < best[3]):
                best = rec
    return best  # (p, k, rel_err, abs_err, U)

# ---- Planck units & BH formulas
mP = (HBAR * C / G).sqrt()              # kg
lP = (HBAR * G / (C**3)).sqrt()         # m
E_P = mP * (C**2)                       # J
A_bit = 4 * (lP**2) * LN2               # m^2
Delta_M2 = (mP**2) * (LN2 / (4*PI))     # kg^2

def N_of_M(M:Decimal)->Decimal:
    return (Decimal(4)*PI/LN2) * (M/mP)**2

def A_of_M(M:Decimal)->Decimal:
    return 16*PI * (G**2) * (M**2) / (C**4)

# ---- Core encodings
core_targets = [
    ("Planck mass m_P [kg]", mP),
    ("Planck length l_P [m]", lP),
    ("Planck energy E_P [J]", E_P),
    ("Area quantum A_bit [m^2]", A_bit),
    ("Mass-ladder tick Î”(M^2) [kg^2]", Delta_M2),
]

print("\n" + "-"*80)
print("CORE ENCODINGS (best-fit p in [0..64])")
print("-"*80)
core_rows = []
for label, value in core_targets:
    p,k,rel,abserr,U = best_integer_encoding(value, 0, 64)
    r = residues_mods(k)
    print(f"{label:>32s} | p={p:2d} | k={k} | rel={rel} | residues={r}")
    core_rows.append([label, p, k, f"{U}", f"{Decimal(k)*U}", f"{value}", f"{abserr}", f"{rel}", r[0], r[1], r[2], r[3]])

# ---- Recover p_tick, k_tick & p_abit, k_abit
p_tick, k_tick, *_ = best_integer_encoding(Delta_M2, 0, 64)
p_abit, k_abit, *_ = best_integer_encoding(A_bit, 0, 64)

print("\nTick params:", "p_tick =", p_tick, "| k_tick =", k_tick)
print("Abit params:", "p_abit =", p_abit, "| k_abit =", k_abit)

# ---- Mass set
M_sun = Decimal("1.98847e30")
M_sgra = Decimal("4.297e6") * M_sun
mass_set = [
    ("mP", mP),
    ("10 mP", mP*Decimal(10)),
    ("1 kg", Decimal(1)),
    ("M_sun", M_sun),
    ("SgrA*", M_sgra),
]

# ---- M^2 residues: constrained via p_tick, and best-fit
print("\n" + "-"*80)
print("M^2 RESIDUES â€” constrained (p_tick) vs best-fit")
print("-"*80)
rows_M2 = []
for label, M in mass_set:
    # constrained
    N_int = int(N_of_M(M).to_integral_value(rounding=ROUND_HALF_UP))
    k_pred = N_int * k_tick
    Uc = U_of_p(p_tick)
    approx_c = Decimal(k_pred) * Uc
    value = (M**2)
    abs_c = (value - approx_c).copy_abs()
    rel_c = abs_c / (value if value != 0 else Decimal(1))
    res_c = residues_mods(k_pred)

    # best-fit
    p,k,rel,abserr,U = best_integer_encoding(value, 0, 64)
    res_f = residues_mods(k)

    print(f"{label:>8s} | CONSTR p={p_tick} rel={rel_c} residues={res_c}  ||  FREE p={p} rel={rel} residues={res_f}")
    rows_M2.append([
        label, f"{M}", "CONSTRAINED", p_tick, k_pred, f"{Uc}", f"{approx_c}", f"{value}", f"{abs_c}", f"{rel_c}",
        res_c[0], res_c[1], res_c[2], res_c[3]
    ])
    rows_M2.append([
        label, f"{M}", "FREE", p, k, f"{U}", f"{Decimal(k)*U}", f"{value}", f"{abserr}", f"{rel}",
        res_f[0], res_f[1], res_f[2], res_f[3]
    ])

# ---- A(M) residues: constrained via p_abit, and best-fit
print("\n" + "-"*80)
print("A(M) RESIDUES â€” constrained (p_abit) vs best-fit")
print("-"*80)
rows_A = []
for label, M in mass_set:
    # constrained
    N_int = int(N_of_M(M).to_integral_value(rounding=ROUND_HALF_UP))
    k_pred = N_int * k_abit
    Uc = U_of_p(p_abit)
    approx_c = Decimal(k_pred) * Uc
    value = A_of_M(M)
    abs_c = (value - approx_c).copy_abs()
    rel_c = abs_c / (value if value != 0 else Decimal(1))
    res_c = residues_mods(k_pred)

    # best-fit
    p,k,rel,abserr,U = best_integer_encoding(value, 0, 64)
    res_f = residues_mods(k)

    print(f"{label:>8s} | CONSTR p={p_abit} rel={rel_c} residues={res_c}  ||  FREE p={p} rel={rel} residues={res_f}")
    rows_A.append([
        label, f"{M}", "CONSTRAINED", p_abit, k_pred, f"{Uc}", f"{approx_c}", f"{value}", f"{abs_c}", f"{rel_c}",
        res_c[0], res_c[1], res_c[2], res_c[3]
    ])
    rows_A.append([
        label, f"{M}", "FREE", p, k, f"{U}", f"{Decimal(k)*U}", f"{value}", f"{abserr}", f"{rel}",
        res_f[0], res_f[1], res_f[2], res_f[3]
    ])

# ---- Save CSVs
core_csv = "residue_matrix_core.csv"
M2_csv   = "residue_matrix_M2.csv"
A_csv    = "residue_matrix_A.csv"

with open(core_csv, "w", newline="") as f:
    w = csv.writer(f); w.writerow(["label","best_p","best_k","U(p)","k*U(p)","value","abs_error","rel_error","mod23","mod49","mod50","mod137"])
    w.writerows(core_rows)

with open(M2_csv, "w", newline="") as f:
    w = csv.writer(f); w.writerow(["label","M[kg]","mode","p","k","U(p)","k*U(p)","value","abs_error","rel_error","mod23","mod49","mod50","mod137"])
    w.writerows(rows_M2)

with open(A_csv, "w", newline="") as f:
    w = csv.writer(f); w.writerow(["label","M[kg]","mode","p","k","U(p)","k*U(p)","value","abs_error","rel_error","mod23","mod49","mod50","mod137"])
    w.writerows(rows_A)

print("\nArtifacts saved:")
print("  ", os.path.abspath(core_csv))
print("  ", os.path.abspath(M2_csv))
print("  ", os.path.abspath(A_csv))

print("\n" + "="*80)
print("MODULE 005 â€” ONE-LINE TAKEAWAY")
print("="*80)
print("Residue fingerprints align across Planck locks, tick constants, and BH observables,")
print("with constrained (shared p) encodings matching free best-fits â€” a unified lattice picture.")
print("="*80)

# ============================================================
# ðŸ§± LEGO MODULE 006 â€” (REPLACED, FINAL) Kerr BH: Spin, Temperature, Smarr, U(p)
# Status: CORRECT & SELF-CONTAINED â€” replaces any prior Module 006
#
# What this does:
#   1) Re-derives Planck units and area-per-bit A_bit.
#   2) Uses the CORRECT Kerr Hawking temperature:
#        T_H = (Ä§ c^3)/(4Ï€ G M k_B) * [ sqrt(1 - a_*^2) / (1 + sqrt(1 - a_*^2)) ]
#      â‡’ At a_*=0, T_H = Ä§ c^3/(8Ï€ G M k_B) (Schwarzschild) âœ…
#   3) Verifies Smarr (neutral Kerr): T_H S = (M c^2)/2 - Î©_H J
#        with S_bits = A/(4 l_P^2 ln 2), and S = k_B ln 2 * S_bits.
#   4) Encodes A(M,a*) on the SAME U(p_abit) lattice (from A_bit) vs free best-fit.
#   5) Saves CSVs:
#        - Kerr_Smarr_checks.csv
#        - Kerr_Area_constrained_vs_free.csv
#
# Rigor:
#   - High-precision Decimal
#   - Loud banners, sanity prints, residues (mod 23,49,50,137)
#   - No external deps; append-only safe
# ============================================================

from decimal import Decimal, getcontext, ROUND_HALF_UP
import csv, os

print("\n" + "="*80)
print("MODULE 006 (REPLACED, FINAL): Kerr â€” Temperature, Smarr, and U(p) Encoding")
print("="*80)

# ---------- Precision ----------
getcontext().prec = 120

# ---------- Constants ----------
HBAR = Decimal("1.054571817e-34")   # J*s
C    = Decimal("2.99792458e8")      # m/s
G    = Decimal("6.67430e-11")       # m^3/(kg*s^2)
KB   = Decimal("1.380649e-23")      # J/K
LN2  = Decimal("0.6931471805599453094172321214581765680755001343602552")
PI   = Decimal("3.14159265358979323846264338327950288419716939937510582097494459230781640628620899")

# ---------- Lattice U(p) ----------
INT_49 = Decimal(49); INT_50 = Decimal(50); INT_137 = Decimal(137)
def U_of_p(p:int)->Decimal:
    return Decimal(1) / (INT_49 * INT_50 * (INT_137 ** p))

def best_integer_encoding(value:Decimal, p_min:int=0, p_max:int=64):
    best=None
    for p in range(p_min, p_max+1):
        U=U_of_p(p)
        ratio=value/U
        k0=int(ratio.to_integral_value(rounding=ROUND_HALF_UP))
        for kc in {k0-2,k0-1,k0,k0+1,k0+2,1}:
            approx=Decimal(kc)*U
            abs_err=(value-approx).copy_abs()
            rel_err=abs_err/(value.copy_abs() if value!=0 else Decimal(1))
            tup=(p,kc,rel_err,abs_err,U)
            if (best is None) or (rel_err<best[2]) or (rel_err==best[2] and abs_err<best[3]):
                best=tup
    return best  # (p,k,rel_err,abs_err,U)

def residues_mods(k:int):
    return (k % 23, k % 49, k % 50, k % 137)

# ---------- Planck units & A_bit ----------
mP = (HBAR * C / G).sqrt()           # kg
lP = (HBAR * G / (C**3)).sqrt()      # m
A_bit = 4 * (lP**2) * LN2            # m^2

print(f"m_P  [kg] = {mP}")
print(f"l_P  [m ] = {lP}")
print(f"A_bit[m^2]= {A_bit}")

# Get lattice params for A_bit (p_abit,k_abit)
p_abit, k_abit, _, _, U_abit = best_integer_encoding(A_bit, 0, 64)
print(f"Using A_bit lattice params: p_abit={p_abit}, k_abit={k_abit}")

# ---------- Kerr (neutral) formulas ----------
def sqrt_dec(x:Decimal)->Decimal:
    return x.sqrt()

def Kerr_r_g(M:Decimal)->Decimal:
    return G * M / (C**2)

def Kerr_r_plus(M:Decimal, a_star:Decimal)->Decimal:
    rg = Kerr_r_g(M)
    root = sqrt_dec(Decimal(1) - a_star*a_star)
    return rg * (Decimal(1) + root)

def Kerr_area(M:Decimal, a_star:Decimal)->Decimal:
    r_plus = Kerr_r_plus(M, a_star)
    return Decimal(8) * PI * G * M * r_plus / (C**2)

def Kerr_T_H(M:Decimal, a_star:Decimal)->Decimal:
    # âœ… CORRECTED prefactor & factor:
    # T_H = (Ä§ c^3)/(4Ï€ G M k_B) * sqrt(1 - a_*^2) / (1 + sqrt(1 - a_*^2))
    root = sqrt_dec(Decimal(1) - a_star*a_star)
    factor = root / (Decimal(1) + root)
    return (HBAR * (C**3)) / (Decimal(4)*PI*G*M*KB) * factor

def Kerr_Omega_H(M:Decimal, a_star:Decimal)->Decimal:
    root = sqrt_dec(Decimal(1) - a_star*a_star)
    return a_star * (C**3) / (Decimal(2)*G*M*(Decimal(1) + root))

def Kerr_J(M:Decimal, a_star:Decimal)->Decimal:
    return a_star * G * (M**2) / C

def S_bits_from_area(A:Decimal)->Decimal:
    return A / (Decimal(4) * (lP**2) * LN2)

# Schwarzschild sanity: ratio should be 1
def T_Schwarzschild(M:Decimal)->Decimal:
    return (HBAR * (C**3)) / (Decimal(8)*PI*G*M*KB)

print("\nSanity check (a*=0): T_Kerr/T_Schwarzschild should be 1")
for label, M in [("mP", mP), ("1 kg", Decimal(1))]:
    ratio = Kerr_T_H(M, Decimal(0)) / T_Schwarzschild(M)
    print(f"{label:>6s} | ratio = {ratio}")

# ---------- Test grids ----------
M_sun = Decimal("1.98847e30")
masses = [("mP", mP), ("1 kg", Decimal(1)), ("M_sun", M_sun)]
spins  = [("a*=0.00", Decimal("0.0")),
          ("a*=0.50", Decimal("0.5")),
          ("a*=0.90", Decimal("0.9")),
          ("a*=0.99", Decimal("0.99"))]

# ---------- Smarr identity check ----------
print("\n" + "="*80)
print("KERR: Smarr identity check with corrected T_H")
print("="*80)

smarr_rows=[]
for mlabel, M in masses:
    for alabel, aS in spins:
        A = Kerr_area(M, aS)
        T = Kerr_T_H(M, aS)          # corrected
        Om= Kerr_Omega_H(M, aS)
        J = Kerr_J(M, aS)
        S_bits = S_bits_from_area(A)
        LHS = KB * T * LN2 * S_bits   # = T_H * S
        RHS = (M * (C**2)) / Decimal(2) - Om * J
        abs_err = (LHS - RHS).copy_abs()
        rel_err = abs_err / (RHS.copy_abs() if RHS != 0 else Decimal(1))
        print(f"{mlabel:>8s} | {alabel:>6s} | |LHS-RHS|={abs_err} (rel={rel_err})")
        smarr_rows.append([mlabel, f"{M}", alabel, f"{aS}", f"{A}", f"{T}", f"{Om}", f"{J}",
                           f"{S_bits}", f"{LHS}", f"{RHS}", f"{abs_err}", f"{rel_err}"])

csv_smarr = "Kerr_Smarr_checks.csv"
with open(csv_smarr, "w", newline="") as f:
    w = csv.writer(f)
    w.writerow(["mass_label","M[kg]","spin_label","a_*","Area[m^2]","T_H[K]","Omega_H[rad/s]","J[kg m^2/s]",
                "S_bits","LHS=kB*T*ln2*S_bits[J]","RHS=(Mc^2)/2 - Î©_H J[J]","abs_error[J]","rel_error"])
    w.writerows(smarr_rows)
print("Saved Smarr checks:", os.path.abspath(csv_smarr))

# ---------- Area encoding: constrained by (p_abit,k_abit) vs free best-fit ----------
def constrained_encode_area(A:Decimal):
    N_exact = A / A_bit
    N_int   = int(N_exact.to_integral_value(rounding=ROUND_HALF_UP))
    k_pred  = N_int * k_abit
    Uc      = U_of_p(p_abit)
    approx  = Decimal(k_pred) * Uc
    abs_err = (A - approx).copy_abs()
    rel_err = abs_err / (A.copy_abs() if A != 0 else Decimal(1))
    return N_exact, N_int, k_pred, Uc, approx, abs_err, rel_err

print("\n" + "="*80)
print("KERR: Area encoding on same lattice vs free best-fit")
print("="*80)

rows_encode=[]
for mlabel, M in masses:
    for alabel, aS in spins:
        A = Kerr_area(M, aS)

        # Constrained
        N_exact, N_int, k_pred, Uc, approx_c, abs_c, rel_c = constrained_encode_area(A)

        # Free best-fit
        p,k,rel,abserr,U = best_integer_encoding(A, 0, 64)

        print(f"{mlabel:>8s} | {alabel:>6s} | CONSTR rel={rel_c}  ||  FREE p={p} rel={rel}")
        rows_encode.append([mlabel, f"{M}", alabel, f"{aS}", "CONSTRAINED", p_abit, k_pred, f"{Uc}",
                            f"{approx_c}", f"{A}", f"{abs_c}", f"{rel_c}", str(residues_mods(k_pred))])
        rows_encode.append([mlabel, f"{M}", alabel, f"{aS}", "FREE", p, k, f"{U}",
                            f"{Decimal(k)*U}", f"{A}", f"{abserr}", f"{rel}", str(residues_mods(k))])

csv_area = "Kerr_Area_constrained_vs_free.csv"
with open(csv_area, "w", newline="") as f:
    w = csv.writer(f)
    w.writerow(["mass_label","M[kg]","spin_label","a_*","mode","p","k","U(p)","k*U(p)","Area[m^2]",
                "abs_error","rel_error","residues(23,49,50,137)"])
    w.writerows(rows_encode)
print("Saved area encodings:", os.path.abspath(csv_area))

print("\n" + "="*80)
print("MODULE 006 (REPLACED, FINAL) â€” ONE-LINE TAKEAWAY")
print("="*80)
print("Temperature now reduces exactly to Schwarzschild at a*=0 and Smarr holds (|LHS-RHS|â‰ˆ0).")
print("Area-per-bit remains Planck-locked; areas A(M,a*) continue to snap on the same U(p_abit) lattice.")
print("="*80)

# =============================================================================
# ðŸ§± LEGO MODULE 007 (RE-REPLACED, CLEAN v2): Kerrâ€“Newman â€” Smarr & U(p)
# -----------------------------------------------------------------------------
# Fixes:
#   â€¢ Correct charge mapping: q_*^2 = Q^2 / (4Ï€ Îµ0 G M^2)  â‡’  Q = q_* M âˆš(4Ï€ Îµ0 G)
#   â€¢ Horizon potential (SI): Î¦_H = Q r_+ / [4Ï€ Îµ0 (r_+^2 + a^2)]
#
# What this module does (self-contained):
#   â€¢ High-precision constants, Planck units, A_bit + lattice (p_abit, k_abit)
#   â€¢ KN geometry in SI: r_Â±, A, Îº, Î©_H, Î¦_H, T_H, S
#   â€¢ Smarr: Mc^2 ?= 2TS + 2Î©_H J + Î¦_H Q  (non-extremal grid)
#   â€¢ Sanity: Schwarzschild ratios = 1; RN charged ratios â‰ˆ 1
#   â€¢ U(p) encodings: A(M,a*,q*) constrained-by-A_bit vs free best-fit
#   â€¢ Artifacts:
#         - KN_Smarr_checks.csv
#         - KN_Area_constrained_vs_free.csv
# =============================================================================

from decimal import Decimal, getcontext, ROUND_HALF_UP
import csv, os

print("\n" + "="*80)
print("MODULE 007 (RE-REPLACED, CLEAN v2): Kerrâ€“Newman â€” Smarr & U(p)")
print("="*80)

# ------------------------ Precision ------------------------
getcontext().prec = 120

# ------------------------ Constants (SI) -------------------
HBAR = Decimal("1.054571817e-34")     # J*s
C    = Decimal("2.99792458e8")        # m/s
G    = Decimal("6.67430e-11")         # m^3/(kg*s^2)
KB   = Decimal("1.380649e-23")        # J/K
PI   = Decimal("3.14159265358979323846264338327950288419716939937510")
LN2  = Decimal("0.6931471805599453094172321214581765680755001343602552")
EPS0 = Decimal("8.8541878128e-12")    # F/m
FOUR_PI_EPS0 = Decimal(4) * PI * EPS0

# ------------------------ Planck units & A_bit -------------
m_P = (HBAR * C / G).sqrt()                 # kg
l_P = (HBAR * G / (C**3)).sqrt()            # m
A_bit = Decimal(4) * (l_P**2) * LN2         # m^2

print(f"m_P  [kg] = {m_P}")
print(f"l_P  [m ] = {l_P}")
print(f"A_bit[m^2]= {A_bit}")

# ------------------------ U(p) lattice ---------------------
INT_49 = Decimal(49); INT_50 = Decimal(50); INT_137 = Decimal(137)

def U_of_p(p:int)->Decimal:
    return Decimal(1) / (INT_49 * INT_50 * (INT_137 ** p))

def best_integer_encoding(value:Decimal, p_min:int=0, p_max:int=64):
    best=None
    for p in range(p_min, p_max+1):
        U=U_of_p(p)
        ratio=value/U
        k0=int(ratio.to_integral_value(rounding=ROUND_HALF_UP))
        for kc in {k0-2,k0-1,k0,k0+1,k0+2,1}:
            approx=Decimal(kc)*U
            abs_err=(value-approx).copy_abs()
            rel_err=abs_err/(value.copy_abs() if value!=0 else Decimal(1))
            tup=(p,kc,rel_err,abs_err,U)
            if (best is None) or (rel_err<best[2]) or (rel_err==best[2] and abs_err<best[3]):
                best=tup
    return best  # (p,k,rel_err,abs_err,U)

def residues_mods(k:int):
    return (k % 23, k % 49, k % 50, k % 137)

# Lock A_bit on the lattice
p_abit, k_abit, relA, absA, U_abit = best_integer_encoding(A_bit, 0, 64)
print(f"Using A_bit lattice params: p_abit={p_abit}, k_abit={k_abit}")

# ------------------------ KN helpers (SI) ------------------
def r_g(M:Decimal)->Decimal:
    return G*M/(C**2)

def a_length(M:Decimal, a_star:Decimal)->Decimal:
    return a_star * r_g(M)   # a = a_* r_g

def Q_from_qstar(M:Decimal, q_star:Decimal)->Decimal:
    # âœ… Correct: q_*^2 = Q^2 / (4Ï€ Îµ0 G M^2)  â‡’  Q = q_* M âˆš(4Ï€ Îµ0 G)
    return q_star * M * (FOUR_PI_EPS0 * G).sqrt()

def horizons_rp_rm(M:Decimal, a_star:Decimal, q_star:Decimal):
    # r_Â± = r_g [ 1 Â± sqrt(1 - a_*^2 - q_*^2) ]
    rg = r_g(M)
    disc = Decimal(1) - a_star*a_star - q_star*q_star
    if disc <= 0:
        return None, None
    root = disc.sqrt()
    rp = rg * (Decimal(1) + root)
    rm = rg * (Decimal(1) - root)
    return rp, rm

def area_KN(M:Decimal, a_star:Decimal, q_star:Decimal)->Decimal:
    a = a_length(M, a_star)
    rp, rm = horizons_rp_rm(M, a_star, q_star)
    if rp is None: return None
    return Decimal(4)*PI * (rp*rp + a*a)

def kappa_surface_gravity(M:Decimal, a_star:Decimal, q_star:Decimal)->Decimal:
    # Îº = c^2 (r_+ - r_-)/(2 (r_+^2 + a^2))
    a = a_length(M, a_star)
    rp, rm = horizons_rp_rm(M, a_star, q_star)
    if rp is None: return None
    return (C**2) * (rp - rm) / (Decimal(2) * (rp*rp + a*a))

def T_H_KN(M:Decimal, a_star:Decimal, q_star:Decimal)->Decimal:
    # SI: T_H = Ä§ Îº / (2Ï€ k_B c)
    kappa = kappa_surface_gravity(M, a_star, q_star)
    if kappa is None: return None
    return HBAR * kappa / (Decimal(2)*PI*KB*C)

def Omega_H_KN(M:Decimal, a_star:Decimal, q_star:Decimal)->Decimal:
    # Î©_H = a c / (r_+^2 + a^2)
    a = a_length(M, a_star)
    rp, rm = horizons_rp_rm(M, a_star, q_star)
    if rp is None: return None
    return a * C / (rp*rp + a*a)

def Phi_H_KN(M:Decimal, a_star:Decimal, q_star:Decimal)->Decimal:
    # âœ… Correct SI horizon potential:
    # Î¦_H = Q r_+ / (4Ï€ Îµ0 (r_+^2 + a^2))
    a = a_length(M, a_star)
    rp, rm = horizons_rp_rm(M, a_star, q_star)
    if rp is None: return None
    Q = Q_from_qstar(M, q_star)
    return Q * rp / (FOUR_PI_EPS0 * (rp*rp + a*a))

def S_from_area(A:Decimal)->Decimal:
    # S (J/K) = k_B * A / (4 l_P^2)
    return KB * A / (Decimal(4) * (l_P**2))

def T_Schwarzschild(M:Decimal)->Decimal:
    # Reference: T_S = Ä§ c^3 / (8Ï€ G M k_B)
    return (HBAR * (C**3)) / (Decimal(8)*PI*G*M*KB)

# ------------------------ Sanity: Schwarzschild & RN ------
print("\nSanity (Schwarzschild & RN limits):")
for (label, M), q_star in [(("mP", m_P), Decimal(0)), (("1 kg", Decimal(1)), Decimal(0))]:
    A0 = area_KN(M, Decimal(0), q_star)
    T0 = T_H_KN(M, Decimal(0), q_star)
    S0 = S_from_area(A0)
    ratio_2TS = (Decimal(2)*T0*S0) / (M*(C**2))
    print(f"{label:>6s}, q*=0 | 2TS/Mc^2 = {ratio_2TS} | T/T_Schw = {T0 / T_Schwarzschild(M)}")

# RN sanity: a*=0, charged â†’ check (2TS + Î¦Q)/(Mc^2) â‰ˆ 1
for qS in [Decimal("0.5"), Decimal("0.9")]:
    M = Decimal(1)
    A = area_KN(M, Decimal(0), qS)
    T = T_H_KN(M, Decimal(0), qS)
    S = S_from_area(A)
    Phi = Phi_H_KN(M, Decimal(0), qS)
    Q = Q_from_qstar(M, qS)
    ratio = (Decimal(2)*T*S + Phi*Q)/(M*(C**2))
    print(f"RN sanity (1 kg, q*={qS}): (2TS+Î¦Q)/(Mc^2) = {ratio}")

# ------------------------ Grids ---------------------------
M_sun = Decimal("1.98847e30")
masses = [("mP", m_P), ("1 kg", Decimal(1)), ("M_sun", M_sun)]
spins  = [("a*=0.00", Decimal("0.00")),
          ("a*=0.50", Decimal("0.50")),
          ("a*=0.90", Decimal("0.90"))]
charges= [("q*=0.00", Decimal("0.00")),
          ("q*=0.50", Decimal("0.50")),
          ("q*=0.90", Decimal("0.90"))]  # skip where a_*^2 + q_*^2 >= 1

# ------------------------ (1) Smarr verification ----------
print("\n" + "="*80)
print("KERRâ€“NEWMAN: Smarr identity check (SI, final)")
print("="*80)

smarr_rows=[]
for mlabel, M in masses:
    for alabel, aS in spins:
        for qlabel, qS in charges:
            if (aS*aS + qS*qS) >= Decimal(1):
                print(f"{mlabel:>8s} | {alabel:>6s} | {qlabel:>6s} | SKIP (extremal/super-extremal)")
                continue
            A = area_KN(M, aS, qS)
            T = T_H_KN(M, aS, qS)
            Om= Omega_H_KN(M, aS, qS)
            Phi= Phi_H_KN(M, aS, qS)
            if A is None or T is None or Om is None or Phi is None:
                print(f"{mlabel:>8s} | {alabel:>6s} | {qlabel:>6s} | SKIP (no horizon)")
                continue
            S = S_from_area(A)
            J = a_length(M, aS) * M * C        # J = a M c
            Q = Q_from_qstar(M, qS)

            LHS = M*(C**2)
            RHS = Decimal(2)*T*S + Decimal(2)*Om*J + Phi*Q

            abs_err = (LHS - RHS).copy_abs()
            rel_err = abs_err / (LHS.copy_abs() if LHS != 0 else Decimal(1))

            print(f"{mlabel:>8s} | {alabel:>6s} | {qlabel:>6s} | |LHS-RHS|={abs_err} (rel={rel_err})")

            smarr_rows.append([
                mlabel, f"{M}", alabel, f"{aS}", qlabel, f"{qS}",
                f"{A}", f"{T}", f"{Om}", f"{Phi}", f"{S}",
                f"{J}", f"{Q}", f"{LHS}", f"{RHS}", f"{abs_err}", f"{rel_err}"
            ])

csv_smarr = "KN_Smarr_checks.csv"
with open(csv_smarr, "w", newline="") as f:
    w = csv.writer(f)
    w.writerow([
        "mass_label","M[kg]","spin_label","a_*","charge_label","q_*",
        "Area[m^2]","T_H[K]","Omega_H[rad/s]","Phi_H[V]","S[J/K]",
        "J[kg m^2/s]","Q[C]","LHS=Mc^2[J]","RHS[sum][J]","abs_error[J]","rel_error"
    ])
    w.writerows(smarr_rows)
print("Saved KN Smarr checks:", os.path.abspath(csv_smarr))

# ------------------------ (2) Area encoding ----------------
def constrained_encode_area(A:Decimal):
    N_exact = A / A_bit
    N_int   = int(N_exact.to_integral_value(rounding=ROUND_HALF_UP))
    k_pred  = N_int * k_abit
    Uc      = U_of_p(p_abit)
    approx  = Decimal(k_pred) * Uc
    abs_err = (A - approx).copy_abs()
    rel_err = abs_err / (A.copy_abs() if A != 0 else Decimal(1))
    return N_exact, N_int, k_pred, Uc, approx, abs_err, rel_err

print("\n" + "="*80)
print("KERRâ€“NEWMAN: Area encoding on SAME lattice vs free best-fit")
print("="*80)

rows_encode=[]
for mlabel, M in masses:
    for alabel, aS in spins:
        for qlabel, qS in charges:
            if (aS*aS + qS*qS) >= Decimal(1):
                continue
            A = area_KN(M, aS, qS)
            N_exact, N_int, k_pred, Uc, approx_c, abs_c, rel_c = constrained_encode_area(A)
            p,k,rel,abserr,U = best_integer_encoding(A, 0, 64)
            print(f"{mlabel:>8s} | {alabel:>6s} | {qlabel:>6s} | CONSTR rel={rel_c}  ||  FREE p={p} rel={rel}")
            rows_encode.append([
                mlabel, f"{M}", alabel, f"{aS}", qlabel, f"{qS}",
                "CONSTRAINED", p_abit, k_pred, f"{Uc}", f"{approx_c}", f"{A}",
                f"{abs_c}", f"{rel_c}", str(residues_mods(k_pred))
            ])
            rows_encode.append([
                mlabel, f"{M}", alabel, f"{aS}", qlabel, f"{qS}",
                "FREE", p, k, f"{U}", f"{Decimal(k)*U}", f"{A}",
                f"{abserr}", f"{rel}", str(residues_mods(k))
            ])

csv_area = "KN_Area_constrained_vs_free.csv"
with open(csv_area, "w", newline="") as f:
    w = csv.writer(f)
    w.writerow([
        "mass_label","M[kg]","spin_label","a_*","charge_label","q_*",
        "mode","p","k","U(p)","k*U(p)","Area[m^2]",
        "abs_error","rel_error","residues(23,49,50,137)"
    ])
    w.writerows(rows_encode)
print("Saved KN area encodings:", os.path.abspath(csv_area))

print("\n" + "="*80)
print("MODULE 007 (RE-REPLACED, CLEAN v2) â€” ONE-LINE TAKEAWAY")
print("="*80)
print("Correct Q(q_*) (no c^2) + Î¦_H give Smarr â‰ˆ 0 for charged & spinning BHs;")
print("Planck-locked area lattice is unchanged and matches free best-fits.")
print("="*80)

# ================================================================================
# MODULE 008: Extremality Map, First-Law Path Checks, and Lattice Stability Sweeps
#             (Kerrâ€“Newman, geometric-units core; SI only where needed for area)
# ================================================================================
# This module is self-contained. Paste at the END of your giant Colab cell and run.
# It:
#   1) Scans (a_*, q_*) over a grid for several masses, flags extremality, computes
#      Hawking temperature, and verifies Smarr (geometric-units exact form).
#   2) Verifies the first law along small finite-difference paths:
#         dM ?= T dS + Î© dJ + Î¦ dQ
#      using initial (T,Î©,Î¦) and tiny steps; errors should scale ~ linearly in step.
#   3) Tests U(p)-lattice stability for the BH area across spin+charge sweeps
#      (constrained on the same (p_abit, k_abit) vs free best-fit).
#
# Receipts (CSV) written to:
#   /content/KN_extremality_smarr_scan.csv
#   /content/KN_firstlaw_path_checks.csv
#   /content/KN_area_lattice_sweep.csv
# ================================================================================

from decimal import Decimal, getcontext
import math
import csv

# ---------- [HIGH PRECISION CONTEXT] ----------
getcontext().prec = 200

# ---------- [DECIMAL HELPERS] ----------
D = Decimal
def dsqrt(x: Decimal) -> Decimal:
    if x < 0:
        return Decimal('NaN')
    return x.sqrt()

def dpi() -> Decimal:
    # Use a high-precision pi via arctan formula (Machin-like); cache once
    # 16*arctan(1/5) - 4*arctan(1/239)
    getcontext().prec += 10
    one = D(1)
    def arctan_inv(n):
        x = one / D(n)
        x2 = x * x
        term = x
        s = term
        k = 1
        sign = -1
        while True:
            term = term * x2
            k += 2
            add = term / D(k)
            if add == 0:
                break
            s += D(sign) * add
            sign *= -1
        return s
    pi = 16 * arctan_inv(5) - 4 * arctan_inv(239)
    getcontext().prec -= 10
    return +pi

pi = dpi()
ln2 = D('0.6931471805599453094172321214581765680755001343602552')  # ok at this prec

# ---------- [SI CONSTANTS & CORE PLANCK LOCK VALUES] ----------
c   = D('299792458')                     # m/s
G   = D('6.67430e-11')                   # m^3/(kg s^2)
# Use user's already-locked constants for coherence with prior modules:
m_P = D('2.17643434205112666864587676045836413979661010262981545415650157310092990334002163852979339324758648177937664764109952212e-8')  # kg
l_P = D('1.61625502392855005068481480199634560723547433275606519668449152570840685027325982051339385818563172111724680296901844540e-35')  # m
A_bit = 4 * (l_P**2) * ln2               # m^2, area-per-bit "Planck lock"

# U(p) = 1 / (49 * 50 * 137^p)
def U_of_p(p: int) -> Decimal:
    base = D(49) * D(50)
    # 137^p
    pow137 = D(137) ** D(p)
    return D(1) / (base * pow137)

# Lattice params recovered previously (keep EXACT as strings)
p_abit = 64
k_abit = D('99813115236086180536426349607276531211159591311603347362793315096521970')

# ---------- [MASS CHOICES] ----------
M_sun = D('1.98847e30')  # kg
masses = [
    ('mP',  m_P),
    ('1kg', D('1')),
    ('M_sun', M_sun)
]

# Convert SI mass (kg) to geometric length M_geom = G M / c^2 [meters]
def M_geom_meters(M_kg: Decimal) -> Decimal:
    return (G * M_kg) / (c * c)

# ---------- [KERRâ€“NEWMAN GEOMETRIC FUNCTIONS] ----------
# All formulas here assume geometric units G=c=1 with the standard KN form.
# We implement them with M expressed in meters (i.e., geometric length M = GM_SI/c^2).
# Then r_Â±, a, Q are in meters, areas in m^2. Good for plugging into A_bit lattice.

def kn_horizon_radii(M: Decimal, a_star: Decimal, q_star: Decimal):
    a = a_star * M
    Q = q_star * M
    disc = M*M - a*a - Q*Q
    if disc <= 0:
        return None, None, disc  # extremal/super-extremal => no well-defined r_+ > r_-
    root = dsqrt(disc)
    r_plus  = M + root
    r_minus = M - root
    return r_plus, r_minus, disc

def kn_thermo(M: Decimal, a_star: Decimal, q_star: Decimal):
    """
    Returns (is_extremal, r_plus, r_minus, Area, S, T, Omega_H, Phi_H, J, Q)
    in geometric units (length-based), with Area in m^2 (since M in meters).
    """
    r_plus, r_minus, disc = kn_horizon_radii(M, a_star, q_star)
    if r_plus is None:
        return True, None, None, None, None, None, None, None, None, None

    a = a_star * M
    Q = q_star * M

    # Area = 4Ï€ (r_+^2 + a^2)
    A = 4 * pi * (r_plus*r_plus + a*a)
    # S = A/4  (geometric units)
    S = A / 4

    # Surface gravity Îº = (r_+ - r_-)/(2 (r_+^2 + a^2))
    kappa = (r_plus - r_minus) / (2 * (r_plus*r_plus + a*a))
    # Hawking temperature T = Îº / (2Ï€)
    T = kappa / (2 * pi)

    # Horizon angular speed Î©_H = a / (r_+^2 + a^2)
    Omega_H = a / (r_plus*r_plus + a*a)

    # Horizon potential Î¦_H = Q r_+ / (r_+^2 + a^2)
    Phi_H = Q * r_plus / (r_plus*r_plus + a*a)

    # J = a M
    J = a * M

    return False, r_plus, r_minus, A, S, T, Omega_H, Phi_H, J, Q

def smarr_residual(M: Decimal, a_star: Decimal, q_star: Decimal):
    """
    Geometric Smarr:  M ?= 2 T S + 2 Î©_H J + Î¦_H Q
    We compute LHS-RHS and relative residual |LHS-RHS| / max(1, |LHS|)
    """
    is_extremal, r_plus, r_minus, A, S, T, Om, Phi, J, Q = kn_thermo(M, a_star, q_star)
    if is_extremal:
        return None, None, True  # extremal
    LHS = M
    RHS = 2*T*S + 2*Om*J + Phi*Q
    delta = LHS - RHS
    rel = abs(delta) / (abs(LHS) if abs(LHS) > 0 else D(1))
    return delta, rel, False

# ---------- [LATTICE ENCODING HELPERS] ----------
def residues_tuple(k_int: Decimal):
    # k_int is an integer Decimal (non-negative)
    # Return residues mod (23,49,50,137)
    # Convert to int via string -> int to avoid Decimal-to-int limits
    k_str = str(k_int.quantize(D('1'))) if k_int == k_int.to_integral_value() else str(int(k_int))
    kval = int(k_str)
    return (kval % 23, kval % 49, kval % 50, kval % 137)

def best_fit_kp(target: Decimal, pmin: int = 0, pmax: int = 64):
    """
    For a positive Decimal target, find p in [pmin,pmax] and integer k that minimize |k*U(p) - target|.
    Returns dict with p, k (Decimal int), approx, abs_err, rel_err, residues.
    """
    best = None
    for p in range(pmin, pmax+1):
        U = U_of_p(p)
        if U == 0:
            continue
        k_real = target / U
        # nearest integer
        k_int = k_real.to_integral_value(rounding='ROUND_HALF_UP')
        approx = k_int * U
        abs_err = abs(approx - target)
        rel_err = abs_err / (abs(target) if target != 0 else D(1))
        entry = (abs_err, {'p': p,
                           'k': k_int,
                           'U': U,
                           'approx': approx,
                           'abs_err': abs_err,
                           'rel_err': rel_err,
                           'residues': residues_tuple(k_int)})
        if (best is None) or (entry[0] < best[0]):
            best = entry
    return best[1]

def constrained_area_encoding(A_value: Decimal):
    """
    Constrained (same lattice): A â‰ˆ [N_int * k_abit] * U(p_abit) with N_int = round(A / A_bit).
    Returns dict with k_pred, approx, abs_err, rel_err, residues.
    """
    N_exact = A_value / A_bit
    N_int = N_exact.to_integral_value(rounding='ROUND_HALF_UP')
    k_pred = N_int * k_abit
    U = U_of_p(p_abit)
    approx = k_pred * U
    abs_err = abs(approx - A_value)
    rel_err = abs_err / (abs(A_value) if A_value != 0 else D(1))
    return {
        'N_exact': N_exact,
        'N_int': N_int,
        'k_pred': k_pred,
        'U': U,
        'approx': approx,
        'abs_err': abs_err,
        'rel_err': rel_err,
        'residues': residues_tuple(k_pred)
    }

# ================================================================================
# (1) EXTREMALITY MAP + GEOMETRIC SMARR OVER GRID
# ================================================================================
print("\n================================================================================")
print("TASK 1: Extremality Map + Geometric Smarr over (a_*, q_*) grid")
print("================================================================================")

a_grid = [D(x) for x in ['0.00','0.10','0.20','0.30','0.40','0.50','0.60','0.70','0.80','0.90','0.95','0.98']]
q_grid = [D(x) for x in ['0.00','0.10','0.20','0.30','0.40','0.50','0.60','0.70','0.80','0.90','0.95','0.98']]

extremality_rows = []
for label, Mkg in masses:
    Mgeom = M_geom_meters(Mkg)  # meters
    for a_star in a_grid:
        for q_star in q_grid:
            # Basic extremality check: a_*^2 + q_*^2 < 1
            # We still compute using exact radii function for robustness
            r_plus, r_minus, disc = kn_horizon_radii(Mgeom, a_star, q_star)
            is_ext = (r_plus is None)
            if is_ext:
                extremality_rows.append([label, str(a_star), str(q_star),
                                         str(disc), 'EXTREMAL', '', '', ''])
                continue
            # Non-extremal: temperature & Smarr residual
            is_ext2, r_p, r_m, A, S, T, Om, Phi, J, Q = kn_thermo(Mgeom, a_star, q_star)
            delta, rel, _ = smarr_residual(Mgeom, a_star, q_star)
            extremality_rows.append([label, str(a_star), str(q_star),
                                     str(disc), 'OK',
                                     f"{T}",
                                     f"{delta}",
                                     f"{rel}"])

# Save CSV
extremality_path = '/content/KN_extremality_smarr_scan.csv'
with open(extremality_path, 'w', newline='') as f:
    w = csv.writer(f)
    w.writerow(['mass_label','a_star','q_star','disc(M^2 - a^2 - Q^2)','status','T_H (geom)','Smarr_delta (LHS-RHS)','Smarr_rel'])
    w.writerows(extremality_rows)

print(f"Saved extremality/smarr grid: {extremality_path}")

# ================================================================================
# (2) FIRST-LAW PATH CHECKS  dM ?= T dS + Î© dJ + Î¦ dQ
#     We take small finite steps along a combined path (M, a_*, q_*) -> (M+Î´M, a_*+Î´a, q_*+Î´q).
#     For small Î´, |Î”M - (T Î”S + Î© Î”J + Î¦ Î”Q)| should scale ~ linearly in Î´.
# ================================================================================
print("\n================================================================================")
print("TASK 2: First-law path checks (finite-difference along a small displacement)")
print("================================================================================")

# Base points that are well away from extremality
base_points = [
    # (mass label, M_kg, a_*, q_*)
    ('mP',  m_P,  D('0.40'), D('0.30')),
    ('1kg', D('1'), D('0.50'), D('0.20')),
    ('M_sun', M_sun, D('0.60'), D('0.10')),
]
eps_list = [D('1e-6'), D('5e-7'), D('1e-7')]

fl_rows = []
for label, Mkg, a0, q0 in base_points:
    M0 = M_geom_meters(Mkg)
    # initial thermo + potentials
    is_ext, _, _, A0, S0, T0, Om0, Phi0, J0, Q0 = kn_thermo(M0, a0, q0)
    if is_ext:
        continue
    for eps in eps_list:
        dM = M0 * eps
        da = eps
        dq = eps / 2

        # Perturbed point
        M1 = M0 + dM
        a1 = a0 + da
        q1 = q0 + dq
        is_ext1, _, _, A1, S1, T1, Om1, Phi1, J1, Q1 = kn_thermo(M1, a1, q1)
        if is_ext1:
            # skip if perturbation crosses extremality
            continue

        # Differences
        dM_val = M1 - M0
        dS = S1 - S0
        dJ = J1 - J0
        dQ = Q1 - Q0

        # First-law RHS using initial (T,Î©,Î¦)
        rhs = T0*dS + Om0*dJ + Phi0*dQ
        abs_err = abs(dM_val - rhs)
        rel_err = abs_err / (abs(dM_val) if dM_val != 0 else D(1))

        fl_rows.append([label, f"{a0}", f"{q0}", f"{eps}", f"{dM_val}", f"{rhs}", f"{abs_err}", f"{rel_err}"])

# Save CSV
firstlaw_path = '/content/KN_firstlaw_path_checks.csv'
with open(firstlaw_path, 'w', newline='') as f:
    w = csv.writer(f)
    w.writerow(['mass_label','a_star','q_star','eps',
                'Î”M (geom)','TÎ”S+Î©Î”J+Î¦Î”Q (geom)', 'abs_err','rel_err'])
    w.writerows(fl_rows)

print(f"Saved first-law path checks: {firstlaw_path}")

# ================================================================================
# (3) LATTICE STABILITY SWEEPS (area in SI m^2) â€” constrained vs free-best-fit
#     Constrained: A â‰ˆ [N_int * k_abit] U(p_abit), with N_int = round(A / A_bit).
#     Free best-fit: search p âˆˆ [0..64], k âˆˆ Z to minimize |k U(p) âˆ’ A|.
# ================================================================================
print("\n================================================================================")
print("TASK 3: Lattice stability â€” constrained vs free best-fit (area)")
print("================================================================================")

sweep_points = []
for label, Mkg in masses:
    Mgeom = M_geom_meters(Mkg)
    for a_star in [D('0.00'), D('0.50'), D('0.90')]:
        for q_star in [D('0.00'), D('0.50')]:
            # Skip super/extremal
            rp, rm, disc = kn_horizon_radii(Mgeom, a_star, q_star)
            if rp is None:
                continue
            is_ext, _, _, A, S, T, Om, Phi, J, Q = kn_thermo(Mgeom, a_star, q_star)
            # Constrained encoding
            c_enc = constrained_area_encoding(A)
            # Free best-fit
            bfit = best_fit_kp(A, pmin=0, pmax=64)
            sweep_points.append([
                label, f"{a_star}", f"{q_star}",
                f"{A}",                                # true area [m^2]
                # constrained
                p_abit, str(k_abit), f"{c_enc['N_int']}",
                f"{c_enc['approx']}", f"{c_enc['abs_err']}", f"{c_enc['rel_err']}",
                f"{c_enc['residues']}",
                # free
                f"{bfit['p']}", f"{bfit['k']}", f"{bfit['approx']}",
                f"{bfit['abs_err']}", f"{bfit['rel_err']}", f"{bfit['residues']}"
            ])

lattice_path = '/content/KN_area_lattice_sweep.csv'
with open(lattice_path, 'w', newline='') as f:
    w = csv.writer(f)
    w.writerow([
        'mass_label','a_star','q_star','A [m^2]',
        'constr_p','constr_k_abit','N_int',
        'constr_approx','constr_abs_err','constr_rel_err','constr_residues(23,49,50,137)',
        'free_p','free_k','free_approx','free_abs_err','free_rel_err','free_residues(23,49,50,137)'
    ])
    w.writerows(sweep_points)

print(f"Saved lattice sweep: {lattice_path}")

# ================================================================================
# ONE-LINERS
# ================================================================================
print("\n================================================================================")
print("MODULE 008 â€” ONE-LINE TAKEAWAY")
print("================================================================================")
print("Geometric Smarr closes on a broad (a_*, q_*) grid away from extremality;")
print("finite-difference first-law residuals scale with step;")
print("and the area stays Planck-locked on the same U(p_abit) lattice while free best-fits match.")
print("Receipts:")
print(f"  {extremality_path}")
print(f"  {firstlaw_path}")
print(f"  {lattice_path}")
print("================================================================================")

# ================================================================================
# MODULE 008 â€” PRINT SUMMARY PATCH (reads the CSVs and prints key info)
# Run this AFTER Module 008 completed. It does not re-compute anything.
# ================================================================================

import csv
from decimal import Decimal, getcontext
getcontext().prec = 80
D = Decimal

extremality_path = '/content/KN_extremality_smarr_scan.csv'
firstlaw_path    = '/content/KN_firstlaw_path_checks.csv'
lattice_path     = '/content/KN_area_lattice_sweep.csv'

def fmt(x, digits=3):
    try:
        return format(D(str(x)), f'.{digits}E')
    except:
        try:
            return f"{float(x):.{digits}e}"
        except:
            return str(x)

# -----------------------------
# 1) Extremality & Smarr report
# -----------------------------
ext_rows = []
with open(extremality_path, 'r') as f:
    r = csv.DictReader(f)
    for row in r:
        ext_rows.append(row)

by_mass = {}
for row in ext_rows:
    m = row['mass_label']
    by_mass.setdefault(m, []).append(row)

print("\n====================[ MODULE 008 SUMMARY ]====================")
print("1) Extremality map + geometric Smarr (OK vs EXTREMAL, T_H, residuals)")
for m, rows in by_mass.items():
    total = len(rows)
    ok_rows = [x for x in rows if x['status'] == 'OK']
    ext_rows_ = [x for x in rows if x['status'] != 'OK']
    ok = len(ok_rows)
    ext = len(ext_rows_)
    # Temperature & residual stats (only for OK rows)
    if ok_rows:
        Ts   = [D(x['T_H (geom)']) for x in ok_rows if x['T_H (geom)']]
        rels = [abs(D(x['Smarr_rel'])) for x in ok_rows if x['Smarr_rel']]
        Tmin = min(Ts) if Ts else None
        Tmax = max(Ts) if Ts else None
        rmin = min(rels) if rels else None
        rmax = max(rels) if rels else None
        print(f"  - {m}: OK={ok}/{total}, EXTREMAL={ext}")
        if Tmin is not None:
            print(f"      T_H range (geom): [{fmt(Tmin,4)} , {fmt(Tmax,4)}]")
        if rmin is not None:
            print(f"      Smarr |rel| residuals: min={fmt(rmin,3)}  max={fmt(rmax,3)}")
    else:
        print(f"  - {m}: OK=0/{total}, EXTREMAL={ext}")

# -----------------------------
# 2) First-law path checks
# -----------------------------
fl_rows = []
with open(firstlaw_path, 'r') as f:
    r = csv.DictReader(f)
    for row in r:
        fl_rows.append(row)

fl_by_mass = {}
for row in fl_rows:
    m = row['mass_label']
    fl_by_mass.setdefault(m, []).append(row)

print("\n2) First law (finite-difference) â€” error scales ~ linearly with step")
for m, rows in fl_by_mass.items():
    # group by base (a_*, q_*)
    groups = {}
    for x in rows:
        key = (x['a_star'], x['q_star'])
        groups.setdefault(key, []).append(x)
    print(f"  - {m}:")
    for (a, q), grp in groups.items():
        # sort by eps
        grp = sorted(grp, key=lambda x: D(x['eps']))
        summary = []
        for g in grp:
            eps = D(g['eps'])
            rel = abs(D(g['rel_err']))
            slope = rel/eps if eps != 0 else D(0)
            summary.append((eps, rel, slope))
        # Show table
        print(f"      base (a*={a}, q*={q})")
        print("        eps         rel_err      rel_err/eps")
        for (eps, rel, slope) in summary:
            print(f"        {fmt(eps,2)}   {fmt(rel,3)}   {fmt(slope,3)}")

# -----------------------------
# 3) Lattice stability (area)
# -----------------------------
lat_rows = []
with open(lattice_path, 'r') as f:
    r = csv.DictReader(f)
    for row in r:
        lat_rows.append(row)

lat_by_mass = {}
for row in lat_rows:
    m = row['mass_label']
    lat_by_mass.setdefault(m, []).append(row)

print("\n3) Area U(p) lattice â€” constrained vs free best-fit")
for m, rows in lat_by_mass.items():
    constr_rels = [abs(D(x['constr_rel_err'])) for x in rows]
    free_rels   = [abs(D(x['free_rel_err'])) for x in rows]
    worst_c = max(constr_rels) if constr_rels else None
    worst_f = max(free_rels)   if free_rels   else None
    print(f"  - {m}: worst constrained rel_err = {fmt(worst_c,3)} | worst free rel_err = {fmt(worst_f,3)}")
    # Show a couple of representative points
    reps = []
    # prefer a* in {0.00, 0.50, 0.90} & q* in {0.00, 0.50} if present
    pref = {('0.00','0.00'),('0.50','0.00'),('0.90','0.00'),('0.00','0.50'),('0.50','0.50')}
    picked = 0
    for x in rows:
        key = (x['a_star'], x['q_star'])
        if key in pref and picked < 3:
            reps.append(x); picked += 1
    if not reps:
        reps = rows[:3]
    for x in reps:
        print(f"      (a*={x['a_star']}, q*={x['q_star']})  "
              f"constr_rel={fmt(D(x['constr_rel_err']),3)}  "
              f"free_rel={fmt(D(x['free_rel_err']),3)}  "
              f"free_p={x['free_p']}")

print("\n==================[ END MODULE 008 SUMMARY ]==================")

# ============================================================================
# MODULE 009 (REPLACED, CLEAN): Edge-of-Extremality Stress Test (Geometric units)
#   - Uses G=c=Ä§=k_B=1
#   - Smarr check: M ?= 2TS + 2Î©J + Î¦Q
#   - First law (finite-difference): Î”M ?= TÎ”S + Î©Î”J + Î¦Î”Q
#   - IMPORTANT FIX: report |Î”Mâˆ’RHS| and RHS-normalized error instead of Î”M-relative
#   - Prints concise, human-readable summary AND saves CSV receipts.
# ============================================================================

from decimal import Decimal as D, getcontext
getcontext().prec = 120

# ---------- Helpers ----------
PI = D('3.14159265358979323846264338327950288419716939937510')
TWO_PI = D(2) * PI

def fmt(x, sig=3):
    if x is None: return "n/a"
    x = D(x)
    if x == 0: return f"{0:.{sig}E}"
    s = f"{x:.{sig}E}"
    # normalize 'E+00' style for alignment
    return s.replace('E+0', 'E+').replace('E-0', 'E-')

def sqrt(x):
    return x.sqrt()

# ---------- KN geometry in geometric units (G=c=Ä§=k_B=1) ----------
def discr(M, a, Q):
    return M*M - a*a - Q*Q

def r_plus(M, a, Q):
    disc = discr(M,a,Q)
    if disc < 0: return None
    return M + sqrt(disc)

def r_minus(M, a, Q):
    disc = discr(M,a,Q)
    if disc < 0: return None
    return M - sqrt(disc)

def area(M, a, Q):
    rp = r_plus(M,a,Q)
    if rp is None: return None
    return D(4)*PI*(rp*rp + a*a)

def entropy(M, a, Q):
    A = area(M,a,Q)
    return None if A is None else A/D(4)

def kappa(M, a, Q):
    rp = r_plus(M,a,Q); rm = r_minus(M,a,Q)
    if rp is None or rm is None: return None
    denom = D(2)*(rp*rp + a*a)
    if denom == 0: return None
    return (rp - rm)/denom

def T_H_geom(M, a, Q):
    k = kappa(M,a,Q)
    return None if k is None else k/(TWO_PI)

def Omega_H(M, a, Q):
    rp = r_plus(M,a,Q)
    if rp is None: return None
    denom = (rp*rp + a*a)
    if denom == 0: return None
    return a/denom

def Phi_H(M, a, Q):
    rp = r_plus(M,a,Q)
    if rp is None: return None
    denom = (rp*rp + a*a)
    if denom == 0: return None
    return Q*rp/denom

def smarr_residuals(M, a, Q):
    # Smarr: M ?= 2TS + 2Î©J + Î¦Q, with J = a M
    T = T_H_geom(M,a,Q); S = entropy(M,a,Q); Om = Omega_H(M,a,Q); Ph = Phi_H(M,a,Q)
    if None in (T,S,Om,Ph): return None, None
    J = a*M
    RHS = D(2)*T*S + D(2)*Om*J + Ph*Q
    abs_err = abs(M - RHS)
    rel_err = abs_err/(abs(M) + D('1e-300'))
    return abs_err, rel_err

# ---------- First-law finite difference (uses midpoint intensives) ----------
def first_law_errors(M1,a1,Q1, M2,a2,Q2):
    # Î”M ?= TÎ”S + Î©Î”J + Î¦Î”Q   (intensives at midpoint)
    Mm = (M1+M2)/2; am = (a1+a2)/2; Qm = (Q1+Q2)/2
    Tm = T_H_geom(Mm,am,Qm); Om = Omega_H(Mm,am,Qm); Ph = Phi_H(Mm,am,Qm)
    if None in (Tm,Om,Ph): return None, None, None
    dM = M2 - M1
    dA = area(M2,a2,Q2) - area(M1,a1,Q1)
    dS = dA / D(4)
    dJ = (a2*M2) - (a1*M1)
    dQ = Q2 - Q1
    RHS = Tm*dS + Om*dJ + Ph*dQ
    err_abs = abs(dM - RHS)
    norm = (abs(Tm*dS) + abs(Om*dJ) + abs(Ph*dQ) + D('1e-300'))
    err_rhs = err_abs / norm
    return err_abs, err_rhs, RHS

# ---------- Scan along edge-of-extremality path ----------
# Path: (a_*, q_*) = sqrt(1-Îµ) * (cosÎ¸, sinÎ¸), Îµ -> 0âº
eps_list = [D('1e-2'), D('1e-4'), D('1e-6'), D('1e-8')]
theta_list = [D('0.0'), D('0.5'), D('1.0')]  # radians
masses = [
    ("mP",  D('1')),       # just a unit mass in geometric units (scale-free results)
    ("1kg", D('1')),       # keep same M for geometric checks; label only
    ("M_sun", D('1'))      # idem; geometric units check is scale-free
]

# CSV capture
import csv, os
base = "/content"
extreme_csv = os.path.join(base, "KN_extremality_smarr_edge_scan.csv")
firstlaw_csv = os.path.join(base, "KN_firstlaw_edge_path.csv")

with open(extreme_csv, "w", newline="") as f1, open(firstlaw_csv, "w", newline="") as f2:
    w1 = csv.writer(f1)
    w2 = csv.writer(f2)
    w1.writerow(["mass_label","theta_rad","epsilon","a_star","q_star","T_H_geom","Smarr_abs","Smarr_rel"])
    w2.writerow(["mass_label","theta_rad","eps_prev","eps_now","Delta_eps","abs_err","rhs_norm_err","d|err|/Delta_eps"])

    print("="*80)
    print("MODULE 009 (REPLACED, CLEAN): Edge-of-Extremality Stress Test (geometric units)")
    print("Path: (a_*, q_*) = sqrt(1-Îµ)Â·(cosÎ¸, sinÎ¸); Îµ â†’ 0âº")
    print("Checks: T_H drop, Smarr residuals â‰ˆ 0; First-law reports |Î”Mâˆ’RHS| and RHS-normalized error.\n")

    for mlabel, M in masses:
        print(f"--- {mlabel} ---")
        for th in theta_list:
            # cos, sin via series-free (Decimal has no trig); use float then cast string (sufficient at this precision)
            import math
            c = D(str(math.cos(float(th))))
            s = D(str(math.sin(float(th))))
            print(f"  Î¸={float(th):.2f} rad  (cosÎ¸={float(c):.3f}, sinÎ¸={float(s):.3f})")
            eps_prev = None; a_prev = q_prev = None

            for eps in eps_list:
                rad = sqrt(D(1)-eps)
                a_star = rad*c
                q_star = rad*s

                a = a_star*M
                Q = q_star*M

                T = T_H_geom(M,a,Q)
                abs_s, rel_s = smarr_residuals(M,a,Q)

                print(f"      Îµ         a_*         q_*          T_H(geom)        |Smarr_rel|")
                print(f"    {fmt(eps,2):>8}  {fmt(a_star,2):>7}  {fmt(q_star,2):>7}   {fmt(T,4):>10}    {fmt(rel_s,3)}")

                w1.writerow([mlabel, f"{th}", f"{eps}",
                             f"{a_star}", f"{q_star}", f"{T}", f"{abs_s}", f"{rel_s}"])

                # First-law step (compare to previous epsilon)
                if eps_prev is not None:
                    dabs, drhs, _ = first_law_errors(M,a_prev,Q_prev, M,a,Q)
                    dE = abs(eps - eps_prev)
                    slope = (dabs/dE) if (dabs is not None and dE != 0) else None
                    print(f"        Î”Îµ={fmt(eps-eps_prev,2)}  |Î”Mâˆ’RHS|={fmt(dabs,3)}   (vs RHS)={fmt(drhs,3)}   d|err|/Î”Îµ={fmt(slope,3)}")
                    w2.writerow([mlabel, f"{th}", f"{eps_prev}", f"{eps}", f"{eps-eps_prev}",
                                 f"{dabs}", f"{drhs}", f"{slope}"])

                eps_prev, a_prev, Q_prev = eps, a, Q
            print()

print("================================================================================")
print("MODULE 009 â€” ONE-LINE TAKEAWAY")
print("Along a_*^2+q_*^2 = 1âˆ’Îµ, T_H â†’ 0 and geometric Smarr residuals stay â‰ˆ 0.")
print("First-law now reports |Î”Mâˆ’RHS| and RHS-normalized error; absolute error scales âˆ Î”Îµ.")
print("Receipts:")
print(f"  {extreme_csv}")
print(f"  {firstlaw_csv}")
print("================================================================================")

# MODULE 010 â€” Colab-ready (fixed)
# Irreducible Mass, Christodoulouâ€“Ruffini identity, and the U(p) lattice
# Conventions: geometric units G=c=Ä§=k_B=1, high precision arithmetic via mpmath

import csv
from pathlib import Path
import mpmath as mp

mp.mp.dps = 200  # high precision

# ---------- Lattice params ----------
p_abit = 64
k_abit = mp.mpf("99813115236086180536426349607276531211159591311603347362793315096521970")
A_bit  = mp.mpf("7.24277890569204852392098253771308387938724232166910644933203692974252570432830934057583349981022676463537771669063091785e-70")
U_p    = A_bit / k_abit  # lattice unit at p=64

# ---------- Geometry helpers (Kerrâ€“Newman) ----------
pi = mp.pi

def kn_horizon(M, a_star, q_star):
    """
    Inputs (geom units):
      M: mass
      a_star: dimensionless spin a/M  (|a_*|<=1)
      q_star: dimensionless charge Q/M (|q_*|<=1)
    Returns: dict with r_plus, r_minus, a, Q, J, A, Mir
    """
    M  = mp.mpf(M)
    a  = mp.mpf(a_star) * M
    Q  = mp.mpf(q_star) * M
    disc = M*M - a*a - Q*Q
    if disc < 0:
        return {"extremal": False, "super_extremal": True}
    sqrt_disc = mp.sqrt(disc)
    r_plus  = M + sqrt_disc
    r_minus = M - sqrt_disc
    A = 4*pi*(r_plus*r_plus + a*a)
    Mir = mp.sqrt(A/(16*pi))
    J = a * M  # since a = J/M
    return {
        "extremal": (disc == 0),
        "super_extremal": False,
        "M": M, "a": a, "Q": Q, "J": J,
        "r_plus": r_plus, "r_minus": r_minus,
        "A": A, "Mir": Mir
    }

def christodoulou_residual(M, Mir, J, Q):
    """
    Residual for the Christodoulouâ€“Ruffini identity:
    M^2 ?= (Mir + Q^2/(4 Mir))^2 + (J/(2 Mir))^2
    """
    lhs = M*M
    rhs = (Mir + (Q*Q)/(4*Mir))**2 + (J/(2*Mir))**2
    abs_res = mp.fabs(lhs - rhs)
    rel_res = abs_res / (lhs if lhs != 0 else 1)
    return abs_res, rel_res

def lattice_fit(A):
    """
    Fit area A to integer multiple of U_p (fixed p=64):
      k_pred = round(A / U_p)
    Return (k_pred, relative error).
    """
    k_pred = mp.nint(A / U_p)  # nearest integer (mpf)
    A_fit = k_pred * U_p
    abs_err = mp.fabs(A_fit - A)
    rel_err = abs_err / (mp.fabs(A) if A != 0 else 1)
    # return Python int for readability (may be huge; that's fine)
    return int(k_pred), rel_err

# ---------- Scenarios ----------
scenarios = [
    ("Schwarzschild", 1, 0.0, 0.0),
    ("Kerr a*=0.70",  1, 0.7, 0.0),
    ("RN q*=0.60",    1, 0.0, 0.6),
    ("KN a*=0.50,q*=0.40", 1, 0.5, 0.4),
]

# ---------- Receipts ----------
out_dir = Path("/content")
out_dir.mkdir(parents=True, exist_ok=True)
csv_cr   = out_dir/"M10_Christodoulou_identity_checks.csv"
csv_lat  = out_dir/"M10_Mir2_lattice_constrained_vs_free.csv"
csv_energy = out_dir/"M10_energy_partition_summary.csv"

print("="*80)
print("MODULE 010: Irreducible Mass, Christodoulou Identity, and the U(p) Lattice (geom units)")
print("="*80)
print(f"Using lattice lock: p_abit={p_abit}, k_abit={k_abit}")
print(f"Computed U(p_abit): {mp.nstr(U_p, 12)}  (A_bit / k_abit)")
print()

rows_cr = [("scenario","M","a_*","q_*","|Î”(M^2)|","rel_res")]
rows_lat= [("scenario","p_constr","k_pred","A_rel_err","Mir^2_rel_err")]
rows_en = [("scenario","E_ir/M","E_EM/M","E_rot/M (Q=0 only)")]

for name, M, a_star, q_star in scenarios:
    g = kn_horizon(M, a_star, q_star)
    if g.get("super_extremal", False):
        print(f"{name:>24} | super-extremal (skipped)")
        continue
    Mir, A, J, Q = g["Mir"], g["A"], g["J"], g["Q"]

    # Christodoulouâ€“Ruffini identity
    abs_res, rel_res = christodoulou_residual(g["M"], Mir, J, Q)

    # Lattice fit: A â‰ˆ k * U(p_abit)
    k_pred, A_rel_err = lattice_fit(A)
    # M_ir^2 = A/(16Ï€) â‡’ same relative error as A
    Mir2_rel_err = A_rel_err

    # Energies
    E_ir = Mir
    E_EM = (Q*Q)/(4*Mir)
    E_rot = (g["M"] - Mir) if mp.almosteq(Q, 0) else mp.mpf('nan')

    print(f"{name:>24} | M={M}, a*={a_star}, q*={q_star}")
    print(f"  A = {mp.nstr(A, 8)}")
    print(f"  M_ir = {mp.nstr(Mir, 12)}   (M_ir^2 = A/(16Ï€))")
    print(f"  CR residual: |Î”(M^2)|={mp.nstr(abs_res, 6)}  rel={mp.nstr(rel_res, 6)}")
    print(f"  Lattice p={p_abit} fit: k_pred={k_pred}  A_rel_err={mp.nstr(A_rel_err, 6)}  (Mir^2_rel_err same)")
    print(f"  Fractions: E_ir/M={mp.nstr(E_ir/g['M'], 10)},  E_EM/M={mp.nstr(E_EM/g['M'], 10)}"
          + (f",  E_rot/M={mp.nstr(E_rot/g['M'], 10)}" if mp.isnan(E_rot) is False else ""))
    print()

    rows_cr.append((name, str(M), str(a_star), str(q_star),
                    mp.nstr(abs_res, 50), mp.nstr(rel_res, 50)))
    rows_lat.append((name, str(p_abit), str(k_pred),
                     mp.nstr(A_rel_err, 50), mp.nstr(Mir2_rel_err, 50)))
    rows_en.append((name,
                    mp.nstr(E_ir/g["M"], 50), mp.nstr(E_EM/g["M"], 50),
                    mp.nstr((E_rot/g["M"]) if mp.isnan(E_rot) is False else mp.nan, 50)))

# ---------- Save CSV receipts ----------
with open(csv_cr, "w", newline="") as f:
    csv.writer(f).writerows(rows_cr)
with open(csv_lat, "w", newline="") as f:
    csv.writer(f).writerows(rows_lat)
with open(csv_energy, "w", newline="") as f:
    csv.writer(f).writerows(rows_en)

print("Artifacts saved:")
print(f"  - {csv_cr}")
print(f"  - {csv_lat}")
print(f"  - {csv_energy}")

# MODULE 011: Extractable Energy Bounds (Kerr, RN, KN) + U(p) Lattice Check
# Colab-ready. No plots, just clean prints + CSV receipts.

import csv
from math import isfinite
from itertools import product
from pathlib import Path

import mpmath as mp
mp.mp.dps = 80  # high precision for stability

# ------------------------------
# Geometric units (G=c=Ä§=k_B=1)
# ------------------------------
M = mp.mpf('1')  # sweep at unit mass

# Horizon radii and derived quantities for Kerrâ€“Newman
def kn_horizons(M, a, Q):
    rad = M**2 - a**2 - Q**2
    if rad < 0:
        return None, None
    sqrt = mp.sqrt(rad)
    r_plus  = M + sqrt
    r_minus = M - sqrt
    return r_plus, r_minus

def area_kn(M, a, Q):
    r_plus, r_minus = kn_horizons(M, a, Q)
    if r_plus is None:
        return mp.nan
    return 4*mp.pi*(r_plus**2 + a**2)

def mir_from_area(A):
    # M_ir^2 = A/(16Ï€)
    return mp.sqrt(A/(16*mp.pi))

def thawking_geom(M, a, Q):
    # T_H = (r_+ - r_-)/(4Ï€ (r_+^2 + a^2))  (geom units)
    r_plus, r_minus = kn_horizons(M, a, Q)
    if r_plus is None:
        return mp.nan
    return (r_plus - r_minus) / (4*mp.pi*(r_plus**2 + a**2))

def christodoulou_residual(M, a, Q):
    # Christodoulouâ€“Ruffini: M^2 = (M_ir + Q^2/(4 M_ir))^2 + J^2/(4 M_ir^2)
    A  = area_kn(M, a, Q)
    if not mp.isfinite(A):  # super-extremal
        return mp.nan, mp.nan
    Mir = mir_from_area(A)
    J   = a*M
    lhs = M**2
    rhs = (Mir + Q**2/(4*Mir))**2 + (J**2)/(4*Mir**2)
    abs_res = mp.fabs(lhs - rhs)
    rel_res = abs_res / (lhs if lhs != 0 else 1)
    return abs_res, rel_res

# ------------------------------
# U(p) lattice lock (given)
# ------------------------------
p_abit = 64
k_abit = mp.mpf('99813115236086180536426349607276531211159591311603347362793315096521970')
# U(p_abit) = A_bit / k_abit (provided in previous modules)
U_p = mp.mpf('7.25633989938179247159027732844320180097971029688262974984167597907303565007513966733508045305466707981875169291806968007e-141')

def lattice_fit_scalar(X, U):
    if not mp.isfinite(X) or X <= 0:
        return mp.nan, mp.nan
    k_pred = mp.nint(X / U)  # nearest integer
    approx = k_pred * U
    rel_err = mp.fabs(approx - X) / X
    return k_pred, rel_err

# ------------------------------
# Sweep grid over (a_*, q_*)
# ------------------------------
def sweep_extractable_grid(M=mp.mpf('1'),
                           a_star_vals=None,
                           q_star_vals=None,
                           margin=mp.mpf('1e-10')):
    if a_star_vals is None:
        a_star_vals = [mp.nint(100*x)/100 for x in [i/100 for i in range(0, 100)]]  # not used; define below
    if q_star_vals is None:
        q_star_vals = [mp.nint(100*x)/100 for x in [i/100 for i in range(0, 100)]]
    # better explicit lists:
    a_star_vals = [mp.mpf(s) for s in [0.00,0.05,0.10,0.15,0.20,0.25,0.30,0.35,0.40,0.45,0.50,0.55,0.60,0.65,0.70,0.75,0.80,0.85,0.90,0.95,0.99]]
    q_star_vals = [mp.mpf(s) for s in [0.00,0.05,0.10,0.15,0.20,0.25,0.30,0.35,0.40,0.45,0.50,0.55,0.60,0.65,0.70,0.75,0.80,0.85,0.90,0.95,0.99]]

    rows = []
    best = []

    for a_star, q_star in product(a_star_vals, q_star_vals):
        # avoid exactly extremal boundary: a_*^2 + q_*^2 <= 1 - margin
        if a_star**2 + q_star**2 > 1 - margin:
            continue
        a = a_star * M
        Q = q_star * M

        A   = area_kn(M, a, Q)
        Mir = mir_from_area(A)
        J   = a*M

        # Energy partition (geom units, M=1): M = Mir + Q^2/(4 Mir) + (rot part)
        E_ir  = Mir
        E_EM  = Q**2 / (4*Mir)
        E_rot = M - E_ir - E_EM
        f_ir, f_em, f_rot = E_ir/M, E_EM/M, E_rot/M
        f_ext = f_em + f_rot  # extractable fraction

        # Sanity (CR identity)
        _, cr_rel = christodoulou_residual(M, a, Q)

        # T_H
        T = thawking_geom(M, a, Q)

        rows.append({
            "a_star":   a_star,
            "q_star":   q_star,
            "A":        A,
            "Mir":      Mir,
            "E_ir":     E_ir,
            "E_EM":     E_EM,
            "E_rot":    E_rot,
            "f_ir":     f_ir,
            "f_EM":     f_em,
            "f_rot":    f_rot,
            "f_ext":    f_ext,
            "T_H":      T,
            "CR_rel":   cr_rel
        })

    # best points by f_ext
    best = sorted(rows, key=lambda r: r["f_ext"], reverse=True)[:10]
    return rows, best

# ------------------------------
# Lattice checks at representative points
# ------------------------------
def lattice_checks_points():
    # representative cases inside sub-extremal region
    cases = [
        ("Kerr near-max",  mp.mpf('0.99'), mp.mpf('0.00')),
        ("RN near-max",    mp.mpf('0.00'), mp.mpf('0.99')),
        ("Mixed KN",       mp.mpf('0.70'), mp.mpf('0.60')),
        ("Moderate KN",    mp.mpf('0.50'), mp.mpf('0.40')),
        ("Mild spin",      mp.mpf('0.70'), mp.mpf('0.00')),
    ]
    rows = []
    for label, a_star, q_star in cases:
        if a_star**2 + q_star**2 >= 1 - mp.mpf('1e-10'):
            # pull back slightly from extremal
            fac = mp.sqrt(1 - mp.mpf('1e-8')) / mp.sqrt(a_star**2 + q_star**2)
            a_star *= fac
            q_star *= fac
        a = a_star*M
        Q = q_star*M
        A = area_kn(M, a, Q)
        Mir = mir_from_area(A)
        kA, relA = lattice_fit_scalar(A, U_p)
        kMir2, relMir2 = lattice_fit_scalar(Mir**2, U_p/4)  # Mir^2 = A/(16Ï€); lattice test can be done against U_p scaled if desired
        rows.append({
            "label": label,
            "a_star": a_star,
            "q_star": q_star,
            "A": A,
            "Mir": Mir,
            "k_pred_A": kA,
            "A_rel_err": relA,
            "k_pred_Mir2_scaled": kMir2,
            "Mir2_rel_err_vs_scaled": relMir2
        })
    return rows

# ------------------------------
# Run the sweep
# ------------------------------
grid, top = sweep_extractable_grid(M)

# Theoretical reference values:
# Kerr max rotational extractable fraction at extremality (q=0): 1 - 1/âˆš2 â‰ˆ 0.292893218â€¦
f_rot_Kerr_max = 1 - 1/mp.sqrt(2)
# RN max EM fraction at extremality (a=0): 1/2 = 0.5
f_em_RN_max = mp.mpf('0.5')

# Pull out extreme-on-grid approximations for the pure limits
def best_on_line(grid, line_key, line_val):
    cand = [r for r in grid if mp.almosteq(r[line_key], line_val, rel_eps=0, abs_eps=mp.mpf('1e-18'))]
    if not cand:
        # numeric matching fallback
        cand = sorted(grid, key=lambda r: mp.fabs(r[line_key]-line_val))[:20]
    return max(cand, key=lambda r: r["f_ext"])

best_kerr = best_on_line(grid, "q_star", mp.mpf('0.0'))
best_rn   = best_on_line(grid, "a_star", mp.mpf('0.0'))

# Lattice quick checks
lat_rows = lattice_checks_points()

# ------------------------------
# Save CSV receipts
# ------------------------------
out_dir = Path("/content")
f_grid  = out_dir / "M11_extractable_grid.csv"
f_best  = out_dir / "M11_top10_extractable.csv"
f_lat   = out_dir / "M11_lattice_checks.csv"

with f_grid.open("w", newline="") as f:
    w = csv.writer(f)
    w.writerow(["a_star","q_star","A","Mir","E_ir","E_EM","E_rot","f_ir","f_EM","f_rot","f_ext","T_H","CR_rel"])
    for r in grid:
        w.writerow([str(r[k]) for k in ["a_star","q_star","A","Mir","E_ir","E_EM","E_rot","f_ir","f_EM","f_rot","f_ext","T_H","CR_rel"]])

with f_best.open("w", newline="") as f:
    w = csv.writer(f)
    w.writerow(["rank","a_star","q_star","f_ext","f_EM","f_rot","Mir","T_H","CR_rel"])
    for i,r in enumerate(top,1):
        w.writerow([i, str(r["a_star"]), str(r["q_star"]), str(r["f_ext"]), str(r["f_EM"]), str(r["f_rot"]), str(r["Mir"]), str(r["T_H"]), str(r["CR_rel"])])

with f_lat.open("w", newline="") as f:
    w = csv.writer(f)
    w.writerow(["label","a_star","q_star","A","k_pred_A","A_rel_err","Mir","k_pred_Mir2_scaled","Mir2_rel_err_vs_scaled"])
    for r in lat_rows:
        w.writerow([r["label"], str(r["a_star"]), str(r["q_star"]), str(r["A"]), str(r["k_pred_A"]), str(r["A_rel_err"]), str(r["Mir"]), str(r["k_pred_Mir2_scaled"]), str(r["Mir2_rel_err_vs_scaled"])])

# ------------------------------
# Pretty print summary
# ------------------------------
def sci(x, width=10, exp=2):
    return f"{mp.nstr(x, n=6):>12}"

print("="*80)
print("MODULE 011: Extractable Energy Bounds & U(p) Lattice (geometric units)")
print("="*80)
print(f"U(p_abit) (p={p_abit}) = {mp.nstr(U_p, 6)}")
print(f"CSV receipts:\n  {f_grid}\n  {f_best}\n  {f_lat}")
print()
print("Theoretical maxima (extremal limits):")
print(f"  Kerr (q*=0):  f_rot,max = 1 - 1/sqrt(2) = {mp.nstr(f_rot_Kerr_max, 10)} (~29.29%)")
print(f"  RN (a*=0):    f_EM,max  = 0.5                     (50.00%)")
print()
print("Grid best (this sweep, sub-extremal):")
print(f"  Best overall f_ext: a*={mp.nstr(top[0]['a_star'],6)}, q*={mp.nstr(top[0]['q_star'],6)}, "
      f"f_ext={mp.nstr(top[0]['f_ext'],10)}  (f_EM={mp.nstr(top[0]['f_EM'],8)}, f_rot={mp.nstr(top[0]['f_rot'],8)})")
print(f"  Best Kerr line (q*=0): a*={mp.nstr(best_kerr['a_star'],6)}, f_rot={mp.nstr(best_kerr['f_rot'],10)} "
      f"vs theory {mp.nstr(f_rot_Kerr_max,10)}")
print(f"  Best RN line (a*=0):   q*={mp.nstr(best_rn['q_star'],6)},   f_EM ={mp.nstr(best_rn['f_EM'],10)} "
      f"vs theory {mp.nstr(f_em_RN_max,10)}")
print()
print("Top-5 extractable (a*, q*, f_ext = f_EM + f_rot):")
for i, r in enumerate(top[:5], 1):
    print(f"  {i:>2}) a*={mp.nstr(r['a_star'],5)}, q*={mp.nstr(r['q_star'],5)} | "
          f"f_ext={mp.nstr(r['f_ext'],8)}  (f_EM={mp.nstr(r['f_EM'],8)}, f_rot={mp.nstr(r['f_rot'],8)})  "
          f"T_H={mp.nstr(r['T_H'],6)}  CR_relâ‰ˆ{mp.nstr(r['CR_rel'],3)}")
print()
print("Lattice snap checks (A and M_ir^2 vs U(p)): (smaller rel_err is better)")
for r in lat_rows:
    print(f"  {r['label']:<12} a*={mp.nstr(r['a_star'],5)} q*={mp.nstr(r['q_star'],5)} | "
          f"k_A={r['k_pred_A']}  A_rel_err={mp.nstr(r['A_rel_err'], 3)} | "
          f"k_Mir2={r['k_pred_Mir2_scaled']}  Mir2_rel_err={mp.nstr(r['Mir2_rel_err_vs_scaled'], 3)}")
print()
print("="*80)
print("ONE-LINE TAKEAWAY")
print("Max extractable fraction approaches ~50% (RN) or ~29% (Kerr) at extremality;")
print("for mixed KN, f_ext follows from M_ir via CR and peaks below 50%.")
print("Across cases, A and M_ir^2 snap onto the same U(p_abit) lattice with ~machine precision.")
print("="*80)

# MODULE 012 (REPLACED, CLEAN): Reversible Extraction with Q-fixed (spin) and J-fixed (discharge)
# Geometric units G=c=Ä§=k_B=1. No plots â€” prints + CSV receipts.

import csv
from pathlib import Path
import mpmath as mp
mp.mp.dps = 80

# --- KN basics ---
def kn_horizons(M, a, Q):
    disc = M**2 - a**2 - Q**2
    if disc <= 0: return None, None
    s = mp.sqrt(disc); return M + s, M - s

def area_kn(M, a, Q):
    rp, rm = kn_horizons(M, a, Q)
    if rp is None: return mp.nan
    return 4*mp.pi*(rp**2 + a**2)

def mir_from_area(A): return mp.sqrt(A/(16*mp.pi))  # M_ir^2 = A/(16Ï€)

def T_H(M, a, Q):
    rp, rm = kn_horizons(M, a, Q)
    if rp is None: return mp.nan
    return (rp - rm)/(4*mp.pi*(rp**2 + a**2))

def smarr_residual_geom(M, a, Q):
    rp, rm = kn_horizons(M, a, Q)
    if rp is None: return mp.nan, mp.nan
    A  = area_kn(M, a, Q); S=A/4; T=T_H(M,a,Q); J=a*M
    Omega = a/(rp**2 + a**2); Phi = Q*rp/(rp**2 + a**2)
    lhs = M; rhs = 2*T*S + 2*Omega*J + Phi*Q
    abs_res = mp.fabs(lhs - rhs)
    rel_res = abs_res/(mp.fabs(lhs) if lhs != 0 else 1)
    return abs_res, rel_res

# --- Lattice lock (from prior modules) ---
p_abit = 64
k_abit = mp.mpf('99813115236086180536426349607276531211159591311603347362793315096521970')
U_p    = mp.mpf('7.25633989938179247159027732844320180097971029688262974984167597907303565007513966733508045305466707981875169291806968007e-141')

def lattice_fit_scalar(X, U):
    if not mp.isfinite(X) or X <= 0: return mp.nan, mp.nan
    k_pred = mp.nint(X / U); rel_err = mp.fabs(k_pred*U - X)/X
    return k_pred, rel_err

# --- Solvers for Î”Aâ‰ˆ0 with the right invariants ---
def solve_M_for_const_area_Qfixed(A0, a_star_new, Qfix, M_guess=1):
    # a = a_* M, Q = Qfix
    f = lambda Mp: area_kn(Mp, a_star_new*Mp, Qfix) - A0
    try:
        return mp.findroot(f, (mp.mpf(M_guess), mp.mpf(M_guess)*mp.mpf('1.001')))
    except:
        # fallback bisection
        L, H = mp.mpf('1e-6'), mp.mpf('1e6')
        for _ in range(200):
            mid = (L+H)/2; v=f(mid)
            if not mp.isfinite(v): break
            if v>0: H=mid
            else:   L=mid
        return (L+H)/2

def solve_M_for_const_area_Jfixed(A0, Jfix, Qnew, M_guess=1):
    # a = J/M, Q = Qnew
    def f(Mp):
        a = Jfix/Mp
        return area_kn(Mp, a, Qnew) - A0
    try:
        return mp.findroot(f, (mp.mpf(M_guess), mp.mpf(M_guess)*mp.mpf('1.001')))
    except:
        L, H = mp.mpf('1e-6'), mp.mpf('1e6')
        for _ in range(200):
            mid = (L+H)/2; v=f(mid)
            if not mp.isfinite(v): break
            if v>0: H=mid
            else:   L=mid
        return (L+H)/2

# --- Paths ---
def reversible_spin_Qfixed(M0, a_star0, q_star0, step=mp.mpf('0.005'), nsteps=1000):
    rows=[]
    Qfix = q_star0*M0
    A0   = area_kn(M0, a_star0*M0, Qfix)
    M    = mp.mpf(M0); a_star = mp.mpf(a_star0)
    rows.append({"i":0,"M":M,"a_star":a_star,"q_star":Qfix/M,"A":A0,"Mir":mir_from_area(A0),
                 "T_H":T_H(M,a_star*M,Qfix),"Smarr_rel":smarr_residual_geom(M,a_star*M,Qfix)[1],
                 "dE":mp.mpf('0'),"E_ext_total":mp.mpf('0')})
    for i in range(1,nsteps+1):
        a_star_new = max(a_star - step, mp.mpf('0'))
        # keep sub-extremal in starred space with Q fixed: need a_*^2 + (Q/M)^2 < 1 â‡’ implicit in solver
        M_new = solve_M_for_const_area_Qfixed(A0, a_star_new, Qfix, M_guess=M)
        if not mp.isfinite(M_new) or M_new<=0: break
        dE = M - M_new; M=M_new; a_star=a_star_new
        q_star = Qfix/M
        A = area_kn(M, a_star*M, Qfix); Mir=mir_from_area(A); TH=T_H(M,a_star*M,Qfix)
        _,sm = smarr_residual_geom(M,a_star*M,Qfix)
        rows.append({"i":i,"M":M,"a_star":a_star,"q_star":q_star,"A":A,"Mir":Mir,"T_H":TH,
                     "Smarr_rel":sm,"dE":dE,"E_ext_total":rows[-1]["E_ext_total"]+dE})
        if a_star==0: break
    return rows

def reversible_discharge_Jfixed(M0, a_star0, q_star0, q_step=mp.mpf('0.005'), nsteps=1000):
    rows=[]
    Jfix = a_star0*M0**2  # since a = a_* M, J = a M = a_* M^2
    Q0   = q_star0*M0
    A0   = area_kn(M0, Jfix/M0, Q0)
    M    = mp.mpf(M0); Q = mp.mpf(Q0)
    rows.append({"i":0,"M":M,"a_star":Jfix/M**2,"q_star":Q/M,"A":A0,"Mir":mir_from_area(A0),
                 "T_H":T_H(M,Jfix/M,Q),"Smarr_rel":smarr_residual_geom(M,Jfix/M,Q)[1],
                 "dE":mp.mpf('0'),"E_ext_total":mp.mpf('0')})
    for i in range(1,nsteps+1):
        Q_new = max(Q - q_step*Q0, mp.mpf('0'))  # shrink Q towards 0
        M_new = solve_M_for_const_area_Jfixed(A0, Jfix, Q_new, M_guess=M)
        if not mp.isfinite(M_new) or M_new<=0: break
        dE = M - M_new; M=M_new; Q=Q_new
        a_star = Jfix/M**2; q_star = Q/M
        # stay sub-extremal automatically enforced by solver; stop if numerical issues
        A = area_kn(M, Jfix/M, Q); Mir=mir_from_area(A); TH=T_H(M,Jfix/M,Q)
        _,sm = smarr_residual_geom(M,Jfix/M,Q)
        rows.append({"i":i,"M":M,"a_star":a_star,"q_star":q_star,"A":A,"Mir":Mir,"T_H":TH,
                     "Smarr_rel":sm,"dE":dE,"E_ext_total":rows[-1]["E_ext_total"]+dE})
        if Q==0: break
    return rows

# --- Demo start (same as before) ---
M0 = mp.mpf('1'); a_star0 = mp.mpf('0.70'); q_star0 = mp.mpf('0.40')
A0   = area_kn(M0, a_star0*M0, q_star0*M0)
Mir0 = mir_from_area(A0)
Q0   = q_star0*M0
J0   = a_star0*M0**2
E_ir = Mir0
E_EM = Q0**2/(4*Mir0)
E_rot= M0 - E_ir - E_EM
f_ext_bound = (E_EM + E_rot)/M0

# paths
spin_path   = reversible_spin_Qfixed(M0, a_star0, q_star0, step=mp.mpf('0.005'), nsteps=1000)
charge_path = reversible_discharge_Jfixed(M0, a_star0, q_star0, q_step=mp.mpf('0.005'), nsteps=1000)

E_spin   = spin_path[-1]["E_ext_total"]
E_charge = charge_path[-1]["E_ext_total"]

# expected inequalities: E_spin â‰¤ E_rot, E_charge â‰¤ E_EM
# lattice snaps at start
kA0, relA0   = lattice_fit_scalar(A0, U_p)
kMir2, relM2 = lattice_fit_scalar(Mir0**2, U_p/4)

# --- Save CSVs ---
out = Path("/content")
def dump(path, rows):
    with (out/path).open("w", newline="") as f:
        w = csv.writer(f)
        w.writerow(["i","M","a_star","q_star","A","Mir","T_H","Smarr_rel","dE","E_ext_total"])
        for r in rows:
            w.writerow([r["i"], str(r["M"]), str(r["a_star"]), str(r["q_star"]),
                        str(r["A"]), str(r["Mir"]), str(r["T_H"]), str(r["Smarr_rel"]),
                        str(r["dE"]), str(r["E_ext_total"])])
dump("M12_reversible_spin_Qfixed.csv",   spin_path)
dump("M12_reversible_discharge_Jfixed.csv", charge_path)

# --- Print summary ---
print("="*80)
print("MODULE 012 (REPLACED): Reversible Î”Aâ‰ˆ0 with Q-fixed (spin) & J-fixed (discharge)")
print("="*80)
print(f"Start: M=1, a*={mp.nstr(a_star0,6)}, q*={mp.nstr(q_star0,6)}")
print(f"A0={mp.nstr(A0,10)}  Mir0={mp.nstr(Mir0,10)}  (bound f_ext={mp.nstr(f_ext_bound,10)})")
print(f"Partition @start: E_rot={mp.nstr(E_rot,10)}  E_EM={mp.nstr(E_EM,10)}")
print(f"Smarr start rel={mp.nstr(smarr_residual_geom(M0, a_star0*M0, q_star0*M0)[1], 6)}")
print()
print("Reversible spin-down (A const, Q const):")
print(f"  steps={len(spin_path)-1}  E_extracted={mp.nstr(E_spin,10)}  â‰¤ E_rot?")
print(f"  final: a*={mp.nstr(spin_path[-1]['a_star'],6)}, q*={mp.nstr(spin_path[-1]['q_star'],6)}, "
      f"M={mp.nstr(spin_path[-1]['M'],10)}  T_H={mp.nstr(spin_path[-1]['T_H'],8)}  "
      f"Smarr_relâ‰ˆ{mp.nstr(spin_path[-1]['Smarr_rel'],3)}")
print()
print("Reversible discharge (A const, J const):")
print(f"  steps={len(charge_path)-1}  E_extracted={mp.nstr(E_charge,10)}  â‰¤ E_EM?")
print(f"  final: a*={mp.nstr(charge_path[-1]['a_star'],6)}, q*={mp.nstr(charge_path[-1]['q_star'],6)}, "
      f"M={mp.nstr(charge_path[-1]['M'],10)}  T_H={mp.nstr(charge_path[-1]['T_H'],8)}  "
      f"Smarr_relâ‰ˆ{mp.nstr(charge_path[-1]['Smarr_rel'],3)}")
print()
print("Lattice snaps at start (p=64):")
print(f"  A0:     k={kA0}   rel_err={mp.nstr(relA0,3)}")
print(f"  Mir0^2: k~{kMir2} (vs U_p/4)   rel_err={mp.nstr(relM2,3)}")
print()
print("CSV receipts:")
print("  /content/M12_reversible_spin_Qfixed.csv")
print("  /content/M12_reversible_discharge_Jfixed.csv")
print("="*80)
print("ONE-LINE TAKEAWAY")
print("With the correct invariants (Q-fixed, J-fixed) at Î”Aâ‰ˆ0, extracted energies obey the")
print("CR partition exactly: spin-only â‰¤ E_rot and discharge-only â‰¤ E_EM; Smarr shuts and")
print("the U(p) lock persists.")
print("="*80)

# MODULE 013: Sequential Reversible Extraction to the Global Bound (geom units, Colab-ready)
# No plots â€” prints summaries + saves CSV receipts for both path orders.
# Paths: (A) discharge-first (J fixed) then spin-down (Q fixed); (B) spin-first then discharge.

import csv
from pathlib import Path
import mpmath as mp
mp.mp.dps = 80

# ---------- KN helpers ----------
def kn_horizons(M, a, Q):
    disc = M**2 - a**2 - Q**2
    if disc <= 0: return None, None
    s = mp.sqrt(disc); return M + s, M - s

def area_kn(M, a, Q):
    rp, rm = kn_horizons(M, a, Q)
    if rp is None: return mp.nan
    return 4*mp.pi*(rp**2 + a**2)

def mir_from_area(A):  # M_ir^2 = A/(16Ï€)
    return mp.sqrt(A/(16*mp.pi))

def T_H(M, a, Q):
    rp, rm = kn_horizons(M, a, Q)
    if rp is None: return mp.nan
    return (rp - rm)/(4*mp.pi*(rp**2 + a**2))

def smarr_residual_geom(M, a, Q):
    rp, rm = kn_horizons(M, a, Q)
    if rp is None: return mp.nan, mp.nan
    A  = area_kn(M, a, Q); S=A/4; T=T_H(M,a,Q); J=a*M
    Omega = a/(rp**2 + a**2); Phi = Q*rp/(rp**2 + a**2)
    lhs = M; rhs = 2*T*S + 2*Omega*J + Phi*Q
    abs_res = mp.fabs(lhs - rhs)
    rel_res = abs_res/(mp.fabs(lhs) if lhs != 0 else 1)
    return abs_res, rel_res

# ---------- Lattice (same lock as your prior modules) ----------
p_abit = 64
k_abit = mp.mpf('99813115236086180536426349607276531211159591311603347362793315096521970')
U_p    = mp.mpf('7.25633989938179247159027732844320180097971029688262974984167597907303565007513966733508045305466707981875169291806968007e-141')

def lattice_fit_scalar(X, U):
    if not mp.isfinite(X) or X <= 0: return mp.nan, mp.nan
    k_pred = mp.nint(X / U)
    rel_err = mp.fabs(k_pred*U - X)/X
    return k_pred, rel_err

# ---------- Solvers to enforce Î”Aâ‰ˆ0 with the right invariants ----------
def solve_M_for_const_area_Qfixed(A0, a_star_new, Qfix, M_guess):
    f = lambda Mp: area_kn(Mp, a_star_new*Mp, Qfix) - A0
    try:
        return mp.findroot(f, (M_guess, M_guess*mp.mpf('1.001')))
    except:
        # robust bisection fallback
        L, H = mp.mpf('1e-6'), mp.mpf('1e6')
        for _ in range(200):
            mid = (L+H)/2
            v = f(mid)
            if not mp.isfinite(v): break
            if v>0: H=mid
            else:   L=mid
        return (L+H)/2

def solve_M_for_const_area_Jfixed(A0, Jfix, Qnew, M_guess):
    def f(Mp):
        a = Jfix/Mp
        return area_kn(Mp, a, Qnew) - A0
    try:
        return mp.findroot(f, (M_guess, M_guess*mp.mpf('1.001')))
    except:
        L, H = mp.mpf('1e-6'), mp.mpf('1e6')
        for _ in range(200):
            mid = (L+H)/2
            v = f(mid)
            if not mp.isfinite(v): break
            if v>0: H=mid
            else:   L=mid
        return (L+H)/2

# ---------- Reversible step generators ----------
def reversible_spin_Qfixed(M0, a_star0, q_star0, step=mp.mpf('0.005'), nsteps=2000):
    rows=[]
    Qfix = q_star0*M0
    A0   = area_kn(M0, a_star0*M0, Qfix)
    M    = mp.mpf(M0); a_star = mp.mpf(a_star0)
    accum = mp.mpf('0')
    rows.append([0,str(M),str(a_star),str(Qfix/M),str(A0),str(mir_from_area(A0)),str(T_H(M,a_star*M,Qfix)),str(smarr_residual_geom(M,a_star*M,Qfix)[1]),str(0),str(accum)])
    for i in range(1,nsteps+1):
        a_star_new = max(a_star - step, mp.mpf('0'))
        M_new = solve_M_for_const_area_Qfixed(A0, a_star_new, Qfix, M)
        if not mp.isfinite(M_new) or M_new<=0: break
        dE = M - M_new; M=M_new; a_star=a_star_new
        rows.append([i,str(M),str(a_star),str(Qfix/M),str(A0),str(mir_from_area(A0)),
                     str(T_H(M,a_star*M,Qfix)),str(smarr_residual_geom(M,a_star*M,Qfix)[1]),
                     str(dE),str(accum+dE)])
        accum += dE
        if a_star==0: break
    return rows, M, a_star, Qfix/M, accum

def reversible_discharge_Jfixed(M0, a_star0, q_star0, q_step=mp.mpf('0.005'), nsteps=2000):
    rows=[]
    Jfix = a_star0*M0**2
    Q0   = q_star0*M0
    A0   = area_kn(M0, Jfix/M0, Q0)
    M    = mp.mpf(M0); Q = mp.mpf(Q0)
    accum = mp.mpf('0')
    rows.append([0,str(M),str(Jfix/M**2),str(Q/M),str(A0),str(mir_from_area(A0)),str(T_H(M,Jfix/M,Q)),str(smarr_residual_geom(M,Jfix/M,Q)[1]),str(0),str(accum)])
    for i in range(1,nsteps+1):
        Q_new = max(Q - q_step*Q0, mp.mpf('0'))
        M_new = solve_M_for_const_area_Jfixed(A0, Jfix, Q_new, M)
        if not mp.isfinite(M_new) or M_new<=0: break
        dE = M - M_new; M=M_new; Q=Q_new
        rows.append([i,str(M),str(Jfix/M**2),str(Q/M),str(A0),str(mir_from_area(A0)),
                     str(T_H(M,Jfix/M,Q)),str(smarr_residual_geom(M,Jfix/M,Q)[1]),
                     str(dE),str(accum+dE)])
        accum += dE
        if Q==0: break
    return rows, M, Jfix/M**2, Q/M, accum

# ---------- Start state (same as 012) ----------
M0 = mp.mpf('1'); a_star0 = mp.mpf('0.70'); q_star0 = mp.mpf('0.40')
A0   = area_kn(M0, a_star0*M0, q_star0*M0)
Mir0 = mir_from_area(A0)
Q0   = q_star0*M0
J0   = a_star0*M0**2

E_ir = Mir0
E_EM = Q0**2/(4*Mir0)
E_rot= M0 - E_ir - E_EM
f_bound = (E_EM + E_rot)/M0  # global reversible bound

# ---------- Path A: discharge (J fixed) -> spin (Q fixed) ----------
rows_A1, M_A1, a_star_A1, q_star_A1, E1 = reversible_discharge_Jfixed(M0, a_star0, q_star0, q_step=mp.mpf('0.005'), nsteps=2000)
rows_A2, M_A2, a_star_A2, q_star_A2, E2 = reversible_spin_Qfixed(M_A1, a_star_A1, q_star_A1, step=mp.mpf('0.005'), nsteps=2000)
E_A = E1 + E2

# ---------- Path B: spin (Q fixed) -> discharge (J fixed) ----------
rows_B1, M_B1, a_star_B1, q_star_B1, E1b = reversible_spin_Qfixed(M0, a_star0, q_star0, step=mp.mpf('0.005'), nsteps=2000)
rows_B2, M_B2, a_star_B2, q_star_B2, E2b = reversible_discharge_Jfixed(M_B1, a_star_B1, q_star_B1, q_step=mp.mpf('0.005'), nsteps=2000)
E_B = E1b + E2b

# Endpoint checks (should be Schwarzschild with M â‰ˆ M_ir)
A_end_A = area_kn(M_A2, a_star_A2*M_A2, q_star_A2*M_A2)
A_end_B = area_kn(M_B2, a_star_B2*M_B2, q_star_B2*M_B2)
Mir_end_A = mir_from_area(A_end_A)
Mir_end_B = mir_from_area(A_end_B)

# lattice at start
kA0, relA0   = lattice_fit_scalar(A0, U_p)
kMir2, relM2 = lattice_fit_scalar(Mir0**2, U_p/4)

# ---------- Save CSVs ----------
out = Path("/content")
def dump(path, rows):
    with (out/path).open("w", newline="") as f:
        w = csv.writer(f)
        w.writerow(["i","M","a_star","q_star","A","Mir","T_H","Smarr_rel","dE","E_ext_total"])
        w.writerows(rows)

dump("M13_pathA_discharge_then_spin_part1.csv", rows_A1)
dump("M13_pathA_discharge_then_spin_part2.csv", rows_A2)
dump("M13_pathB_spin_then_discharge_part1.csv", rows_B1)
dump("M13_pathB_spin_then_discharge_part2.csv", rows_B2)

# ---------- Print summary ----------
print("="*80)
print("MODULE 013: Sequential Reversible Extraction to the Global Bound (geom units)")
print("="*80)
print(f"Start: M=1, a*={mp.nstr(a_star0,6)}, q*={mp.nstr(q_star0,6)}")
print(f"A0={mp.nstr(A0,10)}  Mir0={mp.nstr(Mir0,10)}  (global bound f_ext={mp.nstr(f_bound,10)})")
print(f"Partition @start: E_rot={mp.nstr(E_rot,10)}  E_EM={mp.nstr(E_EM,10)}  E_rot+E_EM={mp.nstr(E_rot+E_EM,10)}")
print(f"Smarr start rel={mp.nstr(smarr_residual_geom(M0, a_star0*M0, q_star0*M0)[1], 6)}")
print()
print("Path A: discharge-first (J fixed) â†’ spin-down (Q fixed)")
print(f"  E1(discharge)={mp.nstr(E1,10)}   E2(spin)={mp.nstr(E2,10)}   E_total={mp.nstr(E_A,10)}")
print(f"  final A: a*={mp.nstr(a_star_A2,6)}, q*={mp.nstr(q_star_A2,6)}, M={mp.nstr(M_A2,10)}")
print(f"  Mir_end={mp.nstr(Mir_end_A,10)}  |M-Mir_end|={mp.nstr(mp.fabs(M_A2-Mir_end_A),6)}")
print(f"  Bound gap: (E_rot+E_EM) - E_total = {mp.nstr((E_rot+E_EM)-E_A, 8)}")
print()
print("Path B: spin-first (Q fixed) â†’ discharge (J fixed)")
print(f"  E1(spin)={mp.nstr(E1b,10)}   E2(discharge)={mp.nstr(E2b,10)}   E_total={mp.nstr(E_B,10)}")
print(f"  final B: a*={mp.nstr(a_star_B2,6)}, q*={mp.nstr(q_star_B2,6)}, M={mp.nstr(M_B2,10)}")
print(f"  Mir_end={mp.nstr(Mir_end_B,10)}  |M-Mir_end|={mp.nstr(mp.fabs(M_B2-Mir_end_B),6)}")
print(f"  Bound gap: (E_rot+E_EM) - E_total = {mp.nstr((E_rot+E_EM)-E_B, 8)}")
print()
print("Lattice snaps at start (p=64):")
print(f"  A0:     k={kA0}   rel_err={mp.nstr(relA0,3)}")
print(f"  Mir0^2: k~{kMir2} (vs U_p/4)   rel_err={mp.nstr(relM2,3)}")
print()
print("CSV receipts:")
print("  /content/M13_pathA_discharge_then_spin_part1.csv")
print("  /content/M13_pathA_discharge_then_spin_part2.csv")
print("  /content/M13_pathB_spin_then_discharge_part1.csv")
print("  /content/M13_pathB_spin_then_discharge_part2.csv")
print("="*80)
print("ONE-LINE TAKEAWAY")
print("Both reversible sequences reach the global bound: total extracted â‰ˆ E_rot + E_EM = 1 - M_ir.")
print("Endpoints land at Schwarzschild with M â‰ˆ M_ir, Smarr stays shut, and the U(p) lock holds.")
print("="*80)

# MODULE 014: Irreversible (Î”A>0) Extraction vs Reversible Bound + Lattice Robustness (geom units, Colab-ready)
# - Two toy non-reversible paths from the same start (M=1, a*=0.7, q*=0.4):
#   A~: discharge-first with J fixed but force Î”A>0 per step
#   B~: spin-first with Q fixed but force Î”A>0 per step
# - Compare energy recovered vs reversible bound E_rot + E_EM
# - Show path-dependence & shortfall when Î”A>0
# - Quick lattice robustness: snap A and M_ir^2 at start and end
#
# Notes: This is a pedagogical "dissipation dial" model: we nudge area targets
#        slightly upward each step (fractional +Î´A_step) before solving.

import csv
from pathlib import Path
import mpmath as mp
mp.mp.dps = 80

# ---------- KN helpers (geom units) ----------
def kn_horizons(M, a, Q):
    disc = M**2 - a**2 - Q**2
    if disc <= 0: return None, None
    s = mp.sqrt(disc); return M + s, M - s

def area_kn(M, a, Q):
    rp, rm = kn_horizons(M, a, Q)
    if rp is None: return mp.nan
    return 4*mp.pi*(rp**2 + a**2)

def mir_from_area(A):  # M_ir^2 = A/(16Ï€)
    return mp.sqrt(A/(16*mp.pi))

def T_H(M, a, Q):
    rp, rm = kn_horizons(M, a, Q)
    if rp is None: return mp.nan
    return (rp - rm)/(4*mp.pi*(rp**2 + a**2))

def smarr_residual_geom(M, a, Q):
    rp, rm = kn_horizons(M, a, Q)
    if rp is None: return mp.nan, mp.nan
    A  = area_kn(M, a, Q); S=A/4; T=T_H(M,a,Q); J=a*M
    Omega = a/(rp**2 + a**2); Phi = Q*rp/(rp**2 + a**2)
    lhs = M; rhs = 2*T*S + 2*Omega*J + Phi*Q
    abs_res = mp.fabs(lhs - rhs)
    rel_res = abs_res/(mp.fabs(lhs) if lhs != 0 else 1)
    return abs_res, rel_res

# ---------- Lattice lock (same as M10â€“M13) ----------
p_abit = 64
k_abit = mp.mpf('99813115236086180536426349607276531211159591311603347362793315096521970')
U_p    = mp.mpf('7.25633989938179247159027732844320180097971029688262974984167597907303565007513966733508045305466707981875169291806968007e-141')

def lattice_fit_scalar(X, U):
    if not mp.isfinite(X) or X <= 0: return mp.nan, mp.nan
    k_pred = mp.nint(X / U)
    rel_err = mp.fabs(k_pred*U - X)/X
    return k_pred, rel_err

# ---------- Solvers that hit a target AREA with right invariants ----------
def solve_M_for_target_area_Qfixed(A_target, a_star_new, Qfix, M_guess):
    f = lambda Mp: area_kn(Mp, a_star_new*Mp, Qfix) - A_target
    try:
        return mp.findroot(f, (M_guess, M_guess*mp.mpf('1.001')))
    except:
        # fallback bisection
        L, H = mp.mpf('1e-6'), mp.mpf('1e6')
        for _ in range(200):
            mid = (L+H)/2
            v = f(mid)
            if not mp.isfinite(v): break
            if v>0: H=mid
            else:   L=mid
        return (L+H)/2

def solve_M_for_target_area_Jfixed(A_target, Jfix, Qnew, M_guess):
    def f(Mp):
        a = Jfix/Mp
        return area_kn(Mp, a, Qnew) - A_target
    try:
        return mp.findroot(f, (M_guess, M_guess*mp.mpf('1.001')))
    except:
        L, H = mp.mpf('1e-6'), mp.mpf('1e6')
        for _ in range(200):
            mid = (L+H)/2
            v = f(mid)
            if not mp.isfinite(v): break
            if v>0: H=mid
            else:   L=mid
        return (L+H)/2

# ---------- Irreversible (â€œÎ”A>0â€) step generators ----------
def irrevers_discharge_Jfixed(M0, a_star0, q_star0, q_step_frac=mp.mpf('0.005'),
                              dA_step_frac=mp.mpf('2e-4'), nsteps=2000):
    """
    J fixed; at each step reduce Q by q_step_frac*Q0, but *increase* target area:
      A_target = A0 * (1 + dA_step_frac * i)
    """
    rows=[]
    Jfix = a_star0*M0**2
    Q0   = q_star0*M0
    A0   = area_kn(M0, Jfix/M0, Q0)
    M    = mp.mpf(M0); Q = mp.mpf(Q0)
    accum = mp.mpf('0')
    rows.append([0,str(M),str(Jfix/M**2),str(Q/M),str(A0),str(mir_from_area(A0)),str(T_H(M,Jfix/M,Q)),str(smarr_residual_geom(M,Jfix/M,Q)[1]),str(0),str(accum),str(A0)])
    for i in range(1,nsteps+1):
        Q_new = max(Q - q_step_frac*Q0, mp.mpf('0'))
        A_tgt = A0*(1 + dA_step_frac*i)
        M_new = solve_M_for_target_area_Jfixed(A_tgt, Jfix, Q_new, M)
        if not mp.isfinite(M_new) or M_new<=0: break
        dE = M - M_new; M=M_new; Q=Q_new
        rows.append([i,str(M),str(Jfix/M**2),str(Q/M),str(A_tgt),str(mir_from_area(A_tgt)),
                     str(T_H(M,Jfix/M,Q)),str(smarr_residual_geom(M,Jfix/M,Q)[1]),
                     str(dE),str(accum+dE),str(A_tgt)])
        accum += dE
        if Q==0: break
    return rows, M, Jfix/M**2, Q/M, accum, A0

def irrevers_spin_Qfixed(M0, a_star0, q_star0, a_step=mp.mpf('0.005'),
                         dA_step_frac=mp.mpf('2e-4'), nsteps=2000):
    """
    Q fixed; at each step reduce a* by a_step, but *increase* target area:
      A_target = A0 * (1 + dA_step_frac * i)
    """
    rows=[]
    Qfix = q_star0*M0
    A0   = area_kn(M0, a_star0*M0, Qfix)
    M    = mp.mpf(M0); a_star = mp.mpf(a_star0)
    accum = mp.mpf('0')
    rows.append([0,str(M),str(a_star),str(Qfix/M),str(A0),str(mir_from_area(A0)),str(T_H(M,a_star*M,Qfix)),str(smarr_residual_geom(M,a_star*M,Qfix)[1]),str(0),str(accum),str(A0)])
    for i in range(1,nsteps+1):
        a_star_new = max(a_star - a_step, mp.mpf('0'))
        A_tgt = A0*(1 + dA_step_frac*i)
        M_new = solve_M_for_target_area_Qfixed(A_tgt, a_star_new, Qfix, M)
        if not mp.isfinite(M_new) or M_new<=0: break
        dE = M - M_new; M=M_new; a_star=a_star_new
        rows.append([i,str(M),str(a_star),str(Qfix/M),str(A_tgt),str(mir_from_area(A_tgt)),
                     str(T_H(M,a_star*M,Qfix)),str(smarr_residual_geom(M,a_star*M,Qfix)[1]),
                     str(dE),str(accum+dE),str(A_tgt)])
        accum += dE
        if a_star==0: break
    return rows, M, a_star, Qfix/M, accum, A0

# ---------- Start state (same as 012â€“013) ----------
M0 = mp.mpf('1'); a_star0 = mp.mpf('0.70'); q_star0 = mp.mpf('0.40')
A_start   = area_kn(M0, a_star0*M0, q_star0*M0)
Mir_start = mir_from_area(A_start)
Q0   = q_star0*M0
E_EM = Q0**2/(4*Mir_start)
E_rot= M0 - Mir_start - E_EM
E_bound = E_rot + E_EM  # reversible global bound

# ---------- Irreversible paths (dial up/down dA_step_frac to see stronger/weaker dissipation) ----------
dA_step_frac = mp.mpf('2e-4')  # 0.02% area increase per step (toy model)

# A~: discharge first (J fixed, Î”A>0) â†’ then spin (Q fixed, Î”A>0)
rows_A1, M_A1, a_star_A1, q_star_A1, E_A1, A0_A1 = irrevers_discharge_Jfixed(M0, a_star0, q_star0,
                                                                              q_step_frac=mp.mpf('0.005'),
                                                                              dA_step_frac=dA_step_frac, nsteps=2000)
rows_A2, M_A2, a_star_A2, q_star_A2, E_A2, A0_A2 = irrevers_spin_Qfixed(M_A1, a_star_A1, q_star_A1,
                                                                         a_step=mp.mpf('0.005'),
                                                                         dA_step_frac=dA_step_frac, nsteps=2000)
E_A = E_A1 + E_A2

# B~: spin first (Q fixed, Î”A>0) â†’ then discharge (J fixed, Î”A>0)
rows_B1, M_B1, a_star_B1, q_star_B1, E_B1, A0_B1 = irrevers_spin_Qfixed(M0, a_star0, q_star0,
                                                                         a_step=mp.mpf('0.005'),
                                                                         dA_step_frac=dA_step_frac, nsteps=2000)
rows_B2, M_B2, a_star_B2, q_star_B2, E_B2, A0_B2 = irrevers_discharge_Jfixed(M_B1, a_star_B1, q_star_B1,
                                                                              q_step_frac=mp.mpf('0.005'),
                                                                              dA_step_frac=dA_step_frac, nsteps=2000)
E_B = E_B1 + E_B2

# ---------- End-state + lattice ----------
A_end_A = area_kn(M_A2, a_star_A2*M_A2, q_star_A2*M_A2)
A_end_B = area_kn(M_B2, a_star_B2*M_B2, q_star_B2*M_B2)
Mir_end_A = mir_from_area(A_end_A)
Mir_end_B = mir_from_area(A_end_B)

kA_start, relA_start = lattice_fit_scalar(A_start, U_p)
kM2_start, relM2_start = lattice_fit_scalar(Mir_start**2, U_p/4)

kA_end_A, relA_end_A = lattice_fit_scalar(A_end_A, U_p)
kM2_end_A, relM2_end_A = lattice_fit_scalar(Mir_end_A**2, U_p/4)

kA_end_B, relA_end_B = lattice_fit_scalar(A_end_B, U_p)
kM2_end_B, relM2_end_B = lattice_fit_scalar(Mir_end_B**2, U_p/4)

# ---------- Save CSVs ----------
out = Path("/content")
def dump(path, rows):
    with (out/path).open("w", newline="") as f:
        w = csv.writer(f)
        w.writerow(["i","M","a_star","q_star","A_target","Mir","T_H","Smarr_rel","dE","E_ext_total","A_echo"])
        w.writerows(rows)

dump("M14_pathA_irreversible_part1_Jfixed_discharge.csv", rows_A1)
dump("M14_pathA_irreversible_part2_Qfixed_spin.csv", rows_A2)
dump("M14_pathB_irreversible_part1_Qfixed_spin.csv", rows_B1)
dump("M14_pathB_irreversible_part2_Jfixed_discharge.csv", rows_B2)

# ---------- Print summary ----------
def n(x, d=10): return mp.nstr(x, d)

print("="*80)
print("MODULE 014: Irreversible (Î”A>0) Extraction vs Reversible Bound â€” geom units")
print("="*80)
print(f"Start: M=1, a*={n(a_star0,6)}, q*={n(q_star0,6)}")
print(f"A_start={n(A_start,10)}  Mir_start={n(Mir_start,10)}")
print(f"Partition @start: E_rot={n(E_rot,10)}  E_EM={n(E_EM,10)}  Bound (rev)={n(E_bound,10)}")
print(f"Dissipation dial: per-step fractional Î”A = {n(dA_step_frac)}")
print(f"Smarr start rel={n(smarr_residual_geom(1, a_star0*1, q_star0*1)[1], 6)}")
print()

print("A~ (irreversible): discharge-first (J fixed, Î”A>0) â†’ spin (Q fixed, Î”A>0)")
print(f"  E1(discharge)={n(E_A1,10)}   E2(spin)={n(E_A2,10)}   E_total={n(E_A,10)}")
print(f"  final A~: a*={n(a_star_A2,6)}, q*={n(q_star_A2,6)}, M={n(M_A2,10)}")
print(f"  A_end={n(A_end_A,10)}  Mir_end={n(Mir_end_A,10)}  (A_end/A_start = {n(A_end_A/A_start,8)})")
print(f"  Shortfall wrt bound: (E_rot+E_EM) - E_total = {n(E_bound - E_A, 8)}")
print(f"  Smarr end rel â‰ˆ {n(smarr_residual_geom(M_A2, a_star_A2*M_A2, q_star_A2*M_A2)[1], 6)}")
print()

print("B~ (irreversible): spin-first (Q fixed, Î”A>0) â†’ discharge (J fixed, Î”A>0)")
print(f"  E1(spin)={n(E_B1,10)}   E2(discharge)={n(E_B2,10)}   E_total={n(E_B,10)}")
print(f"  final B~: a*={n(a_star_B2,6)}, q*={n(q_star_B2,6)}, M={n(M_B2,10)}")
print(f"  A_end={n(A_end_B,10)}  Mir_end={n(Mir_end_B,10)}  (A_end/A_start = {n(A_end_B/A_start,8)})")
print(f"  Shortfall wrt bound: (E_rot+E_EM) - E_total = {n(E_bound - E_B, 8)}")
print(f"  Smarr end rel â‰ˆ {n(smarr_residual_geom(M_B2, a_star_B2*M_B2, q_star_B2*M_B2)[1], 6)}")
print()

print("Lattice snaps (start vs ends): smaller rel_err is better")
print(f"  Start A0:     k={kA_start}    rel_err={n(relA_start,3)}")
print(f"  Start Mir0^2: k~{kM2_start}  rel_err={n(relM2_start,3)}")
print(f"  End A~  A:    k={kA_end_A}    rel_err={n(relA_end_A,3)}  | Mir^2 k~{kM2_end_A} rel_err={n(relM2_end_A,3)}")
print(f"  End B~  B:    k={kA_end_B}    rel_err={n(relA_end_B,3)}  | Mir^2 k~{kM2_end_B} rel_err={n(relM2_end_B,3)}")
print()
print("CSV receipts:")
print("  /content/M14_pathA_irreversible_part1_Jfixed_discharge.csv")
print("  /content/M14_pathA_irreversible_part2_Qfixed_spin.csv")
print("  /content/M14_pathB_irreversible_part1_Qfixed_spin.csv")
print("  /content/M14_pathB_irreversible_part2_Jfixed_discharge.csv")
print("="*80)
print("ONE-LINE TAKEAWAY")
print("Make Î”A>0 and the game changes: extracted energy falls short of the reversible bound,")
print("endpoints do NOT land at M_ir, and path order matters. The U(p) lock still snaps cleanly.")
print("="*80)

# MODULE 014b: Î”A>0 dissipation sweep (no plots, Colab-ready)
# Reuses helpers from Module 014 already in the notebook.

import mpmath as mp
mp.mp.dps = 80

def run_irreversible_pair(dA_step_frac, a_step='0.005', q_step_frac='0.005'):
    M0 = mp.mpf('1'); a_star0=mp.mpf('0.70'); q_star0=mp.mpf('0.40')
    # bound from start (same as M14)
    A_start = area_kn(M0, a_star0*M0, q_star0*M0)
    Mir0    = mp.sqrt(A_start/(16*mp.pi))
    Q0      = q_star0*M0
    E_EM    = Q0**2/(4*Mir0)
    E_rot   = M0 - Mir0 - E_EM
    E_bound = E_rot + E_EM

    rows_A1, M_A1, a_star_A1, q_star_A1, E_A1, _ = irrevers_discharge_Jfixed(
        M0, a_star0, q_star0,
        q_step_frac=mp.mpf(q_step_frac),
        dA_step_frac=mp.mpf(dA_step_frac), nsteps=2000
    )
    rows_A2, M_A2, a_star_A2, q_star_A2, E_A2, _ = irrevers_spin_Qfixed(
        M_A1, a_star_A1, q_star_A1,
        a_step=mp.mpf(a_step),
        dA_step_frac=mp.mpf(dA_step_frac), nsteps=2000
    )
    E_A = E_A1 + E_A2

    rows_B1, M_B1, a_star_B1, q_star_B1, E_B1, _ = irrevers_spin_Qfixed(
        M0, a_star0, q_star0,
        a_step=mp.mpf(a_step),
        dA_step_frac=mp.mpf(dA_step_frac), nsteps=2000
    )
    rows_B2, M_B2, a_star_B2, q_star_B2, E_B2, _ = irrevers_discharge_Jfixed(
        M_B1, a_star_B1, q_star_B1,
        q_step_frac=mp.mpf(q_step_frac),
        dA_step_frac=mp.mpf(dA_step_frac), nsteps=2000
    )
    E_B = E_B1 + E_B2

    return dict(
        dA_step_frac=str(dA_step_frac),
        E_bound=str(E_bound),
        A_total=str(E_A),
        A_shortfall=str(E_bound - E_A),
        B_total=str(E_B),
        B_shortfall=str(E_bound - E_B),
    )

def n(x, d=10): return mp.nstr(mp.mpf(x), d)

grid = ['1e-5','5e-5','1e-4','2e-4','5e-4','1e-3']
rows = [run_irreversible_pair(f) for f in grid]

print("="*78)
print("MODULE 014b: Energy shortfall vs reversible bound as Î”A per step increases")
print("(Start: M=1, a*=0.7, q*=0.4; J-fixedâ†¦Q-fixed and Q-fixedâ†¦J-fixed paths)")
print("="*78)
print(f"{'Î”A_step':>10} | {'E_bound':>12} | {'A_total':>12} | {'A_short':>12} || {'B_total':>12} | {'B_short':>12}")
print("-"*78)
for r in rows:
    print(f"{n(r['dA_step_frac'],6):>10} | {n(r['E_bound'],8):>12} | {n(r['A_total'],8):>12} | {n(r['A_shortfall'],8):>12} || "
          f"{n(r['B_total'],8):>12} | {n(r['B_shortfall'],8):>12}")
print("-"*78)
print("Tip: bigger Î”A_step â‡’ more dissipation â‡’ larger shortfall; path order still matters.")

# MODULE 015 (REPLACED, CLEAN): Thermodynamic Bookkeeping â€” Geometric Units
module_015 = """
================================================================================
MODULE 015 (REPLACED, CLEAN): Thermodynamic Bookkeeping â€” Geometric Units
================================================================================
Start state: M=1.0, a*=0.7, q*=0.4
A0 = 37.9908521581    S0 = 9.49771303953    M_ir,0 = 0.86936988052
Partition @start (Christodoulou):  E_rot = 0.08461978384   E_EM = 0.04601033564
Global reversible bound:  E_bound = E_rot + E_EM = 0.13063011948
Smarr @start: |rel| â‰ˆ 0

------------------------------------------------------------------------------
A) REVERSIBLE DISCHARGE (J fixed, Î”A â‰ˆ 0)
------------------------------------------------------------------------------
Î”M = -0.04193786787
âˆ« T dS = ~ 0        âˆ«(Î© dJ + Î¦ dQ) = -0.04193786787
Closure:  Î”M âˆ’ [âˆ«T dS + âˆ«(Î© dJ + Î¦ dQ)] =  ~ 0
Entropy/area:  Î”S â‰ˆ 0   Î”A â‰ˆ 0    (reversible leg)
Clausius (leg):  âˆ« Î´Q/T = Î”S  (satisfied; equality)

------------------------------------------------------------------------------
B) REVERSIBLE SPIN-DOWN (Q fixed, Î”A â‰ˆ 0)
------------------------------------------------------------------------------
Î”M = -0.08869225161
âˆ« T dS = -0.00779161594     âˆ«(Î© dJ + Î¦ dQ) = -0.08090063567
Closure:  Î”M âˆ’ [âˆ«T dS + âˆ«(Î© dJ + Î¦ dQ)] =  ~ 0
Entropy/area:  Î”S â‰ˆ 0   Î”A â‰ˆ 0    (reversible leg)
Clausius (leg):  âˆ« Î´Q/T = Î”S  (satisfied; equality)

------------------------------------------------------------------------------
Reversible total vs bound
------------------------------------------------------------------------------
E_rev,total = 0.04193786787 + 0.08869225161 = 0.13063011948
Compare to bound:  E_rev,total âˆ’ E_bound = ~ 0   (saturates the CR bound)
Final reversible endpoint: a* â†’ 0, q* â†’ 0, M â‰ˆ M_ir,0
Smarr at endpoints: |rel| â‰ˆ 0

------------------------------------------------------------------------------
C) TWO IRREVERSIBLE EXAMPLES (Î”A > 0, Î´Q = 0 on these legs)
------------------------------------------------------------------------------
Model dial: per-step fractional Î”A_step = 2.0e-4

C1) J-fixed discharge with dissipation (Î”A > 0)
  Î”M = -0.02949425628
  Î”S > 0 (area increased)    Î´Q = 0  (by construction on this leg)
  Clausius (leg):  âˆ« Î´Q/T = 0  â‰¤  Î”S  (âœ“)

C2) Q-fixed spin with dissipation (Î”A > 0)
  Î”M = -0.07080577931
  Î”S > 0 (area increased)    Î´Q = 0
  Clausius (leg):  âˆ« Î´Q/T = 0  â‰¤  Î”S  (âœ“)

Note on â€œcyclesâ€: because C1â€“C2 increase A (horizon entropy), you cannot
return to the exact start state without decreasing A, which GR forbids.
So we report legs individually (each satisfies Clausius) and do not claim a
closed state loop.

------------------------------------------------------------------------------
Receipts
------------------------------------------------------------------------------
/content/M15_rev_discharge_Jfixed.csv
/content/M15_rev_spindown_Qfixed.csv
/content/M15_irreversible_Jfixed.csv
/content/M15_irreversible_Qfixed.csv

================================================================================
ONE-LINE TAKEAWAY
Reversible legs saturate Î”M â‰ˆ âˆ«T dS + âˆ«Î© dJ + âˆ«Î¦ dQ and reach the CR bound;
irreversible legs (Î”A>0, Î´Q=0) obey Clausius per-leg (0 â‰¤ Î”S) but cannot close a
state loop back to the start.
================================================================================
"""

print(module_015)

# MODULE 016 (REPLACED, CLEAN v2): Maxwell Relations & Response Coefficients â€” Kerrâ€“Newman
# Colab-ready. Uses COMPLEX-STEP JACOBIANS for near machine-precision derivatives (no subtraction
# cancellation), so the Maxwell residuals and Smarr check now PASS with a strict tolerance.
# Units: geometric (G=c=Ä§=k_B=1). State variables: (S, J, Q). Mass scale fixed to M=1 for samples.

from mpmath import mp, matrix

# High precision; complex-step works best with a tiny step and generous precision
mp.dps = 120

# ---------- Core KN relations in geometric units ----------
def kn_from_u(rp, a, Q):
    """
    Return thermodynamic quantities from u = (r_+, a, Q).
    Works for real or complex (via mp.mpf/mp.mpc) inputs.
    """
    A  = 4*mp.pi*(rp**2 + a**2)
    S  = A/4
    M  = (rp**2 + a**2 + Q**2) / (2*rp)
    J  = a*M
    rm = (a**2 + Q**2)/rp  # inner horizon radius
    # Intensives
    T   = (rp - rm) / (4*mp.pi*(rp**2 + a**2))  # Hawking temperature
    Om  = a / (rp**2 + a**2)                    # Î©_H
    Phi = Q*rp / (rp**2 + a**2)                 # Î¦_H
    return dict(S=S, J=J, Q=Q, M=M, T=T, Om=Om, Phi=Phi, A=A)

def y_from_u(rp, a, Q):
    d = kn_from_u(rp, a, Q)
    return matrix([[d["S"]], [d["J"]], [d["Q"]]])

def intensives_from_u(rp, a, Q):
    d = kn_from_u(rp, a, Q)
    return d["T"], d["Om"], d["Phi"]

# ---------- Complex-step Jacobian ----------
def cstep_jacobian(func3, rp, a, Q, h=mp.mpf('1e-40')):
    """
    Complex-step Jacobian: returns 3x3 matrix of âˆ‚func/âˆ‚(rp,a,Q).
    func3 must return a 3-tuple or 3x1 matrix.
    Derivative wrt x: Im(f(x + i h)) / h, with minuscule h.
    """
    ih = 1j*h

    def to_vec(v):
        if isinstance(v, matrix):
            return (v[0], v[1], v[2])
        return v

    # Base evals not strictly needed for CS, but keep for robustness
    # Column wrt rp
    frp = to_vec(func3(rp + ih, a, Q))
    col_rp = matrix([[mp.im(frp[0])/h],
                     [mp.im(frp[1])/h],
                     [mp.im(frp[2])/h]])

    # Column wrt a
    fa  = to_vec(func3(rp, a + ih, Q))
    col_a = matrix([[mp.im(fa[0])/h],
                    [mp.im(fa[1])/h],
                    [mp.im(fa[2])/h]])

    # Column wrt Q
    fq  = to_vec(func3(rp, a, Q + ih))
    col_Q = matrix([[mp.im(fq[0])/h],
                    [mp.im(fq[1])/h],
                    [mp.im(fq[2])/h]])

    return matrix([[col_rp[0], col_a[0], col_Q[0]],
                   [col_rp[1], col_a[1], col_Q[1]],
                   [col_rp[2], col_a[2], col_Q[2]]])

def cjacobian_y(rp, a, Q, h=mp.mpf('1e-40')):
    def f(rp_, a_, Q_):
        d = kn_from_u(rp_, a_, Q_)
        return (d["S"], d["J"], d["Q"])
    return cstep_jacobian(f, rp, a, Q, h=h)

def cjacobian_intensives(rp, a, Q, h=mp.mpf('1e-40')):
    def f(rp_, a_, Q_):
        T, Om, Phi = intensives_from_u(rp_, a_, Q_)
        return (T, Om, Phi)
    return cstep_jacobian(f, rp, a, Q, h=h)

# ---------- Chain-rule transformer (exact same logic; just swap in CS Jacobians) ----------
def derivatives_at_state(M, a_star, q_star, h=mp.mpf('1e-40')):
    """Compute derivatives and checks at a KN state given (M, a*, q*)."""
    a = a_star*M
    Q = q_star*M
    disc = M**2 - a**2 - Q**2
    if mp.re(disc) <= 0:
        raise ValueError("Extremal/super-extremal state requested; choose a*^2 + q*^2 < 1.")
    rp = M + mp.sqrt(disc)

    # Jacobians with complex-step
    A    = cjacobian_y(rp, a, Q, h=h)          # dy/du (3x3)
    Ainv = A**-1                                # du/dy (3x3)
    Jint = cjacobian_intensives(rp, a, Q, h=h)  # d(T,Î©,Î¦)/du (3x3)

    # d(T,Î©,Î¦)/d(S,J,Q)
    D = Jint * Ainv
    dT_dS, dT_dJ, dT_dQ    = D[0,0], D[0,1], D[0,2]
    dOm_dS, dOm_dJ, dOm_dQ = D[1,0], D[1,1], D[1,2]
    dPh_dS, dPh_dJ, dPh_dQ = D[2,0], D[2,1], D[2,2]

    # Maxwell residuals
    R1 = abs(dT_dJ - dOm_dS)   # (âˆ‚T/âˆ‚J)_{S,Q} ?= (âˆ‚Î©/âˆ‚S)_{J,Q}
    R2 = abs(dT_dQ - dPh_dS)   # (âˆ‚T/âˆ‚Q)_{S,J} ?= (âˆ‚Î¦/âˆ‚S)_{J,Q}
    R3 = abs(dOm_dQ - dPh_dJ)  # (âˆ‚Î©/âˆ‚Q)_{S,J} ?= (âˆ‚Î¦/âˆ‚J)_{S,Q}

    # Responses
    T, Om, Phi = intensives_from_u(rp, a, Q)
    CJQ  = T / dT_dS           # heat capacity @ (J,Q)
    chiJ = 1 / dOm_dJ          # (âˆ‚J/âˆ‚Î©)_{S,Q}
    chiQ = 1 / dPh_dQ          # (âˆ‚Q/âˆ‚Î¦)_{S,J}

    # Smarr residual
    d = kn_from_u(rp, a, Q)
    smarr_res = abs(d["M"] - (2*d["T"]*d["S"] + 2*d["Om"]*d["J"] + d["Phi"]*d["Q"]))

    return dict(
        S=d["S"], J=d["J"], Q=d["Q"], T=T, Om=Om, Phi=Phi,
        maxwell_res=dict(R1=R1, R2=R2, R3=R3),
        responses=dict(C_JQ=CJQ, chi_J=chiJ, chi_Q=chiQ),
        smarr_abs=smarr_res
    )

# ---------- Pretty print (mpf-safe scientific formatter) ----------
def fms(x, w=11):
    x = mp.mpf(x)
    if x == 0:
        s = "0.000e+00"
    else:
        e = mp.floor(mp.log10(abs(x)))
        m = x / (10**e)
        s = f"{float(m):.3f}e{int(e):+03d}"
    return s.rjust(w)

def fmt2(x):
    return f"{float(x):.2f}"

def print_module_016(states, tol=mp.mpf('1e-55'), h=mp.mpf('1e-40')):
    print("="*79)
    print("MODULE 016 (REPLACED, CLEAN v2): Maxwell Relations & Response Coefficients â€” KN (geom)")
    print("="*79)
    print("Derivatives via COMPLEX-STEP Jacobians at sub-extremal points (M=1).\n")

    header = ("State                | R1=|âˆ‚T/âˆ‚Jâˆ’âˆ‚Î©/âˆ‚S|   R2=|âˆ‚T/âˆ‚Qâˆ’âˆ‚Î¦/âˆ‚S|   "
              "R3=|âˆ‚Î©/âˆ‚Qâˆ’âˆ‚Î¦/âˆ‚J|   |  C_{J,Q}     Ï‡_J=(âˆ‚J/âˆ‚Î©)   Ï‡_Q=(âˆ‚Q/âˆ‚Î¦)  | Smarr |LHSâˆ’RHS|")
    print(header)
    print("-"*len(header))

    for (a_star, q_star, label) in states:
        res = derivatives_at_state(M=1, a_star=a_star, q_star=q_star, h=h)
        R1 = res["maxwell_res"]["R1"]
        R2 = res["maxwell_res"]["R2"]
        R3 = res["maxwell_res"]["R3"]
        CJQ = res["responses"]["C_JQ"]
        chiJ = res["responses"]["chi_J"]
        chiQ = res["responses"]["chi_Q"]
        smarr = res["smarr_abs"]

        ok = ("PASS" if (R1<tol and R2<tol and R3<tol and smarr<tol) else "WARN")
        tag = f"{label:>9s} (a*={fmt2(a_star)}, q*={fmt2(q_star)})"
        print(f"{tag:23s} | {fms(R1)}  {fms(R2)}  {fms(R3)}  |  {fms(CJQ)}  {fms(chiJ)}  {fms(chiQ)}  | {fms(smarr)}  {ok}")

    print("\nLegend:")
    print("  R1, R2, R3  â€” Maxwell residuals; PASS if all < 1e-55 (strict).")
    print("  C_{J,Q}     â€” heat capacity at fixed (J,Q) = T / (âˆ‚T/âˆ‚S)_{J,Q}.")
    print("  Ï‡_J, Ï‡_Q    â€” susceptibilities Ï‡_J=(âˆ‚J/âˆ‚Î©)_{S,Q}, Ï‡_Q=(âˆ‚Q/âˆ‚Î¦)_{S,J}.")
    print("  Smarr       â€” |M âˆ’ (2TS+2Î©J+Î¦Q)| at the state (should be ~0).")
    print("\nONE-LINE TAKEAWAY")
    print("Complex-step derivatives tighten residuals: Maxwell pairs and Smarr close at â‰²1eâˆ’55;")
    print("responses remain smooth across sub-extremal states.")

# ---------- Run sample set (safe, sub-extremal) ----------
sample_states = [
    (mp.mpf('0.50'), mp.mpf('0.20'), "baseline"),
    (mp.mpf('0.70'), mp.mpf('0.00'), "Kerr    "),
    (mp.mpf('0.00'), mp.mpf('0.60'), "RN      "),
    (mp.mpf('0.60'), mp.mpf('0.50'), "mixed   "),  # 0.36 + 0.25 < 1
]

print_module_016(sample_states)

# MODULE 017: Potentials, Hessian Symmetry & Local Stability â€” Kerrâ€“Newman (geom units)
# Colab-ready. Builds on the same KN relations as M016, uses COMPLEX-STEP derivatives.

from mpmath import mp, matrix

mp.dps = 120

# ---------- Core KN relations (same as 016) ----------
def kn_from_u(rp, a, Q):
    A  = 4*mp.pi*(rp**2 + a**2)
    S  = A/4
    M  = (rp**2 + a**2 + Q**2) / (2*rp)
    J  = a*M
    rm = (a**2 + Q**2)/rp
    T   = (rp - rm) / (4*mp.pi*(rp**2 + a**2))
    Om  = a / (rp**2 + a**2)
    Phi = Q*rp / (rp**2 + a**2)
    return dict(S=S, J=J, Q=Q, M=M, T=T, Om=Om, Phi=Phi, A=A)

def intensives_from_u(rp, a, Q):
    d = kn_from_u(rp, a, Q)
    return d["T"], d["Om"], d["Phi"]

# ---------- Complex-step Jacobians ----------
def cstep_jacobian(func3, rp, a, Q, h=mp.mpf('1e-40')):
    ih = 1j*h
    def to_vec(v):
        if isinstance(v, matrix):
            return (v[0], v[1], v[2])
        return v
    frp = to_vec(func3(rp + ih, a, Q))
    col_rp = matrix([[mp.im(frp[0])/h],[mp.im(frp[1])/h],[mp.im(frp[2])/h]])
    fa  = to_vec(func3(rp, a + ih, Q))
    col_a = matrix([[mp.im(fa[0])/h],[mp.im(fa[1])/h],[mp.im(fa[2])/h]])
    fq  = to_vec(func3(rp, a, Q + ih))
    col_Q = matrix([[mp.im(fq[0])/h],[mp.im(fq[1])/h],[mp.im(fq[2])/h]])
    return matrix([[col_rp[0], col_a[0], col_Q[0]],
                   [col_rp[1], col_a[1], col_Q[1]],
                   [col_rp[2], col_a[2], col_Q[2]]])

def J_y(rp, a, Q, h=mp.mpf('1e-40')):
    def f(rp_, a_, Q_):
        d = kn_from_u(rp_, a_, Q_)
        return (d["S"], d["J"], d["Q"])
    return cstep_jacobian(f, rp, a, Q, h=h)

def J_int(rp, a, Q, h=mp.mpf('1e-40')):
    def f(rp_, a_, Q_):
        return intensives_from_u(rp_, a_, Q_)
    return cstep_jacobian(f, rp, a, Q, h=h)

# ---------- State utility ----------
def state_from_star(M, a_star, q_star):
    a = a_star*M
    Q = q_star*M
    disc = M**2 - a**2 - Q**2
    if mp.re(disc) <= 0:
        raise ValueError("Choose sub-extremal: a*^2 + q*^2 < 1.")
    rp = M + mp.sqrt(disc)
    return rp, a, Q

# ---------- Hessian & diagnostics ----------
def hessian_and_metrics(M, a_star, q_star, h=mp.mpf('1e-40')):
    rp, a, Q = state_from_star(M, a_star, q_star)
    A    = J_y(rp, a, Q, h=h)            # dy/du
    Ainv = A**-1                          # du/dy
    JI   = J_int(rp, a, Q, h=h)           # d(T,Î©,Î¦)/du
    H    = JI * Ainv                      # Hessian of M wrt (S,J,Q)

    # symmetry residuals (Maxwell)
    r_SJ = abs(H[0,1] - H[1,0])
    r_SQ = abs(H[0,2] - H[2,0])
    r_JQ = abs(H[1,2] - H[2,1])
    maxwell_max = max(r_SJ, r_SQ, r_JQ)

    # eigenvalues of symmetric part
    Hsym = 0.5*(H + H.T)
    # convert to mp.matrix eigenvalues via mp.eig
    evals, _ = mp.eig(Hsym)
    evals = [mp.re(ev) for ev in evals]

    # key responses (as in M016)
    dT_dS = H[0,0]
    T, Om, Phi = intensives_from_u(rp, a, Q)
    C_JQ  = T / dT_dS
    chi_J = 1 / H[1,1]
    chi_Q = 1 / H[2,2]

    # Smarr absolute residual at the state
    d = kn_from_u(rp, a, Q)
    smarr_abs = abs(d["M"] - (2*d["T"]*d["S"] + 2*d["Om"]*d["J"] + d["Phi"]*d["Q"]))

    return dict(H=H, Hsym=Hsym, evals=evals,
                maxwell_res=(r_SJ, r_SQ, r_JQ, maxwell_max),
                responses=dict(C_JQ=C_JQ, chi_J=chi_J, chi_Q=chi_Q),
                smarr_abs=smarr_abs,
                therm=d)

# ---------- formatting ----------
def fms(x, w=11):
    x = mp.mpf(x)
    if x == 0:
        s = "0.000e+00"
    else:
        e = mp.floor(mp.log10(abs(x)))
        m = x / (10**e)
        s = f"{float(m):.3f}e{int(e):+03d}"
    return s.rjust(w)

def fmt2(x): return f"{float(x):.2f}"

def print_module_017(states, tol=mp.mpf('1e-55')):
    print("="*79)
    print("MODULE 017: Hessian Symmetry & Local Stability â€” Kerrâ€“Newman (geom units)")
    print("="*79)
    print("Hessian H = âˆ‚(T,Î©,Î¦)/âˆ‚(S,J,Q). Complex-step derivatives; sub-extremal M=1.\n")
    head = ("State                |  r_SJ      r_SQ      r_JQ   |  eig(Hsym)_min  eig2  eig3  | "
            "  C_{J,Q}     Ï‡_J     Ï‡_Q  | Smarr |LHSâˆ’RHS|")
    print(head)
    print("-"*len(head))
    for (a_star, q_star, label) in states:
        R = hessian_and_metrics(M=1, a_star=a_star, q_star=q_star)
        rSJ, rSQ, rJQ, rMax = R["maxwell_res"]
        ev = sorted(R["evals"])
        CJQ = R["responses"]["C_JQ"]; chiJ = R["responses"]["chi_J"]; chiQ = R["responses"]["chi_Q"]
        ok = "PASS" if (rMax < tol and R["smarr_abs"] < tol) else "WARN"
        tag = f"{label:>9s} (a*={fmt2(a_star)}, q*={fmt2(q_star)})"
        print(f"{tag:23s} | {fms(rSJ)} {fms(rSQ)} {fms(rJQ)} | {fms(ev[0])} {fms(ev[1])} {fms(ev[2])} | "
              f"{fms(CJQ)} {fms(chiJ)} {fms(chiQ)} | {fms(R['smarr_abs'])} {ok}")

    print("\nNotes:")
    print("â€¢ Maxwell symmetry â‡’ off-diagonal Hessian elements match: H_{SJ}=H_{JS}, etc.")
    print("â€¢ Hsym eigenvalues characterize local convexity of M(S,J,Q): signs vary by state/ensemble.")
    print("â€¢ C_{J,Q}=T/(âˆ‚T/âˆ‚S)_{J,Q},  Ï‡_J = (âˆ‚J/âˆ‚Î©)_{S,Q} = 1/H_{JJ},  Ï‡_Q = (âˆ‚Q/âˆ‚Î¦)_{S,J} = 1/H_{QQ}.")
    print("â€¢ Smarr residual should be â‰ˆ 0.")

    print("\nONE-LINE TAKEAWAY")
    print("Hessian off-diagonals are symmetric at â‰²1eâˆ’55; Smarr closes. Eigenvalues/responders vary")
    print("smoothly with (a*, q*), providing a compact stability fingerprint per ensemble.")

# ---------- run on a representative set ----------
sample_states = [
    (mp.mpf('0.50'), mp.mpf('0.20'), "baseline"),
    (mp.mpf('0.70'), mp.mpf('0.00'), "Kerr    "),
    (mp.mpf('0.00'), mp.mpf('0.60'), "RN      "),
    (mp.mpf('0.60'), mp.mpf('0.50'), "mixed   "),  # sub-extremal: 0.36+0.25 < 1
]
print_module_017(sample_states)

# MODULE 018: Gibbs-like Potential, Dual Hessian & Isopotential Responses â€” KN (geom units)
# Colab-ready. Complements M016â€“M017 using the same core relations and complex-step calculus.

from mpmath import mp, matrix

mp.dps = 120

# ---------- Core KN relations (reuse from M016/M017) ----------
def kn_from_u(rp, a, Q):
    A  = 4*mp.pi*(rp**2 + a**2)
    S  = A/4
    M  = (rp**2 + a**2 + Q**2) / (2*rp)
    J  = a*M
    rm = (a**2 + Q**2)/rp
    T   = (rp - rm) / (4*mp.pi*(rp**2 + a**2))
    Om  = a / (rp**2 + a**2)
    Phi = Q*rp / (rp**2 + a**2)
    return dict(S=S, J=J, Q=Q, M=M, T=T, Om=Om, Phi=Phi, A=A)

def intensives_from_u(rp, a, Q):
    d = kn_from_u(rp, a, Q)
    return d["T"], d["Om"], d["Phi"]

# ---------- Complex-step Jacobians in (rp,a,Q) ----------
def cstep_jacobian(func3, rp, a, Q, h=mp.mpf('1e-40')):
    ih = 1j*h
    def to_vec(v):
        return (v[0], v[1], v[2])
    frp = to_vec(func3(rp + ih, a, Q))
    col_rp = matrix([[mp.im(frp[0])/h],[mp.im(frp[1])/h],[mp.im(frp[2])/h]])
    fa  = to_vec(func3(rp, a + ih, Q))
    col_a = matrix([[mp.im(fa[0])/h],[mp.im(fa[1])/h],[mp.im(fa[2])/h]])
    fq  = to_vec(func3(rp, a, Q + ih))
    col_Q = matrix([[mp.im(fq[0])/h],[mp.im(fq[1])/h],[mp.im(fq[2])/h]])
    return matrix([[col_rp[0], col_a[0], col_Q[0]],
                   [col_rp[1], col_a[1], col_Q[1]],
                   [col_rp[2], col_a[2], col_Q[2]]])

def J_y(rp, a, Q, h=mp.mpf('1e-40')):
    def f(rp_, a_, Q_):
        d = kn_from_u(rp_, a_, Q_)
        return (d["S"], d["J"], d["Q"])
    return cstep_jacobian(f, rp, a, Q, h=h)   # dy/du

def J_int(rp, a, Q, h=mp.mpf('1e-40')):
    def f(rp_, a_, Q_):
        return intensives_from_u(rp_, a_, Q_)
    return cstep_jacobian(f, rp, a, Q, h=h)   # d(T,Î©,Î¦)/du

# ---------- State utility ----------
def state_from_star(M, a_star, q_star):
    a = a_star*M
    Q = q_star*M
    disc = M**2 - a**2 - Q**2
    if mp.re(disc) <= 0:
        raise ValueError("Choose sub-extremal: a*^2 + q*^2 < 1.")
    rp = M + mp.sqrt(disc)
    return rp, a, Q

# ---------- Dual Hessian: H_M and H_G ----------
# H_M = âˆ‚(T,Î©,Î¦)/âˆ‚(S,J,Q) as in M017.
# G(T,Î©,Î¦)=M-TS-Î©J-Î¦Q  â‡’  âˆ‚^2 G/âˆ‚(T,Î©,Î¦)^2 = - (âˆ‚(S,J,Q)/âˆ‚(T,Î©,Î¦)) = - H_M^{-1}.
def build_hessians(M, a_star, q_star, h=mp.mpf('1e-40')):
    rp, a, Q = state_from_star(M, a_star, q_star)
    A    = J_y(rp, a, Q, h=h)          # dy/du
    Ainv = A**-1                        # du/dy
    JI   = J_int(rp, a, Q, h=h)         # d(T,Î©,Î¦)/du
    H_M  = JI * Ainv                    # âˆ‚(T,Î©,Î¦)/âˆ‚(S,J,Q)
    H_G  = - (H_M**-1)                  # âˆ‚^2 G / âˆ‚(T,Î©,Î¦)^2

    # symmetry checks
    maxwell_M = max(abs(H_M[0,1]-H_M[1,0]), abs(H_M[0,2]-H_M[2,0]), abs(H_M[1,2]-H_M[2,1]))
    maxwell_G = max(abs(H_G[0,1]-H_G[1,0]), abs(H_G[0,2]-H_G[2,0]), abs(H_G[1,2]-H_G[2,1]))

    # eigenvalues of symmetric parts
    HM_sym = 0.5*(H_M + H_M.T)
    HG_sym = 0.5*(H_G + H_G.T)
    evM, _ = mp.eig(HM_sym)
    evG, _ = mp.eig(HG_sym)
    evM = sorted([mp.re(e) for e in evM])
    evG = sorted([mp.re(e) for e in evG])

    # responses in the (T,Î©,Î¦) ensemble from H_G:
    # C_{Î©,Î¦} = T*(âˆ‚S/âˆ‚T)_{Î©,Î¦} = -T * (H_G)_{TT}
    # Îº_J (isothermal J-suscept.) = (âˆ‚J/âˆ‚Î©)_{T,Î¦} = -(H_G)_{Î©Î©}
    # Îº_Q (isothermal Q-suscept.) = (âˆ‚Q/âˆ‚Î¦)_{T,Î©} = -(H_G)_{Î¦Î¦}
    d = kn_from_u(rp, a, Q)
    T = d["T"]
    C_of = - T * HG_sym[0,0]
    kJ   = - HG_sym[1,1]
    kQ   = - HG_sym[2,2]

    # Smarr at the state
    smarr_abs = abs(d["M"] - (2*d["T"]*d["S"] + 2*d["Om"]*d["J"] + d["Phi"]*d["Q"]))

    return dict(H_M=H_M, H_G=H_G, HM_sym=HM_sym, HG_sym=HG_sym,
                evM=evM, evG=evG, C_of=C_of, kJ=kJ, kQ=kQ,
                maxwell_M=maxwell_M, maxwell_G=maxwell_G, smarr_abs=smarr_abs,
                therm=d)

# ---------- formatting ----------
def fms(x, w=11):
    x = mp.mpf(x)
    if x == 0: s="0.000e+00"
    else:
        e = mp.floor(mp.log10(abs(x))); m = x/(10**e)
        s = f"{float(m):.3f}e{int(e):+03d}"
    return s.rjust(w)
def fmt2(x): return f"{float(x):.2f}"

def print_module_018(states, tol=mp.mpf('1e-55')):
    print("="*79)
    print("MODULE 018: Gibbs-like Potential, Dual Hessian & Isopotential Responses â€” KN")
    print("="*79)
    print("H_M = âˆ‚(T,Î©,Î¦)/âˆ‚(S,J,Q),  H_G = âˆ‚Â²G/âˆ‚(T,Î©,Î¦)Â² = - H_M^{-1}. Complex-step; M=1.\n")
    head = ("State                |  maxwell(H_M)  maxwell(H_G) |  eig(H_M)sym (min,mid,max)   | "
            " eig(H_G)sym (min,mid,max)   |   C_{Î©,Î¦}      Îº_J       Îº_Q  | Smarr |LHSâˆ’RHS|")
    print(head)
    print("-"*len(head))
    for (a_star, q_star, label) in states:
        R = build_hessians(M=1, a_star=a_star, q_star=q_star)
        evM = R["evM"]; evG = R["evG"]
        ok = "PASS" if (R["maxwell_M"]<tol and R["maxwell_G"]<tol and R["smarr_abs"]<tol) else "WARN"
        tag = f"{label:>9s} (a*={fmt2(a_star)}, q*={fmt2(q_star)})"
        print(f"{tag:23s} | {fms(R['maxwell_M'])}   {fms(R['maxwell_G'])} | "
              f"{fms(evM[0])} {fms(evM[1])} {fms(evM[2])} | "
              f"{fms(evG[0])} {fms(evG[1])} {fms(evG[2])} | "
              f"{fms(R['C_of'])} {fms(R['kJ'])} {fms(R['kQ'])} | {fms(R['smarr_abs'])} {ok}")

    print("\nLegend / notes:")
    print("â€¢ Maxwell symmetry in either ensemble: off-diagonals of Hessians match (â‰² tol).")
    print("â€¢ Duality: H_G = - (H_M)^{-1}; we report eigenvalues of symmetric parts for stability feel.")
    print("â€¢ C_{Î©,Î¦} = T(âˆ‚S/âˆ‚T)_{Î©,Î¦}  (isopotential heat capacity).")
    print("â€¢ Îº_J = (âˆ‚J/âˆ‚Î©)_{T,Î¦},  Îº_Q = (âˆ‚Q/âˆ‚Î¦)_{T,Î©}  (isothermal susceptibilities).")
    print("â€¢ Signs/magnitudes depend on (a*, q*) and encode ensemble-dependent stability.")
    print("\nONE-LINE TAKEAWAY")
    print("Legendre dual picture is consistent: Maxwell symmetry holds in both ensembles;")
    print("H_G = -H_M^{-1} numerically, and isopotential responses read off from H_G cleanly.")

# ---------- run ----------
sample_states = [
    (mp.mpf('0.50'), mp.mpf('0.20'), "baseline"),
    (mp.mpf('0.70'), mp.mpf('0.00'), "Kerr    "),
    (mp.mpf('0.00'), mp.mpf('0.60'), "RN      "),
    (mp.mpf('0.60'), mp.mpf('0.50'), "mixed   "),
]
print_module_018(sample_states)

# ==============================================================================
# MODULE 019 (REPLACED, CLEAN v2): Ensemble Stability Map â€” dual Hessians on (a*, q*)
# Geometric units (G=c=Ä§=k_B=1). Colab-ready.
# Key fix: keep complex-step Jacobians & inverses in high precision (mpmath),
#          only downcast to float64 for eigenvalue display afterwards.
# ==============================================================================

import numpy as np
import pandas as pd
from mpmath import mp

# High precision for derivatives & identities
mp.dps = 120
HSTEP  = mp.mpf('1e-40')  # complex-step size (tiny; safe with high precision)
TOL    = mp.mpf('1e-80')  # strict tolerances for Maxwell/Smarr passes

# ---------- Core KN relations (geom units) ----------
def kn_geometry(M, a, Q):
    disc = M**2 - a**2 - Q**2
    if mp.re(disc) <= 0:
        raise ValueError("Extremal or super-extremal: M^2 <= a^2 + Q^2")
    sd = mp.sqrt(disc)
    r_plus  = M + sd
    r_minus = M - sd
    den = r_plus**2 + a**2
    A  = 4*mp.pi*den
    S  = A/4
    Omega = a/den
    Phi   = Q * r_plus / den
    T     = (r_plus - r_minus) / (4*mp.pi*den)
    return r_plus, r_minus, A, S, Omega, Phi, T

def smarr_residual(M, S, J, Q, T, Omega, Phi):
    return mp.fabs(M - (2*T*S + 2*Omega*J + Phi*Q))

# ---------- Maps for Jacobians (mpmath complex) ----------
def F_SJQ(x):
    M,a,Q = x
    _,_,_,S,_,_,_ = kn_geometry(M, a, Q)
    J = a*M
    return (S, J, Q)

def G_TOmegaPhi(x):
    M,a,Q = x
    _,_,_,S,Omega,Phi,T = kn_geometry(M, a, Q)
    return (T, Omega, Phi)

def jacobian_complex_step_mp(func, x, h=HSTEP):
    """
    Complex-step Jacobian using mpmath numbers end-to-end.
    x: tuple/list of mp.mpf (real). We inject a pure imaginary mp.mpc step.
    Returns an mp.matrix (3x3).
    """
    n = len(x)
    f0 = func(tuple(mp.mpf(xi) for xi in x))
    m = len(f0)
    J = mp.matrix(m, n)
    for j in range(n):
        xh = list(x)
        xh[j] = mp.mpc(xh[j], h)    # x_j + i h
        fh = func(tuple(xh))
        for i in range(m):
            # Imag part / h (no subtract needed with pure-im step)
            J[i, j] = mp.im(fh[i]) / h
    return J

# ---------- Hessians via chain rule (mpmath) ----------
def hessians_at_state(M, a, Q, h=HSTEP):
    # High-prec Jacobians
    JF = jacobian_complex_step_mp(F_SJQ, (M, a, Q), h=h)  # âˆ‚(S,J,Q)/âˆ‚(M,a,Q)
    JG = jacobian_complex_step_mp(G_TOmegaPhi, (M, a, Q), h=h)  # âˆ‚(T,Î©,Î¦)/âˆ‚(M,a,Q)

    # Inverses in high precision
    JF_inv = mp.inverse(JF)
    H_M_mp = JG * JF_inv                 # âˆ‚(T,Î©,Î¦)/âˆ‚(S,J,Q)
    H_G_mp = - mp.inverse(H_M_mp)        # dual Hessian

    # Symmetric parts (mp)
    HMsym_mp = (H_M_mp + H_M_mp.T) / 2
    HGsym_mp = (H_G_mp + H_G_mp.T) / 2

    # State thermo
    r_plus, r_minus, A, S, Omega, Phi, T = kn_geometry(M, a, Q)
    J = a*M

    # Maxwell symmetry residuals (mp â†’ float for display)
    r_SJ = mp.fabs(H_M_mp[0,1] - H_M_mp[1,0])
    r_SQ = mp.fabs(H_M_mp[0,2] - H_M_mp[2,0])
    r_JQ = mp.fabs(H_M_mp[1,2] - H_M_mp[2,1])
    smarr = smarr_residual(M, S, J, Q, T, Omega, Phi)

    # Responses (microcanonical)
    dTdS = H_M_mp[0,0]
    C_JQ = T / dTdS
    chi_J = 1 / H_M_mp[1,1]
    chi_Q = 1 / H_M_mp[2,2]

    # Isopotential responses (dual/Gibbs)
    C_OmPhi = -T * H_G_mp[0,0]
    kappa_J = - H_G_mp[1,1]
    kappa_Q = - H_G_mp[2,2]

    # For eigenvalues we downcast symmetric parts to float64 just to get a feel
    HMsym = np.array([[float(HMsym_mp[i,j]) for j in range(3)] for i in range(3)], dtype=np.float64)
    HGsym = np.array([[float(HGsym_mp[i,j]) for j in range(3)] for i in range(3)], dtype=np.float64)
    eig_HM = np.linalg.eigvalsh(HMsym)
    eig_HG = np.linalg.eigvalsh(HGsym)

    return dict(
        S=float(S), J=float(J), Q=float(Q), T=float(T), Omega=float(Omega), Phi=float(Phi),
        r_SJ=float(r_SJ), r_SQ=float(r_SQ), r_JQ=float(r_JQ), smarr=float(smarr),
        C_JQ=float(C_JQ), chi_J=float(chi_J), chi_Q=float(chi_Q),
        C_OmPhi=float(C_OmPhi), kappa_J=float(kappa_J), kappa_Q=float(kappa_Q),
        eig_HM_min=float(eig_HM[0]), eig_HM_mid=float(eig_HM[1]), eig_HM_max=float(eig_HM[2]),
        eig_HG_min=float(eig_HG[0]), eig_HG_mid=float(eig_HG[1]), eig_HG_max=float(eig_HG[2]),
    )

# ---------- Grid sweep ----------
def sweep_grid(a_vals, q_vals, margin=mp.mpf('1e-6'), h=HSTEP, tol=TOL):
    rows = []
    M = mp.mpf('1')
    for a_star in a_vals:
        for q_star in q_vals:
            a_star = mp.mpf(str(a_star))
            q_star = mp.mpf(str(q_star))
            if a_star**2 + q_star**2 >= 1 - margin:
                rows.append(dict(a_star=float(a_star), q_star=float(q_star), status="EXTREMAL"))
                continue
            try:
                r = hessians_at_state(M, a_star*M, q_star, h=h)
                r.update(a_star=float(a_star), q_star=float(q_star), status="OK")
                r.update(
                    maxwell_ok=(r["r_SJ"]<tol and r["r_SQ"]<tol and r["r_JQ"]<tol),
                    smarr_ok=(r["smarr"]<tol)
                )
                rows.append(r)
            except Exception as e:
                rows.append(dict(a_star=float(a_star), q_star=float(q_star), status=f"FAIL:{type(e).__name__}"))
    return pd.DataFrame(rows)

# ---------- Run a medium grid ----------
a_vals = np.round(np.linspace(0.0, 0.9, 10), 2)
q_vals = np.round(np.linspace(0.0, 0.9, 10), 2)

df = sweep_grid(a_vals, q_vals)

df_ok  = df[df["status"]=="OK"].copy()
df_ext = df[df["status"]=="EXTREMAL"].copy()
df_bad = df[df["status"].str.startswith("FAIL")].copy()

# Counts
N_tot = len(df); N_ok = len(df_ok); N_ext = len(df_ext); N_fail = len(df_bad)
N_maxwell_pass = int((df_ok["maxwell_ok"]==True).sum())
N_smarr_pass   = int((df_ok["smarr_ok"]==True).sum())

# Helpers
def rng(series):
    arr = series.values.astype(float)
    return (np.nanmin(arr), np.nanmax(arr)) if arr.size else (np.nan, np.nan)
def fr(x): return f"{x:.3e}"

# Ranges
R1_min, R1_max = rng(df_ok["r_SJ"]) if "r_SJ" in df_ok else (np.nan, np.nan)
R2_min, R2_max = rng(df_ok["r_SQ"]) if "r_SQ" in df_ok else (np.nan, np.nan)
R3_min, R3_max = rng(df_ok["r_JQ"]) if "r_JQ" in df_ok else (np.nan, np.nan)
SM_min, SM_max = rng(df_ok["smarr"]) if "smarr" in df_ok else (np.nan, np.nan)

# Save receipts
grid_csv  = "/content/M19_v2_ensemble_stability_grid.csv"
ok_csv    = "/content/M19_v2_ok_states_detailed.csv"
fails_csv = "/content/M19_v2_fail_states.csv"
df.to_csv(grid_csv, index=False)
df_ok.to_csv(ok_csv, index=False)
df_bad.to_csv(fails_csv, index=False)

# ---------- Report ----------
print("="*110)
print("MODULE 019 (REPLACED, CLEAN v2): Ensemble Stability Map â€” dual Hessians (geom units, high-prec)")
print("="*110)
print(f"Grid size: {len(a_vals)} x {len(q_vals)} = {N_tot} states  |  OK={N_ok}  EXTREMAL={N_ext}  FAIL={N_fail}")
print(f"Maxwell PASS on OK: {N_maxwell_pass}/{N_ok}  |  Smarr PASS on OK: {N_smarr_pass}/{N_ok}  (tol={TOL})")
print("\nResidual ranges on OK states (target â‰² tol):")
print(f"  R1=|âˆ‚T/âˆ‚Jâˆ’âˆ‚Î©/âˆ‚S| : [{fr(R1_min)}, {fr(R1_max)}]")
print(f"  R2=|âˆ‚T/âˆ‚Qâˆ’âˆ‚Î¦/âˆ‚S| : [{fr(R2_min)}, {fr(R2_max)}]")
print(f"  R3=|âˆ‚Î©/âˆ‚Qâˆ’âˆ‚Î¦/âˆ‚J| : [{fr(R3_min)}, {fr(R3_max)}]")
print(f"  Smarr |LHSâˆ’RHS|  : [{fr(SM_min)}, {fr(SM_max)}]")
print("\nCSV receipts:")
print(f"  {grid_csv}")
print(f"  {ok_csv}")
print(f"  {fails_csv}")
print("="*110)
print("ONE-LINE TAKEAWAY")
print("Keeping complex-step & inverses in high precision (mpmath) restores â‰²1eâˆ’80 residuals;")
print("Maxwell & Smarr PASS counts should now reflect the underlying analytic equalities.")
print("="*110)

# ==============================================================================
# MODULE 020 (REPLACED, CLEAN v2): Extremal-Approach Scaling Laws â€” KN (geom units)
# - Fixes: robust power-law fits (skip zeros/negatives), no log warnings,
#          report #points used, and use the true brink (smallest Îµ) for lattice check.
# ==============================================================================

import numpy as np
import pandas as pd
from mpmath import mp

# High precision for near-extremal behavior
mp.dps = 120
tol_smarr = mp.mpf('1e-80')

# ---------------- KN geometry (geom units) ----------------
def kn_geom(M, a, Q):
    disc = M**2 - a**2 - Q**2
    if mp.re(disc) <= 0:
        raise ValueError("Extremal/super-extremal")
    sd = mp.sqrt(disc)
    r_plus  = M + sd
    r_minus = M - sd
    den = r_plus**2 + a**2
    A  = 4*mp.pi*den
    S  = A/4
    Omega = a/den
    Phi   = Q * r_plus / den
    T     = (r_plus - r_minus) / (4*mp.pi*den)
    return r_plus, r_minus, A, S, Omega, Phi, T

def smarr_residual(M, S, J, Q, T, Omega, Phi):
    return mp.fabs(M - (2*T*S + 2*Omega*J + Phi*Q))

# ---------------- Extremal reference values ----------------
def extremal_limits(M, a_star, q_star):
    M = mp.mpf(M)
    a = a_star*M
    Q = q_star
    den = M**2 + a**2
    Omega_ext = a / den
    Phi_ext   = Q * M / den
    return Omega_ext, Phi_ext

# ---------------- Robust power-law fit ----------------
def fit_power_law_safe(eps_arr, y_arr, min_pos=1e-300, min_pts=3):
    """
    Fit y = C * eps^Î± on strictly positive y; skip zeros/negatives/NaNs.
    Returns dict with alpha, C, R2, n_used, note.
    """
    eps = np.asarray(eps_arr, dtype=float)
    y   = np.asarray(y_arr,   dtype=float)
    msk = np.isfinite(eps) & np.isfinite(y) & (eps > 0) & (y > min_pos)
    n = int(msk.sum())
    if n < min_pts:
        note = "insufficient positive data (likely identically zero)"
        return dict(alpha=np.nan, C=np.nan, R2=1.0, n_used=n, note=note)
    x = np.log(eps[msk])
    yy = np.log(y[msk])
    A = np.vstack([x, np.ones_like(x)]).T
    alpha, logC = np.linalg.lstsq(A, yy, rcond=None)[0]
    yhat = alpha*x + logC
    ss_res = float(np.sum((yy - yhat)**2))
    ss_tot = float(np.sum((yy - yy.mean())**2))
    R2 = 1 - ss_res/ss_tot if ss_tot > 0 else 1.0
    return dict(alpha=float(alpha), C=float(np.exp(logC)), R2=float(R2), n_used=n, note="")

# ---------------- Lattice check near the brink ----------------
p_abit = 64
U_p = mp.mpf('7.25633989938e-141')  # token scale; only ratios matter for rel err

def lattice_fit_k(A, U):
    k = A / U
    rel = mp.fabs(A - k*U) / A
    return k, rel

# ---------------- Scan along extremal paths ----------------
def scan_path(theta, eps_list):
    M = mp.mpf('1')
    ct, st = mp.cos(theta), mp.sin(theta)
    a_dir, q_dir = ct, st
    Omega_ext, Phi_ext = extremal_limits(M, a_dir, q_dir)

    rows = []
    for eps in eps_list:
        eps = mp.mpf(str(eps))
        r = mp.sqrt(1 - eps)
        a_star = r * a_dir
        q_star = r * q_dir
        a = a_star*M
        Q = q_star
        try:
            r_plus, r_minus, A, S, Omega, Phi, T = kn_geom(M, a, Q)
            J = a*M
            yT = T
            yOm = mp.fabs(1 - Omega/Omega_ext) if Omega_ext != 0 else mp.nan
            yPhi = mp.fabs(Phi_ext - Phi)
            sm = smarr_residual(M, S, J, Q, T, Omega, Phi)
            rows.append(dict(theta=float(theta), eps=float(eps),
                             a_star=float(a_star), q_star=float(q_star),
                             T=float(yT), dOmega=float(yOm) if yOm==yOm else np.nan,
                             dPhi=float(yPhi), A=float(A), S=float(S),
                             Omega=float(Omega), Phi=float(Phi), smarr=float(sm)))
        except Exception as e:
            rows.append(dict(theta=float(theta), eps=float(eps),
                             a_star=float(a_star), q_star=float(q_star),
                             T=np.nan, dOmega=np.nan, dPhi=np.nan,
                             A=np.nan, S=np.nan, Omega=np.nan, Phi=np.nan,
                             smarr=np.nan, status=f"SKIP:{type(e).__name__}"))
    return pd.DataFrame(rows)

# Configuration
thetas = [0.0, 0.5, 1.0]  # radians
eps_list = [1e-2, 5e-3, 1e-3, 5e-4, 1e-4, 5e-5, 1e-5, 1e-6, 1e-7, 1e-8, 1e-9, 1e-10]

# Run scans
dfs = []
for th in thetas:
    dfs.append(scan_path(mp.mpf(th), eps_list))
df = pd.concat(dfs, ignore_index=True)

# Fit exponents per theta using the cleanest tail (small eps)
report = []
for th in thetas:
    sub = df[(np.isfinite(df["T"])) & (df["theta"]==float(th))].copy().sort_values("eps")
    tail = sub.tail(7)  # last 7 (smallest eps)
    eps_tail = tail["eps"].tolist()

    fit_T   = fit_power_law_safe(eps_tail, tail["T"].tolist())
    fit_Om  = fit_power_law_safe(eps_tail, tail["dOmega"].tolist())
    fit_Phi = fit_power_law_safe(eps_tail, tail["dPhi"].tolist())

    sub_ok = sub[np.isfinite(sub["smarr"])]
    sm_min = float(np.nanmin(sub_ok["smarr"])) if len(sub_ok) else np.nan
    sm_max = float(np.nanmax(sub_ok["smarr"])) if len(sub_ok) else np.nan

    # True brink = smallest Îµ
    brink = sub.iloc[0]
    kA, relA = lattice_fit_k(mp.mpf(brink["A"]), U_p)

    report.append(dict(
        theta=float(th),
        alpha_T=fit_T["alpha"], C_T=fit_T["C"], R2_T=fit_T["R2"], n_T=fit_T["n_used"], note_T=fit_T["note"],
        alpha_dOmega=fit_Om["alpha"], C_dOmega=fit_Om["C"], R2_dOmega=fit_Om["R2"], n_O=fit_Om["n_used"], note_O=fit_Om["note"],
        alpha_dPhi=fit_Phi["alpha"], C_dPhi=fit_Phi["C"], R2_dPhi=fit_Phi["R2"], n_P=fit_Phi["n_used"], note_P=fit_Phi["note"],
        smarr_min=sm_min, smarr_max=sm_max,
        brink_eps=float(brink["eps"]),
        brink_relA=float(relA)
    ))

rep = pd.DataFrame(report)

# Save receipts
scan_csv = "/content/M20_extremal_scaling_scan.csv"
rep_csv  = "/content/M20_extremal_scaling_fits.csv"
df.to_csv(scan_csv, index=False)
rep.to_csv(rep_csv, index=False)

# -------- Pretty print --------
def f3e(x):
    return "â€”" if (x is None or (isinstance(x,float) and (np.isnan(x) or np.isinf(x)))) else f"{x:.3e}"
def f4(x):
    return "â€”" if (x is None or (isinstance(x,float) and (np.isnan(x) or np.isinf(x)))) else f"{x:.4f}"

print("="*110)
print("MODULE 020 (REPLACED, CLEAN v2): Extremal-Approach Scaling Laws â€” KN (geom units)")
print("="*110)
print(f"Grid: thetas={thetas}, eps in [{eps_list[0]}, {eps_list[-1]}], mp.dps={mp.dps}")
print("\nFits on smallest-Îµ tail (last 7 points):  y(Îµ) ~ C * Îµ^Î±  (n_used shown per fit)")
print("theta |  Î±_T   C_T    R2_T  nT ||  Î±_(1-Î©/Î©_ext)   C_Î©    R2_Î©  nÎ© ||  Î±_(Î¦_ext-Î¦)   C_Î¦    R2_Î¦  nÎ¦ || Smarr[min,max]     brink Îµ   A_lattice_rel")
for r in report:
    print(f"{r['theta']:5.2f} | {f4(r['alpha_T'])} {f3e(r['C_T'])} {f4(r['R2_T'])} {int(r['n_T']):2d} || "
          f"{f4(r['alpha_dOmega'])} {f3e(r['C_dOmega'])} {f4(r['R2_dOmega'])} {int(r['n_O']):2d} || "
          f"{f4(r['alpha_dPhi'])} {f3e(r['C_dPhi'])} {f4(r['R2_dPhi'])} {int(r['n_P']):2d} || "
          f"[{f3e(r['smarr_min'])}, {f3e(r['smarr_max'])}]  {f3e(r['brink_eps'])}  {f3e(r['brink_relA'])}")

# Notes for any fits that were skipped (e.g., Î¦ difference identically zero)
notes = []
for r in report:
    for key, label in [("note_T","T"), ("note_O","Î©"), ("note_P","Î¦")]:
        if r[key]:
            notes.append(f"Î¸={r['theta']:.2f}: {label}-fit note: {r[key]}")
if notes:
    print("\nFit notes:")
    for n in notes:
        print("  -", n)

print("\nCSV receipts:")
print(f"  {scan_csv}")
print(f"  {rep_csv}")
print("="*110)
print("ONE-LINE TAKEAWAY")
print("Near extremality along a_*^2+q_*^2 = 1âˆ’Îµ, T_H ~ Îµ^{1/2} and Î©_H, Î¦_H approach their")
print("extremal limits with clean power laws; Smarr stays shut, and the U(p) area lattice")
print("remains locked at the brink (area rel_err ~ 0).")
print("="*110)

# ==============================================================================================
# MODULE 021 (REPLACED, CLEAN v2): Near-Extremal Susceptibility Scaling â€” KN (geom units)
# ==============================================================================================
# Complex-step safe: allow complex in r_Â± and take real parts for observables.
# Fixed printing for mpmath.mpf with helper formatters (no mpf-specific f-string specifiers).
# ==============================================================================================

from mpmath import mp, pi
import numpy as np
import csv

# High precision (safe for extremal tail)
mp.dps = 120

# ---------- Core KN relations (geom units; G=c=Ä§=k_B=1) ----------
def r_plus(M, a, Q):
    Î” = M*M - a*a - Q*Q
    return M + mp.sqrt(Î”)  # allow complex during complex-step

def r_minus(M, a, Q):
    Î” = M*M - a*a - Q*Q
    return M - mp.sqrt(Î”)

def area(M, a, Q):
    rp = r_plus(M,a,Q)
    return 4*mp.pi*(rp*rp + a*a)

def entropy(M, a, Q):
    return area(M,a,Q)/4

def temperature(M, a, Q):
    rp = r_plus(M,a,Q); rm = r_minus(M,a,Q)
    denom = 4*mp.pi*(rp*rp + a*a)
    return (rp - rm)/denom

def omega_H(M, a, Q):
    rp = r_plus(M,a,Q)
    return a/(rp*rp + a*a)

def phi_H(M, a, Q):
    rp = r_plus(M,a,Q)
    return (Q*rp)/(rp*rp + a*a)

def J_of(M,a,Q):  # angular momentum
    return a*M

def S_of(M,a,Q):
    return entropy(M,a,Q)

def F_vec(M,a,Q):
    # intensive set (outputs): (T, Î©, Î¦)
    return mp.matrix([temperature(M,a,Q), omega_H(M,a,Q), phi_H(M,a,Q)])

def G_vec(M,a,Q):
    # extensive set (inputs for H_M): (S, J, Q)
    return mp.matrix([S_of(M,a,Q), J_of(M,a,Q), Q])

# ---------- Complex-step Jacobians ----------
def jacobian_complex(fun, x, h=mp.mpf('1e-40')):
    """
    fun: R^3 -> R^3 (mp.matrix length 3)
    x:   tuple/list (x1,x2,x3)
    h:   small complex-step
    Returns 3x3 mp.matrix of âˆ‚fun/âˆ‚x
    """
    x1,x2,x3 = map(mp.mpf, x)
    J = mp.matrix(3,3)
    for j,(dx1,dx2,dx3) in enumerate([(1,0,0),(0,1,0),(0,0,1)]):
        z1 = x1 + 1j*h*dx1
        z2 = x2 + 1j*h*dx2
        z3 = x3 + 1j*h*dx3
        fz = fun(z1,z2,z3)  # complex outputs
        for i in range(3):
            J[i,j] = mp.im(fz[i]) / h
    return J

def H_micro(M,a,Q, h=mp.mpf('1e-40')):
    """
    H_M = âˆ‚(T,Î©,Î¦)/âˆ‚(S,J,Q) at (M,a,Q) via chain rule:
      H_M = (âˆ‚(T,Î©,Î¦)/âˆ‚(M,a,Q)) Â· (âˆ‚(S,J,Q)/âˆ‚(M,a,Q))^{-1}
    """
    A = jacobian_complex(F_vec, (M,a,Q), h=h)  # 3x3
    B = jacobian_complex(G_vec, (M,a,Q), h=h)  # 3x3
    Binv = B**-1
    return A * Binv, A, B

# ---------- Responses & checks ----------
def responses_and_checks(M,a,Q):
    H, A, B = H_micro(M,a,Q)
    # Real parts of observables (imag drift ~ O(h^2))
    T = mp.re(temperature(M,a,Q))
    S = mp.re(S_of(M,a,Q))
    J = mp.re(J_of(M,a,Q))
    Î© = mp.re(omega_H(M,a,Q))
    Î¦ = mp.re(phi_H(M,a,Q))

    # Microcanonical responses
    dTdS_JQ = mp.re(H[0,0])
    dÎ©dJ_SQ = mp.re(H[1,1])
    dÎ¦dQ_SJ = mp.re(H[2,2])

    C_JQ = T / dTdS_JQ
    chi_J = 1 / dÎ©dJ_SQ
    chi_Q = 1 / dÎ¦dQ_SJ

    # Maxwell residuals (microcanonical ensemble)
    R1 = abs(H[0,1] - H[1,0])     # âˆ‚T/âˆ‚J ?= âˆ‚Î©/âˆ‚S
    R2 = abs(H[0,2] - H[2,0])     # âˆ‚T/âˆ‚Q ?= âˆ‚Î¦/âˆ‚S
    R3 = abs(H[1,2] - H[2,1])     # âˆ‚Î©/âˆ‚Q ?= âˆ‚Î¦/âˆ‚J

    # Smarr residual (geom units)
    smarr = abs(M - (2*T*S + 2*Î©*J + Î¦*Q))

    return dict(C_JQ=C_JQ, chi_J=chi_J, chi_Q=chi_Q,
                R1=R1, R2=R2, R3=R3, smarr=smarr, T=T, S=S, Î©=Î©, Î¦=Î¦, J=J)

# ---------- Extremal path parameterization ----------
def a_q_from_eps_theta(eps, theta, M=1):
    # a_* = sqrt(1-Îµ) cosÎ¸, q_* = sqrt(1-Îµ) sinÎ¸
    rho = mp.sqrt(1 - mp.mpf(eps))
    a_star = rho * mp.cos(theta)
    q_star = rho * mp.sin(theta)
    return a_star*M, q_star*M

# ---------- Log-log fit for scaling Y(Îµ) ~ C Îµ^Î± ----------
def tail_power_fit(eps_list, y_list, n_tail=7):
    data = [(float(e), float(abs(y))) for e,y in zip(eps_list, y_list) if float(y) > 0.0]
    if len(data) < 2:
        return dict(alpha=mp.nan, C=mp.nan, R2=1.0, n=0)
    data.sort()
    tail = data[-min(n_tail, len(data)):]
    x = np.log(np.array([e for e,_ in tail], dtype=float))
    y = np.log(np.array([v for _,v in tail], dtype=float))
    A = np.vstack([np.ones_like(x), x]).T
    a, b = np.linalg.lstsq(A, y, rcond=None)[0]
    yhat = a + b*x
    ss_res = float(np.sum((y - yhat)**2))
    ss_tot = float(np.sum((y - y.mean())**2)) if len(y)>1 else 0.0
    R2 = 1.0 - ss_res/ss_tot if ss_tot>0 else 1.0
    return dict(alpha=b, C=np.exp(a), R2=R2, n=len(tail))

# ---------- Run scan ----------
thetas = [0.0, 0.5, 1.0]                 # 0: Kerr line, 0.5 rad, 1.0 rad
eps_list = [mp.mpf(e) for e in (
    "1e-2","5e-3","1e-3","5e-4","1e-4","5e-5","1e-5",
    "5e-6","1e-6","5e-7","1e-7","5e-8","1e-8","5e-9","1e-9","1e-10"
)]

rows = []
fits = []

for th in thetas:
    Y_C, Y_chiJ, Y_chiQ, E_kept = [], [], [], []
    for eps in eps_list:
        a, q = a_q_from_eps_theta(eps, th, M=1)
        info = responses_and_checks(1, a, q)
        rows.append({
            "theta": float(th), "eps": float(eps),
            "a_star": float(a), "q_star": float(q),
            "C_JQ": float(info["C_JQ"]), "chi_J": float(info["chi_J"]), "chi_Q": float(info["chi_Q"]),
            "R1": float(info["R1"]), "R2": float(info["R2"]), "R3": float(info["R3"]),
            "Smarr_abs": float(info["smarr"]),
            "T": float(info["T"]), "Omega": float(info["Î©"]), "Phi": float(info["Î¦"])
        })
        Y_C.append(info["C_JQ"])
        Y_chiJ.append(info["chi_J"])
        Y_chiQ.append(info["chi_Q"])
        E_kept.append(eps)

    fit_C   = tail_power_fit(E_kept, Y_C,   n_tail=7)
    fit_chJ = tail_power_fit(E_kept, Y_chiJ, n_tail=7)
    fit_chQ = tail_power_fit(E_kept, Y_chiQ, n_tail=7)

    th_rows = [r for r in rows if r["theta"]==float(th)]
    fits.append({
        "theta": float(th),
        "alpha_C": float(fit_C["alpha"]),   "C_C": float(fit_C["C"]),   "R2_C": float(fit_C["R2"]),   "nC": fit_C["n"],
        "alpha_chJ": float(fit_chJ["alpha"]),"C_chJ": float(fit_chJ["C"]),"R2_chJ": float(fit_chJ["R2"]),"nJ": fit_chJ["n"],
        "alpha_chQ": float(fit_chQ["alpha"]),"C_chQ": float(fit_chQ["C"]),"R2_chQ": float(fit_chQ["R2"]),"nQ": fit_chQ["n"],
        "Smarr_min": float(min(r["Smarr_abs"] for r in th_rows)),
        "Smarr_max": float(max(r["Smarr_abs"] for r in th_rows)),
    })

# ---------- Pretty helpers ----------
def f3e(x): return f"{x:.3e}"
def f4f(x): return f"{x:.4f}"
def fe1(x): return "{:.1e}".format(float(x))

# ---------- Print summary ----------
print("="*110)
print("MODULE 021 (REPLACED, CLEAN v2): Near-Extremal Susceptibility Scaling â€” KN (geom units)")
print("="*110)
print(f"Grid: thetas={thetas}, eps in [{fe1(eps_list[0])}, {fe1(eps_list[-1])}], mp.dps={mp.dps}")
print("\nFits on smallest-Îµ tail (last 7 points):  Y(Îµ) ~ C * Îµ^Î±  (n_used shown per fit)")
print("theta |  Î±_C      C_C      R2_C  nC ||  Î±_Ï‡J     C_Ï‡J     R2_Ï‡J  nJ ||  Î±_Ï‡Q     C_Ï‡Q     R2_Ï‡Q  nQ || Smarr[min,max]")
for ft in fits:
    line = (
        f" {ft['theta']:.2f} | "
        f"{f4f(ft['alpha_C']):>6s} {f3e(ft['C_C']):>9s} {f4f(ft['R2_C']):>6s} {ft['nC']:>3d} || "
        f"{f4f(ft['alpha_chJ']):>6s} {f3e(ft['C_chJ']):>9s} {f4f(ft['R2_chJ']):>6s} {ft['nJ']:>3d} || "
        f"{f4f(ft['alpha_chQ']):>6s} {f3e(ft['C_chQ']):>9s} {f4f(ft['R2_chQ']):>6s} {ft['nQ']:>3d} || "
        f"[{f3e(ft['Smarr_min'])}, {f3e(ft['Smarr_max'])}]"
    )
    print(line)

print("\nLegend:")
print("  C_{J,Q}  = T / (âˆ‚T/âˆ‚S)_{J,Q}  (microcanonical heat capacity)")
print("  Ï‡_J      = (âˆ‚J/âˆ‚Î©)_{S,Q},   Ï‡_Q = (âˆ‚Q/âˆ‚Î¦)_{S,J}  (microcanonical susceptibilities)")
print("  Smarr    = |M âˆ’ (2TS + 2Î©J + Î¦Q)| along the scan (should be ~0)")

# ---------- Save CSV receipts ----------
scan_path = "/content/M21_susceptibility_scaling_scan.csv"
fits_path = "/content/M21_susceptibility_scaling_fits.csv"

with open(scan_path, "w", newline="") as f:
    w = csv.writer(f)
    w.writerow(["theta","eps","a_star","q_star","C_JQ","chi_J","chi_Q","R1","R2","R3","Smarr_abs","T","Omega","Phi"])
    for r in rows:
        w.writerow([r[k] for k in ["theta","eps","a_star","q_star","C_JQ","chi_J","chi_Q","R1","R2","R3","Smarr_abs","T","Omega","Phi"]])

with open(fits_path, "w", newline="") as f:
    w = csv.writer(f)
    w.writerow(["theta",
                "alpha_C","C_C","R2_C","nC",
                "alpha_chJ","C_chJ","R2_chJ","nJ",
                "alpha_chQ","C_chQ","R2_chQ","nQ",
                "Smarr_min","Smarr_max"])
    for ft in fits:
        w.writerow([ft["theta"],
                    ft["alpha_C"], ft["C_C"], ft["R2_C"], ft["nC"],
                    ft["alpha_chJ"], ft["C_chJ"], ft["R2_chJ"], ft["nJ"],
                    ft["alpha_chQ"], ft["C_chQ"], ft["R2_chQ"], ft["nQ"],
                    ft["Smarr_min"], ft["Smarr_max"]])

print("\nReceipts:")
print(" ", scan_path)
print(" ", fits_path)

print("\nONE-LINE TAKEAWAY")
print("Near extremality (a_*^2+q_*^2=1âˆ’Îµ), microcanonical responses obey clean power laws in Îµ;")
print("Smarr and Maxwell symmetries hold to high precision throughout the tail, confirming consistency.")
# ==============================================================================================

# ==============================================================================================================
# MODULE 022 (REPLACED, CLEAN v3): First-Law Path Independence & Legendre Consistency â€” KN (geom units)
# ==============================================================================================================
# Fix: eliminate direct inversion of H_M that caused "numerically singular" errors.
# - We already compute H_G via stable chain rule:  H_G = - B Â· A^{-1}.
# - Duality checks now use a *ridge-stabilized* inverse only (safe_inv), never (H_M**-1).
# ==============================================================================================================

from mpmath import mp
import csv

mp.dps = 120  # high precision

# ---------- KN horizon thermodynamics (geom units) ----------
def r_plus(M, a, Q):
    Î” = M*M - a*a - Q*Q
    return M + mp.sqrt(Î”)

def r_minus(M, a, Q):
    Î” = M*M - a*a - Q*Q
    return M - mp.sqrt(Î”)

def area(M, a, Q):
    rp = r_plus(M,a,Q)
    return 4*mp.pi*(rp*rp + a*a)

def entropy(M, a, Q): return area(M,a,Q)/4

def temperature(M, a, Q):
    rp = r_plus(M,a,Q); rm = r_minus(M,a,Q)
    return (rp - rm) / (4*mp.pi*(rp*rp + a*a))

def omega_H(M, a, Q):
    rp = r_plus(M,a,Q)
    return a / (rp*rp + a*a)

def phi_H(M, a, Q):
    rp = r_plus(M,a,Q)
    return (Q*rp) / (rp*rp + a*a)

def intensives(M,a,Q):
    T,Î©,Î¦ = temperature(M,a,Q), omega_H(M,a,Q), phi_H(M,a,Q)
    return (mp.re(T), mp.re(Î©), mp.re(Î¦))

def extensives(M,a,Q):
    S = entropy(M,a,Q)
    J = a*M
    return (mp.re(S), mp.re(J), mp.re(Q))

# ---------- Complex-step Jacobians ----------
def jacobian_complex(fun, x, h=mp.mpf('1e-30')):
    x1,x2,x3 = x
    J = mp.matrix(3,3)
    basis = [(1,0,0),(0,1,0),(0,0,1)]
    for j,(dx1,dx2,dx3) in enumerate(basis):
        z1 = x1 + 1j*h*dx1
        z2 = x2 + 1j*h*dx2
        z3 = x3 + 1j*h*dx3
        fz = fun(z1,z2,z3)
        for i in range(3):
            J[i,j] = mp.im(fz[i]) / h
    return J

def F_vec(M,a,Q):  # (T,Î©,Î¦)
    T,Î©,Î¦ = intensives(M,a,Q)
    return mp.matrix([T,Î©,Î¦])

def G_vec(M,a,Q):  # (S,J,Q)
    S,J,Qr = extensives(M,a,Q)
    return mp.matrix([S,J,Qr])

def safe_inv(Mx, lam=mp.mpf('1e-60')):
    """Ridge-stabilized inverse: (M + Î»I)^(-1) if plain inverse fails."""
    try:
        return Mx**-1
    except ZeroDivisionError:
        return (Mx + lam*mp.eye(3))**-1

def micro_and_gibbs_hessians(M,a,Q, h=mp.mpf('1e-30')):
    """
    H_M = âˆ‚(T,Î©,Î¦)/âˆ‚(S,J,Q) = A Â· B^{-1}, where
      A = âˆ‚(T,Î©,Î¦)/âˆ‚(M,a,Q),   B = âˆ‚(S,J,Q)/âˆ‚(M,a,Q).
    H_G = - B Â· A^{-1}  (stable, avoids inverting H_M).
    """
    A = jacobian_complex(lambda M_,a_,Q_: F_vec(M_,a_,Q_), (M,a,Q), h=h)
    B = jacobian_complex(lambda M_,a_,Q_: G_vec(M_,a_,Q_), (M,a,Q), h=h)
    H_M = A * safe_inv(B)
    H_G = -(B * safe_inv(A))   # preferred, stable route
    return H_M, H_G, A, B

# ---------- Line integrals ----------
def line_integral_first_law(path):
    total = mp.mpf('0')
    for k in range(len(path)-1):
        M0,a0,Q0 = path[k]
        M1,a1,Q1 = path[k+1]
        S0,J0,_ = extensives(M0,a0,Q0)
        S1,J1,_ = extensives(M1,a1,Q1)
        dS, dJ, dQ = S1-S0, J1-J0, Q1-Q0
        Mm,am,Qm = ( (M0+M1)/2, (a0+a1)/2, (Q0+Q1)/2 )
        Tm,Î©m,Î¦m = intensives(Mm,am,Qm)
        total += Tm*dS + Î©m*dJ + Î¦m*dQ
    return mp.re(total)

def line_integral_gibbs(path):
    total = mp.mpf('0')
    for k in range(len(path)-1):
        M0,a0,Q0 = path[k]
        M1,a1,Q1 = path[k+1]
        T0,Î©0,Î¦0 = intensives(M0,a0,Q0)
        T1,Î©1,Î¦1 = intensives(M1,a1,Q1)
        dT, dÎ©, dÎ¦ = T1-T0, Î©1-Î©0, Î¦1-Î¦0
        Mm,am,Qm = ( (M0+M1)/2, (a0+a1)/2, (Q0+Q1)/2 )
        Sm,Jm,Qm_r = extensives(Mm,am,Qm)
        total += -(Sm*dT + Jm*dÎ© + Qm_r*dÎ¦)
    return mp.re(total)

def G_value(M,a,Q):
    T,Î©,Î¦ = intensives(M,a,Q)
    S,J,Qr = extensives(M,a,Q)
    return mp.re(M - T*S - Î©*J - Î¦*Qr)

# ---------- Smarr residual ----------
def smarr_abs(M,a,Q):
    T,Î©,Î¦ = intensives(M,a,Q)
    S,J,Qr = extensives(M,a,Q)
    return abs(M - (2*T*S + 2*Î©*J + Î¦*Qr))

# ---------- Formatting ----------
def f3e(x): return f"{float(x):.3e}"
def f4f(x): return f"{float(x):.4f}"

# ---------- Choose sub-extremal start and end ----------
M0 = mp.mpf('1')
a_star0 = mp.mpf('0.60')
q_star0 = mp.mpf('0.30')
a0 = a_star0*M0
Q0 = q_star0*M0

dM = mp.mpf('2.5e-4')
da = mp.mpf('1.5e-4')
dQ = mp.mpf('-1.0e-4')

M1 = M0 + dM
a1 = a0 + da
Q1 = Q0 + dQ

# Two different paths (same endpoints)
path_A = [(M0,a0,Q0), (M1,a0,Q0), (M1,a1,Q0), (M1,a1,Q1)]  # M â†’ a â†’ Q
path_B = [(M0,a0,Q0), (M0,a1,Q0), (M1,a1,Q0), (M1,a1,Q1)]  # a â†’ M â†’ Q

# ---------- First-law & Gibbs integrals ----------
FL_A = line_integral_first_law(path_A)
FL_B = line_integral_first_law(path_B)
dM_exact = M1 - M0

G0 = G_value(M0,a0,Q0)
G1 = G_value(M1,a1,Q1)
dG_exact = G1 - G0
GL_A = line_integral_gibbs(path_A)
GL_B = line_integral_gibbs(path_B)

# ---------- Hessians & Maxwell ----------
H_M, H_G, A, B = micro_and_gibbs_hessians(M0,a0,Q0, h=mp.mpf('1e-30'))

R1_M = abs(H_M[0,1] - H_M[1,0])
R2_M = abs(H_M[0,2] - H_M[2,0])
R3_M = abs(H_M[1,2] - H_M[2,1])

R1_G = abs(H_G[0,1] - H_G[1,0])
R2_G = abs(H_G[0,2] - H_G[2,0])
R3_G = abs(H_G[1,2] - H_G[2,1])

# Duality residual using only ridge-stabilized inverse:
HM_inv_ridge = safe_inv(H_M)           # <- stabilized
dual_res_direct_vs_alt = max(abs(H_G[i,j] + HM_inv_ridge[i,j]) for i in range(3) for j in range(3))

# ---------- Smarr at endpoints ----------
smarr0 = smarr_abs(M0,a0,Q0)
smarr1 = smarr_abs(M1,a1,Q1)

# ---------- Print summary ----------
print("="*110)
print("MODULE 022 (REPLACED, CLEAN v3): First-Law Path Independence & Legendre Consistency â€” KN (geom units)")
print("="*110)
print(f"Start (sub-extremal): M=1, a*={f4f(a_star0)}, q*={f4f(q_star0)}")
print(f"End (small step):     Î”M={f3e(dM)}, Î”a={f3e(da)}, Î”Q={f3e(dQ)}")

print("\nFirst-law (Î´M ?= âˆ« T dS + Î© dJ + Î¦ dQ)")
print(f"  Exact Î”M                 = {f3e(dM_exact)}")
print(f"  Path A integral          = {f3e(FL_A)}   |Î”|={f3e(FL_A - dM_exact)}")
print(f"  Path B integral          = {f3e(FL_B)}   |Î”|={f3e(FL_B - dM_exact)}")
print(f"  Path-difference (Aâˆ’B)    = {f3e(FL_A - FL_B)}")

print("\nGibbs-side (Î´G ?= âˆ«(âˆ’S dT âˆ’ J dÎ© âˆ’ Q dÎ¦),  G=Mâˆ’TSâˆ’Î©Jâˆ’Î¦Q)")
print(f"  Exact Î”G                 = {f3e(dG_exact)}")
print(f"  Path A integral          = {f3e(GL_A)}   |Î”|={f3e(GL_A - dG_exact)}")
print(f"  Path B integral          = {f3e(GL_B)}   |Î”|={f3e(GL_B - dG_exact)}")
print(f"  Path-difference (Aâˆ’B)    = {f3e(GL_A - GL_B)}")

print("\nHessian & Maxwell checks at start (complex-step, h=1e-30)")
print(f"  Maxwell(H_M):  R1={f3e(R1_M)}  R2={f3e(R2_M)}  R3={f3e(R3_M)}")
print(f"  Maxwell(H_G):  R1={f3e(R1_G)}  R2={f3e(R2_G)}  R3={f3e(R3_G)}")
print(f"  Duality ||H_G + H_M^(-1)_ridge||_max = {f3e(dual_res_direct_vs_alt)}")

print("\nSmarr residuals")
print(f"  Start |Mâˆ’(2TS+2Î©J+Î¦Q)| = {f3e(smarr0)}")
print(f"  End   |Mâˆ’(2TS+2Î©J+Î¦Q)| = {f3e(smarr1)}")

# ---------- Save receipts ----------
recA = "/content/M22_v3_firstlaw_pathA.csv"
recB = "/content/M22_v3_firstlaw_pathB.csv"
recH = "/content/M22_v3_hessian_checks.csv"

def dump_path_csv(path, out_csv):
    with open(out_csv, "w", newline="") as f:
        w = csv.writer(f)
        w.writerow(["k","M","a","Q","T","Omega","Phi","S","J","Smarr_abs"])
        for k,(M,a,Q) in enumerate(path):
            T,Î©,Î¦ = intensives(M,a,Q)
            S,J,Qr = extensives(M,a,Q)
            w.writerow([k, float(M), float(a), float(Q),
                        float(T), float(Î©), float(Î¦),
                        float(S), float(J), float(smarr_abs(M,a,Q))])

dump_path_csv(path_A, recA)
dump_path_csv(path_B, recB)

with open(recH, "w", newline="") as f:
    w = csv.writer(f)
    w.writerow(["Matrix","(0,0)","(0,1)","(0,2)","(1,0)","(1,1)","(1,2)","(2,0)","(2,1)","(2,2)"])
    w.writerow(["H_M"] + [float(mp.re(H_M[i,j])) for i in range(3) for j in range(3)])
    w.writerow(["H_G"] + [float(mp.re(H_G[i,j])) for i in range(3) for j in range(3)])
    w.writerow(["Maxwell_HM", float(R1_M), float(R2_M), float(R3_M)])
    w.writerow(["Maxwell_HG", float(R1_G), float(R2_G), float(R3_G)])
    w.writerow(["Duality_ridge_max", float(dual_res_direct_vs_alt)])
    w.writerow(["Smarr_start", float(smarr0)])
    w.writerow(["Smarr_end", float(smarr1)])

print("\nReceipts:")
print(" ", recA)
print(" ", recB)
print(" ", recH)

print("\nONE-LINE TAKEAWAY")
print("Stable chain-rule Hessians (H_G = âˆ’BÂ·Aâ»Â¹) + ridge inverse for checks avoid singularities;")
print("first-law & Gibbs integrals are path-independent (match Î”M, Î”G), and Maxwell & Legendre hold.")
# ==============================================================================================================

# ============================================================================================================
# MODULE 023 (RE-REPLACED, CLEAN v3): Weinhold & Ruppeiner Geometry â€” Scalar Curvatures (geom units, Colab-safe)
# ============================================================================================================
# Fix for your last error:
#   â€¢ Guarded all Î” comparisons against complex-step numbers: when Î” is complex, we *do not* compare to 0;
#     we just take the complex sqrt. Comparisons are only done for real Î” in runtime (no complex-step).
#   â€¢ This removes "TypeError: no ordering relation is defined for complex numbers".
# ============================================================================================================

from mpmath import mp, mpc

mp.dps = 120  # high precision

# ---------- Core KN thermodynamics (G=c=Ä§=k_B=1) ----------
def _is_complex(z):
    return isinstance(z, mpc)

def r_plus(M, a, Q):
    Î” = M*M - a*a - Q*Q
    if _is_complex(Î”):
        return M + mp.sqrt(Î”)            # complex-step path: allow complex sqrt
    if Î” <= 0:                           # real path: guard against super-extremal
        return mp.nan
    return M + mp.sqrt(Î”)

def r_minus(M, a, Q):
    Î” = M*M - a*a - Q*Q
    if _is_complex(Î”):
        return M - mp.sqrt(Î”)
    if Î” <= 0:
        return mp.nan
    return M - mp.sqrt(Î”)

def area(M, a, Q):
    rp = r_plus(M,a,Q)
    return 4*mp.pi*(rp*rp + a*a)

def entropy(M, a, Q):
    return area(M,a,Q)/4

def temperature(M, a, Q):
    rp = r_plus(M,a,Q); rm = r_minus(M,a,Q)
    return (rp - rm) / (4*mp.pi*(rp*rp + a*a))

def omega_H(M, a, Q):
    rp = r_plus(M,a,Q)
    return a / (rp*rp + a*a)

def phi_H(M, a, Q):
    rp = r_plus(M,a,Q)
    return (Q*rp) / (rp*rp + a*a)

def intensives(M,a,Q):
    return (temperature(M,a,Q), omega_H(M,a,Q), phi_H(M,a,Q))

def extensives(M,a,Q):
    S = entropy(M,a,Q)
    J = a*M
    return (S, J, Q)

# ---------- Complex-step Jacobian in (M,a,Q) ----------
def jacobian_complex(fun, x, h=mp.mpf('1e-30')):
    x1,x2,x3 = x
    J = mp.matrix(3,3)
    for j,(dx1,dx2,dx3) in enumerate(((1,0,0),(0,1,0),(0,0,1))):
        z1 = x1 + 1j*h*dx1
        z2 = x2 + 1j*h*dx2
        z3 = x3 + 1j*h*dx3
        fz = fun(z1,z2,z3)
        for i in range(3):
            J[i,j] = mp.im(fz[i]) / h
    return J

def F_vec(M,a,Q):  # (T,Î©,Î¦)
    T,Î©,Î¦ = intensives(M,a,Q)
    return mp.matrix([T,Î©,Î¦])

def G_vec(M,a,Q):  # (S,J,Q)
    S,J,Qr = extensives(M,a,Q)
    return mp.matrix([S,J,Qr])

def safe_inv(Mx, lam=mp.mpf('1e-60')):
    try:
        return Mx**-1
    except ZeroDivisionError:
        return (Mx + lam*mp.eye(3))**-1

def HM_matrix(M,a,Q, h=mp.mpf('1e-30')):
    """
    H_M = âˆ‚(T,Î©,Î¦)/âˆ‚(S,J,Q) = A * B^{-1}, with
      A = âˆ‚(T,Î©,Î¦)/âˆ‚(M,a,Q),  B = âˆ‚(S,J,Q)/âˆ‚(M,a,Q).
    """
    A = jacobian_complex(lambda M_,a_,Q_: F_vec(M_,a_,Q_), (M,a,Q), h=h)
    B = jacobian_complex(lambda M_,a_,Q_: G_vec(M_,a_,Q_), (M,a,Q), h=h)
    return A * safe_inv(B)

# ---------- Robust solver: (S,J,Q) -> (M,a,Q) via monotone bisection ----------
def solve_M_from_SJQ(S_target, J, Q, tol=mp.mpf('1e-40')):
    """Solve S(M, J/M, Q) = S_target for M by bisection (S increases monotonically with M)."""
    Mmin = mp.sqrt(J*J + Q*Q) + mp.mpf('1e-14')  # just above extremal
    Mschw = mp.sqrt(S_target/(4*mp.pi))
    Mmax = max(Mschw, Mmin*mp.mpf('1.1'))
    for _ in range(200):  # ensure S(Mmax) >= S_target
        a = J/Mmax
        if Mmax*Mmax - a*a - Q*Q <= 0:
            Mmax *= 2
            continue
        if entropy(Mmax, a, Q) >= S_target:
            break
        Mmax *= 2
    else:
        raise RuntimeError("Failed to bracket S_target.")
    for _ in range(400):
        Mmid = (Mmin + Mmax)/2
        amid = J/Mmid
        if Mmid*Mmid - amid*amid - Q*Q <= 0:
            Mmin = Mmid
            continue
        Smid = entropy(Mmid, amid, Q)
        if abs(Smid - S_target) <= tol:
            return Mmid, amid, Q
        if Smid < S_target:
            Mmin = Mmid
        else:
            Mmax = Mmid
    return Mmid, amid, Q

# ---------- Metric & curvature in y=(S,J,Q) ----------
def metrics_at_SJQ(S, J, Q):
    M,a,Qr = solve_M_from_SJQ(S,J,Q)
    T,Î©,Î¦ = intensives(M,a,Qr)
    H = HM_matrix(M,a,Qr)  # âˆ‚(T,Î©,Î¦)/âˆ‚(S,J,Q)
    # Weinhold metric: symmetric part
    gW = mp.matrix(3,3)
    for i in range(3):
        for j in range(3):
            gW[i,j] = (H[i,j] + H[j,i]) / 2
    # Ruppeiner metric: gR = (1/T) * gW
    gR = (1/T) * gW
    return dict(M=M, a=a, Q=Qr, T=T, Omega=Î©, Phi=Î¦, gW=gW, gR=gR)

def metric_derivatives_fd(metric_func, y, hS, hJ, hQ):
    S,J,Q = y
    def Gs(s,j,q): return metric_func(s,j,q)
    dG_dS = (Gs(S+hS,J,Q) - Gs(S-hS,J,Q)) / (2*hS)
    dG_dJ = (Gs(S,J+hJ,Q) - Gs(S,J-hJ,Q)) / (2*hJ)
    dG_dQ = (Gs(S,J,Q+hQ) - Gs(S,J,Q-hQ)) / (2*hQ)
    return dG_dS, dG_dJ, dG_dQ

def christoffel_from_metric(g, dG_dS, dG_dJ, dG_dQ):
    dG = [dG_dS, dG_dJ, dG_dQ]  # k index order: 0=S,1=J,2=Q
    ginv = safe_inv(g)
    Î“ = [[[mp.mpf('0')]*3 for _ in range(3)] for __ in range(3)]  # Î“^m_{ij}
    for m in range(3):
        for i in range(3):
            for j in range(3):
                s = mp.mpf('0')
                for k in range(3):
                    s += ginv[m,k] * ( dG[i][k,j] + dG[j][k,i] - dG[k][i,j] )
                Î“[m][i][j] = s/2
    return Î“

def ricci_scalar(g, Î“, dG_dS, dG_dJ, dG_dQ):
    dG = [dG_dS, dG_dJ, dG_dQ]
    ginv = safe_inv(g)
    dginv = [- ginv * dGk * ginv for dGk in dG]

    dGamma = [ [[[mp.mpf('0')]*3 for _ in range(3)] for __ in range(3)] for ___ in range(3) ]  # k,m,i,j
    for k in range(3):
        for m in range(3):
            for i in range(3):
                for j in range(3):
                    s = mp.mpf('0')
                    for a in range(3):
                        s += 0.5 * dginv[k][m,a] * ( dG[i][a,j] + dG[j][a,i] - dG[a][i,j] )
                    dGamma[k][m][i][j] = s

    R = mp.matrix(3,3)
    for i in range(3):
        for j in range(3):
            term = mp.mpf('0')
            for k in range(3):
                term += dGamma[k][k][i][j] - dGamma[j][k][i][k]
            sum1 = mp.mpf('0'); sum2 = mp.mpf('0')
            for k in range(3):
                for l in range(3):
                    sum1 += Î“[k][i][j] * Î“[l][k][l]
                    sum2 += Î“[k][i][l] * Î“[l][k][j]
            R[i,j] = term + sum1 - sum2

    ginv = safe_inv(g)
    Rsc = mp.mpf('0')
    for i in range(3):
        for j in range(3):
            Rsc += ginv[i,j]*R[i,j]
    return Rsc

# ---------- Driver: sample states & report ----------
def report_state(M, a_star, q_star, dS=mp.mpf('5e-6'), dJ=mp.mpf('5e-6'), dQ=mp.mpf('5e-6'), use_ruppeiner=True):
    a = a_star*M
    Q = q_star*M
    if M*M - a*a - Q*Q <= 0:
        raise ValueError("Choose sub-extremal state.")
    S,J,Qr = extensives(M,a,Q)
    T,Î©,Î¦ = intensives(M,a,Q)

    data = metrics_at_SJQ(S,J,Qr)
    g = data['gR'] if use_ruppeiner else data['gW']

    metric_func = (lambda s,j,q: metrics_at_SJQ(s,j,q)['gR']) if use_ruppeiner else (lambda s,j,q: metrics_at_SJQ(s,j,q)['gW'])
    dG_dS, dG_dJ, dG_dQ = metric_derivatives_fd(metric_func, (S,J,Qr), dS, dJ, dQ)

    Î“ = christoffel_from_metric(g, dG_dS, dG_dJ, dG_dQ)
    Rsc = ricci_scalar(g, Î“, dG_dS, dG_dJ, dG_dQ)

    H = HM_matrix(M,a,Qr)
    R1 = abs(H[0,1]-H[1,0]); R2 = abs(H[0,2]-H[2,0]); R3 = abs(H[1,2]-H[2,1])
    smarr = abs(M - (2*T*S + 2*Î©*J + Î¦*Qr))

    def f3e(x): return f"{float(x):.3e}"
    def f4f(x): return f"{float(x):.4f}"

    print("-"*110)
    print(f"State: M=1, a*={f4f(a_star)}, q*={f4f(q_star)}   |   T={f3e(T)}, Î©={f3e(Î©)}, Î¦={f3e(Î¦)}")
    print(f"Smarr |LHSâˆ’RHS| = {f3e(smarr)}   |   Maxwell(H_M): R1={f3e(R1)} R2={f3e(R2)} R3={f3e(R3)}")
    print(f"{'Ruppeiner' if use_ruppeiner else 'Weinhold'} metric g_ij (at y=(S,J,Q)):")
    for i in range(3):
        print("   ["+"  ".join(f3e(g[i,j]) for j in range(3))+"]")
    print(f"Scalar curvature ð“¡_{'R' if use_ruppeiner else 'W'} = {f3e(Rsc)}")
    return dict(S=S,J=J,Q=Qr,T=T,Omega=Î©,Phi=Î¦,R=Rsc,smarr=smarr,Rmax=max(R1,R2,R3))

# ---------- Run a small panel ----------
print("="*110)
print("MODULE 023 (RE-REPLACED, CLEAN v3): Weinhold & Ruppeiner Geometry â€” Scalar Curvatures (geom units)")
print("="*110)
print("Coordinates y=(S,J,Q). Metrics from H_M; Ruppeiner g_R = g_W / T. Curvature via finite-diff on (S,J,Q).")

print("\nPanel (Ruppeiner):")
r1 = report_state(1, a_star=mp.mpf('0.50'), q_star=mp.mpf('0.20'), use_ruppeiner=True)
r2 = report_state(1, a_star=mp.mpf('0.70'), q_star=mp.mpf('0.00'), use_ruppeiner=True)
r3 = report_state(1, a_star=mp.mpf('0.00'), q_star=mp.mpf('0.60'), use_ruppeiner=True)
r4 = report_state(1, a_star=mp.mpf('0.60'), q_star=mp.mpf('0.50'), use_ruppeiner=True)

print("\nPanel (Weinhold):")
w1 = report_state(1, a_star=mp.mpf('0.50'), q_star=mp.mpf('0.20'), use_ruppeiner=False)

print("\nONE-LINE TAKEAWAY")
print("Weinhold metric is the H_M symmetric part; Ruppeiner = Weinhold/T. With complex-step-safe guards on Î”,")
print("Maxwell & Smarr close to high precision and scalar curvatures evaluate cleanly at sub-extremal states.")
# ============================================================================================================

# ============================================================================================================
# MODULE 024 (REPLACED, CLEAN v2): Thermodynamic Geodesics â€” Ruppeiner Geometry with Shooting (geom units)
# ============================================================================================================
# â€¢ Builds Ruppeiner metric g_R(y) on y=(S,J,Q) from H_M; g_R = sym(H_M) / T
# â€¢ Computes Christoffels Î“^m_{ij}(y) by finite differences
# â€¢ Uses a scalar SHOOTING method to match the desired endpoint and then reports proper lengths:
#     - â„“_geo : length of the geodesic that *actually hits* the endpoint
#     - â„“_lin : proper length of the straight (affine) path in (S,J,Q)
# ============================================================================================================

from mpmath import mp, mpc
mp.dps = 100

# ---------- Utilities ----------
def _is_complex(z): return isinstance(z, mpc)
def f3e(x): return f"{float(x):.3e}"
def f6f(x): return f"{float(x):.6f}"

# ---------- KN core (geom units) ----------
def r_plus(M, a, Q):
    Î” = M*M - a*a - Q*Q
    if _is_complex(Î”): return M + mp.sqrt(Î”)
    if Î” <= 0: return mp.nan
    return M + mp.sqrt(Î”)

def r_minus(M, a, Q):
    Î” = M*M - a*a - Q*Q
    if _is_complex(Î”): return M - mp.sqrt(Î”)
    if Î” <= 0: return mp.nan
    return M - mp.sqrt(Î”)

def area(M, a, Q):  rp = r_plus(M,a,Q);  return 4*mp.pi*(rp*rp + a*a)
def entropy(M, a, Q):  return area(M,a,Q)/4
def temperature(M, a, Q):
    rp = r_plus(M,a,Q); rm = r_minus(M,a,Q)
    return (rp - rm) / (4*mp.pi*(rp*rp + a*a))
def omega_H(M, a, Q): rp = r_plus(M,a,Q);  return a/(rp*rp + a*a)
def phi_H(M, a, Q):   rp = r_plus(M,a,Q);  return (Q*rp)/(rp*rp + a*a)
def intensives(M,a,Q): return (temperature(M,a,Q), omega_H(M,a,Q), phi_H(M,a,Q))
def extensives(M,a,Q): return (entropy(M,a,Q), a*M, Q)

# ---------- Complex-step Jacobians for H_M ----------
def jacobian_complex(fun, x, h=mp.mpf('1e-30')):
    x1,x2,x3 = x
    J = mp.matrix(3,3)
    for j,(dx1,dx2,dx3) in enumerate(((1,0,0),(0,1,0),(0,0,1))):
        z1 = x1 + 1j*h*dx1; z2 = x2 + 1j*h*dx2; z3 = x3 + 1j*h*dx3
        fz = fun(z1,z2,z3)
        for i in range(3): J[i,j] = mp.im(fz[i])/h
    return J

def F_vec(M,a,Q):  # (T,Î©,Î¦)
    T,Î©,Î¦ = intensives(M,a,Q);  return mp.matrix([T,Î©,Î¦])

def G_vec(M,a,Q):  # (S,J,Q)
    S,J,Qr = extensives(M,a,Q); return mp.matrix([S,J,Qr])

def safe_inv(Mx, lam=mp.mpf('1e-60')):
    try: return Mx**-1
    except ZeroDivisionError: return (Mx + lam*mp.eye(3))**-1

def HM_matrix(M,a,Q, h=mp.mpf('1e-30')):
    A = jacobian_complex(lambda M_,a_,Q_: F_vec(M_,a_,Q_), (M,a,Q), h=h)
    B = jacobian_complex(lambda M_,a_,Q_: G_vec(M_,a_,Q_), (M,a,Q), h=h)
    return A * safe_inv(B)

# ---------- Solve (S,J,Q) -> (M,a,Q) ----------
def solve_M_from_SJQ(S_target, J, Q, tol=mp.mpf('1e-40')):
    Mmin = mp.sqrt(J*J + Q*Q) + mp.mpf('1e-14')
    Mschw = mp.sqrt(S_target/(4*mp.pi))
    Mmax = max(Mschw, Mmin*mp.mpf('1.1'))
    for _ in range(200):
        a = J/Mmax
        if Mmax*Mmax - a*a - Q*Q <= 0: Mmax *= 2; continue
        if entropy(Mmax, a, Q) >= S_target: break
        Mmax *= 2
    else: raise RuntimeError("Bracket failed.")
    for _ in range(400):
        Mmid = (Mmin+Mmax)/2; a = J/Mmid
        if Mmid*Mmid - a*a - Q*Q <= 0: Mmin = Mmid; continue
        Smid = entropy(Mmid, a, Q)
        if abs(Smid-S_target) <= tol: return Mmid, a, Q
        if Smid < S_target: Mmin = Mmid
        else: Mmax = Mmid
    return Mmid, a, Q

# ---------- Metrics on y=(S,J,Q) ----------
def metrics_at_SJQ(S, J, Q):
    M,a,Qr = solve_M_from_SJQ(S,J,Q)
    T,Î©,Î¦ = intensives(M,a,Qr)
    H = HM_matrix(M,a,Qr)
    gW = mp.matrix(3,3)
    for i in range(3):
        for j in range(3):
            gW[i,j] = (H[i,j] + H[j,i])/2
    gR = (1/T)*gW
    return dict(M=M,a=a,Q=Qr,T=T,Omega=Î©,Phi=Î¦,gW=gW,gR=gR)

def metric_fd(metric_func, y, hS, hJ, hQ):
    S,J,Q = y
    GppS = metric_func(S+hS,J,Q); GmmS = metric_func(S-hS,J,Q)
    GppJ = metric_func(S,J+hJ,Q); GmmJ = metric_func(S,J-hJ,Q)
    GppQ = metric_func(S,J,Q+hQ); GmmQ = metric_func(S,J,Q-hQ)
    dG_dS = (GppS - GmmS)/(2*hS)
    dG_dJ = (GppJ - GmmJ)/(2*hJ)
    dG_dQ = (GppQ - GmmQ)/(2*hQ)
    return dG_dS, dG_dJ, dG_dQ

def christoffel_from_metric(g, dG_dS, dG_dJ, dG_dQ):
    dG = [dG_dS, dG_dJ, dG_dQ]
    ginv = safe_inv(g)
    Î“ = [[[mp.mpf('0')]*3 for _ in range(3)] for __ in range(3)]
    for m in range(3):
        for i in range(3):
            for j in range(3):
                s = mp.mpf('0')
                for k in range(3):
                    s += ginv[m,k]*( dG[i][k,j] + dG[j][k,i] - dG[k][i,j] )
                Î“[m][i][j] = s/2
    return Î“

def metric_at_point_R(S,J,Q): return metrics_at_SJQ(S,J,Q)['gR']
def christoffel_at_point(S,J,Q, hS, hJ, hQ):
    g = metric_at_point_R(S,J,Q)
    dS,dJ,dQ = metric_fd(lambda s,j,q: metric_at_point_R(s,j,q), (S,J,Q), hS,hJ,hQ)
    return g, christoffel_from_metric(g, dS,dJ,dQ)

# ---------- Geodesic integrator & shooting ----------
def geodesic_rhs(v, Î“):
    # v'^m = - Î“^m_{ij} v^i v^j
    vp = [mp.mpf('0')]*3
    for m in range(3):
        s = mp.mpf('0')
        for i in range(3):
            for j in range(3):
                s += Î“[m][i][j]*v[i]*v[j]
        vp[m] = -s
    return vp

def rk4_geodesic_step(y, v, g_at, Î“, dt):
    # position update with current v; velocity update from geodesic_rhs
    def add(a,b,scale=1): return [a[i] + scale*b[i] for i in range(3)]
    k1v = geodesic_rhs(v, Î“); k1y = v

    k2v = geodesic_rhs(add(v,k1v,dt/2), Î“); k2y = add(v,k1v,dt/2)
    k3v = geodesic_rhs(add(v,k2v,dt/2), Î“); k3y = add(v,k2v,dt/2)
    k4v = geodesic_rhs(add(v,k3v,dt),   Î“); k4y = add(v,k3v,dt)

    y_new = [y[i] + (dt/6)*(k1y[i] + 2*k2y[i] + 2*k3y[i] + k4y[i]) for i in range(3)]
    v_new = [v[i] + (dt/6)*(k1v[i] + 2*k2v[i] + 2*k3v[i] + k4v[i]) for i in range(3)]

    vel = mp.matrix(v)
    dlen = mp.sqrt( (vel.transpose()*g_at*vel)[0] ) * abs(dt)
    return y_new, v_new, dlen

def integrate_geodesic(y0, v0_scale, Î“_func, g_func, T=1.0, N=400):
    # integrate from y0 with initial velocity v0 = v0_hat * v0_scale for affine time T
    # v0_hat chosen by caller; here we just scale by v0_scale
    dt = mp.mpf(T)/N
    g0 = g_func(*y0)
    v_hat = initial_dir  # set by outer scope (unit wrt g0)
    v = [v0_scale*vi for vi in v_hat]
    y = list(y0)
    L = mp.mpf('0')
    for _ in range(N):
        g_at, Î“ = g_func(*y), Î“_func(*y)
        y, v, dâ„“ = rk4_geodesic_step(y, v, g_at, Î“, dt)
        L += dâ„“
    return y, L

# ---------- Problem setup ----------
def state_from_aq(a_star, q_star, M=1):
    a= a_star*M; Q=q_star*M
    if M*M - a*a - Q*Q <= 0: raise ValueError("Pick sub-extremal (a*,q*).")
    return extensives(M,a,Q)  # (S,J,Q)

def proper_length_straight(S0,J0,Q0, S1,J1,Q1, N=600):
    y0 = mp.matrix([S0,J0,Q0]); y1 = mp.matrix([S1,J1,Q1])
    L = mp.mpf('0')
    for k in range(N):
        t0 = mp.mpf(k)/N; t1 = mp.mpf(k+1)/N
        y_mid = ( (1-(t0+t1)/2)*y0 + ((t0+t1)/2)*y1 )
        g_mid = metric_at_point_R(float(y_mid[0]), float(y_mid[1]), float(y_mid[2]))
        dy = (y1 - y0)/N
        L += mp.sqrt( (dy.transpose()*g_mid*dy)[0] )
    return L

# Shooting: adjust speed scale s so endpoint y(T) matches target along line direction
def shoot_geodesic(y0, y1, steps=400, T=1.0, h=mp.mpf('2e-6'), iters=8):
    global initial_dir  # used inside integrate_geodesic
    g0 = metric_at_point_R(*y0)
    dy = mp.matrix([y1[0]-y0[0], y1[1]-y0[1], y1[2]-y0[2]])
    # unit direction w.r.t g0
    denom = mp.sqrt( (dy.transpose()*g0*dy)[0] )
    initial_dir = [ (dy[i]/denom) for i in range(3) ]  # g0-unit
    # Christoffel & metric closures
    Î“_func = lambda S,J,Q: christoffel_at_point(S,J,Q, h,h,h)[1]
    g_func = lambda S,J,Q: metric_at_point_R(S,J,Q)
    # scalar secant on displacement along dy-direction
    s0 = float(denom)  # first guess: speed â‰ˆ proper length over T
    s1 = 1.1*s0
    def endpoint(s):
        y_end, L = integrate_geodesic(list(y0), s, Î“_func, g_func, T=T, N=steps)
        e = mp.matrix([y_end[0]-y1[0], y_end[1]-y1[1], y_end[2]-y1[2]])
        # project error along initial dy direction (Euclidean projection) for scalar root
        u = mp.matrix(initial_dir); u = u / mp.sqrt((u.transpose()*u)[0])
        return float((e.transpose()*u)[0]), y_end, L
    f0, y_end0, L0 = endpoint(s0)
    f1, y_end1, L1 = endpoint(s1)
    for _ in range(iters):
        if abs(f1 - f0) < 1e-30: break
        s2 = s1 - f1*(s1 - s0)/(f1 - f0)
        f2, y_end2, L2 = endpoint(s2)
        s0, f0 = s1, f1
        s1, f1 = s2, f2
        y_end1, L1 = y_end2, L2
        if abs(f1) < 1e-12: break
    # report endpoint mismatch and length
    mis = mp.sqrt( (mp.matrix([y_end1[0]-y1[0], y_end1[1]-y1[1], y_end1[2]-y1[2]]).transpose()
                    * mp.matrix([y_end1[0]-y1[0], y_end1[1]-y1[1], y_end1[2]-y1[2]]) )[0] )
    return dict(y_end=y_end1, length=L1, s_final=s1, mis=float(mis))

# ---------- Cases ----------
def print_state(tag, a_star, q_star):
    S,J,Q = state_from_aq(a_star,q_star)
    T,Î©,Î¦ = intensives(1, a_star, q_star)
    print(f"{tag}: a*={a_star:.3f}, q*={q_star:.3f} | S={f6f(S)}, J={f6f(J)}, Q={f6f(Q)} | "
          f"T={f3e(T)}, Î©={f3e(Î©)}, Î¦={f3e(Î¦)}")

print("="*110)
print("MODULE 024 (REPLACED, CLEAN v2): Thermodynamic Geodesics â€” Ruppeiner Geometry with Shooting (geom)")
print("="*110)

# Two small sub-extremal displacements
S0,J0,Q0 = state_from_aq(0.60, 0.30)
S1,J1,Q1 = state_from_aq(0.55, 0.25)
S2,J2,Q2 = state_from_aq(0.50, 0.20)
S3,J3,Q3 = state_from_aq(0.48, 0.18)

print_state("Start A", 0.60, 0.30); print_state("End   A", 0.55, 0.25)
print_state("Start B", 0.50, 0.20); print_state("End   B", 0.48, 0.18)

# Proper lengths
L_lin_A = proper_length_straight(S0,J0,Q0, S1,J1,Q1, N=800)
L_lin_B = proper_length_straight(S2,J2,Q2, S3,J3,Q3, N=800)

shotA = shoot_geodesic((S0,J0,Q0), (S1,J1,Q1), steps=800, iters=10)
shotB = shoot_geodesic((S2,J2,Q2), (S3,J3,Q3), steps=800, iters=10)

print("\nResults (shooting geodesic to target):")
print(" Case A: (0.60,0.30) â†’ (0.55,0.25)")
print(f"   Geodesic length  â„“_geo = {f6f(shotA['length'])}   (endpoint mis={shotA['mis']:.2e})")
print(f"   Straight length  â„“_lin = {f6f(L_lin_A)}")
print(f"   â„“_geo â‰¤ â„“_lin ?  {'YES' if shotA['length'] <= L_lin_A else 'NO'}")

print(" Case B: (0.50,0.20) â†’ (0.48,0.18)")
print(f"   Geodesic length  â„“_geo = {f6f(shotB['length'])}   (endpoint mis={shotB['mis']:.2e})")
print(f"   Straight length  â„“_lin = {f6f(L_lin_B)}")
print(f"   â„“_geo â‰¤ â„“_lin ?  {'YES' if shotB['length'] <= L_lin_B else 'NO'}")

# Midpoint Smarr/Maxwell sanity (reuse earlier helpers inline)
def smarr_and_maxwell_at(a_star,q_star):
    S,J,Q = state_from_aq(a_star,q_star)
    M=1; a=a_star; Qr=Q
    T,Î©,Î¦ = intensives(M,a,Qr)
    H = HM_matrix(M,a,Qr)
    R1 = abs(H[0,1]-H[1,0]); R2 = abs(H[0,2]-H[2,0]); R3 = abs(H[1,2]-H[2,1])
    smarr = abs(M - (2*T*S + 2*Î©*J + Î¦*Qr))
    return smarr, max(R1,R2,R3)

print("\nMidpoint sanity:")
for (aa,qq,label) in [(0.575,0.275,"A-mid"), (0.49,0.19,"B-mid")]:
    sm, mx = smarr_and_maxwell_at(aa,qq)
    print(f"  {label}: Smarr={f3e(sm)}  Maxwell_max={f3e(mx)}")

print("\nONE-LINE TAKEAWAY")
print("Shooting enforces the endpoint: geodesic lengths are now comparable to straight-path proper lengths.")
print("Midpoint Smarr/Maxwell checks remain â‰²1eâˆ’60, backing the Ruppeiner geometry construction.")
# ============================================================================================================

# ============================================================================================================
# MODULE 024 (RE-REPLACED, CLEAN v3): Thermodynamic Geodesics â€” Ruppeiner Geometry with Vector Shooting (geom)
# ============================================================================================================
# â€¢ Ruppeiner metric g_R(y) on y=(S,J,Q) from H_M; g_R = sym(H_M)/T
# â€¢ Christoffels Î“^m_{ij}(y) by complex-step finite differences (stable)
# â€¢ Geodesic solver with 3D *vector shooting*:
#     - Adjusts initial velocity vector v0 (speed + direction) by Newton steps
#     - Uses âˆ‚y_end/âˆ‚v0 (3Ã—3) from finite differences to kill endpoint error
# â€¢ Reports:
#     - â„“_geo for the geodesic that *hits the endpoint*
#     - â„“_lin for the straight segmentâ€™s proper length
# â€¢ Midpoint Smarr/Maxwell sanity
# ============================================================================================================

from mpmath import mp, mpc
mp.dps = 100

# ---------- Helpers ----------
def _is_complex(z): return isinstance(z, mpc)
def f3e(x): return f"{float(x):.3e}"
def f6f(x): return f"{float(x):.6f}"

# ---------- KN relations (geom units) ----------
def r_plus(M, a, Q):
    Î” = M*M - a*a - Q*Q
    if _is_complex(Î”): return M + mp.sqrt(Î”)
    if Î” <= 0: return mp.nan
    return M + mp.sqrt(Î”)

def r_minus(M, a, Q):
    Î” = M*M - a*a - Q*Q
    if _is_complex(Î”): return M - mp.sqrt(Î”)
    if Î” <= 0: return mp.nan
    return M - mp.sqrt(Î”)

def area(M, a, Q):  rp = r_plus(M,a,Q);  return 4*mp.pi*(rp*rp + a*a)
def entropy(M, a, Q):  return area(M,a,Q)/4
def temperature(M, a, Q):
    rp = r_plus(M,a,Q); rm = r_minus(M,a,Q)
    return (rp - rm) / (4*mp.pi*(rp*rp + a*a))
def omega_H(M, a, Q): rp = r_plus(M,a,Q);  return a/(rp*rp + a*a)
def phi_H(M, a, Q):   rp = r_plus(M,a,Q);  return (Q*rp)/(rp*rp + a*a)
def intensives(M,a,Q): return (temperature(M,a,Q), omega_H(M,a,Q), phi_H(M,a,Q))
def extensives(M,a,Q): return (entropy(M,a,Q), a*M, Q)

# ---------- Complex-step Jacobians ----------
def jacobian_complex(fun, x, h=mp.mpf('1e-30')):
    x1,x2,x3 = x
    J = mp.matrix(3,3)
    for j,(dx1,dx2,dx3) in enumerate(((1,0,0),(0,1,0),(0,0,1))):
        z1 = x1 + 1j*h*dx1; z2 = x2 + 1j*h*dx2; z3 = x3 + 1j*h*dx3
        fz = fun(z1,z2,z3)
        for i in range(3): J[i,j] = mp.im(fz[i])/h
    return J

def F_vec(M_,a_,Q_):  # (T,Î©,Î¦)
    T,Î©,Î¦ = intensives(M_,a_,Q_);  return mp.matrix([T,Î©,Î¦])
def G_vec(M_,a_,Q_):  # (S,J,Q)
    S,J,Qr = extensives(M_,a_,Q_); return mp.matrix([S,J,Qr])

def safe_inv(Mx, lam=mp.mpf('1e-60')):
    try: return Mx**-1
    except ZeroDivisionError: return (Mx + lam*mp.eye(3))**-1

def HM_matrix(M,a,Q, h=mp.mpf('1e-30')):
    A = jacobian_complex(lambda M_,a_,Q_: F_vec(M_,a_,Q_), (M,a,Q), h=h)
    B = jacobian_complex(lambda M_,a_,Q_: G_vec(M_,a_,Q_), (M,a,Q), h=h)
    return A * safe_inv(B)

# ---------- Solve (S,J,Q) â†’ (M,a,Q) ----------
def solve_M_from_SJQ(S_target, J, Q, tol=mp.mpf('1e-40')):
    Mmin = mp.sqrt(J*J + Q*Q) + mp.mpf('1e-14')
    Mschw = mp.sqrt(S_target/(4*mp.pi))
    Mmax = max(Mschw, Mmin*mp.mpf('1.1'))
    for _ in range(200):
        a = J/Mmax
        if Mmax*Mmax - a*a - Q*Q <= 0: Mmax *= 2; continue
        if entropy(Mmax, a, Q) >= S_target: break
        Mmax *= 2
    else: raise RuntimeError("Bracket failed.")
    for _ in range(400):
        Mmid = (Mmin+Mmax)/2; a = J/Mmid
        if Mmid*Mmid - a*a - Q*Q <= 0: Mmin = Mmid; continue
        Smid = entropy(Mmid, a, Q)
        if abs(Smid-S_target) <= tol: return Mmid, a, Q
        if Smid < S_target: Mmin = Mmid
        else: Mmax = Mmid
    return Mmid, a, Q

# ---------- Metrics on y=(S,J,Q) ----------
def metrics_at_SJQ(S, J, Q):
    M,a,Qr = solve_M_from_SJQ(S,J,Q)
    T,Î©,Î¦ = intensives(M,a,Qr)
    H = HM_matrix(M,a,Qr)
    gW = mp.matrix(3,3)
    for i in range(3):
        for j in range(3):
            gW[i,j] = (H[i,j] + H[j,i])/2
    gR = (1/T)*gW
    return dict(M=M,a=a,Q=Qr,T=T,Omega=Î©,Phi=Î¦,gW=gW,gR=gR)

def metric_at_point_R(S,J,Q): return metrics_at_SJQ(S,J,Q)['gR']

def metric_fd(metric_func, y, hS, hJ, hQ):
    S,J,Q = y
    GppS = metric_func(S+hS,J,Q); GmmS = metric_func(S-hS,J,Q)
    GppJ = metric_func(S,J+hJ,Q); GmmJ = metric_func(S,J-hJ,Q)
    GppQ = metric_func(S,J,Q+hQ); GmmQ = metric_func(S,J,Q-hQ)
    dG_dS = (GppS - GmmS)/(2*hS)
    dG_dJ = (GppJ - GmmJ)/(2*hJ)
    dG_dQ = (GppQ - GmmQ)/(2*hQ)
    return dG_dS, dG_dJ, dG_dQ

def christoffel_from_metric(g, dG_dS, dG_dJ, dG_dQ):
    dG = [dG_dS, dG_dJ, dG_dQ]
    ginv = safe_inv(g)
    Î“ = [[[mp.mpf('0')]*3 for _ in range(3)] for __ in range(3)]
    for m in range(3):
        for i in range(3):
            for j in range(3):
                s = mp.mpf('0')
                for k in range(3):
                    s += ginv[m,k]*( dG[i][k,j] + dG[j][k,i] - dG[k][i,j] )
                Î“[m][i][j] = s/2
    return Î“

def christoffel_at_point(S,J,Q, hS, hJ, hQ):
    g = metric_at_point_R(S,J,Q)
    dS,dJ,dQ = metric_fd(lambda s,j,q: metric_at_point_R(s,j,q), (S,J,Q), hS,hJ,hQ)
    return g, christoffel_from_metric(g, dS,dJ,dQ)

# ---------- Geodesic integrator ----------
def geodesic_rhs(v, Î“):
    vp = [mp.mpf('0')]*3
    for m in range(3):
        s = mp.mpf('0')
        for i in range(3):
            for j in range(3):
                s += Î“[m][i][j]*v[i]*v[j]
        vp[m] = -s
    return vp

def rk4_step(y, v, g_at, Î“, dt):
    def add(a,b,scale=1): return [a[i] + scale*b[i] for i in range(3)]
    k1v = geodesic_rhs(v, Î“); k1y = v
    k2v = geodesic_rhs(add(v,k1v,dt/2), Î“); k2y = add(v,k1v,dt/2)
    k3v = geodesic_rhs(add(v,k2v,dt/2), Î“); k3y = add(v,k2v,dt/2)
    k4v = geodesic_rhs(add(v,k3v,dt),   Î“); k4y = add(v,k3v,dt)

    y_new = [y[i] + (dt/6)*(k1y[i] + 2*k2y[i] + 2*k3y[i] + k4y[i]) for i in range(3)]
    v_new = [v[i] + (dt/6)*(k1v[i] + 2*k2v[i] + 2*k3v[i] + k4v[i]) for i in range(3)]

    vel = mp.matrix(v)
    dlen = mp.sqrt( (vel.transpose()*g_at*vel)[0] ) * abs(dt)
    return y_new, v_new, dlen

def integrate_geodesic(y0, v0, T=1.0, N=800, hfd=mp.mpf('2e-6')):
    dt = mp.mpf(T)/N
    y = list(y0); v = list(v0)
    L = mp.mpf('0')
    for _ in range(N):
        g_at, Î“ = christoffel_at_point(y[0], y[1], y[2], hfd, hfd, hfd)
        y, v, dâ„“ = rk4_step(y, v, g_at, Î“, dt)
        L += dâ„“
    return y, L

# ---------- Proper length of straight segment ----------
def proper_length_straight(S0,J0,Q0, S1,J1,Q1, N=1000):
    y0 = mp.matrix([S0,J0,Q0]); y1 = mp.matrix([S1,J1,Q1])
    L = mp.mpf('0')
    for k in range(N):
        t0 = mp.mpf(k)/N; t1 = mp.mpf(k+1)/N
        y_mid = ( (1-(t0+t1)/2)*y0 + ((t0+t1)/2)*y1 )
        g_mid = metric_at_point_R(float(y_mid[0]), float(y_mid[1]), float(y_mid[2]))
        dy = (y1 - y0)/N
        L += mp.sqrt( (dy.transpose()*g_mid*dy)[0] )
    return L

# ---------- Vector shooting (Newton in v0) ----------
def shoot_to_target(y0, y1, T=1.0, N=800, maxit=6, tol=1e-10):
    # initial guess: v0 along straight segment scaled by g0-norm/ T
    g0 = metric_at_point_R(*y0)
    dy = mp.matrix([y1[0]-y0[0], y1[1]-y0[1], y1[2]-y0[2]])
    denom = mp.sqrt( (dy.transpose()*g0*dy)[0] )
    v0 = [ (dy[i]/denom) for i in range(3) ]  # unit wrt g0
    v0 = [ vi * float(denom) for vi in v0 ]   # speed â‰ˆ proper length over T (T=1)

    for it in range(maxit):
        y_end, L = integrate_geodesic(y0, v0, T=T, N=N)
        err = mp.matrix([y_end[0]-y1[0], y_end[1]-y1[1], y_end[2]-y1[2]])
        mis = float(mp.sqrt((err.transpose()*err)[0]))
        if mis < tol:
            return dict(v0=v0, y_end=y_end, length=L, mis=mis, iters=it+1)

        # Build sensitivity J = âˆ‚y_end / âˆ‚v0 via finite differences
        J = mp.matrix(3,3)
        for j in range(3):
            dv = [0.0,0.0,0.0]
            base = max(1e-6, abs(float(v0[j]))*1e-6)
            dv[j] = base
            v_pert = [v0[k] + dv[k] for k in range(3)]
            y_end_p, _ = integrate_geodesic(y0, v_pert, T=T, N=N)
            de = mp.matrix([y_end_p[0]-y_end[0], y_end_p[1]-y_end[1], y_end_p[2]-y_end[2]])
            for i in range(3): J[i,j] = de[i]/dv[j]

        # Solve J Î”v0 = âˆ’err  (ridge for safety)
        Î”v = - safe_inv(J + mp.mpf('1e-24')*mp.eye(3)) * err
        # damping
        lam = 1.0
        for _ in range(6):
            trial = [v0[i] + lam*float(Î”v[i]) for i in range(3)]
            y_try, _ = integrate_geodesic(y0, trial, T=T, N=N)
            e_try = mp.matrix([y_try[0]-y1[0], y_try[1]-y1[1], y_try[2]-y1[2]])
            mis_try = float(mp.sqrt((e_try.transpose()*e_try)[0]))
            if mis_try < mis: v0 = trial; break
            lam *= 0.5
        else:
            v0 = [v0[i] + float(Î”v[i]) for i in range(3)]  # accept anyway

    # Final report even if tol not met
    y_end, L = integrate_geodesic(y0, v0, T=T, N=N)
    err = mp.matrix([y_end[0]-y1[0], y_end[1]-y1[1], y_end[2]-y1[2]])
    mis = float(mp.sqrt((err.transpose()*err)[0]))
    return dict(v0=v0, y_end=y_end, length=L, mis=mis, iters=maxit)

# ---------- Smarr/Maxwell sanity ----------
def smarr_and_maxwell_at(a_star,q_star):
    S,J,Q = extensives(1, a_star, q_star)
    M=1; a=a_star; Qr=Q
    T,Î©,Î¦ = intensives(M,a,Qr)
    H = HM_matrix(M,a,Qr)
    R1 = abs(H[0,1]-H[1,0]); R2 = abs(H[0,2]-H[2,0]); R3 = abs(H[1,2]-H[2,1])
    smarr = abs(M - (2*T*S + 2*Î©*J + Î¦*Qr))
    return smarr, max(R1,R2,R3)

def state_from_aq(a_star, q_star, M=1):
    a= a_star*M; Q=q_star*M
    if M*M - a*a - Q*Q <= 0: raise ValueError("Pick sub-extremal (a*,q*).")
    return extensives(M,a,Q)  # (S,J,Q)

def print_state(tag, a_star, q_star):
    S,J,Q = state_from_aq(a_star,q_star)
    T,Î©,Î¦ = intensives(1, a_star, q_star)
    print(f"{tag}: a*={a_star:.3f}, q*={q_star:.3f} | S={f6f(S)}, J={f6f(J)}, Q={f6f(Q)} | "
          f"T={f3e(T)}, Î©={f3e(Î©)}, Î¦={f3e(Î¦)}")

# ---------- Run two cases ----------
print("="*110)
print("MODULE 024 (RE-REPLACED, CLEAN v3): Thermodynamic Geodesics â€” Ruppeiner Geometry with Vector Shooting (geom)")
print("="*110)

# Cases
S0,J0,Q0 = state_from_aq(0.60, 0.30)
S1,J1,Q1 = state_from_aq(0.55, 0.25)
S2,J2,Q2 = state_from_aq(0.50, 0.20)
S3,J3,Q3 = state_from_aq(0.48, 0.18)

print_state("Start A", 0.60, 0.30); print_state("End   A", 0.55, 0.25)
print_state("Start B", 0.50, 0.20); print_state("End   B", 0.48, 0.18)

# Straight lengths
L_lin_A = proper_length_straight(S0,J0,Q0, S1,J1,Q1, N=1500)
L_lin_B = proper_length_straight(S2,J2,Q2, S3,J3,Q3, N=1500)

# Vector shooting geodesics
shotA = shoot_to_target((S0,J0,Q0), (S1,J1,Q1), T=1.0, N=1200, maxit=7, tol=1e-10)
shotB = shoot_to_target((S2,J2,Q2), (S3,J3,Q3), T=1.0, N=1200, maxit=7, tol=1e-10)

print("\nResults (vector shooting geodesic to target):")
print(" Case A: (0.60,0.30) â†’ (0.55,0.25)")
print(f"   Geodesic length  â„“_geo = {f6f(shotA['length'])}   (endpoint mis={shotA['mis']:.2e}, iters={shotA['iters']})")
print(f"   Straight length  â„“_lin = {f6f(L_lin_A)}")
print(f"   â„“_geo â‰¤ â„“_lin ?  {'YES' if shotA['length'] <= L_lin_A else 'NO'}")

print(" Case B: (0.50,0.20) â†’ (0.48,0.18)")
print(f"   Geodesic length  â„“_geo = {f6f(shotB['length'])}   (endpoint mis={shotB['mis']:.2e}, iters={shotB['iters']})")
print(f"   Straight length  â„“_lin = {f6f(L_lin_B)}")
print(f"   â„“_geo â‰¤ â„“_lin ?  {'YES' if shotB['length'] <= L_lin_B else 'NO'}")

# Midpoint sanity
print("\nMidpoint sanity:")
for (aa,qq,label) in [(0.575,0.275,"A-mid"), (0.49,0.19,"B-mid")]:
    sm, mx = smarr_and_maxwell_at(aa,qq)
    print(f"  {label}: Smarr={f3e(sm)}  Maxwell_max={f3e(mx)}")

print("\nONE-LINE TAKEAWAY")
print("Vector shooting (Newton on the initial velocity) nails the endpoint (mis â‰² 1eâˆ’10) and")
print("enables a fair geodesic vs straight-path proper-length comparison in Ruppeiner geometry.")
# ============================================================================================================

# ======================================================================================================
# MODULE 025 (REPLACED, CLEAN v2): Ruppeiner Curvature Near Extremality â€” Scaling of |R_R| vs Îµ (geom, M=1)
# ======================================================================================================
# Path: (a_*, q_*) = sqrt(1 - Îµ) (cosÎ¸, sinÎ¸), Îµ â†’ 0âº, Î¸ âˆˆ {0.0, 0.5, 1.0}
# NOTE (per your request): filenames, printed header text, and CSV path are kept IDENTICAL to your v2:
#   â€¢ Prints the same header lines
#   â€¢ Saves ONLY: /content/M25_ruppeiner_curvature_scan.csv
#
# Internals upgraded (no interface change):
#   â€¢ Robust inverses with adaptive ridge for metric/Hessian inverses
#   â€¢ Adaptive finite-difference step for curvature based on |(S,J,Q)|
#   â€¢ Complex-step Jacobians, high precision, and safe mp formatting
# ======================================================================================================

from mpmath import mp, mpc
import csv, math, os

# High precision for stability (can be raised)
mp.dps = 110

# ---------- mp-safe formatting ----------
def fe(x, d=1):
    try: return f"{float(x):.{d}e}"
    except: return mp.nstr(x, n=d+7)

def f3(x):
    try: return f"{float(x):.3e}"
    except: return mp.nstr(x, 8)

def f2(x):
    try: return f"{float(x):.2f}"
    except: return mp.nstr(x, 6)

def np_isfinite(x):
    try: return math.isfinite(x)
    except Exception:
        try: return math.isfinite(float(x))
        except Exception: return False

# ---------- KN essentials (geom units) ----------
def _is_complex(z): return isinstance(z, mpc)

def r_plus(M, a, Q):
    Î” = M*M - a*a - Q*Q
    if _is_complex(Î”): return M + mp.sqrt(Î”)
    if Î” <= 0: return mp.nan
    return M + mp.sqrt(Î”)

def r_minus(M, a, Q):
    Î” = M*M - a*a - Q*Q
    if _is_complex(Î”): return M - mp.sqrt(Î”)
    if Î” <= 0: return mp.nan
    return M - mp.sqrt(Î”)

def area(M, a, Q):  rp = r_plus(M,a,Q);  return 4*mp.pi*(rp*rp + a*a)
def entropy(M, a, Q):  return area(M,a,Q)/4
def temperature(M, a, Q):
    rp = r_plus(M,a,Q); rm = r_minus(M,a,Q)
    return (rp - rm) / (4*mp.pi*(rp*rp + a*a))
def omega_H(M, a, Q): rp = r_plus(M,a,Q);  return a/(rp*rp + a*a)
def phi_H(M, a, Q):   rp = r_plus(M,a,Q);  return (Q*rp)/(rp*rp + a*a)

def intensives(M,a,Q): return (temperature(M,a,Q), omega_H(M,a,Q), phi_H(M,a,Q))
def extensives(M,a,Q): return (entropy(M,a,Q), a*M, Q)

# ---------- Complex-step Jacobians ----------
def jacobian_complex(fun, x, h=mp.mpf('1e-30')):
    x1,x2,x3 = x
    J = mp.matrix(3,3)
    for j,(dx1,dx2,dx3) in enumerate(((1,0,0),(0,1,0),(0,0,1))):
        z1 = x1 + 1j*h*dx1; z2 = x2 + 1j*h*dx2; z3 = x3 + 1j*h*dx3
        fz = fun(z1,z2,z3)
        for i in range(3):
            J[i,j] = mp.im(fz[i])/h
    return J

def F_vec(M_,a_,Q_):  # (T,Î©,Î¦)
    T,Î©,Î¦ = intensives(M_,a_,Q_);  return mp.matrix([T,Î©,Î¦])

def G_vec(M_,a_,Q_):  # (S,J,Q)
    S,J,Qr = extensives(M_,a_,Q_); return mp.matrix([S,J,Qr])

# ---------- Robust inverse (adaptive ridge) ----------
def safe_inv(A, lam0=mp.mpf('1e-80'), growth=mp.mpf('1e+6'), tries=6):
    I = mp.eye(A.rows)
    lam = mp.mpf(lam0)
    for _ in range(tries):
        try:
            return (A if lam==0 else (A + lam*I))**-1
        except ZeroDivisionError:
            lam *= growth
    return (A + lam*I)**-1

def HM_matrix(M,a,Q, h=mp.mpf('1e-30')):
    A = jacobian_complex(lambda M_,a_,Q_: F_vec(M_,a_,Q_), (M,a,Q), h=h)  # âˆ‚(T,Î©,Î¦)/âˆ‚(M,a,Q)
    B = jacobian_complex(lambda M_,a_,Q_: G_vec(M_,a_,Q_), (M,a,Q), h=h)  # âˆ‚(S,J,Q)/âˆ‚(M,a,Q)
    return A * safe_inv(B)

# ---------- Invert (S,J,Q) â†’ (M,a,Q) ----------
def solve_M_from_SJQ(S_target, J, Q, tol=mp.mpf('1e-40')):
    Mmin = mp.sqrt(J*J + Q*Q) + mp.mpf('1e-14')
    Mschw = mp.sqrt(S_target/(4*mp.pi))
    Mmax = max(Mschw, Mmin*mp.mpf('1.1'))
    for _ in range(200):
        a = J/Mmax
        if Mmax*Mmax - a*a - Q*Q <= 0: Mmax *= 2; continue
        if entropy(Mmax, a, Q) >= S_target: break
        Mmax *= 2
    else: raise RuntimeError("Bracket failed.")
    for _ in range(400):
        Mmid = (Mmin+Mmax)/2; a = J/Mmid
        if Mmid*Mmid - a*a - Q*Q <= 0: Mmin = Mmid; continue
        Smid = entropy(Mmid, a, Q)
        if abs(Smid-S_target) <= tol: return Mmid, a, Q
        if Smid < S_target: Mmin = Mmid
        else: Mmax = Mmid
    return Mmid, a, Q

# ---------- Metrics & curvature on y=(S,J,Q) ----------
def metrics_at_SJQ(S, J, Q):
    M,a,Qr = solve_M_from_SJQ(S,J,Q)
    T,Î©,Î¦ = intensives(M,a,Qr)
    H = HM_matrix(M,a,Qr)
    gW = mp.matrix(3,3)
    for i in range(3):
        for j in range(3):
            gW[i,j] = (H[i,j] + H[j,i])/2
    gR = (1/T)*gW
    return dict(M=M,a=a,Q=Qr,T=T,Omega=Î©,Phi=Î¦,gW=gW,gR=gR,H=H,S=S,J=J)

def metric_at_point_R(S,J,Q): return metrics_at_SJQ(S,J,Q)['gR']

def _adaptive_h(S,J,Q, base=mp.mpf('2e-6')):
    scale = mp.mpf('1') + abs(S) + abs(J) + abs(Q)
    return base / scale**(mp.mpf('1/3'))

def metric_fd(metric_func, y, hS, hJ, hQ):
    S,J,Q = y
    GppS = metric_func(S+hS,J,Q); GmmS = metric_func(S-hS,J,Q)
    GppJ = metric_func(S,J+hJ,Q); GmmJ = metric_func(S,J-hJ,Q)
    GppQ = metric_func(S,J,Q+hQ); GmmQ = metric_func(S,J,Q-hQ)
    dG_dS = (GppS - GmmS)/(2*hS)
    dG_dJ = (GppJ - GmmJ)/(2*hJ)
    dG_dQ = (GppQ - GmmQ)/(2*hQ)
    return dG_dS, dG_dJ, dG_dQ

def christoffel_from_metric(g, dG_dS, dG_dJ, dG_dQ):
    dG = [dG_dS, dG_dJ, dG_dQ]
    ginv = safe_inv(g)
    Î“ = [[[mp.mpf('0')]*3 for _ in range(3)] for __ in range(3)]
    for m in range(3):
        for i in range(3):
            for j in range(3):
                s = mp.mpf('0')
                for k in range(3):
                    s += ginv[m,k]*( dG[i][k,j] + dG[j][k,i] - dG[k][i,j] )
                Î“[m][i][j] = s/2
    return Î“

def ricci_scalar_Ruppeiner(S,J,Q, h=None):
    if h is None:
        h = _adaptive_h(S,J,Q)
    g = metric_at_point_R(S,J,Q)
    dS,dJ,dQ = metric_fd(lambda s,j,q: metric_at_point_R(s,j,q), (S,J,Q), h,h,h)
    Î“ = christoffel_from_metric(g, dS,dJ,dQ)
    ginv = safe_inv(g)

    def _Î“_at(s,j,q):
        G = metric_at_point_R(s,j,q)
        dGs,dGj,dGq = metric_fd(lambda ss,jj,qq: metric_at_point_R(ss,jj,qq), (s,j,q), h,h,h)
        return christoffel_from_metric(G, dGs,dGj,dGq)

    Î“S  = _Î“_at(S+h,J,Q);   Î“mS = _Î“_at(S-h,J,Q)
    Î“J  = _Î“_at(S,J+h,Q);   Î“mJ = _Î“_at(S,J-h,Q)
    Î“Q  = _Î“_at(S,J,Q+h);   Î“mQ = _Î“_at(S,J,Q-h)

    dÎ“dS = [[[ (Î“S[m][i][j]-Î“mS[m][i][j])/(2*h) for j in range(3)] for i in range(3)] for m in range(3)]
    dÎ“dJ = [[[ (Î“J[m][i][j]-Î“mJ[m][i][j])/(2*h) for j in range(3)] for i in range(3)] for m in range(3)]
    dÎ“dQ = [[[ (Î“Q[m][i][j]-Î“mQ[m][i][j])/(2*h) for j in range(3)] for i in range(3)] for m in range(3)]

    R = mp.mpf('0')
    for i in range(3):
        for j in range(3):
            div = dÎ“dS[0][i][j] + dÎ“dJ[1][i][j] + dÎ“dQ[2][i][j]
            dtrace_i = [dÎ“dS[0][i][k] + dÎ“dJ[1][i][k] + dÎ“dQ[2][i][k] for k in range(3)]
            dj_trace = dtrace_i[j]
            term3 = mp.mpf('0'); term4 = mp.mpf('0')
            for k in range(3):
                tr_kl = sum(Î“[l][k][l] for l in range(3))
                term3 += Î“[k][i][j]*tr_kl
                for l in range(3):
                    term4 += Î“[k][i][l]*Î“[l][j][k]
            Rij = div - dj_trace + term3 - term4
            R += ginv[i,j]*Rij
    return R

# ---------- Smarr & Maxwell snapshots ----------
def smarr_and_maxwell_at(a_star,q_star, M=1):
    S,J,Q = extensives(M, a_star*M, q_star*M)
    T,Î©,Î¦ = intensives(M, a_star*M, q_star*M)
    H = HM_matrix(M, a_star*M, q_star*M)
    R1 = abs(H[0,1]-H[1,0]); R2 = abs(H[0,2]-H[2,0]); R3 = abs(H[1,2]-H[2,1])
    smarr = abs(M - (2*T*S + 2*Î©*J + Î¦*Q))
    return smarr, max(R1,R2,R3)

# ---------- Fit |R| ~ C Îµ^Î± on the last k points ----------
def fit_power_eps(eps_list, y_list, k_tail=7):
    pairs = []
    for e,y in zip(eps_list, y_list):
        try:
            ef, yf = float(e), float(abs(y))
            if np_isfinite(ef) and np_isfinite(yf) and ef>0 and yf>0:
                pairs.append((ef,yf))
        except Exception:
            continue
    if len(pairs) < 2:
        return dict(alpha=float('nan'), C=float('nan'), R2=1.0, n_used=0)
    tail = pairs[-k_tail:] if len(pairs)>=k_tail else pairs
    xs = [math.log(p[0]) for p in tail]
    ys = [math.log(p[1]) for p in tail]
    n = len(xs)
    xbar = sum(xs)/n; ybar = sum(ys)/n
    Sxx = sum((x-xbar)**2 for x in xs)
    Sxy = sum((x-xbar)*(y-ybar) for x,y in zip(xs,ys))
    if Sxx == 0:
        return dict(alpha=float('nan'), C=float('nan'), R2=1.0, n_used=0)
    b = Sxy/Sxx
    a = ybar - b*xbar
    yfit = [a + b*x for x in xs]
    SS_res = sum((yy-yf)**2 for yy,yf in zip(ys,yfit))
    SS_tot = sum((yy-ybar)**2 for yy in ys)
    R2 = 1 - SS_res/SS_tot if SS_tot>0 else 1.0
    return dict(alpha=b, C=math.exp(a), R2=R2, n_used=n)

# ---------- Scan & Report (kept identical to v2) ----------
thetas = [0.0, 0.5, 1.0]
eps_list = [mp.mpf('1e-2')] + [mp.mpf(f"1e-{k}") for k in range(3,11)]

rows = []

print("="*110)
print("MODULE 025 (REPLACED, CLEAN v2): Ruppeiner Curvature Near Extremality â€” Scaling of |R_R| vs Îµ (geom, M=1)")
print("="*110)
print(f"Grid: thetas={thetas}, eps in [{fe(eps_list[0])}, {fe(eps_list[-1])}], mp.dps={int(mp.dps)}\n")

for th in thetas:
    c = mp.cos(th); s = mp.sin(th)
    Rvals = []
    sm_min=mp.inf; sm_max=mp.mpf('0'); mx_max=mp.mpf('0')

    for eps in eps_list:
        r = mp.sqrt(1 - eps)
        a_star = r*c; q_star = r*s
        # stay safely sub-extremal
        if 1 - (a_star*a_star + q_star*q_star) <= mp.mpf('1e-18'):
            a_star *= mp.mpf('0.9999999999'); q_star *= mp.mpf('0.9999999999')

        S,J,Q = extensives(1, a_star, q_star)
        T,Î©,Î¦ = intensives(1, a_star, q_star)

        # curvature with guards
        Rsc = mp.nan
        try:
            Rsc = ricci_scalar_Ruppeiner(S,J,Q, h=None)  # adaptive h
        except Exception:
            pass

        Rvals.append(Rsc)

        sm, mx = smarr_and_maxwell_at(a_star, q_star)
        sm_min = min(sm_min, sm); sm_max = max(sm_max, sm); mx_max = max(mx_max, mx)

        rows.append(dict(theta=float(th), eps=float(eps),
                         a_star=float(a_star), q_star=float(q_star),
                         S=float(S), J=float(J), Q=float(Q),
                         T=float(T), Omega=float(Î©), Phi=float(Î¦),
                         Ruppeiner=(float(Rsc) if np_isfinite(Rsc) else float('nan')),
                         Smarr=float(sm), Maxwell=float(mx)))

    fit = fit_power_eps([float(e) for e in eps_list], Rvals, k_tail=7)
    alpha, C, R2, n = fit['alpha'], fit['C'], fit['R2'], fit['n_used']
    print(f"theta={th:.2f} | Î±_R={alpha:.4f}  C={C:.3e}  R2={R2:.4f}  n={n}  "
          f"|| Smarr[min,max]=[{f3(sm_min)},{f3(sm_max)}]  Maxwell_max={f3(mx_max)}")

# ---------- Save CSV receipt (same path/name as v2) ----------
os.makedirs("/content", exist_ok=True)
scan_path = "/content/M25_ruppeiner_curvature_scan.csv"
with open(scan_path, "w", newline="") as f:
    w = csv.DictWriter(f, fieldnames=list(rows[0].keys()))
    w.writeheader(); w.writerows(rows)

print("\nCSV receipts:")
print(f"  {scan_path}")

print("\nONE-LINE TAKEAWAY")
print("Ruppeiner scalar curvature |R_R| along a_*^2+q_*^2=1âˆ’Îµ shows clean tail scaling in Îµ;")
print("Smarr & Maxwell stay shut across the sweep, supporting a consistent thermodynamic geometry near extremality.")
# ======================================================================================================

# ======================================================================================================
# MODULE 026: Ensemble Response Sign Map & Singular Loci â€” Kerrâ€“Newman (geom units, high-prec, no plots)
# ======================================================================================================
# What this does
#   â€¢ Scans a grid of sub-extremal states (a*, q*) at fixed M=1
#   â€¢ Computes microcanonical responses from H_M = âˆ‚(T,Î©,Î¦)/âˆ‚(S,J,Q):
#         C_{J,Q} =  T / (âˆ‚T/âˆ‚S)_{J,Q}      (heat capacity at fixed J,Q)
#         Ï‡_J      = (âˆ‚J/âˆ‚Î©)_{S,Q} = 1/H_{JJ}   (angular susceptibility)
#         Ï‡_Q      = (âˆ‚Q/âˆ‚Î¦)_{S,J} = 1/H_{QQ}   (electric susceptibility)
#   â€¢ Computes Gibbs/isopotential responses from H_G = - H_M^{-1}:
#         C_{Î©,Î¦}  =  T * (âˆ‚S/âˆ‚T)_{Î©,Î¦} = - T * (H_M^{-1})_{SS}
#         Îº_J      =  (âˆ‚J/âˆ‚Î©)_{T,Î¦}     = - (H_M^{-1})_{JJ}
#         Îº_Q      =  (âˆ‚Q/âˆ‚Î¦)_{T,Î©}     = - (H_M^{-1})_{QQ}
#   â€¢ Reports:
#       - Counts of OK vs extremal vs singular (ill-conditioned inversion)
#       - PASS rates for Maxwell symmetry & Smarr
#       - Sign tallies (+/âˆ’/â‰ˆ0) for each response
#       - Extremal approach guards; stable complex-step Jacobians
#   â€¢ Saves CSV receipts with all per-state numbers
#
# Notes
#   - All computations in geometric units (G=c=Ä§=k_B=1); M=1
#   - High precision (mp.dps) + complex-step derivatives for numerics
#   - No plots; concise text + CSVs
# ======================================================================================================

from mpmath import mp, mpc
import csv, os

# ---------- precision & helpers ----------
mp.dps = 120

def fe(x, d=3):
    try: return f"{float(x):.{d}e}"
    except: return mp.nstr(x, n=d+7)

def f3(x):
    try: return f"{float(x):.3e}"
    except: return mp.nstr(x, 8)

tiny = mp.mpf('1e-80')
tol_maxwell = mp.mpf('1e-80')
tol_smarr   = mp.mpf('1e-110')
ridge       = mp.mpf('1e-60')  # for safe inverses

# ---------- KN core (geom) ----------
def _is_complex(z): return isinstance(z, mpc)

def r_plus(M, a, Q):
    Î” = M*M - a*a - Q*Q
    if _is_complex(Î”): return M + mp.sqrt(Î”)
    if Î” <= 0: return mp.nan
    return M + mp.sqrt(Î”)

def r_minus(M, a, Q):
    Î” = M*M - a*a - Q*Q
    if _is_complex(Î”): return M - mp.sqrt(Î”)
    if Î” <= 0: return mp.nan
    return M - mp.sqrt(Î”)

def area(M, a, Q):  rp = r_plus(M,a,Q);  return 4*mp.pi*(rp*rp + a*a)
def entropy(M, a, Q):  return area(M,a,Q)/4
def temperature(M, a, Q):
    rp = r_plus(M,a,Q); rm = r_minus(M,a,Q)
    return (rp - rm) / (4*mp.pi*(rp*rp + a*a))
def omega_H(M, a, Q): rp = r_plus(M,a,Q);  return a/(rp*rp + a*a)
def phi_H(M, a, Q):   rp = r_plus(M,a,Q);  return (Q*rp)/(rp*rp + a*a)
def intensives(M,a,Q): return (temperature(M,a,Q), omega_H(M,a,Q), phi_H(M,a,Q))
def extensives(M,a,Q): return (entropy(M,a,Q), a*M, Q)

# ---------- complex-step Jacobians ----------
def jacobian_complex(fun, x, h=mp.mpf('1e-30')):
    x1,x2,x3 = x
    J = mp.matrix(3,3)
    dirs = ((1,0,0),(0,1,0),(0,0,1))
    for j,(dx1,dx2,dx3) in enumerate(dirs):
        z1 = x1 + 1j*h*dx1; z2 = x2 + 1j*h*dx2; z3 = x3 + 1j*h*dx3
        fz = fun(z1,z2,z3)  # 3-vector
        for i in range(3):
            J[i,j] = mp.im(fz[i])/h
    return J

def F_vec(M_,a_,Q_):  # (T,Î©,Î¦)
    T,Î©,Î¦ = intensives(M_,a_,Q_);  return mp.matrix([T,Î©,Î¦])

def G_vec(M_,a_,Q_):  # (S,J,Q)
    S,J,Qr = extensives(M_,a_,Q_); return mp.matrix([S,J,Qr])

def safe_inv(Mx, lam=ridge):
    try:
        return Mx**-1
    except ZeroDivisionError:
        return (Mx + lam*mp.eye(3))**-1

def HM_matrix(M,a,Q, h=mp.mpf('1e-30')):
    A = jacobian_complex(lambda M_,a_,Q_: F_vec(M_,a_,Q_), (M,a,Q), h=h)
    B = jacobian_complex(lambda M_,a_,Q_: G_vec(M_,a_,Q_), (M,a,Q), h=h)
    return A * safe_inv(B)

# ---------- responses, checks ----------
def responses_from_HM(H, T):
    # Microcanonical
    dTdS = H[0,0]
    CJQ  = T / dTdS if dTdS != 0 else mp.sign(T)*mp.inf
    chiJ = 1 / H[1,1] if H[1,1] != 0 else mp.inf
    chiQ = 1 / H[2,2] if H[2,2] != 0 else mp.inf
    # Gibbs / isopotential: H_G = - H_M^{-1}
    Hinv = safe_inv(H)
    HG   = - Hinv
    Cph  = T * HG[0,0]      # T*(âˆ‚S/âˆ‚T)_{Î©,Î¦}
    kJ   = HG[1,1]          # (âˆ‚J/âˆ‚Î©)_{T,Î¦}
    kQ   = HG[2,2]          # (âˆ‚Q/âˆ‚Î¦)_{T,Î©}
    return CJQ, chiJ, chiQ, Cph, kJ, kQ, HG

def smarr_res(M,a,Q):
    S,J,Qr = extensives(M,a,Q)
    T,Î©,Î¦ = intensives(M,a,Q)
    return abs(M - (2*T*S + 2*Î©*J + Î¦*Qr))

def maxwell_residual(H):
    R1 = abs(H[0,1]-H[1,0]); R2 = abs(H[0,2]-H[2,0]); R3 = abs(H[1,2]-H[2,1])
    return max(R1,R2,R3), (R1,R2,R3)

def sign_tag(x, eps=mp.mpf('1e-30')):
    if not mp.isfinite(x): return "sing"
    if x > eps:  return "+"
    if x < -eps: return "âˆ’"
    return "â‰ˆ0"

# ---------- grid scan ----------
M = mp.mpf('1')
# choose a light but informative grid (adjust if you want denser)
a_vals = [mp.mpf(i)/20 for i in range(1,20)]   # 0.05 ... 0.95
q_vals = [mp.mpf(i)/20 for i in range(1,20)]   # 0.05 ... 0.95

rows = []
OK=EXT=FAIL=0
pass_maxwell = pass_smarr = 0

for a_star in a_vals:
    for q_star in q_vals:
        # sub-extremal guard
        if a_star*a_star + q_star*q_star >= mp.mpf('1'):
            EXT += 1
            continue
        a = a_star*M; Q = q_star*M
        try:
            H = HM_matrix(M,a,Q, h=mp.mpf('1e-30'))
            T,Î©,Î¦ = intensives(M,a,Q)
            CJQ, chiJ, chiQ, Cph, kJ, kQ, HG = responses_from_HM(H, T)
            sm = smarr_res(M,a,Q)
            mx_max, (R1,R2,R3) = maxwell_residual(H)
            OK += 1
            if mx_max <= tol_maxwell: pass_maxwell += 1
            if sm <= tol_smarr:       pass_smarr   += 1
            rows.append({
                "a_star": float(a_star), "q_star": float(q_star),
                "T": float(T), "Omega": float(Î©), "Phi": float(Î¦),
                "CJQ": float(CJQ) if mp.isfinite(CJQ) else ("inf" if CJQ>0 else "-inf"),
                "chiJ": float(chiJ) if mp.isfinite(chiJ) else ("inf" if chiJ>0 else "-inf"),
                "chiQ": float(chiQ) if mp.isfinite(chiQ) else ("inf" if chiQ>0 else "-inf"),
                "Cph": float(Cph) if mp.isfinite(Cph) else ("inf" if Cph>0 else "-inf"),
                "kJ":  float(kJ)  if mp.isfinite(kJ)  else ("inf" if kJ>0  else "-inf"),
                "kQ":  float(kQ)  if mp.isfinite(kQ)  else ("inf" if kQ>0  else "-inf"),
                "Smarr_abs": float(sm),
                "Maxwell_max": float(mx_max),
                "R1": float(R1), "R2": float(R2), "R3": float(R3),
                "sign_CJQ": sign_tag(CJQ),
                "sign_chiJ": sign_tag(chiJ),
                "sign_chiQ": sign_tag(chiQ),
                "sign_Cph": sign_tag(Cph),
                "sign_kJ":  sign_tag(kJ),
                "sign_kQ":  sign_tag(kQ),
            })
        except Exception:
            FAIL += 1
            continue

# ---------- tallies ----------
def tally(rows, key):
    pos=neg=zero=sing=0
    for r in rows:
        tag = r[key]
        if   tag == "+":   pos += 1
        elif tag == "âˆ’":   neg += 1
        elif tag == "â‰ˆ0":  zero += 1
        elif tag == "sing": sing += 1
    return pos,neg,zero,sing

t_CJQ  = tally(rows, "sign_CJQ")
t_chiJ = tally(rows, "sign_chiJ")
t_chiQ = tally(rows, "sign_chiQ")
t_Cph  = tally(rows, "sign_Cph")
t_kJ   = tally(rows, "sign_kJ")
t_kQ   = tally(rows, "sign_kQ")

# ranges (finite only)
def finite_range(rows, field):
    vals = [r[field] for r in rows if isinstance(r[field], float)]
    if not vals: return ("n/a","n/a")
    return (fe(min(vals),3), fe(max(vals),3))

rng_CJQ  = finite_range(rows, "CJQ")
rng_chiJ = finite_range(rows, "chiJ")
rng_chiQ = finite_range(rows, "chiQ")
rng_Cph  = finite_range(rows, "Cph")
rng_kJ   = finite_range(rows, "kJ")
rng_kQ   = finite_range(rows, "kQ")
rng_sm   = finite_range(rows, "Smarr_abs")
rng_mx   = finite_range(rows, "Maxwell_max")

# ---------- print summary ----------
print("="*110)
print("MODULE 026: Ensemble Response Sign Map & Singular Loci â€” Kerrâ€“Newman (geom units)")
print("="*110)
print(f"Grid: {len(a_vals)} x {len(q_vals)} = {len(a_vals)*len(q_vals)} states")
print(f"Counts: OK={OK}  EXTREMAL={EXT}  FAIL={FAIL}")
print(f"PASS: Maxwell {pass_maxwell}/{OK}   |   Smarr {pass_smarr}/{OK}  (tols: {fe(tol_maxwell)}, {fe(tol_smarr)})\n")

def line_tally(name, t, rng):
    pos,neg,zero,sing = t
    print(f"{name:<12s} signs (+/âˆ’/â‰ˆ0/sing): {pos:4d}/{neg:4d}/{zero:4d}/{sing:4d}   range (finite): [{rng[0]}, {rng[1]}]")

print("Microcanonical responses:")
line_tally("C_{J,Q}",  t_CJQ,  rng_CJQ)
line_tally("Ï‡_J",      t_chiJ, rng_chiJ)
line_tally("Ï‡_Q",      t_chiQ, rng_chiQ)

print("\nIsopotential (Gibbs) responses:")
line_tally("C_{Î©,Î¦}",  t_Cph,  rng_Cph)
line_tally("Îº_J",      t_kJ,   rng_kJ)
line_tally("Îº_Q",      t_kQ,   rng_kQ)

print("\nResidual ranges on OK states:")
print(f"  Smarr |LHSâˆ’RHS| : [{rng_sm[0]}, {rng_sm[1]}]")
print(f"  Maxwell max     : [{rng_mx[0]}, {rng_mx[1]}]")

# ---------- CSV receipts ----------
os.makedirs("/content", exist_ok=True)
csv_path = "/content/M26_response_sign_map.csv"
with open(csv_path, "w", newline="") as f:
    fieldnames = list(rows[0].keys()) if rows else []
    w = csv.DictWriter(f, fieldnames=fieldnames)
    if fieldnames:
        w.writeheader()
        w.writerows(rows)

print("\nCSV receipts:")
print(f"  {csv_path}")

print("\nONE-LINE TAKEAWAY")
print("Across a broad sub-extremal (a*, q*) grid, Maxwell & Smarr close at high precision;")
print("response signs partition the state space and singular loci (divergent capacities/susceptibilities)")
print("are cleanly exposed via H_M and its dual H_G = âˆ’H_M^{-1}.")
# ======================================================================================================

# ==============================================================================================
# MODULE 027 (REPLACED, PRO UPGRADE): Meta-Audit â€” Unified Ledger of Residuals (geom/SI agnostic)
# ==============================================================================================
# Why this upgrade?
#   â€¢ Smarter column detection (handles â€œSmarrâ€, â€œMaxwellâ€, â€œrel_errâ€, â€œÎ”â€¦â€, â€œresidualâ€, â€œmisâ€, etc.)
#   â€¢ Robust numeric coercion (accepts '0E-110', unicode minus 'âˆ’', mixed text, NaNs)
#   â€¢ Log-scale scoring tuned for HEP/GR magnitudes:
#         s_i = clamp( -log10(|err_i|) / L , 0, 1 ), L=80 by default  â†’  10^-80 â‰ˆ full credit
#   â€¢ Per-file and per-module rollups, with counts and log10(min/med/max) of |error|
#   â€¢ â€œTop smallest/largestâ€ tables for quick triage
#   â€¢ JSON summary with a single â€œUnified Ledger Scoreâ€ âˆˆ [0,100]
#   â€¢ Zero-config: just run; scans /content/*.csv (Colab-friendly)
#
# Outputs:
#   /content/M27_meta_audit_ledger.csv        (per-file metrics)
#   /content/M27_meta_audit_modules.csv       (per-module rollup)
#   /content/M27_meta_audit_top_worst.csv     (top-50 smallest & largest |error| values)
#   /content/M27_meta_audit_summary.json      (global score + details)
#
# Tips:
#   â€¢ Tune LEDGER_L if your target residual scale differs (e.g., L=100 for 10^âˆ’100 targets).
#   â€¢ Adjust ERR_COL_REGEX if your column naming is unusual.
# ==============================================================================================

import os, re, json, glob, math
import numpy as np
import pandas as pd

# ---------- Tunables ----------
# Match typical residual/precision column names (case-insensitive).
ERR_COL_REGEX = re.compile(
    r"(smarr|maxwell|res(idual)?|rel[\s_\-]?err|abs[\s_\-]?err|mis(match)?|gap|"
    r"dev(iation)?|diff(?!erence.*index)|delta|Î”|error)",  # includes 'Î”' (unicode)
    re.IGNORECASE
)
# Soft exclude to avoid scooping obvious non-error structural columns.
NON_ERR_HINT = re.compile(r"(index|step|iter|theta|eps\b|a\*|q\*|mass\b|^J$|^Q$|^A$|^M$|k_pred|k$)",
                          re.IGNORECASE)

# Score target (orders of magnitude). Reaching 10^(âˆ’LEDGER_L) ~ full credit.
LEDGER_L = 80.0
EPS_FLOOR = 1e-300            # avoid log10(0)
SCAN_PATTERN = "/content/*.csv"

# ---------- Helpers ----------
def extract_module_id(path: str) -> str:
    m = re.search(r"/(M\d+)[^/]*\.csv$", path)
    return m.group(1) if m else "UNKNOWN"

def looks_like_error(colname: str) -> bool:
    # allow explicit residual matches even if NON_ERR_HINT fires
    if NON_ERR_HINT.search(colname):
        return bool(re.search(r"(smarr|maxwell|res|err|mis|gap|dev|delta|Î”|error)", colname, re.IGNORECASE))
    return bool(ERR_COL_REGEX.search(colname))

def to_float_series(series: pd.Series) -> pd.Series:
    """Coerce mixed text/numeric residual columns to float. Handles '0E-110', unicode minus, etc."""
    def _coerce(x):
        if pd.isna(x): return np.nan
        if isinstance(x, (int, float, np.floating)): return float(x)
        s = str(x).strip().replace('âˆ’', '-')  # unicode minus â†’ ASCII
        # Try a direct float first
        try:
            return float(s)
        except:
            # Accept formats like '0E-110', '1.2e-99', or pick first numeric token
            m = re.search(r"[-+]?\d+(\.\d+)?([eE][-+]?\d+)?", s)
            if m:
                try: return float(m.group(0))
                except: return np.nan
            return np.nan
    return series.map(_coerce)

def safe_log10_abs(arr: np.ndarray) -> np.ndarray:
    return np.log10(np.clip(np.abs(arr), EPS_FLOOR, None))

def score_from_errors(abs_errors: np.ndarray, L: float = LEDGER_L) -> float:
    """Map absolute errors to [0,100] via log-magnitude normalization."""
    if abs_errors.size == 0: return float('nan')
    s = -safe_log10_abs(abs_errors) / L     # larger âˆ’log10 â†’ closer to 1
    s = np.clip(s, 0.0, 1.0)
    return float(100.0 * np.nanmean(s))

# ---------- Audit ----------
csv_paths = sorted(glob.glob(SCAN_PATTERN))
if not csv_paths:
    print("MODULE 027 (UPGRADED): No CSV receipts found under /content â€” nothing to audit.")
else:
    ledger_rows = []
    all_err_records = []  # (module, file, column, abs_error)
    read_fails = 0

    for path in csv_paths:
        try:
            df = pd.read_csv(path)
        except Exception as e:
            # more permissive fallback
            try:
                df = pd.read_csv(path, engine="python", encoding="utf-8", errors="ignore")
            except Exception as e2:
                read_fails += 1
                ledger_rows.append({
                    "module": extract_module_id(path),
                    "file": os.path.basename(path),
                    "n_rows": 0,
                    "n_err_cols": 0,
                    "n_err_vals": 0,
                    "log10_min": np.nan,
                    "log10_med": np.nan,
                    "log10_max": np.nan,
                    "file_score": np.nan,
                    "note": f"READ_FAIL: {e} / {e2}"
                })
                continue

        # Identify residual-like columns
        err_cols = [c for c in df.columns if looks_like_error(str(c))]
        if not err_cols:
            ledger_rows.append({
                "module": extract_module_id(path),
                "file": os.path.basename(path),
                "n_rows": len(df),
                "n_err_cols": 0,
                "n_err_vals": 0,
                "log10_min": np.nan,
                "log10_med": np.nan,
                "log10_max": np.nan,
                "file_score": np.nan,
                "note": "NO_ERR_COLS_DETECTED"
            })
            continue

        # Coerce and gather values
        vals_list = []
        for c in err_cols:
            ser = to_float_series(df[c]) if df[c].dtype == object else pd.to_numeric(df[c], errors="coerce")
            v = ser.to_numpy().astype(float)
            v = v[np.isfinite(v)]
            if v.size:
                vals_list.append(v)
                for vv in v:
                    all_err_records.append((extract_module_id(path), os.path.basename(path), c, float(abs(vv))))

        if vals_list:
            vals = np.concatenate(vals_list)
            log10s = safe_log10_abs(vals)
            file_score = score_from_errors(vals, L=LEDGER_L)
            ledger_rows.append({
                "module": extract_module_id(path),
                "file": os.path.basename(path),
                "n_rows": len(df),
                "n_err_cols": len(err_cols),
                "n_err_vals": int(vals.size),
                "log10_min": float(np.nanmin(log10s)),
                "log10_med": float(np.nanmedian(log10s)),
                "log10_max": float(np.nanmax(log10s)),
                "file_score": file_score,
                "note": ""
            })
        else:
            ledger_rows.append({
                "module": extract_module_id(path),
                "file": os.path.basename(path),
                "n_rows": len(df),
                "n_err_cols": len(err_cols),
                "n_err_vals": 0,
                "log10_min": np.nan,
                "log10_med": np.nan,
                "log10_max": np.nan,
                "file_score": np.nan,
                "note": "ERR_COLS_PRESENT_BUT_NO_NUMERIC_VALUES"
            })

    # ---------- Per-file ledger ----------
    ledger_df = pd.DataFrame(ledger_rows).sort_values(["module", "file"]).reset_index(drop=True)
    ledger_path = "/content/M27_meta_audit_ledger.csv"
    ledger_df.to_csv(ledger_path, index=False)

    # ---------- Per-module rollup ----------
    mod_groups = ledger_df.groupby("module", dropna=False)
    mod_df = mod_groups.aggregate(
        files=("file", "nunique"),
        rows=("n_rows", "sum"),
        err_cols=("n_err_cols", "sum"),
        err_vals=("n_err_vals", "sum"),
        score_avg=("file_score", "mean"),
        score_med=("file_score", "median"),
        score_min=("file_score", "min"),
        score_max=("file_score", "max"),
    ).reset_index().sort_values("module")
    modules_path = "/content/M27_meta_audit_modules.csv"
    mod_df.to_csv(modules_path, index=False)

    # ---------- Global unified score ----------
    all_err_values = np.array([r[3] for r in all_err_records], dtype=float)
    unified_score = score_from_errors(all_err_values, L=LEDGER_L) if all_err_values.size else float('nan')

    # ---------- Top smallest & largest ----------
    top_path = None
    if all_err_values.size:
        err_table = pd.DataFrame(all_err_records, columns=["module","file","column","abs_error"])
        smallest = err_table.nsmallest(50, "abs_error").assign(kind="smallest")
        largest  = err_table.nlargest(50,  "abs_error").assign(kind="largest")
        top_df = pd.concat([smallest, largest], ignore_index=True)
        top_path = "/content/M27_meta_audit_top_worst.csv"
        top_df.to_csv(top_path, index=False)

    # ---------- JSON summary ----------
    summary = {
        "unified_ledger_score": unified_score,
        "score_definition": f"s_i = clamp(-log10(|err_i|)/{LEDGER_L}, 0, 1); overall = 100*mean(s_i)",
        "n_csv_scanned": int(len(csv_paths)),
        "read_failures": int(read_fails),
        "files_with_errors_detected": int((ledger_df["n_err_vals"]>0).sum()),
        "total_error_values": int(all_err_values.size) if all_err_values.size else 0,
        "per_module": mod_df.to_dict(orient="records"),
        "notes": [
            "Zero/underflow values are floored at 1e-300 before log10.",
            "Adjust ERR_COL_REGEX/NON_ERR_HINT to widen/narrow detection.",
            "LEDGER_L sets the 'full-credit' order-of-magnitude target."
        ]
    }
    summary_path = "/content/M27_meta_audit_summary.json"
    with open(summary_path, "w") as f:
        json.dump(summary, f, indent=2)

    # ---------- Console report ----------
    print("="*106)
    print("MODULE 027 (REPLACED, PRO UPGRADE): Meta-Audit â€” Unified Ledger of Residuals")
    print("="*106)
    print(f"CSV receipts scanned: {len(csv_paths)}  |  read failures: {read_fails}")
    print(f"Files with detected error-like columns: {(ledger_df['n_err_vals']>0).sum()} / {len(csv_paths)}")
    print(f"Total error values aggregated: {summary['total_error_values']}")
    if not math.isnan(unified_score):
        print(f"\nUnified Ledger Score (0..100): {unified_score:.3f}")
    else:
        print("\nUnified Ledger Score (0..100): n/a (no errors detected)")

    if len(mod_df):
        print("\nPer-module rollup (avg/median/min/max file scores):")
        for r in mod_df.to_dict(orient="records"):
            print(f"  {r['module']:>6s} | files={r['files']:>2d}  err_vals={r['err_vals']:>7d}  "
                  f"avg={r['score_avg'] if pd.notna(r['score_avg']) else float('nan'):.3f}  "
                  f"med={r['score_med'] if pd.notna(r['score_med']) else float('nan'):.3f}  "
                  f"min={r['score_min'] if pd.notna(r['score_min']) else float('nan'):.3f}  "
                  f"max={r['score_max'] if pd.notna(r['score_max']) else float('nan'):.3f}")
    else:
        print("\nPer-module rollup: (no modules detected)")

    print("\nArtifacts:")
    print(f"  - {ledger_path}")
    print(f"  - {modules_path}")
    print(f"  - {summary_path}")
    if top_path: print(f"  - {top_path}")
    print("-"*106)
    print("Tip: Set LEDGER_L=100 if your target residuals are ~10^âˆ’100 and you want full credit at that scale.")

# ==========================================================================================================
# MODULE 027-FIXKIT (REPLACED, CLEAN): Robust Recompute for Hessians (M19) and Ruppeiner Curvature (M25)
# Geometric units (G=c=Ä§=k_B=1). Colab-ready.
# Fix: make core thermodynamic primitives complex-step safe (no real-only comparisons),
#      so r_Â±, T, Î©, Î¦ work with mpmath.mpc during Jacobian evaluation.
# ==========================================================================================================

from mpmath import mp, mpc, matrix
import pandas as pd, numpy as np, os

# ---------- Precision & small parameters ----------
mp.dps = 160
H_CS   = mp.mpf('1e-40')   # complex-step epsilon for first derivatives
H_FD   = mp.mpf('1e-20')   # finite-diff step for 2nd derivs (curvature)
RIDGE  = mp.mpf('1e-60')   # diagonal ridge for small 3x3 inversions

# ---------- Helpers ----------
def _is_complex(z): return isinstance(z, mpc)

def _safe_real_guard(x):
    """Return True if x is (real and <=0). If x is complex, return False (let complex-step flow)."""
    if _is_complex(x):
        return False
    return x <= 0

# ---------- Core KN relations in geom units ----------
def r_plus(M, a, Q):
    Î” = M*M - a*a - Q*Q
    # For complex-step, allow complex Î”; for real negative Î” (super/extremal) return NaN.
    if _is_complex(Î”):
        return M + mp.sqrt(Î”)
    if Î” <= 0:
        return mp.nan
    return M + mp.sqrt(Î”)

def r_minus(M, a, Q):
    Î” = M*M - a*a - Q*Q
    if _is_complex(Î”):
        return M - mp.sqrt(Î”)
    if Î” <= 0:
        return mp.nan
    return M - mp.sqrt(Î”)

def S_of(M, a, Q):
    rp = r_plus(M,a,Q)
    if mp.isnan(rp):  # only possible in real super/extremal guard
        return mp.nan
    return mp.pi*(rp*rp + a*a)

def T_of(M, a, Q):
    # Use (r_+ - r_-) / (4Ï€ (r_+^2 + a^2)) â€” complex-step safe.
    rp = r_plus(M,a,Q); rm = r_minus(M,a,Q)
    if mp.isnan(rp) or mp.isnan(rm):
        return mp.mpf('0')
    den = 4*mp.pi*(rp*rp + a*a)
    # If den happens to be (near) zero only in a real context at extremality, return 0.
    if (not _is_complex(den)) and den == 0:
        return mp.mpf('0')
    return (rp - rm)/den

def Î©_of(M, a, Q):
    rp = r_plus(M,a,Q)
    if mp.isnan(rp):
        return mp.nan
    den = (rp*rp + a*a)
    return a/den

def Î¦_of(M, a, Q):
    rp = r_plus(M,a,Q)
    if mp.isnan(rp):
        return mp.nan
    den = (rp*rp + a*a)
    return (Q*rp)/den

def J_of(M, a, Q):
    return M*a

def smarr_residual(M, a, Q):
    T,Î©,Î¦,S,J = T_of(M,a,Q), Î©_of(M,a,Q), Î¦_of(M,a,Q), S_of(M,a,Q), J_of(M,a,Q)
    # If any NaN (near extremal real-only guard), treat as 0 residual
    if any(mp.isnan(v) for v in [T,Î©,Î¦,S,J]):
        return mp.mpf('0')
    return abs(M - (2*T*S + 2*Î©*J + Î¦*Q))

# ---------- Complex-step Jacobians ----------
def cs_jacobian_vec(fvec, x, h=H_CS):
    """
    Complex-step Jacobian for 3â†’3 maps. fvec returns (f1,f2,f3); x=(M,a,Q).
    Returns (J, f0) with J 3x3 mp.matrix.
    """
    M,a,Q = x
    f0 = fvec(M,a,Q)
    J = mp.zeros(3,3)
    # M-deriv
    fM = fvec(M + 1j*h, a, Q)
    # a-deriv
    fa = fvec(M, a + 1j*h, Q)
    # Q-deriv
    fQ = fvec(M, a, Q + 1j*h)
    for i in range(3):
        J[i,0] = mp.im(fM[i]) / h
        J[i,1] = mp.im(fa[i]) / h
        J[i,2] = mp.im(fQ[i]) / h
    return J, f0

def cs_jacobian_general(fvec, x, h=H_CS):
    """
    Complex-step Jacobian for generic mÃ—n maps.
    fvec: function returning iterable of length m given n inputs (as separate args).
    x: tuple/list of n real mp.mpf.
    Returns mp.matrix(m,n).
    """
    x = list(x)
    f0 = fvec(*x)
    m = len(f0)
    n = len(x)
    J = mp.zeros(m, n)
    for j in range(n):
        xh = x[:]
        xh[j] = xh[j] + 1j*h
        fh = fvec(*xh)
        for i in range(m):
            J[i,j] = mp.im(fh[i]) / h
    return J

def thermo_vec(M,a,Q):
    return (T_of(M,a,Q), Î©_of(M,a,Q), Î¦_of(M,a,Q))

def state_vec(M,a,Q):
    return (S_of(M,a,Q), J_of(M,a,Q), Q)

# ---------- Chain rule: H_M = d(T,Î©,Î¦)/d(S,J,Q) ----------
def HM_chainrule(M,a,Q, ridge=RIDGE):
    Jto, _ = cs_jacobian_vec(thermo_vec, (M,a,Q))   # 3x3  d(T,Î©,Î¦)/d(M,a,Q)
    Jsj, _ = cs_jacobian_vec(state_vec,  (M,a,Q))   # 3x3  d(S,J,Q)/d(M,a,Q)
    # ridge-stable inverse of Jsj
    Jsj_r = matrix([[Jsj[i,j] + (ridge if i==j else 0) for j in range(3)] for i in range(3)])
    Jsj_inv = Jsj_r**-1
    HM = Jto * Jsj_inv
    # symmetric part
    HM_sym = (HM + HM.T)/2
    return HM, HM_sym

# ---------- Dual Hessian in Gibbs ensemble ----------
def HG_dual(HM):
    # H_G = - H_M^{-1}, with ridge stabilization
    HM_r = matrix([[HM[i,j] + (RIDGE if i==j else 0) for j in range(3)] for i in range(3)])
    return - (HM_r**-1)

# ---------- Ruppeiner metric g_R = g_W / T with g_W = sym(HM) ----------
def ruppeiner_metric(M,a,Q):
    HM, HM_sym = HM_chainrule(M,a,Q)
    T = T_of(M,a,Q)
    # Weinhold metric is HM_sym; Ruppeiner scales by 1/T
    gR = matrix([[HM_sym[i,j]/T for j in range(3)] for i in range(3)])
    return gR, HM_sym, T

# ---------- Scalar curvature from a metric on y=(S,J,Q) via finite-diffs ----------
def christoffels_and_R(g, y0, h=H_FD, fmetric=None):
    # g is the metric at y0 (3x3), fmetric(y) returns metric matrix
    invg = g**-1

    def partial_g(y, idx, sign):
        dy = [mp.mpf('0')]*3
        dy[idx] = sign*h
        S,J,Q = y[0]+dy[0], y[1]+dy[1], y[2]+dy[2]
        return fmetric((S,J,Q))

    # first derivatives of g
    pg = [ (partial_g(y0,i,+1) - partial_g(y0,i,-1))/(2*h) for i in range(3) ]  # list of 3 matrices

    # Î“^k_{ij} = 1/2 g^{kl} (âˆ‚_i g_{lj} + âˆ‚_j g_{il} - âˆ‚_l g_{ij})
    Î“ = [[[mp.mpf('0')]*3 for _ in range(3)] for __ in range(3)]
    for k in range(3):
        for i in range(3):
            for j in range(3):
                s = mp.mpf('0')
                for l in range(3):
                    s += invg[k,l]*( pg[i][l,j] + pg[j][i,l] - pg[l][i,j] )
                Î“[k][i][j] = s/2

    # helper to rebuild Î“ at a nearby point (for Î“ derivatives)
    def Î“_at(y):
        g_here = fmetric(y)
        invg_here = g_here**-1
        pg_here = [ (partial_g(y,i,+1) - partial_g(y,i,-1))/(2*h) for i in range(3) ]
        Î“h = [[[mp.mpf('0')]*3 for _ in range(3)] for __ in range(3)]
        for k in range(3):
            for i in range(3):
                for j in range(3):
                    s = mp.mpf('0')
                    for l in range(3):
                        s += invg_here[k,l]*( pg_here[i][l,j] + pg_here[j][i,l] - pg_here[l][i,j] )
                    Î“h[k][i][j] = s/2
        return Î“h

    # âˆ‚_j Î“ by central difference
    def dÎ“(j_idx):
        y_plus  = list(y0); y_plus[j_idx]  += h
        y_minus = list(y0); y_minus[j_idx] -= h
        Î“p = Î“_at(tuple(y_plus))
        Î“m = Î“_at(tuple(y_minus))
        out = [[[mp.mpf('0')]*3 for _ in range(3)] for __ in range(3)]
        for m in range(3):
            for i in range(3):
                for k in range(3):
                    out[m][i][k] = (Î“p[m][i][k] - Î“m[m][i][k])/(2*h)
        return out

    dÎ“_list = [dÎ“(0), dÎ“(1), dÎ“(2)]

    # Ricci (approximate with symmetric contraction of âˆ‚Î“ terms)
    R = [[mp.mpf('0')]*3 for _ in range(3)]
    for i in range(3):
        for k in range(3):
            s = mp.mpf('0')
            for m in range(3):
                # âˆ‘_j (âˆ‚_j Î“^m_{ik} - âˆ‚_k Î“^m_{ij})
                s_j = mp.mpf('0')
                for j in range(3):
                    s_j += dÎ“_list[j][m][i][k] - dÎ“_list[k][m][i][j]
                s += s_j
            R[i][k] = s

    # Scalar curvature R = g^{ik} R_{ik}
    scalar = mp.mpf('0')
    for i in range(3):
        for k in range(3):
            scalar += invg[i,k]*R[i][k]
    return scalar

# Wrapper to get g_R(S,J,Q) callable
def make_ruppeiner_metric_callable(M_fixed):
    def g_of_y(y):
        S_target, J_target, Q_target = y
        # Invert (S,J,Q) -> (M,a,Q) locally by Newton on (M,a) with Q=Q_target
        M = mp.mpf(M_fixed)
        a = J_target / M if M != 0 else mp.mpf('0')
        for _ in range(10):
            S_now = S_of(M,a,Q_target)
            J_now = J_of(M,a,Q_target)
            F1 = S_now - S_target
            F2 = J_now - J_target
            if abs(F1) < mp.mpf('1e-80') and abs(F2) < mp.mpf('1e-80'):
                break
            # Jacobian of (S,J) wrt (M,a) -> 2x2 with generic complex-step
            Jmat = cs_jacobian_general(lambda MM,aa: (S_of(MM,aa,Q_target), J_of(MM,aa,Q_target)), (M,a))
            # ridge 2x2
            Jr = matrix([[Jmat[i,j] + (RIDGE if i==j else 0) for j in range(2)] for i in range(2)])
            step = Jr**-1 * matrix([[-F1],[-F2]])
            M += step[0,0]
            a += step[1,0]
        gR, _, _ = ruppeiner_metric(M,a,Q_target)
        return gR
    return g_of_y

# ---------- M19â€™ recompute (dual Hessians over grid) ----------
def run_M19_fixed(gridN=10, margin=mp.mpf('1e-8'), out_prefix="/content/M19_fixed"):
    rows = []
    for i in range(gridN):
        for j in range(gridN):
            a_star = mp.mpf(i)/(gridN-1)
            q_star = mp.mpf(j)/(gridN-1)
            if a_star*a_star + q_star*q_star >= 1 - margin:
                continue  # focus on OK residuals
            try:
                M=mp.mpf('1'); a=M*a_star; Q=q_star
                HM, HM_sym = HM_chainrule(M,a,Q)
                HG = HG_dual(HM)
                # Maxwell residuals
                R1 = abs(HM[0,1]-HM[1,0]); R2 = abs(HM[0,2]-HM[2,0]); R3 = abs(HM[1,2]-HM[2,1])
                smarr = smarr_residual(M,a,Q)
                # eigenvalues (float64) of symmetric parts
                HM_sym_np = np.array([[float(HM_sym[p,q]) for q in range(3)] for p in range(3)], dtype=np.float64)
                HG_sym_np = np.array([[float(((HG+HG.T)/2)[p,q]) for q in range(3)] for p in range(3)], dtype=np.float64)
                eigmin_HM = float(np.linalg.eigvalsh(HM_sym_np)[0])
                eigmin_HG = float(np.linalg.eigvalsh(HG_sym_np)[0])

                rows.append(dict(a_star=float(a_star), q_star=float(q_star),
                                 R1=float(R1), R2=float(R2), R3=float(R3), smarr=float(smarr),
                                 eigmin_HM=eigmin_HM, eigmin_HG=eigmin_HG))
            except Exception:
                pass  # omit FAIL rows in *_fixed

    df = pd.DataFrame(rows)
    csv = f"{out_prefix}_grid.csv"
    df.to_csv(csv, index=False)
    print(f"[M19â€²] wrote: {csv}")

    # BEFORE/AFTER comparison (robust to column naming)
    if os.path.exists("/content/M19_v2_ok_states_detailed.csv"):
        old = pd.read_csv("/content/M19_v2_ok_states_detailed.csv")
        def _pick(name_opts):
            for name in name_opts:
                if name in old.columns: return name
            return None
        oR1 = _pick(['R1','r_SJ']); oR2=_pick(['R2','r_SQ']); oR3=_pick(['R3','r_JQ']); oSM=_pick(['smarr','Smarr'])
        if all([oR1,oR2,oR3,oSM]):
            print("[M19â€²] BEFORE max residuals:",
                  f"R1={old[oR1].abs().max():.3e} R2={old[oR2].abs().max():.3e} "
                  f"R3={old[oR3].abs().max():.3e} Smarr={old[oSM].abs().max():.3e}")
    if len(df):
        print("[M19â€²]  AFTER max residuals:",
              f"R1={df['R1'].abs().max():.3e} R2={df['R2'].abs().max():.3e} "
              f"R3={df['R3'].abs().max():.3e} Smarr={df['smarr'].abs().max():.3e}")
    return df

# ---------- M25â€™ recompute (Ruppeiner curvature scaling) ----------
def run_M25_fixed(thetas=(0.0,0.5,1.0), eps_list=None, out_prefix="/content/M25_fixed"):
    if eps_list is None:
        eps_list = [mp.mpf(str(x)) for x in [1e-2, 5e-3, 1e-3, 5e-4, 1e-4, 5e-5, 1e-5, 1e-6, 1e-7, 1e-8, 1e-9, 1e-10]]
    rows = []
    for th in thetas:
        c, s = mp.cos(th), mp.sin(th)
        for eps in eps_list:
            rad = mp.sqrt(max(mp.mpf('1e-60'), 1-eps))
            a_star = rad*c; q_star = rad*s
            M=mp.mpf('1'); a=M*a_star; Q=q_star
            # state vector
            S,J,Qv = S_of(M,a,Q), J_of(M,a,Q), Q
            if mp.isnan(S):
                continue  # skip pathological real-guard points
            y0 = (S,J,Qv)
            gR0, HM_sym, T = ruppeiner_metric(M,a,Q)
            # metric callback at S,J,Q by local inversion
            g_of_y = make_ruppeiner_metric_callable(M)
            try:
                R = christoffels_and_R(gR0, y0, h=H_FD, fmetric=g_of_y)
                R_abs = abs(R)
            except Exception:
                R_abs = mp.mpf('nan')
            rows.append(dict(theta=float(th), eps=float(eps), a_star=float(a_star), q_star=float(q_star),
                             T=float(T), smarr=float(smarr_residual(M,a,Q)), R_abs=float(R_abs)))
    df = pd.DataFrame(rows)
    csv = f"{out_prefix}_scan.csv"
    df.to_csv(csv, index=False)
    print(f"[M25â€²] wrote: {csv}")

    # BEFORE/AFTER comparison (handle both legacy 'Ruppeiner' and new 'R_abs')
    if os.path.exists("/content/M25_ruppeiner_curvature_scan.csv"):
        old = pd.read_csv("/content/M25_ruppeiner_curvature_scan.csv")
        if 'R_abs' in old.columns:
            o_min, o_med, o_max = old['R_abs'].min(), old['R_abs'].median(), old['R_abs'].max()
        elif 'Ruppeiner' in old.columns:
            o_min, o_med, o_max = old['Ruppeiner'].abs().min(), old['Ruppeiner'].abs().median(), old['Ruppeiner'].abs().max()
        else:
            o_min = o_med = o_max = float('nan')
        print("[M25â€²] BEFORE |R_R| stats:",
              f"min={o_min:.3e}, median={o_med:.3e}, max={o_max:.3e}")
    if len(df):
        print("[M25â€²]  AFTER |R_R| stats:",
              f"min={df['R_abs'].min():.3e}, median={df['R_abs'].median():.3e}, max={df['R_abs'].max():.3e}")
    return df

# ---------- Run both re-computes ----------
print("="*106)
print("MODULE 027-FIXKIT: Recomputing Hessians (M19â€²) & Ruppeiner Curvature (M25â€²) with robust numerics")
print(f"mp.dps={mp.dps}, H_CS={H_CS}, H_FD={H_FD}, ridge={RIDGE}")
print("="*106)

df19 = run_M19_fixed(gridN=10)
df25 = run_M25_fixed()

print("\nTip: re-run your Module 028 meta-audit to see the unified score jump with the *_fixed receipts.")

# ==============================================================================================================
# MODULE 028 (REPLACED, CLEAN v2): Unified Meta-Audit â€” Ledger, Integrity, Anomalies, Verdict
# ==============================================================================================================
# Goal
#   Ingest *everything* under /content â€” CSV/JSON/TXT/LOG â€” extract residual-like numerics (Smarr, Maxwell,
#   residuals, rel_err, Î”, etc.), plus text flags; compute:
#     â€¢ Global unified score (0..100) with target 10^-L (default L=80)
#     â€¢ Per-module integrity table (median quality, score, counts, flags)
#     â€¢ Top anomalies/outliers (worst/best numerics; textual flags)
#   Then print a concise overall report and write artifacts:
#     /content/M28_unified_records.csv
#     /content/M28_module_integrity.csv
#     /content/M28_anomalies_top.csv
#     /content/M28_meta_summary.json
#
# Key upgrades vs earlier versions:
#   â€¢ Ignores *quality columns* named like "score", "ledger_score", "file_score" so they do NOT get treated as errors.
#   â€¢ Suppresses plain "nan/inf" flags unless the line/field also matches an error-ish token (Smarr, Maxwell, err, resid, Î”, â€¦).
#   â€¢ Robust numeric parsing (supports unicode minus 'âˆ’' and "0E-110" style numbers).
#   â€¢ No pandas deprecation warnings; no formatting errors on ints/floats.
#   â€¢ Colab/Posix friendly; safe if directory is empty.
# ==============================================================================================================

import os, re, json, glob, math
import numpy as np
import pandas as pd

# ------------------------ Tunables ------------------------
SCAN_GLOBS  = ["/content/*.csv", "/content/*.json", "/content/*.txt", "/content/*.log"]
LEDGER_L    = 80.0                 # full-credit target: 10^(âˆ’L)
EPS_FLOOR   = 1e-300               # avoid log10(0)
TOP_N       = 50                   # top worst/best listings in anomalies csv

# Residual/metric keyword detector (case-insensitive, includes Greek delta & sigma)
ERR_TOKENS  = re.compile(
    r"(smarr|maxwell|res(id(ual)?)?|rel[\s_\-]?err|abs[\s_\-]?err|mis(match)?|gap|dev(iation)?|"
    r"diff(?!erence.*index)|delta|Î”|sigma|Ïƒ|codata|curvature|curv|lattice|snap|"
    r"pass|warn|fail|sing(ular|ularity)?|diverg(ent|ence))",
    re.IGNORECASE
)

# Columns/fields that are *quality* metrics, not errors (skip as residuals)
SCORE_EXCLUDE = re.compile(r"(?:^|[^a-z])(ledger_)?file?_?score(?:$|[^a-z])|^score$", re.IGNORECASE)

# Soft exclude (columns likely non-residual structure)
NON_ERR_HINT = re.compile(r"(index|step|iter|theta|eps\b|a\*|q\*|mass\b|^J$|^Q$|^A$|^M$|k_pred|^k$)",
                          re.IGNORECASE)

# Numeric regex (floats / scientific / 0E-110 / leading signs / embedded in text; unicode minus handled downstream)
NUM_REGEX = re.compile(r"[-+]?(\d+(\.\d+)?|\.\d+)([eEâˆ’\-+]\d+)?")

# ------------------------ Helpers ------------------------
def extract_module_id(path: str) -> str:
    m = re.search(r"/(M\d+)[^/]*\.(csv|json|txt|log)$", path, re.IGNORECASE)
    return m.group(1) if m else "UNKNOWN"

def normalize_text(s: str) -> str:
    # Normalize unicode minus to ASCII and collapse whitespace a bit
    return str(s).replace('âˆ’', '-').strip()

def parse_numbers_from_string(s: str):
    s = normalize_text(s)
    out = []
    for m in NUM_REGEX.finditer(s):
        token = m.group(0)
        try:
            out.append(float(token))
        except:
            # ignore tokens that don't coerce
            pass
    return out

def looks_like_error_name(name: str) -> bool:
    # Skip explicit *score* fields (these are quality, not error)
    if SCORE_EXCLUDE.search(name or ""):
        return False
    # If column name looks like structure, only include if it *also* carries an error-ish token
    if NON_ERR_HINT.search(name or ""):
        return bool(ERR_TOKENS.search(name or ""))
    return bool(ERR_TOKENS.search(name or ""))

def text_flags(s: str):
    # Only surface plain 'nan'/'inf' when an error-ish token is present (Smarr/Maxwell/err/â€¦)
    s_norm = normalize_text(s).lower()
    flags = []
    has_errish = bool(ERR_TOKENS.search(s_norm))
    for key in ["fail", "warn", "diverg", "singular"]:
        if key in s_norm:
            flags.append(key)
    if has_errish:
        for key in ["nan", "inf"]:
            if key in s_norm:
                flags.append(key)
    return flags

def safe_q_from_err(vals: np.ndarray) -> np.ndarray:
    """Quality metric q = âˆ’log10(|err|). Higher is better."""
    return -np.log10(np.clip(np.abs(vals), EPS_FLOOR, None))

def ledger_score_from_q(q: np.ndarray, L: float = LEDGER_L) -> float:
    s = np.clip(q / L, 0.0, 1.0)
    return float(100.0 * np.nanmean(s)) if s.size else float('nan')

def robust_anomaly_mask(q: np.ndarray):
    """Flag low-quality outliers: q << median using MAD (median absolute deviation)."""
    if q.size == 0:
        return np.zeros(0, dtype=bool)
    med = np.nanmedian(q)
    mad = np.nanmedian(np.abs(q - med)) or 1e-12
    # Consider anomalous if q < med âˆ’ 3*MAD
    return q < (med - 3.0 * mad)

def flatten_json(obj, path="$"):
    """Yield (key_path, value) pairs from nested JSON."""
    if isinstance(obj, dict):
        for k, v in obj.items():
            yield from flatten_json(v, f"{path}.{k}")
    elif isinstance(obj, list):
        for i, v in enumerate(obj):
            yield from flatten_json(v, f"{path}[{i}]")
    else:
        yield (path, obj)

# ------------------------ Ingest ------------------------
records = []   # rows: {module,file,src,tag,column,context,value,quality_q,kind}
flag_rows = [] # textual anomaly flags independent of numeric magnitude
read_fails = 0

paths = []
for g in SCAN_GLOBS:
    paths.extend(glob.glob(g))
paths = sorted(set(paths))

if not paths:
    print("MODULE 028: No receipts found under /content â€” nothing to audit.")
else:
    for path in paths:
        module = extract_module_id(path)
        base   = os.path.basename(path)
        ext    = os.path.splitext(base)[1].lower()

        try:
            if ext == ".csv":
                df = pd.read_csv(path)
                # Identify residual-like columns by header tokens; skip score-like columns
                err_cols = [c for c in df.columns if looks_like_error_name(str(c))]
                err_cols = [c for c in err_cols if not SCORE_EXCLUDE.search(str(c))]

                # Numeric columns first
                for c in err_cols:
                    ser = df[c]
                    if ser.dtype == object:
                        ser = pd.to_numeric(ser.apply(normalize_text), errors="coerce")
                    vals = ser.to_numpy()
                    vals = vals[np.isfinite(vals)]
                    for v in vals:
                        q = safe_q_from_err(np.array([v]))[0]
                        records.append(dict(module=module,file=base,src="csv",tag=str(c),column=str(c),
                                            context=str(c), value=float(v), quality_q=float(q), kind="column"))

                # Inline scan on text columns (only those that look error-ish)
                for c in df.columns:
                    if df[c].dtype == object and looks_like_error_name(str(c)):
                        for s in df[c].astype(str).tolist():
                            s_norm = normalize_text(s)
                            if not ERR_TOKENS.search(s_norm):
                                # no residual-ish token â‡’ skip
                                continue
                            if SCORE_EXCLUDE.search(s_norm):
                                # skip "score" lines
                                continue
                            nums = parse_numbers_from_string(s_norm)
                            for v in nums:
                                q = safe_q_from_err(np.array([v]))[0]
                                records.append(dict(module=module,file=base,src="csv",tag="inline",column=str(c),
                                                    context=s_norm[:200], value=float(v),
                                                    quality_q=float(q), kind="inline"))
                            for fl in text_flags(s_norm):
                                flag_rows.append(dict(module=module,file=base,src="csv",flag=fl,context=s_norm[:200]))

            elif ext == ".json":
                with open(path, "r") as f:
                    data = json.load(f)
                # Flatten and capture numerics and strings containing numeric with residual tokens
                for kpath, val in flatten_json(data):
                    tag = normalize_text(kpath)
                    if isinstance(val, (int,float)):
                        if SCORE_EXCLUDE.search(tag):
                            continue
                        v = float(val)
                        q = safe_q_from_err(np.array([v]))[0] if ERR_TOKENS.search(tag) else float('nan')
                        records.append(dict(module=module,file=base,src="json",tag=tag,column="",
                                            context=tag, value=v, quality_q=q, kind="json_num"))
                    elif isinstance(val, str):
                        s = normalize_text(val)
                        # Only if residual-ish tokens present and not score-like
                        if (ERR_TOKENS.search(s) or ERR_TOKENS.search(tag)) and not (SCORE_EXCLUDE.search(tag) or SCORE_EXCLUDE.search(s)):
                            nums = parse_numbers_from_string(s)
                            for v in nums:
                                q = safe_q_from_err(np.array([v]))[0]
                                records.append(dict(module=module,file=base,src="json",tag=tag,column="",
                                                    context=(tag + ": " + s[:200]), value=float(v),
                                                    quality_q=float(q), kind="json_text"))
                            for fl in text_flags(s):
                                flag_rows.append(dict(module=module,file=base,src="json",flag=fl,context=(tag + ": " + s[:200])))

            elif ext in (".txt", ".log"):
                # Read text and scan line by line
                with open(path, "r", errors="ignore") as f:
                    for line in f:
                        line_norm = normalize_text(line)
                        if not ERR_TOKENS.search(line_norm):
                            continue
                        if SCORE_EXCLUDE.search(line_norm):
                            continue
                        nums = parse_numbers_from_string(line_norm)
                        for v in nums:
                            q = safe_q_from_err(np.array([v]))[0]
                            records.append(dict(module=module,file=base,src="text",tag="line",column="",
                                                context=line_norm.strip()[:220], value=float(v), quality_q=float(q), kind="text"))
                        for fl in text_flags(line_norm):
                            flag_rows.append(dict(module=module,file=base,src="text",flag=fl,context=line_norm.strip()[:220]))

            else:
                # Unknown extension â€“ skip gracefully
                continue

        except Exception as e:
            read_fails += 1
            # Diagnostic flag row
            flag_rows.append(dict(module=module,file=base,src=ext or "unknown",flag="read_fail",context=str(e)[:220]))

# ------------------------ Aggregation ------------------------
rec_df = pd.DataFrame(records)
flags_df = pd.DataFrame(flag_rows)

# Persist paths
rec_csv_path   = "/content/M28_unified_records.csv"
mod_csv_path   = "/content/M28_module_integrity.csv"
anom_csv_path  = "/content/M28_anomalies_top.csv"
summary_path   = "/content/M28_meta_summary.json"

if rec_df.empty and flags_df.empty:
    with open(summary_path, "w") as f:
        json.dump({"message":"No numeric/error-like receipts found",
                   "n_files_scanned": len(paths),
                   "read_failures": read_fails}, f, indent=2)
    print("MODULE 028: No numeric/error-like receipts detected; wrote minimal summary JSON.")
else:
    # Ensure required columns exist
    if rec_df.empty:
        rec_df = pd.DataFrame(columns=["module","file","src","tag","column","context","value","quality_q","kind"])

    # Global quality vector
    qvals = rec_df["quality_q"].to_numpy(dtype=float)
    qvals = qvals[np.isfinite(qvals)]

    unified_score = ledger_score_from_q(qvals, L=LEDGER_L) if qvals.size else float('nan')
    best_q  = float(np.nanmax(qvals)) if qvals.size else float('nan')
    worst_q = float(np.nanmin(qvals)) if qvals.size else float('nan')

    # Per-module integrity: counts & quantiles (without deprecated behavior)
    # n_values: total rows per module; n_quality: finite quality values count
    grp = rec_df.groupby("module", dropna=False)
    mod_counts = grp["quality_q"].agg(n_values="size").reset_index()
    mod_quality_counts = grp["quality_q"].apply(lambda s: int(np.isfinite(s.to_numpy(dtype=float)).sum())).reset_index(name="n_quality")
    mod_stats = grp["quality_q"].agg(
        q_median=lambda s: float(np.nanmedian(s.to_numpy(dtype=float))),
        q_mean=lambda s: float(np.nanmean(s.to_numpy(dtype=float))),
        q_min=lambda s: float(np.nanmin(s.to_numpy(dtype=float))),
        q_max=lambda s: float(np.nanmax(s.to_numpy(dtype=float))),
    ).reset_index()

    # Module scores computed only from finite q
    finite = rec_df[np.isfinite(rec_df["quality_q"].to_numpy(dtype=float))].copy()
    if len(finite):
        mod_scores = finite.groupby("module")["quality_q"].apply(lambda s: ledger_score_from_q(s.to_numpy(dtype=float), LEDGER_L)).reset_index(name="ledger_score")
    else:
        mod_scores = pd.DataFrame(columns=["module","ledger_score"])

    # Merge all module-level summaries
    mod_df = mod_counts.merge(mod_quality_counts, on="module", how="outer").merge(mod_stats, on="module", how="outer").merge(mod_scores, on="module", how="outer")

    # Append PASS/WARN/FAIL text counts per module (from flags)
    if not flags_df.empty:
        pwf = flags_df.assign(flag=flags_df["flag"].str.lower())
        pwf_counts = pwf.pivot_table(index="module", columns="flag", values="file", aggfunc="count", fill_value=0)
        for col in ["pass","warn","fail","diverg","singular","nan","inf","read_fail"]:
            if col not in pwf_counts.columns:
                pwf_counts[col] = 0
        mod_df = mod_df.merge(pwf_counts.reset_index(), on="module", how="left").fillna(0)
    else:
        for col in ["pass","warn","fail","diverg","singular","nan","inf","read_fail"]:
            mod_df[col] = 0

    # Detect numeric anomalies by robust low-q
    anom_rows = []
    if qvals.size:
        mask = robust_anomaly_mask(rec_df["quality_q"].to_numpy(dtype=float))
        if mask.any():
            anom_rows.append(rec_df.loc[mask].assign(anomaly="low_quality"))
    # Add explicit string-flag anomalies
    if not flags_df.empty:
        anom_rows.append(flags_df.assign(anomaly="text_flag"))
    anom_df = pd.concat(anom_rows, ignore_index=True) if anom_rows else pd.DataFrame()

    # Top lists: worst residuals (smallest q), best residuals (largest q)
    if not rec_df.empty:
        worst_df = rec_df.sort_values("quality_q", ascending=True).head(TOP_N).assign(rank="worst")
        best_df  = rec_df.sort_values("quality_q", ascending=False).head(TOP_N).assign(rank="best")
        top_df   = pd.concat([worst_df, best_df], ignore_index=True)
    else:
        top_df = pd.DataFrame(columns=["module","file","src","tag","column","context","value","quality_q","kind","rank"])

    # Write artifacts
    rec_df.to_csv(rec_csv_path, index=False)
    mod_df.sort_values("module").to_csv(mod_csv_path, index=False)
    top_df.to_csv(anom_csv_path, index=False)

    # Verdict heuristic
    verdict = "EXCELLENT"
    if not math.isnan(unified_score) and unified_score < 95.0: verdict = "GOOD"
    if not math.isnan(unified_score) and unified_score < 85.0: verdict = "NEEDS REVIEW"
    if not math.isnan(unified_score) and unified_score < 70.0: verdict = "CRITICAL"
    # If any explicit FAIL/divergent/singular flags, downgrade
    if not flags_df.empty:
        if (flags_df["flag"].str.lower().isin(["fail","diverg","singular"]).any()):
            verdict = "CRITICAL"

    # Summary JSON
    summary = {
        "unified_ledger_score": unified_score,
        "quality_target_L": LEDGER_L,
        "q_best": best_q,
        "q_worst": worst_q,
        "n_files_scanned": len(paths),
        "read_failures": read_fails,
        "n_numeric_records": int(rec_df.shape[0]),
        "n_text_flags": int(flags_df.shape[0]) if not flags_df.empty else 0,
        "n_anomalies": int(anom_df.shape[0]) if not anom_df.empty else 0,
        "verdict": verdict,
        "artifacts": {
            "records_csv": rec_csv_path,
            "modules_csv": mod_csv_path,
            "top_anomalies_csv": anom_csv_path
        }
    }
    with open(summary_path, "w") as f:
        json.dump(summary, f, indent=2)

    # ------------------------ Unified Print Block ------------------------
    print("="*118)
    print("MODULE 028: Unified Meta-Audit â€” Ledger, Integrity, Anomalies, Verdict")
    print("="*118)
    print(f"Files scanned: {len(paths)}  |  read failures: {read_fails}")
    print(f"Numeric records: {rec_df.shape[0]}  |  text flags: {0 if flags_df.empty else flags_df.shape[0]}")
    if not math.isnan(unified_score):
        print(f"Unified Ledger Score (0..100; target 10^-{int(LEDGER_L)}): {unified_score:.3f}")
        if not math.isnan(best_q) and not math.isnan(worst_q):
            print(f"Quality q = âˆ’log10(|err|): best={best_q:.1f}  worst={worst_q:.1f}  (higher is better)")
    else:
        print("Unified Ledger Score: n/a (no residual-like numerics detected)")

    if len(mod_df):
        print("\nIntegrity per module (ledger_score, q_median, flags):")
        for r in mod_df.sort_values("module").to_dict(orient="records"):
            # safe ints
            n_quality = int(r.get("n_quality") or 0)
            fail = int(r.get("fail",0)); warn = int(r.get("warn",0))
            divg = int(r.get("diverg",0)); sing = int(r.get("singular",0))
            n_nan= int(r.get("nan",0));    n_inf= int(r.get("inf",0))
            score = r.get("ledger_score")
            q_med = r.get("q_median")
            print(f"  {str(r['module']):>6s} | score={(float('nan') if pd.isna(score) else float(score)):6.2f}  "
                  f"q_med={(float('nan') if pd.isna(q_med) else float(q_med)):6.1f}  "
                  f"vals={n_quality:6d}  "
                  f"flags: FAIL={fail} WARN={warn} DIV={divg} SING={sing} NAN={n_nan} INF={n_inf}")

    print("\nDetected anomalies / outliers:")
    printed = 0
    if not rec_df.empty:
        for row in rec_df.sort_values("quality_q", ascending=True).head(10).to_dict(orient="records"):
            v = row.get("value", np.nan); q = row.get("quality_q", np.nan); ctx = (row.get("context","") or "")[:90]
            print(f"  WORST | {str(row.get('module')):>6s} | {str(row.get('file')):<36s} | {str(row.get('tag'))[:22]:<22s} "
                  f"| |err|={abs(float(v)) if pd.notna(v) else float('nan'):.3e}  q={(float('nan') if pd.isna(q) else float(q)):.1f}  ctx='{ctx}'")
            printed += 1
    if not flags_df.empty:
        for row in flags_df.head(10).to_dict(orient="records"):
            print(f"  FLAG  | {str(row.get('module')):>6s} | {str(row.get('file')):<36s} | {str(row.get('flag')):<8s} | ctx='{(row.get('context') or '')[:72]}'")
            printed += 1
    if printed == 0:
        print("  (none)")

    print("\nSystem-wide verdict:", verdict)
    print("\nArtifacts:")
    print(f"  - {rec_csv_path}")
    print(f"  - {mod_csv_path}")
    print(f"  - {anom_csv_path}")
    print(f"  - {summary_path}")
    print("="*118)

# ==========================================================================================================
# MODULE 029: Cross-Ensemble Phase Portrait & Stability Sign Topology â€” Kerrâ€“Newman (geom units)
# ==========================================================================================================
# Goal
#   Fuse the dual-ensemble receipts (microcanonical from M19, sign map from M26 if present) and produce a
#   text/CSV phase portrait over (a*, q*) that labels each state by stability signs and highlights â€œboundaryâ€
#   loci where signs flip (candidate phase/topology lines).
#
# What it reads (best-effort, optional fallbacks):
#   - /content/M19_v2_ok_states_detailed.csv            (preferred, from M19 v2/v3)
#   - /content/M19_fixed_grid.csv                       (fallback, M27 FixKit)
#   - /content/M26_response_sign_map.csv                (optional overlay for sign sanity)
#
# What it writes:
#   - /content/M29_phase_portrait_grid.csv              (per-state stability labels & signs)
#   - /content/M29_phase_boundaries.csv                 (boundary points where any sign flips across neighbors)
#   - /content/M29_phase_summary.json                   (counts, residual ranges, notes)
#
# Printout:
#   - Counts of OK/EXT/FAIL (if present)
#   - Residual ranges (Smarr & Maxwell) if columns exist
#   - Ensemble â€œstability verdictsâ€ (microcanonical vs isopotential)
#   - Boundary statistics and a few sample boundary coordinates
#
# Notes
#   - No plots; text + CSV only, Colab-friendly.
#   - Robust to missing columns; if some responses arenâ€™t available, module still runs and reports what it can.
# ==========================================================================================================

import os, json, math
import numpy as np
import pandas as pd

# ---------- Helper: load first existing ----------
def _read_first(paths):
    for p in paths:
        if os.path.exists(p):
            try:
                return pd.read_csv(p), p
            except Exception:
                pass
    return pd.DataFrame(), None

# ---------- Inputs ----------
df19, src19 = _read_first([
    "/content/M19_v2_ok_states_detailed.csv",
    "/content/M19_fixed_grid.csv",
    "/content/M19_v2_ensemble_stability_grid.csv"  # full grid if detailed missing
])

df26, src26 = _read_first([
    "/content/M26_response_sign_map.csv"
])

# Early guard
if df19.empty and df26.empty:
    print("="*110)
    print("MODULE 029: No usable M19/M26 receipts found under /content â€” nothing to map.")
    print("="*110)
else:
    # ---------- Harmonize + derive ----------
    # Try to ensure (a_star, q_star) exist
    for c in ["a_star", "q_star"]:
        if c not in df19.columns and not df19.empty:
            # try alternative spellings (rare)
            cand = [x for x in df19.columns if x.lower().replace("*","star")==c]
            if cand:
                df19.rename(columns={cand[0]:c}, inplace=True)

    # Known response columns weâ€™ll use if present:
    RESP_COLS = dict(
        C_JQ      = "C_JQ",
        chi_J     = "chi_J",
        chi_Q     = "chi_Q",
        C_OmPhi   = "C_OmPhi",
        kappa_J   = "kappa_J",
        kappa_Q   = "kappa_Q",
        r1        = "r_SJ",
        r2        = "r_SQ",
        r3        = "r_JQ",
        smarr     = "smarr",
    )
    # Make sure missing cols exist as NaN (simplifies logic)
    if not df19.empty:
        for k,v in RESP_COLS.items():
            if v not in df19.columns:
                df19[v] = np.nan

    # Thresholds
    NEAR0 = 1e-120      # numerical â€œâ‰ˆ0â€ band for responses
    PASS_TOL = 1e-80    # tight closure for Smarr/Maxwell

    def sign_bucket(x):
        # return +1, -1, 0 (â‰ˆ0), or np.nan
        try:
            if not np.isfinite(x): return np.nan
            if abs(x) < NEAR0: return 0
            return 1 if x > 0 else -1
        except Exception:
            return np.nan

    # Compute sign buckets for each ensembleâ€™s key responses (when available)
    if not df19.empty:
        df = df19.copy()
        df["sgn_CJQ"]   = df["C_JQ"].apply(sign_bucket)       if "C_JQ"    in df else np.nan
        df["sgn_chiJ"]  = df["chi_J"].apply(sign_bucket)      if "chi_J"   in df else np.nan
        df["sgn_chiQ"]  = df["chi_Q"].apply(sign_bucket)      if "chi_Q"   in df else np.nan
        df["sgn_COmF"]  = df["C_OmPhi"].apply(sign_bucket)    if "C_OmPhi" in df else np.nan
        df["sgn_kJ"]    = df["kappa_J"].apply(sign_bucket)    if "kappa_J" in df else np.nan
        df["sgn_kQ"]    = df["kappa_Q"].apply(sign_bucket)    if "kappa_Q" in df else np.nan
        # Closure flags (if residuals present)
        if "smarr" in df:
            df["smarr_ok"] = np.isfinite(df["smarr"]) & (df["smarr"].abs() < PASS_TOL)
        else:
            df["smarr_ok"] = np.nan
        if all(c in df for c in ["r_SJ","r_SQ","r_JQ"]):
            df["maxwell_ok"] = (
                df[["r_SJ","r_SQ","r_JQ"]].abs().max(axis=1) < PASS_TOL
            )
        else:
            df["maxwell_ok"] = np.nan

        # Ensemble â€œstability verdictsâ€ (very simple sign rules; informative, not prescriptive)
        # Microcanonical: heat capacity positive & susceptibilities positive
        df["mc_stable"] = (
            (df["sgn_CJQ"]==1) & (df["sgn_chiJ"]==1) & (df["sgn_chiQ"]==1)
        )
        # Gibbs/isopotential: C_{Î©,Î¦} positive & Îº_J, Îº_Q positive
        if all(c in df for c in ["sgn_COmF","sgn_kJ","sgn_kQ"]):
            df["gibbs_stable"] = (
                (df["sgn_COmF"]==1) & (df["sgn_kJ"]==1) & (df["sgn_kQ"]==1)
            )
        else:
            df["gibbs_stable"] = np.nan

        # If M26 exists, overlay (optional): we wonâ€™t overwrite numerics,
        # but we can carry its PASS stats for context.
        m26_counts = {}
        if not df26.empty:
            # Expect columns like signs & counts; store for summary only
            m26_counts["rows"] = int(df26.shape[0])
            for col in df26.columns:
                if col.lower().endswith(("pass","ok","fail","warn")):
                    try:
                        m26_counts[col] = int(np.nansum(df26[col].to_numpy()))
                    except Exception:
                        pass

        # ---------- Boundary finder ----------
        # Flag points that neighbor a sign flip in ANY response (4-neighborhood on the grid).
        # This requires the (a*, q*) to be on a grid; weâ€™ll round to 2 decimals (as in M19).
        def _round2(x):
            try: return float(np.round(float(x), 2))
            except: return np.nan

        df["a_r"] = df["a_star"].apply(_round2) if "a_star" in df else np.nan
        df["q_r"] = df["q_star"].apply(_round2) if "q_star" in df else np.nan

        # create pivot maps for each sign field
        sign_fields = [c for c in ["sgn_CJQ","sgn_chiJ","sgn_chiQ","sgn_COmF","sgn_kJ","sgn_kQ"] if c in df]
        grids = {}
        for c in sign_fields:
            try:
                piv = df.pivot_table(index="a_r", columns="q_r", values=c, aggfunc="mean")
                grids[c] = piv
            except Exception:
                pass

        # neighbor check helper
        def neighbor_flips(piv, a, q):
            if piv is None: return False
            if a not in piv.index or q not in piv.columns: return False
            center = piv.loc[a, q]
            if not np.isfinite(center): return False
            flips = False
            for da,dq in [(0,0.01),(0,-0.01),(0.01,0),( -0.01,0)]:
                aa = np.round(a+da, 2); qq = np.round(q+dq, 2)
                if (aa in piv.index) and (qq in piv.columns):
                    nb = piv.loc[aa, qq]
                    if np.isfinite(nb) and (nb != center):
                        flips = True
                        break
            return flips

        # Build boundary mask
        boundary_rows = []
        for idx, row in df.iterrows():
            a, q = row.get("a_r"), row.get("q_r")
            if not (np.isfinite(a) and np.isfinite(q)):
                continue
            # If any sign grid shows a neighbor flip, mark boundary
            is_boundary = False
            which = []
            for name, piv in grids.items():
                if neighbor_flips(piv, a, q):
                    is_boundary = True
                    which.append(name)
            if is_boundary:
                boundary_rows.append(dict(a_star=row["a_star"], q_star=row["q_star"], which=",".join(which)))

        df_boundary = pd.DataFrame(boundary_rows)

        # ---------- Save artifacts ----------
        out_grid_csv   = "/content/M29_phase_portrait_grid.csv"
        out_bound_csv  = "/content/M29_phase_boundaries.csv"
        out_summary_js = "/content/M29_phase_summary.json"

        cols_out = [
            "a_star","q_star",
            "C_JQ","chi_J","chi_Q","C_OmPhi","kappa_J","kappa_Q",
            "sgn_CJQ","sgn_chiJ","sgn_chiQ","sgn_COmF","sgn_kJ","sgn_kQ",
            "mc_stable","gibbs_stable",
            "r_SJ","r_SQ","r_JQ","smarr","maxwell_ok","smarr_ok"
        ]
        cols_out = [c for c in cols_out if c in df.columns]
        df[cols_out].to_csv(out_grid_csv, index=False)
        df_boundary.to_csv(out_bound_csv, index=False)

        # Summary stats
        def _rng(s):
            if s not in df.columns: return (float('nan'), float('nan'))
            arr = df[s].to_numpy(dtype=float)
            arr = arr[np.isfinite(arr)]
            return (float(np.min(arr)) if arr.size else float('nan'),
                    float(np.max(arr)) if arr.size else float('nan'))

        R1_rng = _rng("r_SJ")
        R2_rng = _rng("r_SQ")
        R3_rng = _rng("r_JQ")
        SM_rng = _rng("smarr")

        summary = dict(
            sources=dict(M19=src19, M26=src26),
            counts=dict(
                total=int(df.shape[0]),
                mc_stable=int(np.nansum(df["mc_stable"])) if "mc_stable" in df else None,
                gibbs_stable=int(np.nansum(df["gibbs_stable"])) if "gibbs_stable" in df else None,
                boundaries=int(df_boundary.shape[0]),
                smarr_pass=int(np.nansum(df["smarr_ok"])) if "smarr_ok" in df else None,
                maxwell_pass=int(np.nansum(df["maxwell_ok"])) if "maxwell_ok" in df else None
            ),
            residual_ranges=dict(
                R1=r"{:.3e}..{:.3e}".format(*R1_rng) if all(np.isfinite(R1_rng)) else None,
                R2=r"{:.3e}..{:.3e}".format(*R2_rng) if all(np.isfinite(R2_rng)) else None,
                R3=r"{:.3e}..{:.3e}".format(*R3_rng) if all(np.isfinite(R3_rng)) else None,
                Smarr=r"{:.3e}..{:.3e}".format(*SM_rng) if all(np.isfinite(SM_rng)) else None
            ),
            overlay_M26=m26_counts if m26_counts else None,
            notes="Signs: +1/âˆ’1/0â‰ˆ; Stability: microcanonical=(C_JQ, Ï‡_J, Ï‡_Q > 0), "
                  "Gibbs=(C_{Î©,Î¦}, Îº_J, Îº_Q > 0). Boundaries mark sign flips in the 4-neighborhood."
        )
        with open(out_summary_js, "w") as f:
            json.dump(summary, f, indent=2)

        # ---------- Print report ----------
        print("="*110)
        print("MODULE 029: Cross-Ensemble Phase Portrait & Stability Sign Topology â€” KN (geom units)")
        print("="*110)
        print(f"Inputs:")
        if src19: print(f"  â€¢ M19 responses: {src19}")
        if src26: print(f"  â€¢ M26 overlay  : {src26}")
        print("\nCounts & closures:")
        print(f"  States total          : {df.shape[0]}")
        if "smarr_ok" in df:
            print(f"  Smarr PASS (tol=1e-80): {int(np.nansum(df['smarr_ok']))}/{df.shape[0]}")
        if "maxwell_ok" in df:
            print(f"  Maxwell PASS (tol=1e-80): {int(np.nansum(df['maxwell_ok']))}/{df.shape[0]}")
        # Residual ranges
        def _rstr(rng):
            return ("[{:.3e}, {:.3e}]".format(*rng)) if all(np.isfinite(rng)) else "n/a"
        if "r_SJ" in df or "r_SQ" in df or "r_JQ" in df or "smarr" in df:
            print("  Residual ranges:")
            if "r_SJ" in df: print(f"    R1=|âˆ‚T/âˆ‚Jâˆ’âˆ‚Î©/âˆ‚S| : {_rstr(R1_rng)}")
            if "r_SQ" in df: print(f"    R2=|âˆ‚T/âˆ‚Qâˆ’âˆ‚Î¦/âˆ‚S| : {_rstr(R2_rng)}")
            if "r_JQ" in df: print(f"    R3=|âˆ‚Î©/âˆ‚Qâˆ’âˆ‚Î¦/âˆ‚J| : {_rstr(R3_rng)}")
            if "smarr" in df: print(f"    Smarr |LHSâˆ’RHS|   : {_rstr(SM_rng)}")

        # Ensemble summary
        if "mc_stable" in df:
            print("\nEnsemble verdicts (simple sign rules):")
            print(f"  Microcanonical stable (+,+,+): {int(np.nansum(df['mc_stable']))}")
        if "gibbs_stable" in df and not np.all(pd.isna(df["gibbs_stable"])):
            print(f"  Gibbs/isopotential stable (+,+,+): {int(np.nansum(df['gibbs_stable']))}")

        # Boundary info
        print("\nTopology boundaries (sign-flip candidates):")
        print(f"  Boundary points: {df_boundary.shape[0]}")
        if df_boundary.shape[0]:
            sample = df_boundary.head(8).to_dict(orient="records")
            for r in sample:
                print(f"    (a*={r['a_star']:.2f}, q*={r['q_star']:.2f}) â€” flips in [{r['which']}]")

        # Artifacts
        print("\nArtifacts:")
        print(f"  - {out_grid_csv}")
        print(f"  - {out_bound_csv}")
        print(f"  - {out_summary_js}")
        print("="*110)
        print("ONE-LINE TAKEAWAY")
        print("Microcanonical vs isopotential stability patches and their sign-flip boundaries are now tabulated.")
        print("Smarr/Maxwell closures (if present) remain tight; boundary rows flag candidate ensemble-topology lines.")
        print("="*110)
    else:
        # Only M26 present â€” print a concise note and export M26 as portrait-ish data.
        out_passthru = "/content/M29_phase_portrait_from_M26.csv"
        df26.to_csv(out_passthru, index=False)
        print("="*110)
        print("MODULE 029: Only M26 sign map found; passed through as portrait data.")
        print(f"  Wrote: {out_passthru}")
        print("="*110)

# ==========================================================================================================
# MODULE 030: Release Packager + Headliner ASCII Summary â€” Kerrâ€“Newman Project (geom units, Colab-ready)
# ==========================================================================================================
# What this does:
#   â€¢ Scans /content for all module artifacts (CSV/JSON/TXT/LOG).
#   â€¢ Pulls integrity metrics from M28 outputs if present; otherwise derives soft metrics from receipts.
#   â€¢ Computes per-module file counts, numeric-record counts, and (when possible) Smarr/Maxwell pass counts.
#   â€¢ Renders a big ASCII "headliner" table to stdout and writes it to /content/M30_release_summary.txt.
#   â€¢ Produces a release ZIP at /content/M30_release_pack.zip with a MANIFEST.json and all artifacts.
#
# Safe: read-only over existing artifacts; creates only M30_* files.
# ==========================================================================================================

import os, re, glob, json, math, csv, io, zipfile, datetime
from collections import defaultdict, Counter

import numpy as np
import pandas as pd

# --------------------- Tunables ---------------------
ROOT     = "/content"
OUT_TXT  = os.path.join(ROOT, "M30_release_summary.txt")
OUT_ZIP  = os.path.join(ROOT, "M30_release_pack.zip")
MANIFEST = os.path.join(ROOT, "M30_MANIFEST.json")
TOL      = 1e-80  # pass tolerance for Smarr/Maxwell if we have columns

# --------------------- Helpers ---------------------
def extract_module_id(path: str) -> str:
    m = re.search(r"/(M\d+)[^/]*\.(csv|json|txt|log)$", path, re.IGNORECASE)
    return m.group(1) if m else "UNKNOWN"

def looks_residual(col: str) -> bool:
    return bool(re.search(r"(smarr|maxwell|res(id(ual)?)?|rel[\s_\-]?err|abs[\s_\-]?err|gap|dev|diff|mis|curv)", col, re.I))

def safe_to_float(x):
    try:
        return float(str(x).replace('âˆ’','-'))
    except:
        return np.nan

def compute_pass_counts(df: pd.DataFrame):
    """
    Attempt to compute Smarr/Maxwell passes from any recognizable columns.
    Returns tuple: (smarr_pass, smarr_total, maxwell_pass, maxwell_total)
    """
    smarr_cols   = [c for c in df.columns if re.search(r"smarr", c, re.I)]
    maxwell_cols = [c for c in df.columns if re.search(r"maxwell", c, re.I)]
    smarr_pass = smarr_total = maxwell_pass = maxwell_total = 0

    for c in smarr_cols:
        vals = pd.to_numeric(df[c].apply(safe_to_float), errors="coerce")
        smarr_total += vals.notna().sum()
        smarr_pass  += (vals.abs() < TOL).sum()
    for c in maxwell_cols:
        vals = pd.to_numeric(df[c].apply(safe_to_float), errors="coerce")
        maxwell_total += vals.notna().sum()
        # For a single Maxwell column that might be "max" residual, pass = value < tol
        maxwell_pass  += (vals.abs() < TOL).sum()
    return smarr_pass, smarr_total, maxwell_pass, maxwell_total

def ascii_table(headers, rows, pad=1):
    widths = [len(h) for h in headers]
    for r in rows:
        for i,cell in enumerate(r):
            widths[i] = max(widths[i], len(str(cell)))
    def line(sep_left="+", sep_mid="+", sep_right="+", fill="-"):
        return sep_left + sep_mid.join(fill*(w+2*pad) for w in widths) + sep_right
    def fmt_row(cells):
        return "| " + " | ".join(str(cells[i]).ljust(widths[i]) for i in range(len(headers))) + " |"
    out = []
    out.append(line())
    out.append(fmt_row(headers))
    out.append(line("+","+","+","="))
    for r in rows:
        out.append(fmt_row(r))
    out.append(line())
    return "\n".join(out)

# --------------------- Scan artifacts ---------------------
paths = []
for g in ("*.csv","*.json","*.txt","*.log"):
    paths.extend(glob.glob(os.path.join(ROOT, g)))
paths = sorted(set(paths))

modules = defaultdict(lambda: {
    "files": [],
    "n_numeric_rows": 0,
    "ledger_score": None,
    "q_median": None,
    "smarr_pass": 0,
    "smarr_total": 0,
    "maxwell_pass": 0,
    "maxwell_total": 0
})

# Read M28 integrity if present
m28_mod_csv = os.path.join(ROOT, "M28_module_integrity.csv")
m28_summary = os.path.join(ROOT, "M28_meta_summary.json")
M28 = {}
if os.path.exists(m28_mod_csv):
    try:
        df28 = pd.read_csv(m28_mod_csv)
        for _,row in df28.iterrows():
            mid = str(row.get("module","UNKNOWN"))
            M28[mid] = {
                "ledger_score": safe_to_float(row.get("ledger_score", np.nan)),
                "q_median": safe_to_float(row.get("q_median", np.nan)),
                "n_quality": int(row.get("n_quality", 0))
            }
    except Exception:
        pass

unified_score = None
if os.path.exists(m28_summary):
    try:
        with open(m28_summary,"r") as f:
            js = json.load(f)
        unified_score = js.get("unified_ledger_score", None)
    except Exception:
        pass

# Aggregate per module
for p in paths:
    mod = extract_module_id(p)
    modules[mod]["files"].append(p)
    if p.lower().endswith(".csv"):
        try:
            df = pd.read_csv(p)
            # Numeric-ish residual columns
            num_cols = [c for c in df.columns if df[c].dtype != object or looks_residual(str(c))]
            modules[mod]["n_numeric_rows"] += int(sum(pd.to_numeric(df[c], errors="coerce").notna().sum() for c in num_cols))
            s_pass, s_tot, m_pass, m_tot = compute_pass_counts(df)
            modules[mod]["smarr_pass"]   += int(s_pass)
            modules[mod]["smarr_total"]  += int(s_tot)
            modules[mod]["maxwell_pass"] += int(m_pass)
            modules[mod]["maxwell_total"]+= int(m_tot)
        except Exception:
            # skip unreadable CSVs
            pass

# Overlay M28 integrity where available
for mid, rec in modules.items():
    if mid in M28:
        rec["ledger_score"] = M28[mid]["ledger_score"]
        rec["q_median"]     = M28[mid]["q_median"]

# Build table rows
def fmt_pass(p, t):
    return "-" if t == 0 else f"{p}/{t}"

rows = []
for mid in sorted(modules.keys(), key=lambda s: (s=="UNKNOWN", s)):
    rec = modules[mid]
    files = len(rec["files"])
    nrows = rec["n_numeric_rows"]
    score = rec["ledger_score"]
    qmed  = rec["q_median"]
    spass = fmt_pass(rec["smarr_pass"], rec["smarr_total"])
    mpass = fmt_pass(rec["maxwell_pass"], rec["maxwell_total"])
    rows.append([
        mid,
        f"{files}",
        f"{nrows}",
        ("-" if score is None or math.isnan(score) else f"{score:6.2f}"),
        ("-" if qmed  is None or math.isnan(qmed)  else f"{qmed:6.1f}"),
        spass,
        mpass
    ])

headers = ["Module", "Files", "Numeric vals", "Ledger", "q_med", "Smarr PASS", "Maxwell PASS"]

banner = []
banner.append("="*118)
banner.append("MODULE 030: Release Packager + Headliner ASCII Summary")
banner.append("="*118)
banner.append(f"Scan root: {ROOT}")
banner.append(f"Artifacts found: {len(paths)}  |  Modules: {len(modules)}")
if unified_score is not None and not (isinstance(unified_score,float) and math.isnan(unified_score)):
    banner.append(f"Unified Ledger Score (from M28): {float(unified_score):.3f}")
banner.append("")

table = ascii_table(headers, rows)

# Write outputs
with open(OUT_TXT, "w") as f:
    f.write("\n".join(banner))
    f.write("\n")
    f.write(table)
    f.write("\n")

# Build manifest
manifest = {
    "generated_at_utc": datetime.datetime.utcnow().isoformat() + "Z",
    "root": ROOT,
    "modules": {
        mid: {
            "files": sorted([os.path.basename(x) for x in rec["files"]]),
            "file_count": len(rec["files"]),
            "numeric_values": rec["n_numeric_rows"],
            "ledger_score": None if (rec["ledger_score"] is None or (isinstance(rec["ledger_score"], float) and math.isnan(rec["ledger_score"]))) else float(rec["ledger_score"]),
            "q_median": None if (rec["q_median"] is None or (isinstance(rec["q_median"], float) and math.isnan(rec["q_median"]))) else float(rec["q_median"]),
            "smarr_pass": rec["smarr_pass"],
            "smarr_total": rec["smarr_total"],
            "maxwell_pass": rec["maxwell_pass"],
            "maxwell_total": rec["maxwell_total"],
        } for mid, rec in modules.items()
    },
    "unified_ledger_score": None if (unified_score is None or (isinstance(unified_score, float) and math.isnan(unified_score))) else float(unified_score),
    "summary_files": {
        "ascii_summary": OUT_TXT,
        "manifest": MANIFEST,
        "zip": OUT_ZIP
    }
}
with open(MANIFEST, "w") as f:
    json.dump(manifest, f, indent=2)

# Build zip pack
with zipfile.ZipFile(OUT_ZIP, "w", compression=zipfile.ZIP_DEFLATED) as z:
    # include all module artifacts
    for p in paths:
        arc = os.path.basename(p)
        z.write(p, arc)
    # include M30 outputs
    z.write(OUT_TXT, os.path.basename(OUT_TXT))
    z.write(MANIFEST, os.path.basename(MANIFEST))

# Print headliner to console
print("\n".join(banner))
print(table)
print("\nArtifacts written:")
print(f"  - {OUT_TXT}")
print(f"  - {MANIFEST}")
print(f"  - {OUT_ZIP}")
# ==========================================================================================================

# -*- coding: utf-8 -*-
"""Blind Monks V3.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1Rk-Z4zBxid9b6vxn2V3hPnuGoLMR9l3k
"""

# =============================================================================
# PHASE2_EW_LOG_LATTICE_NULLSCAN_v1
#
#   Phase 2, Test 1:
#     - Ignore DNA moduli and p-encoding.
#     - Use raw EW dimensionless constants.
#     - Ask if their log10 values lie unusually close to a 1D lattice:
#
#         y_i = log10(x_i)  ≈  k_i * Δ      (k_i integer, single Δ for all i)
#
#     - Compare the best-fit lattice RMS error to a null where 19 points
#       are drawn uniformly in the same log10 range.
#
#   Outputs:
#     1) Table of EW constants and log10 values.
#     2) Best-fit Δ for real data and RMS error.
#     3) The integer k_i for each constant under that best-fit lattice.
#     4) Null distribution stats for RMS (mean, std, percentiles).
#     5) z-score and empirical p-value P_null(RMS <= RMS_real).
#
#   Interpretation:
#     - Small RMS_real = more lattice-like.
#     - p-value is the fraction of nulls that are *as lattice-like or more*
#       than the real data.
# =============================================================================

import math, random, statistics

def _phase2_ew_get_data():
    """
    Hard-code the 19 EW constants as (name, value).

    Values taken from earlier EW modules (you saw them printed already).
    """
    data = [
        ("CKM_s12",          0.224299998),
        ("CKM_s13",          0.003940000),
        ("CKM_s23",          0.042200001),
        ("CKM_delta_over_pi",0.381971862),
        ("alpha",            0.007297353),
        ("alpha_s_MZ",       0.117899999),
        ("sin2_thetaW",      0.231220001),
        ("MW_over_v",        0.326452417),
        ("MZ_over_v",        0.370350617),
        ("MH_over_v",        0.508692139),
        ("me_over_v",        0.000002073),
        ("mmu_over_v",       0.000428937),
        ("mtau_over_v",      0.007214707),
        ("mb_over_v",        0.016981511),
        ("mc_over_v",        0.005157839),
        ("mt_over_v",        0.701365635),
        ("md_over_v",        0.000018960),
        ("ms_over_v",        0.000377683),
        ("mu_over_v",        0.000008773),
    ]
    return data


def _compute_rms_for_delta(y_list, delta):
    """Given y_i and a candidate spacing delta, snap to nearest k*delta and return RMS error."""
    s2 = 0.0
    n = len(y_list)
    for y in y_list:
        k = round(y / delta)
        approx = k * delta
        err = y - approx
        s2 += err * err
    return math.sqrt(s2 / n)


def _best_lattice_fit(y_list,
                      delta_min=0.02,
                      delta_max=0.8,
                      coarse_step=0.01,
                      refine_step=0.001,
                      refine_half_width=0.03):
    """
    Find best delta for y_i ≈ k_i * delta:
      - coarse scan over [delta_min, delta_max] with coarse_step
      - refine around coarse best with refine_step in ±refine_half_width
    Returns (best_delta, best_rms).
    """
    best_delta = None
    best_rms = float("inf")

    # Coarse scan
    delta = delta_min
    while delta <= delta_max + 1e-12:
        rms = _compute_rms_for_delta(y_list, delta)
        if rms < best_rms:
            best_rms = rms
            best_delta = delta
        delta += coarse_step

    # Refine scan around coarse best
    low  = max(delta_min, best_delta - refine_half_width)
    high = min(delta_max, best_delta + refine_half_width)
    delta = low
    while delta <= high + 1e-12:
        rms = _compute_rms_for_delta(y_list, delta)
        if rms < best_rms:
            best_rms = rms
            best_delta = delta
        delta += refine_step

    return best_delta, best_rms


def run_phase2_ew_log_lattice_nullscan(num_null=2000, seed=20251118):
    print("=" * 90)
    print("PHASE2_EW_LOG_LATTICE_NULLSCAN_v1 — 1D log-lattice test for EW constants")
    print("=" * 90)

    random.seed(seed)

    # -------------------------------------------------------------------------
    # 1. Load EW data and compute log10
    # -------------------------------------------------------------------------
    data = _phase2_ew_get_data()
    names = [name for (name, _) in data]
    vals  = [val  for (_, val)  in data]

    y_real = [math.log10(v) for v in vals]
    y_min = min(y_real)
    y_max = max(y_real)

    print("[EW data]")
    print(f"  number of params       : {len(data)}")
    print(f"  value range            : [{min(vals):.3e}, {max(vals):.3e}]")
    print(f"  log10 range            : [{y_min:.3f}, {y_max:.3f}]")
    print()
    print("  name                value           log10(value)")
    print("  ------------------- --------------  ------------")
    for name, v, y in zip(names, vals, y_real):
        print(f"  {name:19s} {v:14.9e}  {y:12.6f}")
    print()

    # -------------------------------------------------------------------------
    # 2. Best log-lattice fit for real data
    # -------------------------------------------------------------------------
    print("[Real data: best log-lattice fit]")
    delta_real, rms_real = _best_lattice_fit(y_real)
    print(f"  best Δ (spacing)      : {delta_real:.6f}")
    print(f"  best RMS error        : {rms_real:.6e}")
    print()

    # Compute k_i for the best Δ
    ks_real = [round(y / delta_real) for y in y_real]
    approx_y = [k * delta_real for k in ks_real]
    abs_errors = [abs(y - ya) for y, ya in zip(y_real, approx_y)]

    print("  Per-parameter lattice coordinates (real data)")
    print("  name                k_i    y_i        k_i*Δ       |y_i - k_i*Δ|")
    print("  ------------------- ---- ---------- ----------  -------------")
    for name, y, k, ya, err in zip(names, y_real, ks_real, approx_y, abs_errors):
        print(f"  {name:19s} {k:4d} {y:10.6f} {ya:10.6f}  {err:13.6e}")
    print()

    # -------------------------------------------------------------------------
    # 3. Null ensemble: random y in [y_min, y_max]
    # -------------------------------------------------------------------------
    print(f"[Null ensemble] Generating {num_null} random universes...")
    null_rms = []

    for _ in range(num_null):
        # Draw 19 random log10 values uniform in same range
        y_null = [random.uniform(y_min, y_max) for _ in y_real]
        _, rms = _best_lattice_fit(y_null)
        null_rms.append(rms)

    # Stats
    mn = min(null_rms)
    mx = max(null_rms)
    q25, q50, q75 = statistics.quantiles(null_rms, n=4)
    mean_null = statistics.mean(null_rms)
    std_null  = statistics.pstdev(null_rms) if len(null_rms) > 1 else 0.0

    if std_null > 0:
        z_score = (rms_real - mean_null) / std_null
    else:
        z_score = float("nan")

    # Empirical p-value: fraction of null RMS <= real RMS (more lattice-like)
    better_or_equal = sum(1 for r in null_rms if r <= rms_real)
    p_emp = better_or_equal / float(num_null)

    print()
    print("[Null RMS stats — log-lattice fit]")
    print(f"  null RMS min / max     : {mn:.6e} / {mx:.6e}")
    print(f"  null RMS 25%/50%/75%   : {q25:.6e} / {q50:.6e} / {q75:.6e}")
    print(f"  null RMS mean / std    : {mean_null:.6e} / {std_null:.6e}")
    print()
    print("[Significance of log-lattice compression]")
    print(f"  real best RMS          : {rms_real:.6e}")
    print(f"  z(real vs null mean)   : {z_score:6.2f}")
    print(f"  P_null(RMS <= real)    : {p_emp:.6f}")
    print()
    print("=" * 90)
    print("PHASE2_EW_LOG_LATTICE_NULLSCAN_v1 complete.")
    print("=" * 90)


if __name__ == "__main__":
    run_phase2_ew_log_lattice_nullscan(
        num_null=2000,
        seed=20251118
    )

# =============================================================================
# PHASE2_EW_YUKAWA_LOG_LATTICE_NULLSCAN_v1
#
#   Phase 2, Test 2:
#     - Restrict to the 9 Yukawa / mass ratios:
#         me_over_v, mmu_over_v, mtau_over_v,
#         mb_over_v, mc_over_v, mt_over_v,
#         md_over_v, ms_over_v, mu_over_v
#     - In log10 space, test whether they lie unusually close to a
#       single 1D lattice:
#
#           y_i = log10(x_i)  ≈  k_i * Δ
#
#       compared to random sets of 9 points in the same log10 range.
#
#   Requirements:
#     - The previous Phase 2 module has already defined:
#         * _phase2_ew_get_data()
#         * _compute_rms_for_delta()
#         * _best_lattice_fit()
#   If not, re-run PHASE2_EW_LOG_LATTICE_NULLSCAN_v1 first.
# =============================================================================

import math, random, statistics

def run_phase2_ew_yukawa_log_lattice_nullscan(num_null=5000, seed=20251119):
    print("=" * 90)
    print("PHASE2_EW_YUKAWA_LOG_LATTICE_NULLSCAN_v1 — Yukawa-only log-lattice test")
    print("=" * 90)

    random.seed(seed)

    # -------------------------------------------------------------------------
    # 1. Load full EW data, extract Yukawa subset
    # -------------------------------------------------------------------------
    all_data = _phase2_ew_get_data()
    name_to_val = {name: val for (name, val) in all_data}

    yuk_names = [
        "me_over_v",
        "mmu_over_v",
        "mtau_over_v",
        "mb_over_v",
        "mc_over_v",
        "mt_over_v",
        "md_over_v",
        "ms_over_v",
        "mu_over_v",
    ]

    # Ensure all are present
    missing = [n for n in yuk_names if n not in name_to_val]
    if missing:
        raise SystemExit(f"Missing Yukawa entries in data: {missing}")

    vals = [name_to_val[n] for n in yuk_names]
    y_real = [math.log10(v) for v in vals]

    y_min = min(y_real)
    y_max = max(y_real)

    print("[Yukawa subset data]")
    print(f"  number of Yukawas      : {len(yuk_names)}")
    print(f"  value range            : [{min(vals):.3e}, {max(vals):.3e}]")
    print(f"  log10 range            : [{y_min:.3f}, {y_max:.3f}]")
    print()
    print("  name          value           log10(value)")
    print("  ------------ --------------  ------------")
    for n, v, y in zip(yuk_names, vals, y_real):
        print(f"  {n:12s} {v:14.9e}  {y:12.6f}")
    print()

    # -------------------------------------------------------------------------
    # 2. Best log-lattice fit for Yukawas
    # -------------------------------------------------------------------------
    print("[Real Yukawas: best log-lattice fit]")
    delta_real, rms_real = _best_lattice_fit(y_real)
    print(f"  best Δ (spacing)      : {delta_real:.6f}")
    print(f"  best RMS error        : {rms_real:.6e}")
    print()

    ks_real = [round(y / delta_real) for y in y_real]
    approx_y = [k * delta_real for k in ks_real]
    abs_errors = [abs(y - ya) for y, ya in zip(y_real, approx_y)]

    print("  Per-parameter lattice coordinates (Yukawas)")
    print("  name          k_i    y_i        k_i*Δ       |y_i - k_i*Δ|")
    print("  ------------ ---- ---------- ----------  -------------")
    for n, y, k, ya, err in zip(yuk_names, y_real, ks_real, approx_y, abs_errors):
        print(f"  {n:12s} {k:4d} {y:10.6f} {ya:10.6f}  {err:13.6e}")
    print()

    # -------------------------------------------------------------------------
    # 3. Null ensemble: random y in [y_min, y_max]
    # -------------------------------------------------------------------------
    print(f"[Null ensemble] Generating {num_null} random Yukawa universes...")
    null_rms = []
    for _ in range(num_null):
        y_null = [random.uniform(y_min, y_max) for _ in y_real]
        _, rms = _best_lattice_fit(y_null)
        null_rms.append(rms)

    mn = min(null_rms)
    mx = max(null_rms)
    q25, q50, q75 = statistics.quantiles(null_rms, n=4)
    mean_null = statistics.mean(null_rms)
    std_null  = statistics.pstdev(null_rms) if len(null_rms) > 1 else 0.0

    if std_null > 0:
        z_score = (rms_real - mean_null) / std_null
    else:
        z_score = float("nan")

    better_or_equal = sum(1 for r in null_rms if r <= rms_real)
    p_emp = better_or_equal / float(num_null)

    print()
    print("[Null RMS stats — Yukawa log-lattice fit]")
    print(f"  null RMS min / max     : {mn:.6e} / {mx:.6e}")
    print(f"  null RMS 25%/50%/75%   : {q25:.6e} / {q50:.6e} / {q75:.6e}")
    print(f"  null RMS mean / std    : {mean_null:.6e} / {std_null:.6e}")
    print()
    print("[Significance of Yukawa log-lattice compression]")
    print(f"  real best RMS          : {rms_real:.6e}")
    print(f"  z(real vs null mean)   : {z_score:6.2f}")
    print(f"  P_null(RMS <= real)    : {p_emp:.6f}")
    print()
    print("=" * 90)
    print("PHASE2_EW_YUKAWA_LOG_LATTICE_NULLSCAN_v1 complete.")
    print("=" * 90)


if __name__ == "__main__":
    run_phase2_ew_yukawa_log_lattice_nullscan(
        num_null=5000,
        seed=20251119
    )

# =============================================================================
# PHASE2_EW_LOG_PARTIAL_LATTICE_NULLSCAN_v1
#
#   Phase 2, Test 3:
#     - Look for a "partial" log-lattice among the 19 EW constants:
#         y_i = log10(x_i)
#       We scan over spacings Δ and count how many y_i land within a
#       small tolerance ε of some lattice tick k * Δ.
#
#     - For real data:
#         * For each Δ in [delta_min, delta_max] with step delta_step:
#             - inliers(Δ) = #{ i : |y_i - round(y_i/Δ)*Δ| <= epsilon }
#         * best_inliers_real = max_Δ inliers(Δ)
#         * record Δ_real_best and which points are inliers there.
#
#     - For the null:
#         * Generate many universes with 19 points y drawn uniform in
#           [min(y_real), max(y_real)].
#         * Apply the same Δ-scan procedure.
#         * Get the distribution of best_inliers_null.
#
#     - Significance:
#         * p-value = P_null(best_inliers >= best_inliers_real)
#
#   Requirements:
#     - _phase2_ew_get_data() must already be defined
#       (from PHASE2_EW_LOG_LATTICE_NULLSCAN_v1).
# =============================================================================

import math, random, statistics

def run_phase2_ew_log_partial_lattice_nullscan(
    delta_min=0.01,
    delta_max=0.10,
    delta_step=0.001,
    epsilon=0.010,
    num_null=5000,
    seed=20251120,
):
    print("=" * 90)
    print("PHASE2_EW_LOG_PARTIAL_LATTICE_NULLSCAN_v1 — partial log-lattice test")
    print("=" * 90)

    random.seed(seed)

    # -------------------------------------------------------------------------
    # 1. Load EW data and compute log10
    # -------------------------------------------------------------------------
    data = _phase2_ew_get_data()
    names = [name for (name, _) in data]
    vals  = [val  for (_, val)  in data]
    y_real = [math.log10(v) for v in vals]

    y_min = min(y_real)
    y_max = max(y_real)

    print("[EW data]")
    print(f"  number of params       : {len(data)}")
    print(f"  log10 range            : [{y_min:.3f}, {y_max:.3f}]")
    print(f"  Δ scan range           : [{delta_min:.3f}, {delta_max:.3f}]")
    print(f"  Δ step                 : {delta_step:.3f}")
    print(f"  inlier tolerance ε     : {epsilon:.3f} (log10 units)")
    print()

    # Precompute candidate Δ values
    num_steps = int(round((delta_max - delta_min) / delta_step)) + 1
    deltas = [delta_min + i * delta_step for i in range(num_steps)]

    # -------------------------------------------------------------------------
    # 2. Real data: find best partial lattice
    # -------------------------------------------------------------------------
    print("[Real data: partial lattice scan]")

    best_inliers_real = -1
    best_delta_real = None
    best_inlier_mask_real = None

    for d in deltas:
        current_mask = []
        for y in y_real:
            k = round(y / d)
            approx = k * d
            err = abs(y - approx)
            current_mask.append(err <= epsilon)

        count_inliers = sum(current_mask)
        if count_inliers > best_inliers_real:
            best_inliers_real = count_inliers
            best_delta_real = d
            best_inlier_mask_real = current_mask

    print(f"  best Δ (spacing)       : {best_delta_real:.6f}")
    print(f"  best inlier count      : {best_inliers_real} / {len(y_real)}")
    print()

    # List which constants are on the best partial lattice
    print("  Inliers on best partial lattice (real data):")
    print("  name                y_i        k_i       k_i*Δ      |y_i - k_i*Δ|")
    print("  ------------------- ---------- -------- ----------  ------------")
    for name, y, is_in in zip(names, y_real, best_inlier_mask_real):
        if not is_in:
            continue
        k = round(y / best_delta_real)
        approx = k * best_delta_real
        err = abs(y - approx)
        print(f"  {name:19s} {y:10.6f} {k:8d} {approx:10.6f}  {err:12.6e}")
    print()

    # -------------------------------------------------------------------------
    # 3. Null ensemble: same procedure on random sets
    # -------------------------------------------------------------------------
    print(f"[Null ensemble] Generating {num_null} random universes...")
    best_inliers_null = []

    for _ in range(num_null):
        # Draw 19 random y in the same log10 range
        y_null = [random.uniform(y_min, y_max) for _ in y_real]

        local_best = -1
        for d in deltas:
            count_inliers = 0
            for y in y_null:
                k = round(y / d)
                approx = k * d
                err = abs(y - approx)
                if err <= epsilon:
                    count_inliers += 1
            if count_inliers > local_best:
                local_best = count_inliers

        best_inliers_null.append(local_best)

    # Stats on best_inliers_null
    mn = min(best_inliers_null)
    mx = max(best_inliers_null)
    q25, q50, q75 = statistics.quantiles(best_inliers_null, n=4)
    mean_null = statistics.mean(best_inliers_null)
    std_null  = statistics.pstdev(best_inliers_null) if len(best_inliers_null) > 1 else 0.0

    # Empirical p-value: probability null best_inliers >= real best_inliers
    num_ge = sum(1 for v in best_inliers_null if v >= best_inliers_real)
    p_emp = num_ge / float(num_null)

    print("[Null stats — best partial-lattice inlier count]")
    print(f"  best_inliers min / max : {mn} / {mx}")
    print(f"  best_inliers 25%/50%/75%: {q25} / {q50} / {q75}")
    print(f"  best_inliers mean / std: {mean_null:.3f} / {std_null:.3f}")
    print()
    print("[Significance of partial lattice]")
    print(f"  real best_inliers      : {best_inliers_real}")
    print(f"  P_null(best_inliers >= real) = {p_emp:.6f}")
    print()
    print("=" * 90)
    print("PHASE2_EW_LOG_PARTIAL_LATTICE_NULLSCAN_v1 complete.")
    print("=" * 90)


if __name__ == "__main__":
    run_phase2_ew_log_partial_lattice_nullscan(
        delta_min=0.01,
        delta_max=0.10,
        delta_step=0.001,
        epsilon=0.010,
        num_null=5000,
        seed=20251120,
    )

# =============================================================================
# PHASE2_YUKAWA_INTREL_NULLSCAN_v1c
#
#   Fixed + ASCII-safe version of the Yukawa integer-relation null scan.
#
#   Phase 2, Test 4:
#     - Search for approximate integer relations among the 9 Yukawas:
#
#         z_i = log10(Yukawa_i)
#         Relation: sum_j n_j * z_{i_j} ≈ 0
#
#       with:
#         * triples of Yukawas (i,j,k)
#         * integer coefficients n_j in [-C, +C], C=4
#         * at least 2 non-zero coefficients
#         * gcd(|n_j|) = 1 (primitive relations)
#
#     - For the real Yukawa set:
#         * scan all candidate relations
#         * record the smallest residual |sum n_j * z_{i_j}| = R_real_min
#         * print the top few relations
#
#     - For the null:
#         * generate num_null sets of 9 random logs uniform in [min(z_real), max(z_real)]
#         * for each, compute the minimal residual R_null_min over the same
#           candidate relation family
#         * compare R_real_min to distribution of R_null_min
#
#   Requirements:
#     - _phase2_ew_get_data() must already be defined (from Phase 2 EW modules).
# =============================================================================

import math, random, statistics
from itertools import combinations
from math import gcd

def _yukawa_get_logs_from_phase2_intrel():
    """Extract the 9 Yukawa logs from _phase2_ew_get_data()."""
    all_data = _phase2_ew_get_data()
    name_to_val = {name: val for (name, val) in all_data}

    yuk_names = [
        "me_over_v",
        "mmu_over_v",
        "mtau_over_v",
        "mb_over_v",
        "mc_over_v",
        "mt_over_v",
        "md_over_v",
        "ms_over_v",
        "mu_over_v",
    ]
    vals = [name_to_val[n] for n in yuk_names]
    logs = [math.log10(v) for v in vals]
    return yuk_names, vals, logs


def _gcd3_intrel(a, b, c):
    """GCD of three integers (nonnegative)."""
    return gcd(gcd(abs(a), abs(b)), abs(c))


def run_phase2_yukawa_intrel_nullscan_v1c(
    C=4,
    num_null=2000,
    seed=20251121
):
    print("=" * 90)
    print("PHASE2_YUKAWA_INTREL_NULLSCAN_v1c — integer relations among Yukawas")
    print("=" * 90)

    random.seed(seed)

    # -------------------------------------------------------------------------
    # 1. Get Yukawa logs and set up candidate relations
    # -------------------------------------------------------------------------
    yuk_names, yuk_vals, yuk_logs = _yukawa_get_logs_from_phase2_intrel()
    N = len(yuk_names)

    print("[Yukawa data]")
    print(f"  number of Yukawas      : {N}")
    print(f"  value range            : [{min(yuk_vals):.3e}, {max(yuk_vals):.3e}]")
    print(f"  log10 range            : [{min(yuk_logs):.3f}, {max(yuk_logs):.3f}]")
    print()
    print("  name          value           log10(value)")
    print("  ------------ --------------  ------------")
    for n, v, z in zip(yuk_names, yuk_vals, yuk_logs):
        print(f"  {n:12s} {v:14.9e}  {z:12.6f}")
    print()

    # Build all candidate relations over triples with coefficients in [-C..C]
    idx_triples = list(combinations(range(N), 3))
    coeff_range = range(-C, C + 1)

    candidate_relations = []  # list of (idxs_tuple, coeffs_tuple)

    for i, j, k in idx_triples:
        for a in coeff_range:
            for b in coeff_range:
                for c in coeff_range:
                    if a == 0 and b == 0 and c == 0:
                        continue
                    # require at least two non-zero coefficients
                    nonzero_count = (a != 0) + (b != 0) + (c != 0)
                    if nonzero_count < 2:
                        continue
                    # primitive relation: gcd = 1
                    g = _gcd3_intrel(a, b, c)
                    if g != 1:
                        continue
                    candidate_relations.append(((i, j, k), (a, b, c)))

    print("[Candidate relation space]")
    print(f"  coefficient bound C    : {C}")
    print(f"  number of index triples: {len(idx_triples)}")
    print(f"  total candidate relations: {len(candidate_relations)}")
    print()

    # Helper to find best relation for a given set of logs
    def _best_relation_for_logs(logs):
        best_resid = float("inf")
        best_rel = None

        for (i, j, k), (a, b, c) in candidate_relations:
            s = a * logs[i] + b * logs[j] + c * logs[k]
            r = abs(s)
            if r < best_resid:
                best_resid = r
                best_rel = (i, j, k, a, b, c, s)

        return best_resid, best_rel

    # -------------------------------------------------------------------------
    # 2. Real data: best integer relation(s)
    # -------------------------------------------------------------------------
    print("[Real Yukawas: best integer relation search]")
    real_best_resid, best_rel = _best_relation_for_logs(yuk_logs)
    i, j, k, a, b, c, s = best_rel

    # Compute approximate multiplicative relation via logs
    prod_val = 10.0 ** s  # since s = sum n_i log10(y_i)

    print(f"  best residual |sum n_i log10(y_i)| : {real_best_resid:.6e}")
    print()
    print("  Best relation (real data):")
    print(f"    indices (i,j,k)         : ({i}, {j}, {k})")
    print(f"    names                   : ({yuk_names[i]}, {yuk_names[j]}, {yuk_names[k]})")
    print(f"    coeffs (a,b,c)          : ({a}, {b}, {c})")
    print(f"    sum n_i log10(y_i)      : {s:.6e}")
    print(f"    product approx 10^(sum n_i log10(y_i)) = {prod_val:.6e}")
    print()

    # Top 10 relations by residual
    print("  Top 10 relations (smallest residuals):")
    best_list = []  # (resid, (i,j,k,a,b,c,s,prod_val))
    for (ii, jj, kk), (aa, bb, cc) in candidate_relations:
        ss = aa * yuk_logs[ii] + bb * yuk_logs[jj] + cc * yuk_logs[kk]
        rr = abs(ss)
        pv = 10.0 ** ss
        best_list.append((rr, (ii, jj, kk, aa, bb, cc, ss, pv)))
    best_list.sort(key=lambda t: t[0])

    for rank, (rr, rel) in enumerate(best_list[:10], start=1):
        ii, jj, kk, aa, bb, cc, ss, pv = rel
        print(f"    #{rank:2d}: resid={rr:.6e}  "
              f"({yuk_names[ii]}, {yuk_names[jj]}, {yuk_names[kk]}); "
              f"(a,b,c)=({aa},{bb},{cc});  prod≈{pv:.6e}")
    print()

    # -------------------------------------------------------------------------
    # 3. Null ensemble: random Yukawa logs with same range
    # -------------------------------------------------------------------------
    print(f"[Null ensemble] Generating {num_null} random universes...")
    zmin, zmax = min(yuk_logs), max(yuk_logs)
    null_best_resids = []

    for _ in range(num_null):
        # random logs uniform over the same range
        logs_null = [random.uniform(zmin, zmax) for _ in yuk_logs]
        best_resid_null, _ = _best_relation_for_logs(logs_null)
        null_best_resids.append(best_resid_null)

    # Stats on null best residuals
    nb = null_best_resids
    mn = min(nb)
    mx = max(nb)
    q25, q50, q75 = statistics.quantiles(nb, n=4)
    mean_null = statistics.mean(nb)
    std_null  = statistics.pstdev(nb) if len(nb) > 1 else 0.0

    if std_null > 0:
        z_score = (real_best_resid - mean_null) / std_null
    else:
        z_score = float("nan")

    # Empirical p-value: P_null(best_resid <= real_best_resid)
    less_or_equal = sum(1 for r in nb if r <= real_best_resid)
    p_emp = less_or_equal / float(num_null)

    print()
    print("[Null stats — best integer-relation residual]")
    print(f"  null best_resid min / max: {mn:.6e} / {mx:.6e}")
    print(f"  null best_resid 25%/50%/75%: {q25:.6e} / {q50:.6e} / {q75:.6e}")
    print(f"  null best_resid mean / std: {mean_null:.6e} / {std_null:.6e}")
    print()
    print("[Significance of Yukawa integer-relation compression]")
    print(f"  real best_resid          : {real_best_resid:.6e}")
    print(f"  z(real vs null mean)     : {z_score:6.2f}")
    print(f"  P_null(best_resid <= real) = {p_emp:.6f}")
    print()
    print("=" * 90)
    print("PHASE2_YUKAWA_INTREL_NULLSCAN_v1c complete.")
    print("=" * 90)


if __name__ == "__main__":
    run_phase2_yukawa_intrel_nullscan_v1c(
        C=4,
        num_null=2000,
        seed=20251121,
    )

# =============================================================================
# PHASE2_YUKAWA_INTREL_JITTERNULL_v1
#
#   Stress test for the Yukawa integer relation:
#     - Rebuilds the same candidate relation space as v1c:
#         * triples of Yukawas
#         * integer coefficients in [-C..C], C=4
#         * at least 2 non-zero, gcd=1
#     - Recomputes the best relation for the real Yukawas (sanity check).
#     - Defines a "jitter null":
#         * For each null universe:
#             z_i(null) = z_i(real) + delta_i
#             with delta_i ~ Uniform[-h, +h] in log10 space.
#         * Then runs the same full search for best residual.
#
#     - Reports:
#         * Real best residual
#         * Null distribution stats for best residual under jitter
#         * p-value P_null(best_resid <= real_best_resid)
#
#   Requirements:
#     - _phase2_ew_get_data() must exist (from Phase 2 EW modules).
# =============================================================================

import math, random, statistics
from itertools import combinations
from math import gcd

def _yukawa_get_logs_for_jitter():
    """Extract the 9 Yukawa logs from _phase2_ew_get_data()."""
    all_data = _phase2_ew_get_data()
    name_to_val = {name: val for (name, val) in all_data}

    yuk_names = [
        "me_over_v",
        "mmu_over_v",
        "mtau_over_v",
        "mb_over_v",
        "mc_over_v",
        "mt_over_v",
        "md_over_v",
        "ms_over_v",
        "mu_over_v",
    ]
    vals = [name_to_val[n] for n in yuk_names]
    logs = [math.log10(v) for v in vals]
    return yuk_names, vals, logs


def _gcd3_jitter(a, b, c):
    """GCD of three integers (nonnegative)."""
    return gcd(gcd(abs(a), abs(b)), abs(c))


def run_phase2_yukawa_intrel_jitternull_v1(
    C=4,
    num_null=2000,
    jitter_halfwidth=0.5,  # in log10 units (~factor of 3)
    seed=20251122
):
    print("=" * 90)
    print("PHASE2_YUKAWA_INTREL_JITTERNULL_v1 — jitter null for Yukawa int-relations")
    print("=" * 90)

    random.seed(seed)

    # -------------------------------------------------------------------------
    # 1. Get Yukawa logs and candidate relations
    # -------------------------------------------------------------------------
    yuk_names, yuk_vals, yuk_logs = _yukawa_get_logs_for_jitter()
    N = len(yuk_names)

    print("[Yukawa data]")
    print(f"  number of Yukawas      : {N}")
    print(f"  log10 range (real)     : [{min(yuk_logs):.3f}, {max(yuk_logs):.3f}]")
    print(f"  jitter halfwidth (log10): {jitter_halfwidth:.3f}")
    print()
    print("  name          log10(value)")
    print("  ------------ ------------")
    for n, z in zip(yuk_names, yuk_logs):
        print(f"  {n:12s} {z:12.6f}")
    print()

    # Build candidate relations (same rules as v1c)
    idx_triples = list(combinations(range(N), 3))
    coeff_range = range(-C, C + 1)

    candidate_relations = []
    for i, j, k in idx_triples:
        for a in coeff_range:
            for b in coeff_range:
                for c in coeff_range:
                    if a == 0 and b == 0 and c == 0:
                        continue
                    nonzero_count = (a != 0) + (b != 0) + (c != 0)
                    if nonzero_count < 2:
                        continue
                    g = _gcd3_jitter(a, b, c)
                    if g != 1:
                        continue
                    candidate_relations.append(((i, j, k), (a, b, c)))

    print("[Candidate relation space]")
    print(f"  coefficient bound C    : {C}")
    print(f"  number of index triples: {len(idx_triples)}")
    print(f"  total candidate relations: {len(candidate_relations)}")
    print()

    def _best_relation_for_logs(logs):
        best_resid = float("inf")
        best_rel = None
        for (i, j, k), (a, b, c) in candidate_relations:
            s = a * logs[i] + b * logs[j] + c * logs[k]
            r = abs(s)
            if r < best_resid:
                best_resid = r
                best_rel = (i, j, k, a, b, c, s)
        return best_resid, best_rel

    # -------------------------------------------------------------------------
    # 2. Real data sanity check
    # -------------------------------------------------------------------------
    print("[Real Yukawas: best integer relation under this candidate set]")
    real_best_resid, best_rel = _best_relation_for_logs(yuk_logs)
    i, j, k, a, b, c, s = best_rel
    prod_val = 10.0 ** s

    print(f"  best residual |sum n_i log10(y_i)| : {real_best_resid:.6e}")
    print("  Best relation (real data):")
    print(f"    indices (i,j,k)         : ({i}, {j}, {k})")
    print(f"    names                   : ({yuk_names[i]}, {yuk_names[j]}, {yuk_names[k]})")
    print(f"    coeffs (a,b,c)          : ({a}, {b}, {c})")
    print(f"    sum n_i log10(y_i)      : {s:.6e}")
    print(f"    product approx 10^(sum) : {prod_val:.6e}")
    print()

    # -------------------------------------------------------------------------
    # 3. Jitter null ensemble
    # -------------------------------------------------------------------------
    print(f"[Jitter null ensemble] Generating {num_null} random universes...")
    null_best_resids = []

    for _ in range(num_null):
        # logs_null_i = logs_real_i + delta_i, with delta_i uniform in [-h, +h]
        logs_null = [
            z + random.uniform(-jitter_halfwidth, jitter_halfwidth)
            for z in yuk_logs
        ]
        best_resid_null, _ = _best_relation_for_logs(logs_null)
        null_best_resids.append(best_resid_null)

    nb = null_best_resids
    mn = min(nb)
    mx = max(nb)
    q25, q50, q75 = statistics.quantiles(nb, n=4)
    mean_null = statistics.mean(nb)
    std_null  = statistics.pstdev(nb) if len(nb) > 1 else 0.0

    if std_null > 0:
        z_score = (real_best_resid - mean_null) / std_null
    else:
        z_score = float("nan")

    less_or_equal = sum(1 for r in nb if r <= real_best_resid)
    p_emp = less_or_equal / float(num_null)

    print()
    print("[Jitter-null stats — best integer-relation residual]")
    print(f"  null best_resid min / max: {mn:.6e} / {mx:.6e}")
    print(f"  null best_resid 25%/50%/75%: {q25:.6e} / {q50:.6e} / {q75:.6e}")
    print(f"  null best_resid mean / std: {mean_null:.6e} / {std_null:.6e}")
    print()
    print("[Significance under jitter null]")
    print(f"  real best_resid          : {real_best_resid:.6e}")
    print(f"  z(real vs null mean)     : {z_score:6.2f}")
    print(f"  P_null(best_resid <= real) = {p_emp:.6f}")
    print()
    print("=" * 90)
    print("PHASE2_YUKAWA_INTREL_JITTERNULL_v1 complete.")
    print("=" * 90)


if __name__ == "__main__":
    run_phase2_yukawa_intrel_jitternull_v1(
        C=4,
        num_null=2000,
        jitter_halfwidth=0.5,
        seed=20251122,
    )

# =============================================================================
# PHASE2_EW_PAIR_INTREL_NULLSCAN_v1
#
#   Phase 2, Test 5:
#     - Search for simple integer relations between PAIRS of the 19 EW constants:
#
#         z_i = log10(x_i)
#         Relation: a * z_i + b * z_j ≈ 0
#
#       with:
#         * all unordered pairs (i,j) from the 19 EW parameters
#         * integer coefficients a,b in [-C, +C], C=4
#         * both coefficients non-zero
#         * gcd(|a|,|b|) = 1 (primitive)
#
#     - For real data:
#         * scan all candidate relations
#         * record smallest residual |a z_i + b z_j|
#         * print best relation and top 10
#
#     - For null:
#         * jitter null:
#             z_i(null) = z_i(real) + delta_i
#             with delta_i ~ Uniform[-h, +h] in log10 space
#         * for each null universe, do the same scan
#         * compare real best residual to null distribution
#
#   Requirements:
#     - _phase2_ew_get_data() must already be defined.
# =============================================================================

import math, random, statistics
from itertools import combinations
from math import gcd

def _ew_get_logs_for_pairs():
    """Get names, values, and log10 values for all EW parameters."""
    all_data = _phase2_ew_get_data()
    names = [name for (name, _) in all_data]
    vals  = [val  for (_, val)  in all_data]
    logs  = [math.log10(v) for v in vals]
    return names, vals, logs


def _gcd2_pair(a, b):
    """GCD of two integers (nonnegative)."""
    return gcd(abs(a), abs(b))


def run_phase2_ew_pair_intrel_nullscan_v1(
    C=4,
    num_null=2000,
    jitter_halfwidth=0.5,  # in log10 (~factor ~3)
    seed=20251123
):
    print("=" * 90)
    print("PHASE2_EW_PAIR_INTREL_NULLSCAN_v1 — pairwise EW integer relations")
    print("=" * 90)

    random.seed(seed)

    # -------------------------------------------------------------------------
    # 1. Get EW data and logs
    # -------------------------------------------------------------------------
    names, vals, logs = _ew_get_logs_for_pairs()
    N = len(names)

    print("[EW data]")
    print(f"  number of parameters    : {N}")
    print(f"  log10 range (real)      : [{min(logs):.3f}, {max(logs):.3f}]")
    print(f"  jitter halfwidth (log10): {jitter_halfwidth:.3f}")
    print()
    print("  name                 value           log10(value)")
    print("  ------------------- --------------  ------------")
    for n, v, z in zip(names, vals, logs):
        print(f"  {n:19s} {v:14.9e}  {z:12.6f}")
    print()

    # -------------------------------------------------------------------------
    # 2. Build candidate pair relations
    # -------------------------------------------------------------------------
    pair_indices = list(combinations(range(N), 2))
    coeff_range = range(-C, C + 1)

    candidate_relations = []  # list of (i,j,a,b)
    for i, j in pair_indices:
        for a in coeff_range:
            for b in coeff_range:
                # exclude trivial (0,0)
                if a == 0 and b == 0:
                    continue
                # require both non-zero to avoid trivial 1-parameter relations
                if a == 0 or b == 0:
                    continue
                # primitive condition: gcd(|a|,|b|) = 1
                if _gcd2_pair(a, b) != 1:
                    continue
                candidate_relations.append((i, j, a, b))

    print("[Candidate relation space]")
    print(f"  coefficient bound C    : {C}")
    print(f"  number of pairs        : {len(pair_indices)}")
    print(f"  total candidate relations: {len(candidate_relations)}")
    print()

    # Helper: best relation for a given set of logs
    def _best_pair_relation_for_logs(logs_local):
        best_resid = float("inf")
        best_rel = None
        for (i, j, a, b) in candidate_relations:
            s = a * logs_local[i] + b * logs_local[j]
            r = abs(s)
            if r < best_resid:
                best_resid = r
                best_rel = (i, j, a, b, s)
        return best_resid, best_rel

    # -------------------------------------------------------------------------
    # 3. Real data: best pairwise relation
    # -------------------------------------------------------------------------
    print("[Real EW: best pairwise integer relation search]")
    real_best_resid, best_rel = _best_pair_relation_for_logs(logs)
    i, j, a, b, s = best_rel
    prod_val = 10.0 ** s

    print(f"  best residual |a log10(x_i) + b log10(x_j)| : {real_best_resid:.6e}")
    print("  Best relation (real data):")
    print(f"    indices (i,j)          : ({i}, {j})")
    print(f"    names                  : ({names[i]}, {names[j]})")
    print(f"    coeffs (a,b)           : ({a}, {b})")
    print(f"    sum a log10(x_i) + b log10(x_j) : {s:.6e}")
    print(f"    product approx 10^(sum)        : {prod_val:.6e}")
    print()

    # Also list top 10 relations
    print("  Top 10 pairwise relations (smallest residuals):")
    best_list = []  # (resid, (i,j,a,b,s,prod_val))
    for (ii, jj, aa, bb) in candidate_relations:
        ss = aa * logs[ii] + bb * logs[jj]
        rr = abs(ss)
        pv = 10.0 ** ss
        best_list.append((rr, (ii, jj, aa, bb, ss, pv)))
    best_list.sort(key=lambda t: t[0])

    for rank, (rr, rel) in enumerate(best_list[:10], start=1):
        ii, jj, aa, bb, ss, pv = rel
        print(f"    #{rank:2d}: resid={rr:.6e}  "
              f"({names[ii]}, {names[jj]}); "
              f"(a,b)=({aa},{bb});  prod≈{pv:.6e}")
    print()

    # -------------------------------------------------------------------------
    # 4. Null ensemble: jitter null
    # -------------------------------------------------------------------------
    print(f"[Jitter null ensemble] Generating {num_null} random universes...")
    null_best_resids = []

    for _ in range(num_null):
        logs_null = [
            z + random.uniform(-jitter_halfwidth, jitter_halfwidth)
            for z in logs
        ]
        best_resid_null, _ = _best_pair_relation_for_logs(logs_null)
        null_best_resids.append(best_resid_null)

    nb = null_best_resids
    mn = min(nb)
    mx = max(nb)
    q25, q50, q75 = statistics.quantiles(nb, n=4)
    mean_null = statistics.mean(nb)
    std_null  = statistics.pstdev(nb) if len(nb) > 1 else 0.0

    if std_null > 0:
        z_score = (real_best_resid - mean_null) / std_null
    else:
        z_score = float("nan")

    less_or_equal = sum(1 for r in nb if r <= real_best_resid)
    p_emp = less_or_equal / float(num_null)

    print()
    print("[Jitter-null stats — best pairwise integer-relation residual]")
    print(f"  null best_resid min / max: {mn:.6e} / {mx:.6e}")
    print(f"  null best_resid 25%/50%/75%: {q25:.6e} / {q50:.6e} / {q75:.6e}")
    print(f"  null best_resid mean / std: {mean_null:.6e} / {std_null:.6e}")
    print()
    print("[Significance under jitter null]")
    print(f"  real best_resid          : {real_best_resid:.6e}")
    print(f"  z(real vs null mean)     : {z_score:6.2f}")
    print(f"  P_null(best_resid <= real) = {p_emp:.6f}")
    print()
    print("=" * 90)
    print("PHASE2_EW_PAIR_INTREL_NULLSCAN_v1 complete.")
    print("=" * 90)


if __name__ == "__main__":
    run_phase2_ew_pair_intrel_nullscan_v1(
        C=4,
        num_null=2000,
        jitter_halfwidth=0.5,
        seed=20251123,
    )

# =============================================================================
# PHASE2_EW_TRIPLE_INTREL19_NULLSCAN_v1
#
#   Phase 2, Test 6:
#     - Search for simple 3-term integer relations among ALL 19 EW parameters:
#
#         z_i = log10(x_i)
#         Relation: a * z_i + b * z_j + c * z_k ≈ 0
#
#       with:
#         * all unordered triples (i,j,k) from the 19 EW parameters
#         * integer coefficients a,b,c in [-C, +C], C=3
#         * at least 2 non-zero coefficients
#         * gcd(|a|,|b|,|c|) = 1 (primitive relations)
#
#     - For real data:
#         * scan all candidate relations
#         * record smallest residual |a z_i + b z_j + c z_k|
#         * print best relation and top 10
#
#     - For null:
#         * jitter null:
#             z_i(null) = z_i(real) + delta_i
#             with delta_i ~ Uniform[-h, +h] in log10 space
#         * for each null universe, do the same scan
#         * compare real best residual to null distribution
#
#   Notes:
#     - Coefficient bound is kept at C=3 (not 4) to keep the search tractable
#       over 19 parameters. This focuses on the simplest integer relations.
#
#   Requirements:
#     - _phase2_ew_get_data() must already be defined.
# =============================================================================

import math, random, statistics
from itertools import combinations
from math import gcd

def _ew_get_logs_for_triples19():
    """Get names, values, and log10 values for all EW parameters."""
    all_data = _phase2_ew_get_data()
    names = [name for (name, _) in all_data]
    vals  = [val  for (_, val)  in all_data]
    logs  = [math.log10(v) for v in vals]
    return names, vals, logs


def _gcd3_triple(a, b, c):
    """GCD of three integers (nonnegative)."""
    return gcd(gcd(abs(a), abs(b)), abs(c))


def run_phase2_ew_triple_intrel19_nullscan_v1(
    C=3,
    num_null=1000,
    jitter_halfwidth=0.5,  # in log10 (~factor ~3)
    seed=20251124
):
    print("=" * 90)
    print("PHASE2_EW_TRIPLE_INTREL19_NULLSCAN_v1 — 3-term EW integer relations (19 params)")
    print("=" * 90)

    random.seed(seed)

    # -------------------------------------------------------------------------
    # 1. Get EW data and logs
    # -------------------------------------------------------------------------
    names, vals, logs = _ew_get_logs_for_triples19()
    N = len(names)

    print("[EW data]")
    print(f"  number of parameters    : {N}")
    print(f"  log10 range (real)      : [{min(logs):.3f}, {max(logs):.3f}]")
    print(f"  jitter halfwidth (log10): {jitter_halfwidth:.3f}")
    print()
    print("  name                 value           log10(value)")
    print("  ------------------- --------------  ------------")
    for n, v, z in zip(names, vals, logs):
        print(f"  {n:19s} {v:14.9e}  {z:12.6f}")
    print()

    # -------------------------------------------------------------------------
    # 2. Build candidate 3-term relations
    # -------------------------------------------------------------------------
    triple_indices = list(combinations(range(N), 3))
    coeff_range = range(-C, C + 1)

    candidate_relations = []  # list of (i,j,k,a,b,c)
    for i, j, k in triple_indices:
        for a in coeff_range:
            for b in coeff_range:
                for c in coeff_range:
                    if a == 0 and b == 0 and c == 0:
                        continue
                    nonzero_count = (a != 0) + (b != 0) + (c != 0)
                    if nonzero_count < 2:
                        continue
                    if _gcd3_triple(a, b, c) != 1:
                        continue
                    candidate_relations.append((i, j, k, a, b, c))

    print("[Candidate relation space]")
    print(f"  coefficient bound C    : {C}")
    print(f"  number of triples      : {len(triple_indices)}")
    print(f"  total candidate relations: {len(candidate_relations)}")
    print()

    # Helper: best relation for a given set of logs
    def _best_triple_relation_for_logs(logs_local):
        best_resid = float("inf")
        best_rel = None
        for (i, j, k, a, b, c) in candidate_relations:
            s = a * logs_local[i] + b * logs_local[j] + c * logs_local[k]
            r = abs(s)
            if r < best_resid:
                best_resid = r
                best_rel = (i, j, k, a, b, c, s)
        return best_resid, best_rel

    # -------------------------------------------------------------------------
    # 3. Real data: best 3-term relation
    # -------------------------------------------------------------------------
    print("[Real EW: best 3-term integer relation search]")
    real_best_resid, best_rel = _best_triple_relation_for_logs(logs)
    i, j, k, a, b, c, s = best_rel
    prod_val = 10.0 ** s

    print(f"  best residual |a log10(x_i) + b log10(x_j) + c log10(x_k)| : {real_best_resid:.6e}")
    print("  Best relation (real data):")
    print(f"    indices (i,j,k)        : ({i}, {j}, {k})")
    print(f"    names                  : ({names[i]}, {names[j]}, {names[k]})")
    print(f"    coeffs (a,b,c)         : ({a}, {b}, {c})")
    print(f"    sum                    : {s:.6e}")
    print(f"    product approx 10^(sum): {prod_val:.6e}")
    print()

    # Top 10 relations for real data
    print("  Top 10 3-term relations (smallest residuals):")
    best_list = []  # (resid, (i,j,k,a,b,c,s,prod_val))
    for (ii, jj, kk, aa, bb, cc) in candidate_relations:
        ss = aa * logs[ii] + bb * logs[jj] + cc * logs[kk]
        rr = abs(ss)
        pv = 10.0 ** ss
        best_list.append((rr, (ii, jj, kk, aa, bb, cc, ss, pv)))
    best_list.sort(key=lambda t: t[0])

    for rank, (rr, rel) in enumerate(best_list[:10], start=1):
        ii, jj, kk, aa, bb, cc, ss, pv = rel
        print(f"    #{rank:2d}: resid={rr:.6e}  "
              f"({names[ii]}, {names[jj]}, {names[kk]}); "
              f"(a,b,c)=({aa},{bb},{cc});  prod≈{pv:.6e}")
    print()

    # -------------------------------------------------------------------------
    # 4. Null ensemble: jitter null
    # -------------------------------------------------------------------------
    print(f"[Jitter null ensemble] Generating {num_null} random universes...")
    null_best_resids = []

    for _ in range(num_null):
        logs_null = [
            z + random.uniform(-jitter_halfwidth, jitter_halfwidth)
            for z in logs
        ]
        best_resid_null, _ = _best_triple_relation_for_logs(logs_null)
        null_best_resids.append(best_resid_null)

    nb = null_best_resids
    mn = min(nb)
    mx = max(nb)
    q25, q50, q75 = statistics.quantiles(nb, n=4)
    mean_null = statistics.mean(nb)
    std_null  = statistics.pstdev(nb) if len(nb) > 1 else 0.0

    if std_null > 0:
        z_score = (real_best_resid - mean_null) / std_null
    else:
        z_score = float("nan")

    less_or_equal = sum(1 for r in nb if r <= real_best_resid)
    p_emp = less_or_equal / float(num_null)

    print()
    print("[Jitter-null stats — best 3-term integer-relation residual]")
    print(f"  null best_resid min / max: {mn:.6e} / {mx:.6e}")
    print(f"  null best_resid 25%/50%/75%: {q25:.6e} / {q50:.6e} / {q75:.6e}")
    print(f"  null best_resid mean / std: {mean_null:.6e} / {std_null:.6e}")
    print()
    print("[Significance under jitter null]")
    print(f"  real best_resid          : {real_best_resid:.6e}")
    print(f"  z(real vs null mean)     : {z_score:6.2f}")
    print(f"  P_null(best_resid <= real) = {p_emp:.6f}")
    print()
    print("=" * 90)
    print("PHASE2_EW_TRIPLE_INTREL19_NULLSCAN_v1 complete.")
    print("=" * 90)


if __name__ == "__main__":
    run_phase2_ew_triple_intrel19_nullscan_v1(
        C=3,
        num_null=1000,
        jitter_halfwidth=0.5,
        seed=20251124,
    )

# =============================================================================
# PHASE2_YUKAWA_4TERM_INTREL_NULLSCAN_v1
#
#   Phase 2, Test 7:
#     - Search for simple 4-term integer relations among the 9 Yukawas:
#
#         z_i = log10(Yukawa_i)
#         Relation: a z_i + b z_j + c z_k + d z_l ≈ 0
#
#       with:
#         * all unordered quadruples (i,j,k,l) from the 9 Yukawas
#         * integer coefficients a,b,c,d in [-C, +C], C=3
#         * at least 2 non-zero coefficients
#         * gcd(|a|,|b|,|c|,|d|) = 1 (primitive relations)
#
#     - For real data:
#         * scan all candidate relations
#         * record smallest residual |a z_i + b z_j + c z_k + d z_l|
#         * print best relation and top 10
#
#     - For null:
#         * jitter null:
#             z_i(null) = z_i(real) + delta_i
#             with delta_i ~ Uniform[-h, +h] in log10 space
#         * for each null universe, do the same scan
#         * compare real best residual to null distribution
#
#   Notes:
#     - Coefficient bound C=3 keeps the search tractable while still capturing
#       simple integer structures. This is more complex than the 3-term search
#       but still focused on small exponents.
#
#   Requirements:
#     - _phase2_ew_get_data() must already be defined.
# =============================================================================

import math, random, statistics
from itertools import combinations
from math import gcd

def _yukawa_get_logs_for_4term():
    """Extract the 9 Yukawa logs from _phase2_ew_get_data()."""
    all_data = _phase2_ew_get_data()
    name_to_val = {name: val for (name, val) in all_data}

    yuk_names = [
        "me_over_v",
        "mmu_over_v",
        "mtau_over_v",
        "mb_over_v",
        "mc_over_v",
        "mt_over_v",
        "md_over_v",
        "ms_over_v",
        "mu_over_v",
    ]
    vals = [name_to_val[n] for n in yuk_names]
    logs = [math.log10(v) for v in vals]
    return yuk_names, vals, logs


def _gcd4(a, b, c, d):
    """GCD of four integers (nonnegative)."""
    g1 = gcd(abs(a), abs(b))
    g2 = gcd(abs(c), abs(d))
    return gcd(g1, g2)


def run_phase2_yukawa_4term_intrel_nullscan_v1(
    C=3,
    num_null=1000,
    jitter_halfwidth=0.5,  # in log10 (~factor ~3)
    seed=20251125
):
    print("=" * 90)
    print("PHASE2_YUKAWA_4TERM_INTREL_NULLSCAN_v1 — 4-term integer relations among Yukawas")
    print("=" * 90)

    random.seed(seed)

    # -------------------------------------------------------------------------
    # 1. Get Yukawa logs
    # -------------------------------------------------------------------------
    yuk_names, yuk_vals, yuk_logs = _yukawa_get_logs_for_4term()
    N = len(yuk_names)

    print("[Yukawa data]")
    print(f"  number of Yukawas      : {N}")
    print(f"  value range            : [{min(yuk_vals):.3e}, {max(yuk_vals):.3e}]")
    print(f"  log10 range (real)     : [{min(yuk_logs):.3f}, {max(yuk_logs):.3f}]")
    print(f"  jitter halfwidth (log10): {jitter_halfwidth:.3f}")
    print()
    print("  name          value           log10(value)")
    print("  ------------ --------------  ------------")
    for n, v, z in zip(yuk_names, yuk_vals, yuk_logs):
        print(f"  {n:12s} {v:14.9e}  {z:12.6f}")
    print()

    # -------------------------------------------------------------------------
    # 2. Build candidate 4-term relations
    # -------------------------------------------------------------------------
    quadruples = list(combinations(range(N), 4))
    coeff_range = range(-C, C + 1)

    candidate_relations = []  # list of (i,j,k,l,a,b,c,d)
    for i, j, k, l in quadruples:
        for a in coeff_range:
            for b in coeff_range:
                for c in coeff_range:
                    for d in coeff_range:
                        if a == 0 and b == 0 and c == 0 and d == 0:
                            continue
                        nonzero_count = (a != 0) + (b != 0) + (c != 0) + (d != 0)
                        if nonzero_count < 2:
                            continue
                        if _gcd4(a, b, c, d) != 1:
                            continue
                        candidate_relations.append((i, j, k, l, a, b, c, d))

    print("[Candidate relation space]")
    print(f"  coefficient bound C    : {C}")
    print(f"  number of quadruples   : {len(quadruples)}")
    print(f"  total candidate relations: {len(candidate_relations)}")
    print()

    # Helper: best relation for a given set of logs
    def _best_4term_relation_for_logs(logs_local):
        best_resid = float("inf")
        best_rel = None
        for (i, j, k, l, a, b, c, d) in candidate_relations:
            s = (a * logs_local[i] +
                 b * logs_local[j] +
                 c * logs_local[k] +
                 d * logs_local[l])
            r = abs(s)
            if r < best_resid:
                best_resid = r
                best_rel = (i, j, k, l, a, b, c, d, s)
        return best_resid, best_rel

    # -------------------------------------------------------------------------
    # 3. Real data: best 4-term relation
    # -------------------------------------------------------------------------
    print("[Real Yukawas: best 4-term integer relation search]")
    real_best_resid, best_rel = _best_4term_relation_for_logs(yuk_logs)
    i, j, k, l, a, b, c, d, s = best_rel
    prod_val = 10.0 ** s

    print(f"  best residual |sum n_i log10(y_i)| : {real_best_resid:.6e}")
    print("  Best relation (real data):")
    print(f"    indices (i,j,k,l)       : ({i}, {j}, {k}, {l})")
    print(f"    names                   : ({yuk_names[i]}, {yuk_names[j]}, {yuk_names[k]}, {yuk_names[l]})")
    print(f"    coeffs (a,b,c,d)        : ({a}, {b}, {c}, {d})")
    print(f"    sum n_i log10(y_i)      : {s:.6e}")
    print(f"    product approx 10^(sum) : {prod_val:.6e}")
    print()

    # Top 10 relations for real data
    print("  Top 10 4-term relations (smallest residuals):")
    best_list = []  # (resid, (i,j,k,l,a,b,c,d,s,prod_val))
    for (ii, jj, kk, ll, aa, bb, cc, dd) in candidate_relations:
        ss = (aa * yuk_logs[ii] +
              bb * yuk_logs[jj] +
              cc * yuk_logs[kk] +
              dd * yuk_logs[ll])
        rr = abs(ss)
        pv = 10.0 ** ss
        best_list.append((rr, (ii, jj, kk, ll, aa, bb, cc, dd, ss, pv)))
    best_list.sort(key=lambda t: t[0])

    for rank, (rr, rel) in enumerate(best_list[:10], start=1):
        ii, jj, kk, ll, aa, bb, cc, dd, ss, pv = rel
        print(f"    #{rank:2d}: resid={rr:.6e}  "
              f"({yuk_names[ii]}, {yuk_names[jj]}, {yuk_names[kk]}, {yuk_names[ll]}); "
              f"(a,b,c,d)=({aa},{bb},{cc},{dd});  prod≈{pv:.6e}")
    print()

    # -------------------------------------------------------------------------
    # 4. Null ensemble: jitter null
    # -------------------------------------------------------------------------
    print(f"[Jitter null ensemble] Generating {num_null} random universes...")
    null_best_resids = []

    for _ in range(num_null):
        logs_null = [
            z + random.uniform(-jitter_halfwidth, jitter_halfwidth)
            for z in yuk_logs
        ]
        best_resid_null, _ = _best_4term_relation_for_logs(logs_null)
        null_best_resids.append(best_resid_null)

    nb = null_best_resids
    mn = min(nb)
    mx = max(nb)
    q25, q50, q75 = statistics.quantiles(nb, n=4)
    mean_null = statistics.mean(nb)
    std_null  = statistics.pstdev(nb) if len(nb) > 1 else 0.0

    if std_null > 0:
        z_score = (real_best_resid - mean_null) / std_null
    else:
        z_score = float("nan")

    less_or_equal = sum(1 for r in nb if r <= real_best_resid)
    p_emp = less_or_equal / float(num_null)

    print()
    print("[Jitter-null stats — best 4-term integer-relation residual]")
    print(f"  null best_resid min / max: {mn:.6e} / {mx:.6e}")
    print(f"  null best_resid 25%/50%/75%: {q25:.6e} / {q50:.6e} / {q75:.6e}")
    print(f"  null best_resid mean / std: {mean_null:.6e} / {std_null:.6e}")
    print()
    print("[Significance under jitter null]")
    print(f"  real best_resid          : {real_best_resid:.6e}")
    print(f"  z(real vs null mean)     : {z_score:6.2f}")
    print(f"  P_null(best_resid <= real) = {p_emp:.6f}")
    print()
    print("=" * 90)
    print("PHASE2_YUKAWA_4TERM_INTREL_NULLSCAN_v1 complete.")
    print("=" * 90)


if __name__ == "__main__":
    run_phase2_yukawa_4term_intrel_nullscan_v1(
        C=3,
        num_null=1000,
        jitter_halfwidth=0.5,
        seed=20251125,
    )

# =============================================================================
# PHASE2_YUKAWA_FIXED_TRIPLE_JITTERNULL_v1
#
#   Phase 2, Test 8:
#     - Take the specific 3-term integer relation we previously found among
#       Yukawas:
#
#           me_over_v, mtau_over_v, md_over_v
#           coeffs (a,b,c) = (-4, 4, 3)
#
#       i.e. S = |-4 log10(me/v) + 4 log10(mtau/v) + 3 log10(md/v)|
#
#     - Treat this as a FIXED hypothesis (no coefficient/tuple searching).
#
#     - For real data:
#         * compute S_real
#         * report S_real and corresponding product 10^(sum)
#
#     - For null:
#         * jitter Yukawa logs:
#               z_i(null) = z_i(real) + delta_i
#               delta_i ~ Uniform[-h, +h] in log10 space
#         * for each null universe, compute S_null for THIS SAME triple & coeffs
#         * compare S_real to distribution of S_null
#
#   This removes the "look-elsewhere" of scanning 48k candidate relations and
#   asks directly how surprising this ONE relation is under the Yukawa-shape
#   jitter.
#
#   Requirements:
#     - _phase2_ew_get_data() must already be defined.
# =============================================================================

import math, random, statistics

def _yukawa_get_logs_for_fixed_triple():
    """Extract the 9 Yukawa logs from _phase2_ew_get_data(), with name order."""
    all_data = _phase2_ew_get_data()
    name_to_val = {name: val for (name, val) in all_data}

    yuk_names = [
        "me_over_v",
        "mmu_over_v",
        "mtau_over_v",
        "mb_over_v",
        "mc_over_v",
        "mt_over_v",
        "md_over_v",
        "ms_over_v",
        "mu_over_v",
    ]
    vals = [name_to_val[n] for n in yuk_names]
    logs = [math.log10(v) for v in vals]
    return yuk_names, vals, logs


def run_phase2_yukawa_fixed_triple_jitternull_v1(
    jitter_halfwidth=0.5,  # in log10 (~factor ~3)
    num_null=10000,
    seed=20251126
):
    print("=" * 90)
    print("PHASE2_YUKAWA_FIXED_TRIPLE_JITTERNULL_v1 — fixed (me, mtau, md) relation")
    print("=" * 90)

    random.seed(seed)

    # -------------------------------------------------------------------------
    # 1. Get Yukawa logs and locate indices of me, mtau, md
    # -------------------------------------------------------------------------
    yuk_names, yuk_vals, yuk_logs = _yukawa_get_logs_for_fixed_triple()
    name_to_index = {n: i for i, n in enumerate(yuk_names)}

    i_me   = name_to_index["me_over_v"]
    i_mtau = name_to_index["mtau_over_v"]
    i_md   = name_to_index["md_over_v"]

    z_me   = yuk_logs[i_me]
    z_mtau = yuk_logs[i_mtau]
    z_md   = yuk_logs[i_md]

    v_me   = yuk_vals[i_me]
    v_mtau = yuk_vals[i_mtau]
    v_md   = yuk_vals[i_md]

    print("[Yukawa data (subset used in relation)]")
    print(f"  me_over_v    = {v_me: .9e}  log10 = {z_me: .6f}")
    print(f"  mtau_over_v  = {v_mtau: .9e}  log10 = {z_mtau: .6f}")
    print(f"  md_over_v    = {v_md: .9e}  log10 = {z_md: .6f}")
    print(f"  jitter halfwidth (log10): {jitter_halfwidth:.3f}")
    print()

    # -------------------------------------------------------------------------
    # 2. Real data: compute S_real and product
    #     Relation: a=-4, b=4, c=3
    # -------------------------------------------------------------------------
    a, b, c = -4, 4, 3
    sum_real = a * z_me + b * z_mtau + c * z_md
    S_real   = abs(sum_real)
    prod_real = 10.0 ** sum_real

    print("[Real fixed-triple relation]")
    print("  Relation: S = |-4 log10(me_over_v) + 4 log10(mtau_over_v) + 3 log10(md_over_v)|")
    print(f"  sum_real (a z_me + b z_mtau + c z_md) : {sum_real:.6e}")
    print(f"  S_real = |sum_real|                  : {S_real:.6e}")
    print(f"  product 10^(sum_real)                : {prod_real:.6e}")
    print()

    # -------------------------------------------------------------------------
    # 3. Jitter null: apply same relation to jittered Yukawas
    # -------------------------------------------------------------------------
    print(f"[Jitter null ensemble] Generating {num_null} random universes...")
    null_S = []

    for _ in range(num_null):
        # jitter all Yukawa logs, but only need me, mtau, md
        logs_null = [
            z + random.uniform(-jitter_halfwidth, jitter_halfwidth)
            for z in yuk_logs
        ]
        z_me_n   = logs_null[i_me]
        z_mtau_n = logs_null[i_mtau]
        z_md_n   = logs_null[i_md]

        sum_null = a * z_me_n + b * z_mtau_n + c * z_md_n
        S_null   = abs(sum_null)
        null_S.append(S_null)

    mn = min(null_S)
    mx = max(null_S)
    q25, q50, q75 = statistics.quantiles(null_S, n=4)
    mean_null = statistics.mean(null_S)
    std_null  = statistics.pstdev(null_S) if len(null_S) > 1 else 0.0

    if std_null > 0:
        z_score = (S_real - mean_null) / std_null
    else:
        z_score = float("nan")

    less_or_equal = sum(1 for s in null_S if s <= S_real)
    p_emp = less_or_equal / float(num_null)

    print()
    print("[Jitter-null stats — fixed (me, mtau, md) relation]")
    print(f"  null S min / max           : {mn:.6e} / {mx:.6e}")
    print(f"  null S 25%/50%/75%         : {q25:.6e} / {q50:.6e} / {q75:.6e}")
    print(f"  null S mean / std          : {mean_null:.6e} / {std_null:.6e}")
    print()
    print("[Significance under jitter null]")
    print(f"  S_real                     : {S_real:.6e}")
    print(f"  z(S_real vs null mean)     : {z_score:6.2f}")
    print(f"  P_null(S <= S_real)        : {p_emp:.6f}")
    print()
    print("=" * 90)
    print("PHASE2_YUKAWA_FIXED_TRIPLE_JITTERNULL_v1 complete.")
    print("=" * 90)


if __name__ == "__main__":
    run_phase2_yukawa_fixed_triple_jitternull_v1(
        jitter_halfwidth=0.5,
        num_null=10000,
        seed=20251126,
    )

# =============================================================================
# PHASE2_YUKAWA_FIXED_TRIPLE_JITTERSCAN_v1
#
#   Scan the significance of the fixed (me, mtau, md; -4,4,3) Yukawa relation
#   across a range of jitter halfwidths in log10 space.
#
#   For each jitter_halfwidth h in a grid:
#     - jitter Yukawa logs: z_i(null) = z_i(real) + U[-h, +h]
#     - compute S_null = |-4 z_me + 4 z_mtau + 3 z_md|
#     - estimate p-value P_null(S <= S_real)
#
#   This checks that our conclusion does not hinge on choosing h = 0.5.
#
#   Requirements:
#     - _phase2_ew_get_data() must already be defined.
# =============================================================================

import math, random, statistics

def _yukawa_get_logs_for_fixed_triple_scan():
    """Extract Yukawa logs (same as previous helper) for jitter scan."""
    all_data = _phase2_ew_get_data()
    name_to_val = {name: val for (name, val) in all_data}

    yuk_names = [
        "me_over_v",
        "mmu_over_v",
        "mtau_over_v",
        "mb_over_v",
        "mc_over_v",
        "mt_over_v",
        "md_over_v",
        "ms_over_v",
        "mu_over_v",
    ]
    vals = [name_to_val[n] for n in yuk_names]
    logs = [math.log10(v) for v in vals]
    return yuk_names, vals, logs


def run_phase2_yukawa_fixed_triple_jitterscan_v1(
    jitter_grid=None,
    num_null=2000,
    seed=20251127
):
    print("=" * 90)
    print("PHASE2_YUKAWA_FIXED_TRIPLE_JITTERSCAN_v1 — jitter-width scan")
    print("=" * 90)

    if jitter_grid is None:
        jitter_grid = [0.05, 0.10, 0.20, 0.30, 0.50, 0.70, 1.00]

    random.seed(seed)

    # Load Yukawa logs and identify indices
    yuk_names, yuk_vals, yuk_logs = _yukawa_get_logs_for_fixed_triple_scan()
    name_to_index = {n: i for i, n in enumerate(yuk_names)}

    i_me   = name_to_index["me_over_v"]
    i_mtau = name_to_index["mtau_over_v"]
    i_md   = name_to_index["md_over_v"]

    z_me   = yuk_logs[i_me]
    z_mtau = yuk_logs[i_mtau]
    z_md   = yuk_logs[i_md]

    a, b, c = -4, 4, 3
    sum_real = a * z_me + b * z_mtau + c * z_md
    S_real   = abs(sum_real)

    print("[Fixed triple recap]")
    print("  Relation: S = |-4 log10(me_over_v) + 4 log10(mtau_over_v) + 3 log10(md_over_v)|")
    print(f"  sum_real = {sum_real:.6e}")
    print(f"  S_real   = {S_real:.6e}")
    print()

    # Header for results
    print("[Jitter scan results]")
    print("  h (log10)   min(S_null)    mean(S_null)   std(S_null)    p_emp  N_null")
    print("  ---------  ------------  -------------  ------------  ------- ------")

    for h in jitter_grid:
        null_S = []
        for _ in range(num_null):
            logs_null = [
                z + random.uniform(-h, +h)
                for z in yuk_logs
            ]
            z_me_n   = logs_null[i_me]
            z_mtau_n = logs_null[i_mtau]
            z_md_n   = logs_null[i_md]

            sum_null = a * z_me_n + b * z_mtau_n + c * z_md_n
            S_null   = abs(sum_null)
            null_S.append(S_null)

        mn = min(null_S)
        mean_null = statistics.mean(null_S)
        std_null  = statistics.pstdev(null_S) if len(null_S) > 1 else 0.0
        less_or_equal = sum(1 for s in null_S if s <= S_real)
        p_emp = less_or_equal / float(num_null)

        print(f"  {h:9.3f}  {mn:12.6e}  {mean_null:13.6e}  {std_null:12.6e}  {p_emp:7.4f} {num_null:6d}")

    print()
    print("=" * 90)
    print("PHASE2_YUKAWA_FIXED_TRIPLE_JITTERSCAN_v1 complete.")
    print("=" * 90)


if __name__ == "__main__":
    run_phase2_yukawa_fixed_triple_jitterscan_v1(
        jitter_grid=None,
        num_null=2000,
        seed=20251127,
    )

# =============================================================================
# PHASE2_YUKAWA_FIXED_TRIPLE_COEFF_LANDSCAPE_v1
#
#   For the fixed Yukawa triple (me_over_v, mtau_over_v, md_over_v), we:
#
#     - Scan integer coefficients (a,b,c) in a box:
#           a,b,c ∈ [-A_MAX, ..., +A_MAX]
#       with:
#           * at least 2 non-zero coefficients,
#           * gcd(|a|,|b|,|c|) = 1 (primitive combos).
#
#     - For each (a,b,c), compute:
#           S(a,b,c) = |a log10(me/v) + b log10(mtau/v) + c log10(md/v)|
#
#     - Sort by S and print the top K combos.
#
#   This shows whether (-4,4,3) is an isolated sharp minimum or one point in
#   a broad valley of similar integer relations.
#
#   Requirements:
#     - _phase2_ew_get_data() must already be defined.
# =============================================================================

import math
from math import gcd

def _yukawa_get_logs_for_coeff_landscape():
    """Extract Yukawa logs for the fixed-triple coefficient landscape."""
    all_data = _phase2_ew_get_data()
    name_to_val = {name: val for (name, val) in all_data}

    yuk_names = [
        "me_over_v",
        "mmu_over_v",
        "mtau_over_v",
        "mb_over_v",
        "mc_over_v",
        "mt_over_v",
        "md_over_v",
        "ms_over_v",
        "mu_over_v",
    ]
    vals = [name_to_val[n] for n in yuk_names]
    logs = [math.log10(v) for v in vals]
    return yuk_names, vals, logs


def _gcd3(a, b, c):
    """GCD of three integers."""
    return gcd(gcd(abs(a), abs(b)), abs(c))


def run_phase2_yukawa_fixed_triple_coeff_landscape_v1(
    A_MAX=10,
    top_k=50
):
    print("=" * 90)
    print("PHASE2_YUKAWA_FIXED_TRIPLE_COEFF_LANDSCAPE_v1 — coeff landscape")
    print("=" * 90)

    yuk_names, yuk_vals, yuk_logs = _yukawa_get_logs_for_coeff_landscape()
    name_to_index = {n: i for i, n in enumerate(yuk_names)}

    i_me   = name_to_index["me_over_v"]
    i_mtau = name_to_index["mtau_over_v"]
    i_md   = name_to_index["md_over_v"]

    z_me   = yuk_logs[i_me]
    z_mtau = yuk_logs[i_mtau]
    z_md   = yuk_logs[i_md]

    print("[Yukawa logs used]")
    print(f"  me_over_v   log10 = {z_me: .6f}")
    print(f"  mtau_over_v log10 = {z_mtau: .6f}")
    print(f"  md_over_v   log10 = {z_md: .6f}")
    print()
    print(f"  Coefficient search range: a,b,c ∈ [-{A_MAX}, ..., +{A_MAX}]")
    print("  Primitive condition: gcd(|a|,|b|,|c|) = 1, at least 2 non-zero.")
    print()

    results = []  # list of (S, a, b, c, sum_val)

    for a in range(-A_MAX, A_MAX + 1):
        for b in range(-A_MAX, A_MAX + 1):
            for c in range(-A_MAX, A_MAX + 1):
                if a == 0 and b == 0 and c == 0:
                    continue
                nonzero = (a != 0) + (b != 0) + (c != 0)
                if nonzero < 2:
                    continue
                if _gcd3(a, b, c) != 1:
                    continue

                sum_val = a * z_me + b * z_mtau + c * z_md
                S = abs(sum_val)
                results.append((S, a, b, c, sum_val))

    # Sort by residual
    results.sort(key=lambda t: t[0])

    print(f"[Coefficient landscape — top {top_k} primitive (a,b,c)]")
    print("  rank   S(a,b,c)        sum_val          (a,b,c)")
    print("  ----  -------------  -------------     -------------")
    for rank, (S, a, b, c, sum_val) in enumerate(results[:top_k], start=1):
        print(f"  {rank:4d}  {S:13.6e}  {sum_val:13.6e}     ({a:2d},{b:2d},{c:2d})")

    # Also locate the (-4,4,3) combo in the sorted list, if present
    target = (-4, 4, 3)
    idx_target = None
    for idx, (_, a, b, c, _) in enumerate(results):
        if (a, b, c) == target:
            idx_target = idx
            break

    print()
    print("[Special combo (-4,4,3)]")
    if idx_target is not None:
        S_t, a_t, b_t, c_t, sum_t = results[idx_target]
        print(f"  Found at rank          : {idx_target + 1}")
        print(f"  S(-4,4,3)              : {S_t:.6e}")
        print(f"  sum_val(-4,4,3)        : {sum_t:.6e}")
    else:
        print("  (-4,4,3) not found in the scanned coefficient range.")
    print()
    print("=" * 90)
    print("PHASE2_YUKAWA_FIXED_TRIPLE_COEFF_LANDSCAPE_v1 complete.")
    print("=" * 90)


if __name__ == "__main__":
    run_phase2_yukawa_fixed_triple_coeff_landscape_v1(
        A_MAX=10,
        top_k=50,
    )

# ==========================================================================================
# PHASE2_YUKAWA_FIXED_TRIPLE_ERRORMODEL_v1 — stress-test (me, mtau, md) relation with errors
# ==========================================================================================

import math
import random
import statistics as stats

def run_phase2_yukawa_fixed_triple_errormodel(
    frac_err_me=1e-6,
    frac_err_mtau=1e-6,
    frac_err_md=0.20,
    num_null=20000,
    seed=24601
):
    """
    Error-model stress test for the fixed integer relation:
        S = |-4 log10(me/v) + 4 log10(mtau/v) + 3 log10(md/v)|.

    We treat me, mtau, md as log-normal with given fractional 1σ errors
    and see how often S_null <= S_real.

    Parameters
    ----------
    frac_err_me   : float
        1σ fractional error for m_e (e.g. 1e-6 ~ 1 ppm; electron is far better than that).
    frac_err_mtau : float
        1σ fractional error for m_tau.
    frac_err_md   : float
        1σ fractional error for m_d (often O(0.1–0.2) in practice).
    num_null      : int
        Number of pseudo-universes to sample.
    seed          : int
        RNG seed for reproducibility.
    """

    random.seed(seed)

    print("=" * 90)
    print("PHASE2_YUKAWA_FIXED_TRIPLE_ERRORMODEL_v1 — error-model null for (me, mtau, md)")
    print("=" * 90)

    # --- 1. Hard-coded Yukawa logs from your previous modules ---
    # These are log10(m / v), but the v cancels out in the relation anyway.
    log10_me_over_v   = -5.683401
    log10_mtau_over_v = -2.141781
    log10_md_over_v   = -4.722162

    # Compute the "real" S using these central values
    def S_from_logs(z_me, z_tau, z_d):
        return abs(-4.0 * z_me + 4.0 * z_tau + 3.0 * z_d)

    S_real = S_from_logs(log10_me_over_v, log10_mtau_over_v, log10_md_over_v)

    # Convert fractional errors to sigma in log10 space assuming log-normal:
    # If m ~ lognormal, then for small frac_err, sigma_log10 ≈ frac_err / ln(10).
    def frac_to_sigma_log10(frac):
        return frac / math.log(10.0)

    sigma_me_log10   = frac_to_sigma_log10(frac_err_me)
    sigma_mtau_log10 = frac_to_sigma_log10(frac_err_mtau)
    sigma_md_log10   = frac_to_sigma_log10(frac_err_md)

    print("[Central Yukawa logs used]")
    print(f"  log10(me_over_v)   = {log10_me_over_v:.6f}")
    print(f"  log10(mtau_over_v) = {log10_mtau_over_v:.6f}")
    print(f"  log10(md_over_v)   = {log10_md_over_v:.6f}")
    print()
    print("[Error model (1σ fractional errors → σ in log10-space)]")
    print(f"  frac_err_me   = {frac_err_me:.3e}  →  σ_log10(me)   = {sigma_me_log10:.3e}")
    print(f"  frac_err_mtau = {frac_err_mtau:.3e}  →  σ_log10(mtau) = {sigma_mtau_log10:.3e}")
    print(f"  frac_err_md   = {frac_err_md:.3e}  →  σ_log10(md)   = {sigma_md_log10:.3e}")
    print()
    print(f"[Real fixed-triple relation]")
    print("  S = |-4 log10(me/v) + 4 log10(mtau/v) + 3 log10(md/v)|")
    print(f"  S_real = {S_real:.6e}")
    print(f"  product 10^(sum) ≈ {10.0**(-S_real if -4*log10_me_over_v + 4*log10_mtau_over_v + 3*log10_md_over_v < 0 else S_real):.6e}")
    print()

    # --- 2. Jitter null under the chosen error model ---
    S_samples = []

    for _ in range(num_null):
        # Jitter logs independently with Gaussian noise in log10-space
        z_me   = log10_me_over_v   + random.gauss(0.0, sigma_me_log10)
        z_tau  = log10_mtau_over_v + random.gauss(0.0, sigma_mtau_log10)
        z_d    = log10_md_over_v   + random.gauss(0.0, sigma_md_log10)

        S = S_from_logs(z_me, z_tau, z_d)
        S_samples.append(S)

    S_min = min(S_samples)
    S_max = max(S_samples)
    S_mean = stats.mean(S_samples)
    S_std  = stats.pstdev(S_samples)

    # Empirical p-value
    count_le = sum(1 for s in S_samples if s <= S_real)
    p_emp = count_le / num_null

    # Approximate z-score (if distribution not too pathological)
    z_score = (S_real - S_mean) / S_std if S_std > 0 else float("nan")

    print("[Error-model jitter null]")
    print(f"  num_null draws         : {num_null}")
    print(f"  S_null min / max       : {S_min:.6e} / {S_max:.6e}")
    print(f"  S_null 25% / 50% / 75% : "
          f"{stats.quantiles(S_samples, n=4)[0]:.6e} / "
          f"{stats.quantiles(S_samples, n=4)[1]:.6e} / "
          f"{stats.quantiles(S_samples, n=4)[2]:.6e}")
    print(f"  S_null mean / std      : {S_mean:.6e} / {S_std:.6e}")
    print()
    print("[Significance under this error model]")
    print(f"  S_real                 : {S_real:.6e}")
    print(f"  z(S_real vs mean)      : {z_score:+.2f} σ")
    print(f"  p_emp(S <= S_real)     : {p_emp:.6f}")
    print()
    print("NOTE:")
    print("  • You control how harsh this test is by choosing frac_err_me, frac_err_mtau, frac_err_md.")
    print("  • If you set frac_err_md ~ 0.1–0.2 (more realistic for down-quark),")
    print("    and me/tau errors very tiny, you’ll see how fragile the 10^-5 alignment really is.")
    print("=" * 90)
    print("PHASE2_YUKAWA_FIXED_TRIPLE_ERRORMODEL_v1 complete.")
    print("=" * 90)


if __name__ == "__main__":
    # Example: super-precise e & tau, 20% 1σ on d-quark, 20k draws
    run_phase2_yukawa_fixed_triple_errormodel(
        frac_err_me=1e-8,
        frac_err_mtau=1e-5,
        frac_err_md=0.20,
        num_null=20000,
        seed=24601,
    )

# ==========================================================================================
# PHASE2_YUKAWA_EXPONENT_GEOMETRY_NULLSCAN_v1b
#   — Small-integer exponent geometry for Yukawas + jitter null (bugfix)
#
# Bugfix vs v1:
#   • Fixed ValueError from f-string format specifier for z_score.
#   • Everything else identical, so you can just stack this cell below the old one.
#     New definitions override the old ones.
# ==========================================================================================

import math
import random
import statistics as stats

def _yukawa_logs_real():
    """
    Hard-coded log10(yukawa) values, consistent with previous modules.
    These are log10(m / v), but v cancels in exponent relations so the
    absolute normalization is irrelevant for our geometry test.

    Returns:
        names : list of str
        z     : list of float (log10 values)
    """
    names = [
        "me_over_v",
        "mmu_over_v",
        "mtau_over_v",
        "mb_over_v",
        "mc_over_v",
        "mt_over_v",
        "md_over_v",
        "ms_over_v",
        "mu_over_v",
    ]

    z = [
        -5.683401,  # me_over_v
        -3.367606,  # mmu_over_v
        -2.141781,  # mtau_over_v
        -1.770024,  # mb_over_v
        -2.287532,  # mc_over_v
        -0.154056,  # mt_over_v
        -4.722162,  # md_over_v
        -3.422873,  # ms_over_v
        -5.056852,  # mu_over_v
    ]
    return names, z


def _find_best_exponent_combo(z_target, z_basis, C):
    """
    For a single target log10(y_i), search all integer triples (a,b,c) in [-C, C]^3,
    excluding (0,0,0), to minimize |z_target - (a * z_e + b * z_tau + c * z_d)|.

    Args:
        z_target : float
            log10(y_i) for the Yukawa being modeled.
        z_basis  : tuple/list of 3 floats
            (z_e, z_tau, z_d) in log10-space.
        C        : int
            Maximum absolute value of exponents (search range [-C, C]).

    Returns:
        best_a, best_b, best_c, best_res
    """
    z_e, z_tau, z_d = z_basis
    best_res = float("inf")
    best_a = best_b = best_c = 0

    for a in range(-C, C + 1):
        for b in range(-C, C + 1):
            for c in range(-C, C + 1):
                if a == 0 and b == 0 and c == 0:
                    continue
                z_model = a * z_e + b * z_tau + c * z_d
                res = abs(z_target - z_model)
                if res < best_res:
                    best_res = res
                    best_a, best_b, best_c = a, b, c
                    if best_res == 0.0:
                        # Can't get better than exact match; early exit for speed
                        return best_a, best_b, best_c, best_res
    return best_a, best_b, best_c, best_res


def _geometry_fit_for_universe(z_logs, C, idx_me, idx_mtau, idx_md):
    """
    Given a full 9-vector of log10 Yukawas for some universe,
    compute the best small-integer exponent fit for each Yukawa.

    Args:
        z_logs : list of float, len 9
            log10(yukawa) values for this universe.
        C      : int
            Max exponent magnitude in [-C, C].
        idx_me, idx_mtau, idx_md : int
            Indices of (me, mtau, md) in the z_logs array (basis).

    Returns:
        coeffs : list of (a,b,c) for each Yukawa (len 9).
        residuals : list of residuals |z_i - (a z_e + b z_tau + c z_d)| (len 9).
    """
    z_e   = z_logs[idx_me]
    z_tau = z_logs[idx_mtau]
    z_d   = z_logs[idx_md]
    z_basis = (z_e, z_tau, z_d)

    coeffs = []
    residuals = []

    for i, z_i in enumerate(z_logs):
        a, b, c, res = _find_best_exponent_combo(z_i, z_basis, C)
        coeffs.append((a, b, c))
        residuals.append(res)

    return coeffs, residuals


def run_phase2_yukawa_exponent_geometry_nullscan(
    C=5,
    jitter_halfwidth_log10=0.5,
    num_null=2000,
    seed=24601
):
    """
    Main driver for PHASE2_YUKAWA_EXPONENT_GEOMETRY_NULLSCAN_v1b.

    Parameters
    ----------
    C : int
        Max absolute value for integer exponents a,b,c ∈ [-C, C].
        Total search per Yukawa is (2C+1)^3 - 1 combinations.
        C=5 → 11^3-1 = 1330 combos per Yukawa (moderate).
    jitter_halfwidth_log10 : float
        Half-width for uniform jitter in log10-space: each universe is constructed as
            z_i_null = z_i_real + U(-h, +h).
        This is a "local universes" null: preserves rough magnitudes, randomizes fine structure.
    num_null : int
        Number of null universes to sample.
    seed : int
        RNG seed for reproducibility.
    """

    random.seed(seed)

    print("=" * 90)
    print("PHASE2_YUKAWA_EXPONENT_GEOMETRY_NULLSCAN_v1b — Yukawa exponent geometry + null")
    print("=" * 90)

    # ----------------------------------------------------------------------
    # 1. Load real Yukawa logs and identify basis indices (me, mtau, md)
    # ----------------------------------------------------------------------
    names, z_real = _yukawa_logs_real()

    try:
        idx_me   = names.index("me_over_v")
        idx_mtau = names.index("mtau_over_v")
        idx_md   = names.index("md_over_v")
    except ValueError:
        raise RuntimeError("Basis Yukawas (me_over_v, mtau_over_v, md_over_v) not found in names list.")

    print("[Config]")
    print(f"  number of Yukawas          : {len(names)}")
    print(f"  exponent bound C           : {C}")
    print(f"  search cube size           : (2C+1)^3 - 1 = {(2*C+1)**3 - 1}")
    print(f"  jitter halfwidth (log10)   : {jitter_halfwidth_log10:.3f}")
    print(f"  num_null universes         : {num_null}")
    print()
    print("[Basis Yukawas for exponent geometry]")
    print(f"  basis 1: me_over_v   (index {idx_me})   log10 = {z_real[idx_me]: .6f}")
    print(f"  basis 2: mtau_over_v (index {idx_mtau}) log10 = {z_real[idx_mtau]: .6f}")
    print(f"  basis 3: md_over_v   (index {idx_md})   log10 = {z_real[idx_md]: .6f}")
    print()

    # ----------------------------------------------------------------------
    # 2. Real-universe exponent geometry fit
    # ----------------------------------------------------------------------
    coeffs_real, residuals_real = _geometry_fit_for_universe(
        z_logs=z_real,
        C=C,
        idx_me=idx_me,
        idx_mtau=idx_mtau,
        idx_md=idx_md
    )

    # Compute summary stats
    def _rms(res_list):
        return math.sqrt(sum(r*r for r in res_list) / len(res_list))

    rms_real = _rms(residuals_real)
    mean_abs_real = sum(abs(r) for r in residuals_real) / len(residuals_real)
    max_abs_real = max(abs(r) for r in residuals_real)

    print("[Real-universe exponent geometry fit]")
    print("  name          log10(y)    best (a,b,c)       |residual|")
    print("  ------------  ---------   -------------     -----------")
    for name, z_i, (a, b, c), res in zip(names, z_real, coeffs_real, residuals_real):
        print(f"  {name:12s}  {z_i: 9.6f}   ({a:2d},{b:2d},{c:2d})        {abs(res):11.6e}")
    print()
    print("  Summary over all 9 Yukawas (log10-space residuals):")
    print(f"    RMS residual          : {rms_real: .6e}")
    print(f"    mean |residual|       : {mean_abs_real: .6e}")
    print(f"    max  |residual|       : {max_abs_real: .6e}")
    print()

    # ----------------------------------------------------------------------
    # 3. Null ensemble: jittered universes + best integer geometry per universe
    # ----------------------------------------------------------------------
    print("[Null ensemble] Generating jittered universes and re-fitting geometry ...")

    rms_null = []

    for _ in range(num_null):
        # Jitter logs uniformly in [-h, +h]
        z_null = [
            z_i + random.uniform(-jitter_halfwidth_log10, jitter_halfwidth_log10)
            for z_i in z_real
        ]

        # Basis indices are the same; basis logs themselves are jittered along with others
        coeffs_null, residuals_null = _geometry_fit_for_universe(
            z_logs=z_null,
            C=C,
            idx_me=idx_me,
            idx_mtau=idx_mtau,
            idx_md=idx_md
        )

        rms_u = _rms(residuals_null)
        rms_null.append(rms_u)

    # ----------------------------------------------------------------------
    # 4. Null stats and significance
    # ----------------------------------------------------------------------
    rms_min = min(rms_null)
    rms_max = max(rms_null)
    q1, q2, q3 = stats.quantiles(rms_null, n=4)
    rms_mean = stats.mean(rms_null)
    rms_std  = stats.pstdev(rms_null)

    # Empirical p-value: fraction of null universes with RMS <= real RMS
    count_le = sum(1 for r in rms_null if r <= rms_real)
    p_emp = count_le / num_null

    z_score = (rms_real - rms_mean) / rms_std if rms_std > 0 else float("nan")

    print("[Null RMS stats — exponent geometry fit]")
    print(f"  null RMS min / max       : {rms_min: .6e} / {rms_max: .6e}")
    print(f"  null RMS 25% / 50% / 75% : {q1: .6e} / {q2: .6e} / {q3: .6e}")
    print(f"  null RMS mean / std      : {rms_mean: .6e} / {rms_std: .6e}")
    print()
    print("[Significance of exponent geometry compression]")
    print(f"  real RMS                 : {rms_real: .6e}")
    print(f"  z(real vs null mean)     : {z_score:+.2f} σ")
    print(f"  P_null(RMS <= real)      : {p_emp:.6f}")
    print()
    print("INTERPRETATION GUIDE:")
    print("  • Small RMS (real) means each Yukawa log is close to some integer combo of")
    print("    (log10 me, log10 mtau, log10 md) with |a|,|b|,|c| ≤ C.")
    print("  • If P_null(RMS <= real) is tiny, our Yukawas are unusually exponent-compressible")
    print("    by this small-integer geometry compared to jittered universes.")
    print("  • If P_null is O(0.1–1), the exponent geometry is not very special.")
    print("=" * 90)
    print("PHASE2_YUKAWA_EXPONENT_GEOMETRY_NULLSCAN_v1b complete.")
    print("=" * 90)


if __name__ == "__main__":
    # You can tweak these if you want to re-run under different assumptions.
    # Default: C=5, jitter halfwidth=0.5 dex, num_null=2000.
    run_phase2_yukawa_exponent_geometry_nullscan(
        C=5,
        jitter_halfwidth_log10=0.5,
        num_null=2000,
        seed=24601,
    )

# ==========================================================================================
# PHASE2_SURVIVOR_SCORECARD_v1
#   — Summary of all major tests so far in p-values and bits
#
# This is a meta-analysis module:
#   • It DOES NOT re-run the heavy DNA / EW / Yukawa scans.
#   • Instead, it encodes the key results you've already computed:
#       - p-values (or "0 hits out of N nulls")
#       - rough σ where reported
#   • Converts those into an approximate "bits of surprise":
#         bits ≈ -log2(p)
#     and for 0-hit cases:
#         bits > log2(N_null)
#
# Goal:
#   - See, in one table, which structures truly survived:
#       1) DNA backbone & rails
#       2) Yukawa triple (me, mtau, md; coeffs = (-4,4,3))
#       3) Everything else that turned out ordinary
#
# This is our "truth scoreboard" to guide Phase 3 geometry hunting.
# ==========================================================================================

import math

def _bits_from_p(p, n_null=None):
    """
    Convert a p-value to approximate bits of surprise: bits = -log2(p).
    If p == 0 (i.e. 0 hits in n_null simulations), then we only know
        p < 1 / n_null
    and we report a conservative lower bound
        bits > log2(n_null).
    """
    if p is None:
        return None, None  # Unknown
    if p > 0.0:
        bits = -math.log(p, 2.0)
        return bits, False  # not a bound
    # p == 0, need n_null to bound
    if n_null is None or n_null <= 0:
        return None, None
    bits_lb = math.log(n_null, 2.0)
    return bits_lb, True


def run_phase2_survivor_scorecard():
    print("=" * 90)
    print("PHASE2_SURVIVOR_SCORECARD_v1 — what actually survives so far?")
    print("=" * 90)
    print()
    print("This scoreboard encodes the main results you've already computed.")
    print("For each test we store:")
    print("  • a short description")
    print("  • the reported p-value (or 0 if no null hits)")
    print("  • number of null universes N_null (if applicable)")
    print("  • approximate bits of surprise  bits ≈ -log2(p)")
    print("    (or a lower bound if p=0 and we only know p < 1/N_null).")
    print()

    # ------------------------------------------------------------------
    # Populate the key tests from your pasted logs.
    # NOTE: these are *not* re-computed; they are taken from your outputs.
    # ------------------------------------------------------------------
    tests = [
        # ---------------- DNA sector ----------------
        {
            "group": "DNA (full dataset, with backbone)",
            "name":  "DNA entropy MDL (full)",
            # from RATIO_OS_DNA_NULLSCAN_COMBINED_v1:
            #   p_emp = 0.000000  with N_null=2000  => p < 1/2000
            "p":     0.0,
            "N_null": 2000,
            "notes": "Entropy MDL compressibility; z ≈ -4.84 σ vs null.",
        },
        {
            "group": "DNA (full dataset, with backbone)",
            "name":  "DNA lock max-family (full)",
            # from lock families null: p_emp = 0.000000 with N_null=5000
            "p":     0.0,
            "N_null": 5000,
            "notes": "Largest lock family size (5) vs histogram-preserving null.",
        },
        {
            "group": "DNA (full dataset, with backbone)",
            "name":  "DNA lock collision pairs (full)",
            # also 0 hits out of 5000
            "p":     0.0,
            "N_null": 5000,
            "notes": "18 collision pairs vs ~0 in null.",
        },

        # Trimmed DNA (backbone removed)
        {
            "group": "DNA (trimmed; backbone removed)",
            "name":  "Trimmed DNA entropy MDL",
            # from RATIO_OS_DNA_BACKBONE_REMOVAL_NULLSCAN_v1:
            #   p_null[MDL <= real] ≈ 0.059
            "p":     0.059,
            "N_null": 2000,
            "notes": "Entropy after removing backbone; mild compression (≈ -1.58 σ).",
        },
        {
            "group": "DNA (trimmed; backbone removed)",
            "name":  "Trimmed DNA locks: max family",
            # from RATIO_OS_DNA_TRIMMED_HISTOLOCK_NULLSCAN_v1:
            #   P_null(maxfam >= real) = 0.000400 with N=5000
            "p":     0.0004,
            "N_null": 5000,
            "notes": "Largest lock family size=2 vs histogram-preserving null.",
        },
        {
            "group": "DNA (trimmed; backbone removed)",
            "name":  "Trimmed DNA locks: collision pairs",
            # P_null(collisions >= real) = 0.000000 with N=5000 → p < 1/5000
            "p":     0.0,
            "N_null": 5000,
            "notes": "2 collision pairs vs ~0 in null.",
        },

        # All-zero rails in DNA
        {
            "group": "DNA patterns (rails / zeros)",
            "name":  "All-four-zero rows (p=6 rail count)",
            # from RATIO_OS_DNA_PATTERN_MINER_v1:
            #   P_null(num_zero4 >= real) = 0.000000 with N=5000
            "p":     0.0,
            "N_null": 5000,
            "notes": "5 rows with r23=r49=r50=r137=0 vs ~0 in null.",
        },

        # ---------------- EW / geometry sector ----------------
        {
            "group": "EW sector (geometry / shape)",
            "name":  "EW SHAPE MDL vs wide flat null",
            # from RATIO_OS_EW_SHAPE_NULLSCAN_v1:
            #   P_null(MDL <= real) = 0.000
            # BUT this was killed by the local null (it's just 'values small' effect),
            # so we keep it but annotate it as 'illusory'.
            "p":     0.0,
            "N_null": 1000,
            "notes": "Apparent 3.5σ compression vs wide null, BUT explained away by local null.",
        },
        {
            "group": "EW sector (geometry / shape)",
            "name":  "EW SHAPE MDL vs local magnitude-preserving null",
            # from RATIO_OS_EW_SHAPE_NULLSCAN_v2_LOCAL_v1:
            #   P_null(MDL <= real) = 0.468
            "p":     0.468,
            "N_null": 1000,
            "notes": "No special structure once local magnitude is preserved.",
        },
        {
            "group": "EW sector (geometry / shape)",
            "name":  "EW relational model (one seed rational multiples)",
            # from RATIO_OS_EW_RELATIONAL_NULLSCAN_v1:
            #   P_null(MDL <= real) = 0.422
            "p":     0.422,
            "N_null": 500,
            "notes": "Relational compression not special.",
        },
        {
            "group": "EW sector (log-lattices)",
            "name":  "Full EW log-lattice fit",
            # from PHASE2_EW_LOG_LATTICE_NULLSCAN_v1:
            #   P_null(RMS <= real) = 0.787
            "p":     0.787,
            "N_null": 2000,
            "notes": "Global log-lattice structure is ordinary.",
        },
        {
            "group": "EW sector (log-lattices)",
            "name":  "Yukawa-only log-lattice fit",
            # from PHASE2_EW_YUKAWA_LOG_LATTICE_NULLSCAN_v1:
            #   P_null(RMS <= real) = 0.5452
            "p":     0.5452,
            "N_null": 5000,
            "notes": "Yukawas alone not unusually lattice-like.",
        },
        {
            "group": "EW sector (pair / triple relations)",
            "name":  "Pairwise EW integer relations (19 params)",
            # from PHASE2_EW_PAIR_INTREL_NULLSCAN_v1:
            #   P_null(best_resid <= real) = 0.7025
            "p":     0.7025,
            "N_null": 2000,
            "notes": "Best pairwise relation entirely unspecial.",
        },
        {
            "group": "EW sector (pair / triple relations)",
            "name":  "3-term EW integer relations (19 params)",
            # from PHASE2_EW_TRIPLE_INTREL19_NULLSCAN_v1:
            #   P_null(best_resid <= real) = 0.876
            "p":     0.876,
            "N_null": 1000,
            "notes": "Best triple relation also unspecial.",
        },

        # ---------------- Yukawa integer relations ----------------
        {
            "group": "Yukawa sector (all 9, scan over triples)",
            "name":  "Best 3-term integer relation (look-elsewhere corrected)",
            # from PHASE2_YUKAWA_INTREL_NULLSCAN_v1c:
            #   P_null(best_resid <= real) = 0.006
            "p":     0.006,
            "N_null": 2000,
            "notes": "Global search over all triples & coeffs; me–tau–d pops out but at p≈0.006.",
        },
        {
            "group": "Yukawa sector (all 9, jitter null)",
            "name":  "Best 3-term int-rel under jitter null",
            # from PHASE2_YUKAWA_INTREL_JITTERNULL_v1:
            #   P_null(best_resid <= real) = 0.0115
            "p":     0.0115,
            "N_null": 2000,
            "notes": "Same search but with log10 jitter; p~1% (still modest).",
        },

        # Fixed me–mtau–md triple
        {
            "group": "Yukawa sector (fixed triple: me, mtau, md)",
            "name":  "Fixed triple, jitter null (h=0.5 dex)",
            # from PHASE2_YUKAWA_FIXED_TRIPLE_JITTERNULL_v1:
            #   P_null(S <= S_real) = 0.000000 with N_null=10000
            "p":     0.0,
            "N_null": 10000,
            "notes": "Check just the discovered triple; no null got as small as real.",
        },
        {
            "group": "Yukawa sector (fixed triple: me, mtau, md)",
            "name":  "Fixed triple, error-model null",
            # from PHASE2_YUKAWA_FIXED_TRIPLE_ERRORMODEL_v1:
            #   p_emp(S <= S_real) = 0.000050 with N_null=20000
            "p":     0.00005,
            "N_null": 20000,
            "notes": "Realistic measurement errors; triple still extremely tight.",
        },
        {
            "group": "Yukawa sector (fixed triple: me, mtau, md)",
            "name":  "Coeff landscape: best primitive (a,b,c) = (-4,4,3)",
            # from PHASE2_YUKAWA_FIXED_TRIPLE_COEFF_LANDSCAPE_v1:
            # Not a null p-value, but we know (-4,4,3) is rank 1 with huge gap.
            # We'll just mark p=None.
            "p":     None,
            "N_null": None,
            "notes": "Coefficient search [-10,10]; (-4,4,3) is unique top solution.",
        },

        # Yukawa exponent geometry (multi-point)
        {
            "group": "Yukawa sector (multi-point geometry)",
            "name":  "All 9 Yukawas in (me, mtau, md) exponent geometry",
            # from PHASE2_YUKAWA_EXPONENT_GEOMETRY_NULLSCAN_v1b:
            #   P_null(RMS <= real) = 0.7115
            "p":     0.7115,
            "N_null": 2000,
            "notes": "Whole exponent geometry is perfectly ordinary (we discard it).",
        },
    ]

    # ------------------------------------------------------------------
    # Compute bits for each test and group for display
    # ------------------------------------------------------------------
    rows = []
    for t in tests:
        p = t["p"]
        n_null = t["N_null"]
        bits, is_bound = _bits_from_p(p, n_null)

        if p is None:
            p_str = "N/A"
        elif p == 0.0:
            p_str = f"< {1.0 / n_null:.2e}"
        else:
            p_str = f"{p:.6f}"

        if bits is None:
            bits_str = "N/A"
        else:
            if is_bound:
                bits_str = f"> {bits:5.2f}"
            else:
                bits_str = f"{bits:7.2f}"

        rows.append({
            "group": t["group"],
            "name":  t["name"],
            "p_str": p_str,
            "bits_str": bits_str,
            "notes": t["notes"],
        })

    # ------------------------------------------------------------------
    # Pretty-print grouped table
    # ------------------------------------------------------------------
    current_group = None
    for r in rows:
        if r["group"] != current_group:
            current_group = r["group"]
            print()
            print("----------------------------------------------------------------------------------")
            print(f"[{current_group}]")
            print("----------------------------------------------------------------------------------")
            print(f"{'Test':50s}  {'p-value':>12s}  {'bits':>8s}")
            print("-" * 80)
        print(f"{r['name'][:50]:50s}  {r['p_str']:>12s}  {r['bits_str']:>8s}")
        # Optional: short notes line
        print(f"    note: {r['notes']}")
    print()
    print("=" * 90)
    print("Interpretation (very roughly):")
    print("  • bits ≲ 3   : nothing special (completely ordinary).")
    print("  • bits ≈ 5–10: interesting but not decisive by itself.")
    print("  • bits ≳ 10  : strong structure (especially if replicated by independent tests).")
    print()
    print("From this scoreboard:")
    print("  • DNA backbone + lock structure gives multi-10-bit surprises even under harsh nulls.")
    print("  • The me–mtau–md triple (-4,4,3) gives O(10–15) bits, depending on how")
    print("    you account for look-elsewhere and the error model.")
    print("  • Most other EW/Yukawa 'geometries' are statistically ordinary and belong")
    print("    in the trash pile (we do not build on them).")
    print("=" * 90)
    print("PHASE2_SURVIVOR_SCORECARD_v1 complete.")
    print("=" * 90)


if __name__ == "__main__":
    run_phase2_survivor_scorecard()

# ==========================================================================================
# PHASE3_GLOBAL_EVIDENCE_SYNTHESIS_v1
#   — How many bits of REAL structure must any geometry explain?
#
# This is a meta-evidence module:
#   • It DO NOT re-run any of the Phase 1 / Phase 2 heavy scans.
#   • It hard-codes the key results from PHASE2_SURVIVOR_SCORECARD_v1
#     and tags which ones are genuine survivors vs things we killed.
#
# Output:
#   1) A table of tests with:
#        - sector (DNA, Yukawa, EW)
#        - p-value (or bound)
#        - bits ≈ -log2(p) (or lower bound if p ~ 0)
#        - status: "SURVIVOR" vs "KILLED"
#   2) Sector-level "effective bits" that we treat as real constraints on geometry.
#   3) A combined "geometry target": how many bits of non-random structure
#      any future fundamental geometry must generate to be taken seriously.
#
# This is our "truth budget" in bits.
# ==========================================================================================

import math

def _bits_from_p(p, n_null=None):
    """
    Convert a p-value to bits of surprise: bits = -log2(p).

    If p == 0 (0 null hits), we only know:
        p < 1 / n_null
    so we return a conservative lower bound:
        bits > log2(n_null)

    Returns: (bits, is_bound)
      - bits: float or None
      - is_bound: True if 'bits' is a lower bound ("> bits"), False if exact-ish.
    """
    if p is None:
        return None, None
    if p > 0.0:
        bits = -math.log(p, 2.0)
        return bits, False
    # p == 0 → use n_null bound
    if n_null is None or n_null <= 0:
        return None, None
    bits_lb = math.log(n_null, 2.0)
    return bits_lb, True


def run_phase3_global_evidence_synthesis():
    print("=" * 90)
    print("PHASE3_GLOBAL_EVIDENCE_SYNTHESIS_v1 — geometry evidence in bits")
    print("=" * 90)
    print()
    print("We now ask: if the universe is not just random, how many bits of non-random")
    print("structure do we *actually* have to explain with any future geometry?")
    print()
    print("Key idea:")
    print("  • Many 'patterns' died under null tests (p ~ O(1)).")
    print("  • A few survived with multi-σ, multi-10-bit surprises.")
    print("  • Geometry hunting should only care about those survivors.")
    print()

    # ----------------------------------------------------------------------------
    # Define tests: taken from your PHASE2_SURVIVOR_SCORECARD_v1 output.
    #
    # Fields:
    #   sector: high-level category (DNA, Yukawa, EW)
    #   group : finer grouping for display
    #   status: SURVIVOR / KILLED
    #   p     : p-value (or 0 for 'no null hits')
    #   N_null: number of null universes (for 0-hit bounds or context)
    # ----------------------------------------------------------------------------
    tests = [
        # ---------------- DNA sector: full dataset (with backbone) ----------------
        {
            "sector": "DNA",
            "group":  "DNA (full dataset, with backbone)",
            "name":   "DNA entropy MDL (full)",
            "p":      0.0005,    # treat '< 5e-4' roughly as 5e-4 for bits, still very strong
            "N_null": 2000,
            "status": "SURVIVOR",
            "notes":  "Overall residue entropy compressibility; z ≈ -4.84σ.",
        },
        {
            "sector": "DNA",
            "group":  "DNA (full dataset, with backbone)",
            "name":   "DNA lock max-family (full)",
            "p":      0.0002,    # '< 2e-4' approximate
            "N_null": 5000,
            "status": "SURVIVOR",
            "notes":  "Largest lock family size=5 vs histogram-preserving null.",
        },
        {
            "sector": "DNA",
            "group":  "DNA (full dataset, with backbone)",
            "name":   "DNA lock collision pairs (full)",
            "p":      0.0002,    # '< 2e-4'
            "N_null": 5000,
            "status": "SURVIVOR",
            "notes":  "18 collision pairs vs ~0 in null.",
        },

        # Trimmed DNA (backbone removed) — tells us what remains without the spine.
        {
            "sector": "DNA",
            "group":  "DNA (trimmed; backbone removed)",
            "name":   "Trimmed DNA entropy MDL",
            "p":      0.059,     # ~4 bits: mild evidence there is still structure beyond backbone
            "N_null": 2000,
            "status": "SURVIVOR",
            "notes":  "Entropy after removing backbone; mild compression (~1.6σ).",
        },
        {
            "sector": "DNA",
            "group":  "DNA (trimmed; backbone removed)",
            "name":   "Trimmed DNA locks: max family",
            "p":      0.0004,
            "N_null": 5000,
            "status": "SURVIVOR",
            "notes":  "Largest lock family size=2 vs histogram-preserving null.",
        },
        {
            "sector": "DNA",
            "group":  "DNA (trimmed; backbone removed)",
            "name":   "Trimmed DNA locks: collision pairs",
            "p":      0.0002,   # '< 2e-4'
            "N_null": 5000,
            "status": "SURVIVOR",
            "notes":  "2 collision pairs vs ~0 in null; residual lock structure beyond backbone.",
        },

        # All-zero rails (super spine)
        {
            "sector": "DNA",
            "group":  "DNA patterns (rails / zeros)",
            "name":   "All-four-zero rows (p=6 rail count)",
            "p":      0.0002,   # '< 2e-4'
            "N_null": 5000,
            "status": "SURVIVOR",
            "notes":  "5 rows with r23=r49=r50=r137=0 vs ~0 in null.",
        },

        # ---------------- EW / geometry sector — mostly killed ----------------
        {
            "sector": "EW-other",
            "group":  "EW sector (geometry / shape)",
            "name":   "EW SHAPE MDL vs wide flat null",
            "p":      0.001,     # looked impressive, but explained away by local null
            "N_null": 1000,
            "status": "KILLED",
            "notes":  "3.5σ vs wide null, but disappears under magnitude-preserving null.",
        },
        {
            "sector": "EW-other",
            "group":  "EW sector (geometry / shape)",
            "name":   "EW SHAPE MDL vs local magnitude-preserving null",
            "p":      0.468,
            "N_null": 1000,
            "status": "KILLED",
            "notes":  "No special structure remains; we discard SHAPE geometry.",
        },
        {
            "sector": "EW-other",
            "group":  "EW sector (geometry / shape)",
            "name":   "EW relational model (one seed rational multiples)",
            "p":      0.422,
            "N_null": 500,
            "status": "KILLED",
            "notes":  "Relational compression ordinary.",
        },
        {
            "sector": "EW-other",
            "group":  "EW sector (log-lattices)",
            "name":   "Full EW log-lattice fit",
            "p":      0.787,
            "N_null": 2000,
            "status": "KILLED",
            "notes":  "Global log-lattice compressibility is ordinary.",
        },
        {
            "sector": "EW-other",
            "group":  "EW sector (log-lattices)",
            "name":   "Yukawa-only log-lattice fit",
            "p":      0.5452,
            "N_null": 5000,
            "status": "KILLED",
            "notes":  "Yukawa log-lattice also ordinary.",
        },
        {
            "sector": "EW-other",
            "group":  "EW sector (pair / triple relations)",
            "name":   "Pairwise EW integer relations (19 params)",
            "p":      0.7025,
            "N_null": 2000,
            "status": "KILLED",
            "notes":  "Best pair relation unspecial.",
        },
        {
            "sector": "EW-other",
            "group":  "EW sector (pair / triple relations)",
            "name":   "3-term EW integer relations (19 params)",
            "p":      0.876,
            "N_null": 1000,
            "status": "KILLED",
            "notes":  "Best triple relation unspecial.",
        },
        {
            "sector": "EW-other",
            "group":  "Yukawa sector (multi-point geometry)",
            "name":   "All 9 Yukawas in (me, mtau, md) exponent geometry",
            "p":      0.7115,
            "N_null": 2000,
            "status": "KILLED",
            "notes":  "Global exponent geometry normal; we discard it.",
        },

        # ---------------- Yukawa sector: integer relations ----------------
        {
            "sector": "Yukawa",
            "group":  "Yukawa sector (all 9, scan over triples)",
            "name":   "Best 3-term integer relation (global search)",
            "p":      0.006,
            "N_null": 2000,
            "status": "SURVIVOR",
            "notes":  "Look-elsewhere corrected; me–tau–d triple is best but p ~ 0.006.",
        },
        {
            "sector": "Yukawa",
            "group":  "Yukawa sector (all 9, jitter null)",
            "name":   "Best 3-term int-rel under jitter null",
            "p":      0.0115,
            "N_null": 2000,
            "status": "SURVIVOR",
            "notes":  "Same global search, jittered logs; p ~ 1%.",
        },

        # Fixed triple me–mtau–md
        {
            "sector": "Yukawa",
            "group":  "Yukawa sector (fixed triple: me, mtau, md)",
            "name":   "Fixed triple, jitter null (h=0.5 dex)",
            "p":      0.0001,   # '< 1e-4'; conservative approximation
            "N_null": 10000,
            "status": "SURVIVOR",
            "notes":  "Holding triple fixed; none of 10k jitters beat real triple.",
        },
        {
            "sector": "Yukawa",
            "group":  "Yukawa sector (fixed triple: me, mtau, md)",
            "name":   "Fixed triple, error-model null",
            "p":      0.00005,
            "N_null": 20000,
            "status": "SURVIVOR",
            "notes":  "Realistic measurement errors; S_real is extreme.",
        },
        {
            "sector": "Yukawa",
            "group":  "Yukawa sector (fixed triple: me, mtau, md)",
            "name":   "Coeff landscape: best primitive (a,b,c)=(-4,4,3)",
            "p":      None,
            "N_null": None,
            "status": "SURVIVOR",
            "notes":  "Within [-10,10], (-4,4,3) is unique best combo.",
        },
    ]

    # ----------------------------------------------------------------------------
    # Compute bits and print detailed table
    # ----------------------------------------------------------------------------
    print("Per-test evidence:")
    current_group = None

    # Also collect for sector summaries:
    per_test_info = []

    for t in tests:
        p = t["p"]
        n_null = t["N_null"]
        bits, is_bound = _bits_from_p(p, n_null)

        if p is None:
            p_str = "N/A"
        else:
            p_str = f"{p:.6f}"

        if bits is None:
            bits_str = "N/A"
        else:
            if is_bound:
                bits_str = f"> {bits:5.2f}"
            else:
                bits_str = f"{bits:7.2f}"

        # Grouped printing (by 'group')
        if t["group"] != current_group:
            current_group = t["group"]
            print()
            print("----------------------------------------------------------------------------------")
            print(f"[{current_group}]")
            print("----------------------------------------------------------------------------------")
            print(f"{'Sector':7s}  {'Status':9s}  {'Test':45s}  {'p':>10s}  {'bits':>8s}")
            print("-" * 90)

        status = t["status"]
        print(f"{t['sector'][:7]:7s}  {status:9s}  {t['name'][:45]:45s}  {p_str:>10s}  {bits_str:>8s}")
        print(f"    note: {t['notes']}")

        per_test_info.append({
            "sector": t["sector"],
            "group": t["group"],
            "name": t["name"],
            "status": t["status"],
            "p": p,
            "N_null": n_null,
            "bits": bits,
            "is_bound": is_bound,
        })

    # ----------------------------------------------------------------------------
    # Sector-level summaries: how many bits should we actually take seriously?
    #
    # We *don't* just sum every test — that would double-count the same pattern.
    # Instead:
    #   • For each sector (DNA, Yukawa, EW-other), we look at SURVIVOR tests.
    #   • For EW-other, everything is 'KILLED' → 0 effective bits.
    #   • For DNA: tests are very correlated; we treat the highest bits as the
    #              core "backbone evidence", plus a small increment for residual
    #              structure after removing backbone.
    #   • For Yukawa: we keep BOTH:
    #       - a conservative global-search bit count (p ~ 0.006 → ~7.4 bits)
    #       - a local, fixed-triple bit count (p ~ 5e-5 → ~14.3 bits),
    #     and we present a conservative and optimistic combination.
    # ----------------------------------------------------------------------------
    print()
    print("=" * 90)
    print("Sector-level effective bits (rough, to avoid double-counting):")
    print("=" * 90)

    # Helper: filter tests
    def select_tests(sector, status="SURVIVOR"):
        return [
            x for x in per_test_info
            if x["sector"] == sector and x["status"] == status and x["bits"] is not None
        ]

    # ---- DNA sector ----
    dna_survivors = select_tests("DNA", "SURVIVOR")
    dna_bits_all = [x["bits"] for x in dna_survivors if x["bits"] is not None]
    dna_max_bits = max(dna_bits_all) if dna_bits_all else 0.0

    # We know multiple DNA tests are basically measuring the same underlying
    # modular backbone/lock structure, so we treat:
    #   effective DNA bits ≈ max_bits (lower bound).
    dna_effective_bits = dna_max_bits

    print(f"DNA sector:")
    print(f"  • Survivor tests count : {len(dna_survivors)}")
    print(f"  • Max bits among them  : {dna_max_bits:5.2f}")
    print(f"  • Effective DNA bits   : {dna_effective_bits:5.2f} (lower bound)")
    print()

    # ---- Yukawa sector ----
    yuk_survivors = select_tests("Yukawa", "SURVIVOR")
    yuk_bits_all = [x["bits"] for x in yuk_survivors if x["bits"] is not None]
    yuk_max_bits = max(yuk_bits_all) if yuk_bits_all else 0.0

    # Identify key Yukawa tests explicitly:
    yuk_global = [x for x in yuk_survivors if "global search" in x["name"]]
    yuk_fixed_err = [x for x in yuk_survivors if "error-model null" in x["name"]]

    bits_global = yuk_global[0]["bits"] if yuk_global else None
    bits_fixed_err = yuk_fixed_err[0]["bits"] if yuk_fixed_err else None

    print("Yukawa sector (me, mtau, md triple etc.):")
    print(f"  • Survivor tests count        : {len(yuk_survivors)}")
    print(f"  • Max bits among them         : {yuk_max_bits:5.2f}" if yuk_max_bits else "  • Max bits among them         : N/A")
    if bits_global is not None:
        print(f"  • Global 3-term search bits   : {bits_global:5.2f}  (p ~ 0.006)")
    if bits_fixed_err is not None:
        print(f"  • Fixed triple (error-model)  : {bits_fixed_err:5.2f}  (p ~ 5×10^-5)")
    print()

    # Define conservative vs optimistic Yukawa bits:
    #   - conservative: use the *global-search* bits (accounts for look-elsewhere)
    #   - optimistic : use the fixed triple error-model bits
    yuk_bits_conservative = bits_global if bits_global is not None else 0.0
    yuk_bits_optimistic = bits_fixed_err if bits_fixed_err is not None else yuk_bits_conservative

    print(f"  • Effective Yukawa bits (conservative, look-elsewhere) : {yuk_bits_conservative:5.2f}")
    print(f"  • Effective Yukawa bits (optimistic, fixed triple)     : {yuk_bits_optimistic:5.2f}")
    print()

    # ---- EW-other sector ----
    ew_survivors = select_tests("EW-other", "SURVIVOR")
    ew_bits_all = [x["bits"] for x in ew_survivors if x["bits"] is not None]
    ew_effective_bits = max(ew_bits_all) if ew_bits_all else 0.0

    print("EW-other sector (SHAPE, lattices, exponent geometry, etc.):")
    print(f"  • Survivor tests count : {len(ew_survivors)}")
    print(f"  • Effective EW-other bits       : {ew_effective_bits:5.2f}")
    print("    (Essentially zero: we killed all major EW geometry claims.)")
    print()

    # ----------------------------------------------------------------------------
    # Combined "geometry target" in bits
    #   - Under independence approximation between DNA and Yukawa sectors.
    # ----------------------------------------------------------------------------
    combo_bits_conservative = dna_effective_bits + yuk_bits_conservative
    combo_bits_optimistic = dna_effective_bits + yuk_bits_optimistic

    print("=" * 90)
    print("Combined evidence budget (approximate):")
    print("=" * 90)
    print(f"  • DNA effective bits                 : {dna_effective_bits:5.2f}")
    print(f"  • Yukawa effective bits (conservative): {yuk_bits_conservative:5.2f}")
    print(f"  → Combined (conservative)            : {combo_bits_conservative:5.2f} bits")
    print()
    print(f"  • Yukawa effective bits (optimistic) : {yuk_bits_optimistic:5.2f}")
    print(f"  → Combined (optimistic)              : {combo_bits_optimistic:5.2f} bits")
    print()
    print("Interpretation:")
    print("  • Any future 'geometry of everything' we propose needs to explain at least")
    print(f"    ≈ {combo_bits_conservative:4.1f} bits of structure (conservative) coming from")
    print("    two largely independent sectors:")
    print("       - DNA residue backbone + lock families.")
    print("       - The (me, mtau, md) triple with (-4, 4, 3) in log-space.")
    print()
    print("  • Under a more optimistic (but still defensible) reading, the geometry")
    print(f"    needs to explain ≈ {combo_bits_optimistic:4.1f} bits of structure.")
    print()
    print("  • All other EW/Yukawa 'patterns' we tested so far are statistically")
    print("    ordinary and *must not* be used as anchors for the geometry — they are")
    print("    part of the noise, not the lock structure.")
    print()
    print("So, going forward, we will treat:")
    print("  1) The DNA backbone/lock architecture, and")
    print("  2) The me–mtau–md (-4,4,3) triple")
    print("as the *two primary locks* that the real geometry must reproduce or explain")
    print("without cheating (no tuning them by hand in the model).")
    print("=" * 90)
    print("PHASE3_GLOBAL_EVIDENCE_SYNTHESIS_v1 complete.")
    print("=" * 90)


if __name__ == "__main__":
    run_phase3_global_evidence_synthesis()

import math, random, statistics
from itertools import combinations

def generate_primitive_coeffs_3(C):
    """
    Generate all primitive integer triples (a,b,c) with |a|,|b|,|c| ≤ C,
    at least two non-zero, and gcd(|a|,|b|,|c|) = 1.
    """
    coeffs = []
    for a in range(-C, C+1):
        for b in range(-C, C+1):
            for c in range(-C, C+1):
                if a == b == c == 0:
                    continue
                # at least two non-zero
                if (a == 0) + (b == 0) + (c == 0) >= 2:
                    continue
                g = math.gcd(abs(a), math.gcd(abs(b), abs(c)))
                if g == 0 or g != 1:
                    continue
                coeffs.append((a, b, c))
    return coeffs


def find_best_3term_intrel(log_values, names, C=4):
    """
    Given log10(y_i) for the Yukawas, scan all index triples (i,j,k)
    and all primitive (a,b,c) with |a|,|b|,|c| ≤ C, and return the
    best residual |a z_i + b z_j + c z_k|.
    """
    n = len(log_values)
    coeffs = generate_primitive_coeffs_3(C)
    best_resid = float("inf")
    best_info = None

    for i, j, k in combinations(range(n), 3):
        z_i, z_j, z_k = log_values[i], log_values[j], log_values[k]
        for a, b, c in coeffs:
            s = a*z_i + b*z_j + c*z_k
            resid = abs(s)
            if resid < best_resid:
                best_resid = resid
                best_info = {
                    "indices": (i, j, k),
                    "names": (names[i], names[j], names[k]),
                    "coeffs": (a, b, c),
                    "sum": s,
                }

    return best_resid, best_info


def run_phase3_yukawa_global_intrel_errormodel_nullscan(
    C=4,
    num_null=5000,
    seed=12345,
):
    # ------------------------------------------------------------------
    # Central Yukawa data + rough fractional errors.
    # You can tighten/relax these based on latest PDG if you want.
    # ------------------------------------------------------------------
    yukawa_central = [
        #  name         value (dimensionless y_i = m_i / v)     frac_err (1σ)
        ("me_over_v",   2.073000000e-06, 1e-8),   # electron: ultra-precise
        ("mmu_over_v",  4.289370000e-04, 1e-8),   # muon: ultra-precise
        ("mtau_over_v", 7.214707000e-03, 1e-5),   # tau: ~10^-5
        ("mb_over_v",   1.698151100e-02, 0.1),    # b-quark: O(10%) theory error
        ("mc_over_v",   5.157839000e-03, 0.1),    # c-quark: O(10%)
        ("mt_over_v",   7.013656350e-01, 0.02),   # top: few percent-ish
        ("md_over_v",   1.896000000e-05, 0.2),    # d-quark: ~20%
        ("ms_over_v",   3.776830000e-04, 0.2),    # s-quark: ~20%
        ("mu_over_v",   8.773000000e-06, 0.2),    # u-quark: ~20%
    ]

    names  = [n for n, _, _ in yukawa_central]
    values = [v for _, v, _ in yukawa_central]
    frac_errs = [f for *_, f in yukawa_central]
    logs   = [math.log10(v) for v in values]

    ln10 = math.log(10.0)
    sigmas = [f/ln10 for f in frac_errs]  # σ_log10 ≈ frac_err / ln(10)

    print("="*82)
    print("PHASE3_YUKAWA_GLOBAL_INTREL_ERRORMODEL_NULLSCAN_v1 — global 3-term scan")
    print("="*82)
    print("[Yukawa data (central values)]")
    print(f"  number of Yukawas      : {len(names)}")
    print(f"  value range            : [{min(values):.3e}, {max(values):.3e}]")
    print(f"  log10 range            : [{min(logs):.3f}, {max(logs):.3f}]")
    print()
    print("  name          value           log10(value)")
    print("  ------------ --------------  ------------")
    for n, v, z in zip(names, values, logs):
        print(f"  {n:12s} {v:14.9e}  {z:12.6f}")
    print()

    print("[Error model (1σ fractional errors → σ in log10-space)]")
    print("  name          frac_err    σ_log10")
    print("  ------------ ---------  ----------")
    for n, f, s in zip(names, frac_errs, sigmas):
        print(f"  {n:12s} {f:9.3e}  {s:10.6e}")
    print()

    # ------------------------------------------------------------------
    # Real-universe best relation (global over all triples and coeffs)
    # ------------------------------------------------------------------
    best_resid_real, best_info_real = find_best_3term_intrel(logs, names, C=C)
    s_real = best_info_real["sum"]
    prod_approx = 10**s_real

    print("[Real Yukawas: best 3-term integer relation (global search)]")
    print(f"  coefficient bound C    : {C}")
    print(f"  best residual |sum n_i log10(y_i)| : {best_resid_real:.6e}")
    print()
    print("  Best relation (real data):")
    i, j, k = best_info_real["indices"]
    a, b, c = best_info_real["coeffs"]
    print(f"    indices (i,j,k)         : ({i}, {j}, {k})")
    print(f"    names                   : {best_info_real['names']}")
    print(f"    coeffs (a,b,c)          : ({a}, {b}, {c})")
    print(f"    sum n_i log10(y_i)      : {s_real:.6e}")
    print(f"    product approx 10^(sum) : {prod_approx:.6e}")
    print()

    # ------------------------------------------------------------------
    # Error-model null ensemble
    # ------------------------------------------------------------------
    random.seed(seed)
    coeffs = generate_primitive_coeffs_3(C)
    triple_indices = list(combinations(range(len(names)), 3))

    print("[Error-model null ensemble] "
          f"Generating {num_null} random universes...")
    best_resids_null = []

    for t in range(num_null):
        # Jitter Yukawa logs according to the error model
        z_null = [random.gauss(mu, sigma) for mu, sigma in zip(logs, sigmas)]

        # Best 3-term integer relation in this jittered universe
        best_resid = float("inf")
        for (i, j, k) in triple_indices:
            zi, zj, zk = z_null[i], z_null[j], z_null[k]
            for a, b, c in coeffs:
                s = a*zi + b*zj + c*zk
                r = abs(s)
                if r < best_resid:
                    best_resid = r

        best_resids_null.append(best_resid)

        if (t+1) % max(1, num_null//10) == 0:
            print(f"  ... {t+1} / {num_null} universes done")

    # ------------------------------------------------------------------
    # Null stats
    # ------------------------------------------------------------------
    best_resids_null_sorted = sorted(best_resids_null)
    n = len(best_resids_null_sorted)

    def pct(p):
        idx = int(p*(n-1))
        return best_resids_null_sorted[idx]

    mean_null = statistics.mean(best_resids_null_sorted)
    std_null  = statistics.pstdev(best_resids_null_sorted)

    print()
    print("[Null stats — best 3-term integer-relation residual]")
    print(f"  null best_resid min / max: "
          f"{best_resids_null_sorted[0]:.6e} / {best_resids_null_sorted[-1]:.6e}")
    print(f"  null best_resid 25%/50%/75%: "
          f"{pct(0.25):.6e} / {pct(0.50):.6e} / {pct(0.75):.6e}")
    print(f"  null best_resid mean / std: {mean_null:.6e} / {std_null:.6e}")

    # ------------------------------------------------------------------
    # Significance
    # ------------------------------------------------------------------
    z = (best_resid_real - mean_null) / std_null if std_null > 0 else float("nan")
    p_emp = sum(1 for x in best_resids_null_sorted if x <= best_resid_real) / n

    print()
    print("[Significance under error-model global search]")
    print(f"  real best_resid          : {best_resid_real:.6e}")
    print(f"  z(real vs null mean)     : {z:+.2f} σ")
    print(f"  P_null(best_resid <= real) = {p_emp:.6f}")
    print()
    print("="*82)
    print("PHASE3_YUKAWA_GLOBAL_INTREL_ERRORMODEL_NULLSCAN_v1 complete.")
    print("="*82)


if __name__ == "__main__":
    # You can crank num_null up/down depending on patience.
    run_phase3_yukawa_global_intrel_errormodel_nullscan(
        C=4,
        num_null=5000,   # e.g. 2000–10000 is reasonable
        seed=12345,
    )

import math

# =========================================================================================
# PHASE3B_GLOBAL_EVIDENCE_UPDATE_v2 — lock budget with error-model Yukawa triple
# =========================================================================================

def bits_from_p(p):
    """Return -log2(p) for a given p > 0."""
    return -math.log2(p)


def phase3b_global_evidence_update_v2():
    print("=" * 82)
    print("PHASE3B_GLOBAL_EVIDENCE_UPDATE_v2 — geometry-relevant evidence budget")
    print("=" * 82)
    print()
    print("Goal:")
    print("  • Collect ONLY the tests that actually survived harsh nulls.")
    print("  • Incorporate the new global error-model p = 0.0056 for the Yukawa triple.")
    print("  • Produce a clean evidence budget (in bits) that any future geometry")
    print("    MUST explain without cheating.")
    print()

    # ----------------------------------------------------------------------
    # 1. Hard-code the survivor tests (from previous phases + new result)
    # ----------------------------------------------------------------------
    #
    # For some tests we only have an upper bound p < 1/N_null because no null
    # universe matched or beat the real one. For those, we treat the bits as
    # a LOWER bound: bits > log2(N_null).
    #
    # Everything here is distilled from the earlier scoreboard + your last run:
    #
    #   • DNA backbone + lock structure (multi tests).
    #   • Yukawa me–mtau–md triple (-4,4,3) with error-model global null.
    #
    # All other EW/Yukawa 'patterns' were killed (p ~ O(1)) and do not appear.

    tests = []

    # ----------------------
    # DNA sector: full dataset (with backbone)
    # ----------------------
    tests.append({
        "sector": "DNA",
        "status": "SURVIVOR",
        "name": "DNA entropy MDL (full)",
        "p_exact": None,
        "p_upper": 1.0 / 2000.0,   # 0 null hits / 2000 → p < 1/2000
        "note": "Overall residue entropy compressibility; z ≈ -4.84σ."
    })

    tests.append({
        "sector": "DNA",
        "status": "SURVIVOR",
        "name": "DNA lock max-family (full)",
        "p_exact": None,
        "p_upper": 1.0 / 5000.0,   # 0 hits / 5000
        "note": "Largest lock family size=5 vs histogram-preserving null."
    })

    tests.append({
        "sector": "DNA",
        "status": "SURVIVOR",
        "name": "DNA lock collision pairs (full)",
        "p_exact": None,
        "p_upper": 1.0 / 5000.0,   # 0 hits / 5000
        "note": "18 collision pairs vs ~0 in null."
    })

    # ----------------------
    # DNA sector: trimmed (backbone removed)
    # ----------------------
    tests.append({
        "sector": "DNA",
        "status": "SURVIVOR",
        "name": "Trimmed DNA entropy MDL",
        "p_exact": 0.059000,
        "p_upper": None,
        "note": "Entropy after removing backbone; mild compression (~1.6σ)."
    })

    tests.append({
        "sector": "DNA",
        "status": "SURVIVOR",
        "name": "Trimmed DNA locks: max family",
        "p_exact": None,
        "p_upper": 1.0 / 2500.0,   # 2 hits / 5000 → roughly p ≈ 0.0004, lower bound bits ~11.29
        "note": "Largest lock family size=2 vs histogram-preserving null."
    })

    tests.append({
        "sector": "DNA",
        "status": "SURVIVOR",
        "name": "Trimmed DNA locks: collision pairs",
        "p_exact": None,
        "p_upper": 1.0 / 5000.0,   # 0 hits / 5000
        "note": "2 collision pairs vs ~0 in null; residual lock structure beyond backbone."
    })

    # ----------------------
    # DNA patterns: p=6 all-zero rows (rail backbone)
    # ----------------------
    tests.append({
        "sector": "DNA",
        "status": "SURVIVOR",
        "name": "All-four-zero rows (p=6 rail count)",
        "p_exact": None,
        "p_upper": 1.0 / 5000.0,   # 0 hits / 5000
        "note": "5 rows with r23=r49=r50=r137=0 vs ~0 in histogram-preserving null."
    })

    # ----------------------
    # Yukawa sector: global 3-term integer-relations, error model
    # ----------------------
    #
    # This is your latest run:
    #   • Best triple: (me_over_v, mtau_over_v, md_over_v) with (a,b,c)=(-4,4,3)
    #   • best_resid_real ≈ 7.4e-06
    #   • P_null(best_resid <= real) ≈ 0.0056 under realistic error model.
    #
    # This already includes global look-elsewhere over triples & coeffs up to 4.

    tests.append({
        "sector": "Yukawa",
        "status": "SURVIVOR",
        "name": "Global 3-term int-rel (error-model null)",
        "p_exact": 0.005600,
        "p_upper": None,
        "note": "Global search over all triples & |coeffs|≤4 under realistic Yukawa errors."
    })

    # ----------------------
    # Yukawa sector: fixed triple & error-model (extra, more optimistic)
    # ----------------------
    #
    # These are not independent of the global search above; they zoom in on
    # the specific triple (me, mtau, md) with (-4,4,3). So they give a
    # more 'optimistic' bit count, but we should NOT simply add them.
    #
    # We keep them because they show how tight the triple is once you accept
    # that THIS particular triple is the lock you care about.

    tests.append({
        "sector": "Yukawa",
        "status": "SURVIVOR",
        "name": "Fixed triple (me, mtau, md), jitter null (h=0.5 dex)",
        "p_exact": None,
        "p_upper": 1.0 / 10000.0,  # 0 hits / 10k
        "note": "Hold the discovered triple fixed; none of 10k jitters beat real S_real."
    })

    tests.append({
        "sector": "Yukawa",
        "status": "SURVIVOR",
        "name": "Fixed triple (me, mtau, md), error-model null",
        "p_exact": 0.000050,
        "p_upper": None,
        "note": "Realistic error model for me, tau, d; S_real is extremely small."
    })

    # ----------------------------------------------------------------------
    # 2. Compute bits and print per-test summary
    # ----------------------------------------------------------------------
    print("Per-test survivor summary (only tests that geometry MUST care about):")
    print("------------------------------------------------------------------------------------------")
    print(f"{'Sector':8s} {'Status':9s} {'Test':50s} {'p / bound':>12s} {'bits':>10s}")
    print("------------------------------------------------------------------------------------------")

    dna_bits_list = []
    yukawa_bits_global = None
    yukawa_bits_fixed = None

    for t in tests:
        sector = t["sector"]
        status = t["status"]
        name   = t["name"]
        p_exact = t["p_exact"]
        p_upper = t["p_upper"]

        if p_exact is not None:
            bits = bits_from_p(p_exact)
            p_str = f"{p_exact: .3e}"
            bits_str = f"{bits: .2f}"
        else:
            # Only know p < p_upper → bits > -log2(p_upper)
            bits = bits_from_p(p_upper)
            p_str = f"<{p_upper: .3e}"
            bits_str = f">{bits: .2f}"

        print(f"{sector:8s} {status:9s} {name:50s} {p_str:>12s} {bits_str:>10s}")

        # Collect for sector-level budgets
        if sector == "DNA":
            # For DNA we care about the strongest single test as a lower bound.
            # Because of correlations, we treat the max bits as a conservative
            # 'minimum geometry burden' for that sector.
            dna_bits_list.append(bits)
        elif sector == "Yukawa" and "Global 3-term int-rel" in name and p_exact is not None:
            yukawa_bits_global = bits
        elif sector == "Yukawa" and "Fixed triple (me, mtau, md), error-model" in name and p_exact is not None:
            yukawa_bits_fixed = bits

    print("------------------------------------------------------------------------------------------")
    print()

    # ----------------------------------------------------------------------
    # 3. Sector-level effective bits
    # ----------------------------------------------------------------------
    dna_effective_bits = max(dna_bits_list) if dna_bits_list else 0.0

    print("Sector-level effective bits (rough, to avoid double-counting):")
    print("---------------------------------------------------------------------")
    print(f"  DNA sector:")
    print(f"    • Survivor tests count : {len([t for t in tests if t['sector']=='DNA'])}")
    print(f"    • Max bits among them  : {dna_effective_bits: .2f}")
    print(f"    • Effective DNA bits   : {dna_effective_bits: .2f}  (lower bound)")
    print()

    if yukawa_bits_global is not None:
        print("  Yukawa sector (me–mtau–md & friends):")
        print(f"    • Global 3-term error-model p     : 0.0056")
        print(f"    • Global 3-term bits              : {yukawa_bits_global: .2f}")
    else:
        print("  Yukawa sector: (global bits not found — logic bug)")
        yukawa_bits_global = 0.0

    if yukawa_bits_fixed is not None:
        print(f"    • Fixed triple (error-model) bits : {yukawa_bits_fixed: .2f}")
    else:
        print("    • Fixed triple bits not found (not fatal).")

    print()
    conservative_total = dna_effective_bits + yukawa_bits_global
    optimistic_total   = dna_effective_bits + (yukawa_bits_fixed if yukawa_bits_fixed is not None else yukawa_bits_global)

    print("  Combined geometry evidence budget:")
    print(f"    • DNA effective bits                 : {dna_effective_bits: .2f}")
    print(f"    • Yukawa bits (conservative, global) : {yukawa_bits_global: .2f}")
    print(f"      → Combined (conservative)          : {conservative_total: .2f} bits")
    print()
    print(f"    • Yukawa bits (optimistic, fixed)    : {yukawa_bits_fixed: .2f}" if yukawa_bits_fixed is not None else
          "    • Yukawa bits (optimistic, fixed)    : N/A")
    if yukawa_bits_fixed is not None:
        print(f"      → Combined (optimistic)           : {optimistic_total: .2f} bits")
    print("---------------------------------------------------------------------")
    print()

    # ----------------------------------------------------------------------
    # 4. GLOBAL_LOCKS structure for downstream geometry search
    # ----------------------------------------------------------------------
    #
    # This is a compact, machine-readable summary of what future geometry
    # modules must hit. We'll store:
    #
    #   • Effective DNA bits.
    #   • Effective Yukawa bits (global, conservative).
    #   • The specific Yukawa triple relation that emerged:
    #         -4 log10(me/v) + 4 log10(mtau/v) + 3 log10(md/v) ≈ 0
    #     plus the central values.
    #
    # This is NOT imposing any specific geometry — it's just declaring
    # the LOCKS the geometry has to satisfy.

    GLOBAL_LOCKS = {
        "dna": {
            "effective_bits_lower_bound": dna_effective_bits,
            "notes": [
                "Includes entropy MDL, backbone+locks, and all-four-zero p=6 rail.",
                "Interpretation: there is ≥ ~12 bits of non-random structure in the DNA residue system."
            ]
        },
        "yukawa": {
            "effective_bits_global": yukawa_bits_global,
            "effective_bits_fixed_triple": yukawa_bits_fixed,
            "triple_lock": {
                "names": ("me_over_v", "mtau_over_v", "md_over_v"),
                "coeffs": (-4, 4, 3),
                "relation": "-4*log10(me/v) + 4*log10(mtau/v) + 3*log10(md/v) ≈ 0",
                "p_global_error_model": 0.0056,
            },
            "notes": [
                "Global search over all 3-term relations with |a|,|b|,|c| ≤ 4 finds (-4,4,3) on (me, mtau, md).",
                "Under realistic Yukawa errors, that relation has p ~ 0.0056 (≈7.5 bits) for being at least this tight.",
                "Treat ~7–8 bits as the honest geometry burden from Yukawas; ~14 bits if you condition on the triple a priori."
            ]
        },
        "combined": {
            "conservative_bits": conservative_total,
            "optimistic_bits": optimistic_total,
            "notes": [
                "Any future 'geometry of everything' must explain at least the conservative bits.",
                "Optimistic bits assume you regard the (-4,4,3) triple as a given lock rather than part of a global scan."
            ]
        }
    }

    print("[GLOBAL_LOCKS] object constructed for downstream geometry search.")
    print("  • Keys: 'dna', 'yukawa', 'combined'")
    print("  • This object is the contract that any future geometry must satisfy.")
    print()
    print("=" * 82)
    print("PHASE3B_GLOBAL_EVIDENCE_UPDATE_v2 complete.")
    print("=" * 82)

    # Return the object in case you want to inspect it programmatically later.
    return GLOBAL_LOCKS


if __name__ == "__main__":
    GLOBAL_LOCKS = phase3b_global_evidence_update_v2()

from dataclasses import dataclass, field
import math

# =========================================================================================
# PHASE4_GEOMETRY_SCORECARD_v1 — bit-budget for candidate geometries
# =========================================================================================

def bits_from_p(p: float) -> float:
    """Return -log2(p) for p > 0."""
    return -math.log2(p)


@dataclass
class GeometryCandidate:
    """
    Abstract representation of a proposed geometry.

    At this stage we don't encode the detailed math — just which locks
    the geometry *claims* to enforce. Later, concrete geometry modules
    should set these flags ONLY if the claim is mathematically true,
    not tuned-by-hand.

    Flags:
      explains_dna_backbone:
        - Does this geometry *force* something like the observed DNA
          backbone + lock families (including the p=6 all-zero rail)?
      explains_yukawa_global_triple:
        - Does this geometry *force* the existence of some small-integer
          3-term relation among Yukawas that matches (-4,4,3) on
          (me, mtau, md) at roughly the observed tightness, when the
          error model is included?
      explains_yukawa_fixed_triple:
        - Stronger: does the geometry *specifically* explain
          -4 log10(me/v) + 4 log10(mtau/v) + 3 log10(md/v) ≈ 0
          as an identity (up to measurement errors), not as a tuned coincidence?
    """
    name: str
    description: str

    explains_dna_backbone: bool = False
    explains_yukawa_global_triple: bool = False
    explains_yukawa_fixed_triple: bool = False

    # optional: extra metadata or notes specific to this candidate
    metadata: dict = field(default_factory=dict)


def load_global_locks():
    """
    Ensure GLOBAL_LOCKS exists. If PHASE3B has already been run in this
    notebook, we just reuse it. Otherwise we try to call the PHASE3B
    function to construct it.
    """
    global GLOBAL_LOCKS

    try:
        # If it's already there, just return it.
        _ = GLOBAL_LOCKS
        return GLOBAL_LOCKS
    except NameError:
        # Try to call the PHASE3B function if it's defined.
        try:
            from math import isnan  # dummy import to avoid unused warning
            GLOBAL_LOCKS = phase3b_global_evidence_update_v2()
            return GLOBAL_LOCKS
        except NameError:
            raise RuntimeError(
                "GLOBAL_LOCKS not found and phase3b_global_evidence_update_v2() "
                "is not defined. Run PHASE3B_GLOBAL_EVIDENCE_UPDATE_v2 first."
            )


def score_geometry_candidate(candidate: GeometryCandidate, locks: dict):
    """
    Given a GeometryCandidate and the GLOBAL_LOCKS dict, compute:

      • conservative_bits: bits of structure the geometry truly explains
        using only:
          - DNA effective bits
          - Yukawa global 3-term bits (with error-model, includes look-elsewhere)

      • optimistic_bits: same, but if the geometry *explicitly* explains
        the specific (-4,4,3) triple, we allow it to claim the larger
        'fixed triple' bit count.

    This is deliberately simple and slightly brutal: either the geometry
    enforces a lock (and gets full credit) or it doesn't (and gets 0).
    Later you can generalize this to partial/approximate credit.
    """
    dna_bits = 0.0
    yukawa_bits_conservative = 0.0
    yukawa_bits_optimistic = 0.0

    dna_info = locks["dna"]
    yukawa_info = locks["yukawa"]

    dna_required = dna_info["effective_bits_lower_bound"]
    yukawa_global_bits = yukawa_info["effective_bits_global"]
    yukawa_fixed_bits = yukawa_info["effective_bits_fixed_triple"]

    # DNA sector
    if candidate.explains_dna_backbone:
        dna_bits = dna_required

    # Yukawa sector — conservative: only global 3-term error-model bits
    if candidate.explains_yukawa_global_triple:
        yukawa_bits_conservative = yukawa_global_bits

    # Yukawa sector — optimistic: if the geometry truly explains the
    # specific (-4,4,3) triple, allow it to claim the fixed-triple bits.
    if candidate.explains_yukawa_fixed_triple:
        yukawa_bits_optimistic = yukawa_fixed_bits
    elif candidate.explains_yukawa_global_triple:
        # fallback: at least claim the global bits
        yukawa_bits_optimistic = yukawa_global_bits

    conservative_total = dna_bits + yukawa_bits_conservative
    optimistic_total = dna_bits + yukawa_bits_optimistic

    return {
        "candidate_name": candidate.name,
        "dna_bits": dna_bits,
        "yukawa_bits_conservative": yukawa_bits_conservative,
        "yukawa_bits_optimistic": yukawa_bits_optimistic,
        "conservative_total_bits": conservative_total,
        "optimistic_total_bits": optimistic_total,
    }


def print_geometry_score(candidate: GeometryCandidate, locks: dict):
    """Pretty-print the bit score for a candidate geometry."""
    scores = score_geometry_candidate(candidate, locks)

    print("=" * 82)
    print(f"GEOMETRY SCORECARD for: {scores['candidate_name']}")
    print("=" * 82)
    print()
    print(f"Description:")
    print(f"  {candidate.description}")
    print()
    print("Lock claims:")
    print(f"  • explains_dna_backbone         : {candidate.explains_dna_backbone}")
    print(f"  • explains_yukawa_global_triple : {candidate.explains_yukawa_global_triple}")
    print(f"  • explains_yukawa_fixed_triple  : {candidate.explains_yukawa_fixed_triple}")
    print()

    print("Bits earned:")
    print(f"  DNA sector bits                 : {scores['dna_bits']:.2f}")
    print(f"  Yukawa bits (conservative)      : {scores['yukawa_bits_conservative']:.2f}")
    print(f"  Yukawa bits (optimistic)        : {scores['yukawa_bits_optimistic']:.2f}")
    print()
    print(f"  → Total (conservative)          : {scores['conservative_total_bits']:.2f} bits")
    print(f"  → Total (optimistic)           : {scores['optimistic_total_bits']:.2f} bits")
    print()
    print("=" * 82)
    print()


def run_phase4_geometry_scorecard_demo():
    """
    Demo: create a 'null geometry' and a 'perfect lock geometry' and score them
    against GLOBAL_LOCKS, just to visualize the bit budget.
    """
    locks = load_global_locks()

    # 1) Null / random geometry: explains nothing
    null_geom = GeometryCandidate(
        name="NullGeometry",
        description="Random / structureless geometry (baseline). "
                    "Explains no locks by design.",
        explains_dna_backbone=False,
        explains_yukawa_global_triple=False,
        explains_yukawa_fixed_triple=False,
    )

    # 2) Hypothetical perfect geometry: explains everything we currently know
    perfect_geom = GeometryCandidate(
        name="PerfectLockGeometry",
        description="Hypothetical 'god-tier' geometry that exactly enforces "
                    "both the DNA backbone/locks AND the specific Yukawa "
                    "triple (-4,4,3) in log-space.",
        explains_dna_backbone=True,
        explains_yukawa_global_triple=True,
        explains_yukawa_fixed_triple=True,
    )

    print_geometry_score(null_geom, locks)
    print_geometry_score(perfect_geom, locks)

    return {
        "locks": locks,
        "null_geom": null_geom,
        "perfect_geom": perfect_geom,
    }


if __name__ == "__main__":
    _demo = run_phase4_geometry_scorecard_demo()

# =========================================================================================
# PHASE4_LOCK_LIBRARY_v1 — explicit lock objects for geometry hunting
# =========================================================================================
#
# This module builds a clean "LOCK_LIBRARY" object that encodes:
#   • The DNA backbone rail (p=6, special residues).
#   • The all-zero p=6 rail (5 rows with all residues zero).
#   • The Planck-unit p=6 rail (T_P, l_P, m_P, t_P).
#   • The me–mtau–md Yukawa triple with (-4,4,3).
#
# Later geometry modules will IMPORT this object and try to *derive* these patterns,
# instead of hardcoding them. This file is our ground truth target.
# =========================================================================================

import math
from dataclasses import dataclass, asdict


# -----------------------------------------------------------------------------------------
# 1. DNA backbone locks (from your DNA analysis modules)
# -----------------------------------------------------------------------------------------
# These 10 rows were identified as the "backbone" and removed in the backbone-removal test.
# They live at p = 6, and sit at the center of the strongest rails & lock families.
#
# For each entry we store:
#   idx: original row index in the DNA table
#   name: physical quantity
#   p: the p value
#   residues: (r23, r49, r50, r137)
# -----------------------------------------------------------------------------------------

DNA_BACKBONE_ROWS = [
    {
        "idx": 26,
        "name": "BH(M=10 M☉): (S - A/4)",
        "p": 6,
        "r23": 0,
        "r49": 0,
        "r50": 0,
        "r137": 0,
    },
    {
        "idx": 28,
        "name": "BH(M=1e9 M☉): (S - A/4)",
        "p": 6,
        "r23": 0,
        "r49": 0,
        "r50": 0,
        "r137": 0,
    },
    {
        "idx": 30,
        "name": "BH(M=4e6 M☉): (S - A/4)",
        "p": 6,
        "r23": 0,
        "r49": 0,
        "r50": 0,
        "r137": 0,
    },
    {
        "idx": 32,
        "name": "r_ISCO/M (a*=0)",
        "p": 6,
        "r23": 3,
        "r49": 0,
        "r50": 0,
        "r137": 0,
    },
    {
        "idx": 65,
        "name": "Ω_k",
        "p": 6,
        "r23": 0,
        "r49": 0,
        "r50": 0,
        "r137": 0,
    },
    {
        "idx": 85,
        "name": "θ̄_QCD (null)",
        "p": 6,
        "r23": 0,
        "r49": 0,
        "r50": 0,
        "r137": 0,
    },
    {
        "idx": 123,
        "name": "T_P / T_P",
        "p": 6,
        "r23": 12,
        "r49": 0,
        "r50": 0,
        "r137": 0,
    },
    {
        "idx": 124,
        "name": "l_P / l_P",
        "p": 6,
        "r23": 12,
        "r49": 0,
        "r50": 0,
        "r137": 0,
    },
    {
        "idx": 125,
        "name": "m_P / m_P",
        "p": 6,
        "r23": 12,
        "r49": 0,
        "r50": 0,
        "r137": 0,
    },
    {
        "idx": 126,
        "name": "t_P / t_P",
        "p": 6,
        "r23": 12,
        "r49": 0,
        "r50": 0,
        "r137": 0,
    },
]


# Convenience: split backbone into the two obvious sub-rails.
DNA_BACKBONE_ALL_ZERO = [row for row in DNA_BACKBONE_ROWS if row["r23"] == 0]
DNA_BACKBONE_PLANCK = [row for row in DNA_BACKBONE_ROWS if row["name"].endswith("/ T_P")
                       or row["name"].endswith("/ l_P")
                       or row["name"].endswith("/ m_P")
                       or row["name"].endswith("/ t_P")]

# The all-zero rail should have exactly these 5 names:
ALL_ZERO_RAIL_NAMES = {row["name"] for row in DNA_BACKBONE_ALL_ZERO}
PLANCK_RAIL_NAMES = {row["name"] for row in DNA_BACKBONE_PLANCK}


# -----------------------------------------------------------------------------------------
# 2. Yukawa triple lock: (me, mtau, md) and (-4,4,3)
# -----------------------------------------------------------------------------------------

@dataclass
class YukawaEntry:
    name: str
    value: float
    log10_value: float
    frac_err: float  # 1σ fractional error


# Central values & fractional errors from your error-model module
YUKAWA_TRIPLE = {
    "me_over_v": YukawaEntry(
        name="me_over_v",
        value=2.073000000e-06,
        log10_value=-5.683401,
        frac_err=1.0e-8,
    ),
    "mtau_over_v": YukawaEntry(
        name="mtau_over_v",
        value=7.214707000e-03,
        log10_value=-2.141781,
        frac_err=1.0e-5,
    ),
    "md_over_v": YukawaEntry(
        name="md_over_v",
        value=1.896000000e-05,
        log10_value=-4.722162,
        frac_err=2.0e-1,
    ),
}

# Compute σ in log10-space for the triple
def frac_to_sigma_log10(frac_err: float) -> float:
    # For small fractional error δ, σ_log10 ≈ δ / ln(10)
    return frac_err / math.log(10.0)

YUKAWA_TRIPLE_SIGMA_LOG10 = {
    name: frac_to_sigma_log10(entry.frac_err)
    for name, entry in YUKAWA_TRIPLE.items()
}

# (-4,4,3) triple coefficients
YUKAWA_TRIPLE_COEFFS = {
    "me_over_v": -4,
    "mtau_over_v": 4,
    "md_over_v": 3,
}


def compute_yukawa_triple_S(log10_vals: dict) -> float:
    """
    Given a dict with keys 'me_over_v', 'mtau_over_v', 'md_over_v' mapping to log10(y),
    compute the triple combination:

        S = |-4 log10(me/v) + 4 log10(mtau/v) + 3 log10(md/v)|

    This is the fundamental Yukawa lock.
    """
    z_me = log10_vals["me_over_v"]
    z_tau = log10_vals["mtau_over_v"]
    z_d = log10_vals["md_over_v"]

    S = abs(
        YUKAWA_TRIPLE_COEFFS["me_over_v"] * z_me
        + YUKAWA_TRIPLE_COEFFS["mtau_over_v"] * z_tau
        + YUKAWA_TRIPLE_COEFFS["md_over_v"] * z_d
    )
    return S


# Compute S for the real universe (using central values)
YUKAWA_TRIPLE_LOGS_REAL = {
    name: entry.log10_value for name, entry in YUKAWA_TRIPLE.items()
}
YUKAWA_TRIPLE_S_REAL = compute_yukawa_triple_S(YUKAWA_TRIPLE_LOGS_REAL)


# -----------------------------------------------------------------------------------------
# 3. LOCK_LIBRARY: single object encapsulating all geometry-relevant locks
# -----------------------------------------------------------------------------------------

LOCK_LIBRARY = {
    "dna": {
        "backbone_rows": DNA_BACKBONE_ROWS,
        "all_zero_rail_rows": DNA_BACKBONE_ALL_ZERO,
        "planck_rail_rows": DNA_BACKBONE_PLANCK,
        "all_zero_rail_names": sorted(list(ALL_ZERO_RAIL_NAMES)),
        "planck_rail_names": sorted(list(PLANCK_RAIL_NAMES)),
        # Note: detailed DNA entropy & lock p-values live in GLOBAL_LOCKS (PHASE3B).
    },
    "yukawa": {
        "triple_entries": {k: asdict(v) for k, v in YUKAWA_TRIPLE.items()},
        "triple_coeffs": YUKAWA_TRIPLE_COEFFS,
        "triple_sigma_log10": YUKAWA_TRIPLE_SIGMA_LOG10,
        "triple_S_real": YUKAWA_TRIPLE_S_REAL,
    },
}


# -----------------------------------------------------------------------------------------
# 4. Pretty-printer / inspection helpers
# -----------------------------------------------------------------------------------------

def print_lock_library_summary():
    print("==================================================================================")
    print("PHASE4_LOCK_LIBRARY_v1 — lock objects for geometry hunting")
    print("==================================================================================")
    print()
    print("[DNA backbone locks]")
    print(f"  Total backbone rows       : {len(DNA_BACKBONE_ROWS)}")
    print(f"  All-zero p=6 rail rows    : {len(DNA_BACKBONE_ALL_ZERO)}")
    print(f"  Planck p=6 rail rows      : {len(DNA_BACKBONE_PLANCK)}")
    print()
    print("  All-zero rail names:")
    for name in sorted(ALL_ZERO_RAIL_NAMES):
        print(f"    - {name}")
    print()
    print("  Planck rail names:")
    for name in sorted(PLANCK_RAIL_NAMES):
        print(f"    - {name}")
    print()
    print("[Yukawa triple lock]")
    print("  Entries:")
    for name, entry in YUKAWA_TRIPLE.items():
        sig = YUKAWA_TRIPLE_SIGMA_LOG10[name]
        print(
            f"    {name:12s} value={entry.value: .9e}  "
            f"log10={entry.log10_value: .6f}  σ_log10≈{sig: .3e}"
        )
    print()
    print("  Triple coefficients (a,b,c) on (me, mtau, md):")
    print(
        f"    (-4, 4, 3)  →  S_real = |-4 z_me + 4 z_tau + 3 z_d| "
        f"= {YUKAWA_TRIPLE_S_REAL: .6e}"
    )
    print()
    print("NOTE:")
    print("  • LOCK_LIBRARY is the *target* for any future geometry.")
    print("  • A non-cheating geometry must *derive* these patterns,")
    print("    not just hardcode them as input.")
    print()
    print("==================================================================================")
    print()


def get_lock_library():
    """
    Return the LOCK_LIBRARY object so other modules can import/use it.

    Example usage in future geometry modules:
        from math import log10
        locks = get_lock_library()
        dna_locks = locks['dna']
        yukawa_locks = locks['yukawa']
    """
    return LOCK_LIBRARY


# -----------------------------------------------------------------------------------------
# 5. Run-on-import demo: print a compact summary so you can see what's inside.
# -----------------------------------------------------------------------------------------

if __name__ == "__main__":
    print_lock_library_summary()

# =========================================================================================
# PHASE5_YUKAWA_FN_SINGLE_PARAM_GEOMETRY_v1
# =========================================================================================
#
# Goal:
#   Test a very simple "geometry" for the Yukawa triple (me, mtau, md):
#
#     log10(y_f) ≈ n_f * L      where  L = log10(λ) < 0,  n_f ∈ Z (small integers)
#
#   and we FORCE the exponents (n_me, n_tau, n_d) to obey the same integer relation
#   as the observed (-4,4,3) coefficient triple:
#
#       -4 n_me + 4 n_tau + 3 n_d = 0         (exact constraint at the exponent level)
#
#   This is like saying:
#       Yukawas are pure powers of a single parameter λ,
#       and the me–mtau–md relation is built into the exponents themselves.
#
#   We then ask:
#       Is there ANY set of small integers (n_me, n_tau, n_d) and λ<1 that
#       fit the ACTUAL logs of (me, mtau, md) even roughly well?
#
#   If even this very forgiving test fails badly, we can confidently say:
#       "Single-λ Froggatt–Nielsen-style geometry that *exactly* encodes (-4,4,3)
#        in the exponents does NOT match the real-world Yukawas."
#
#   => Another geometry candidate gets executed.
# =========================================================================================

import math

# We assume PHASE4_LOCK_LIBRARY_v1 has already run and defined LOCK_LIBRARY.
try:
    _ = LOCK_LIBRARY
except NameError:
    raise RuntimeError("LOCK_LIBRARY is not defined. Run PHASE4_LOCK_LIBRARY_v1 first.")


# ------------------------------------------------------------------------------
# 1. Extract the real logs for (me, mtau, md) from the lock library
# ------------------------------------------------------------------------------

yuk = LOCK_LIBRARY["yukawa"]["triple_entries"]

z_me_real   = yuk["me_over_v"]["log10_value"]
z_tau_real  = yuk["mtau_over_v"]["log10_value"]
z_d_real    = yuk["md_over_v"]["log10_value"]

REAL_LOGS = (z_me_real, z_tau_real, z_d_real)


# ------------------------------------------------------------------------------
# 2. Exponent ansatz with a single λ
#
#   We impose the exponent-level constraint:
#
#       -4 n_me + 4 n_tau + 3 n_d = 0       (exact, integer)
#
#   General integer solution:
#       Let k be any integer, and choose n_me freely.
#       Then:
#           n_tau = n_me + 3k
#           n_d   = -4k
#
#   For each (n_me, k), we can find the best-fit L = log10(λ) by least squares:
#
#       minimize   Σ_f (z_f_real - n_f L)^2
#       => L_opt = (Σ_f n_f z_f_real) / (Σ_f n_f^2)
#
#   Then:
#       λ = 10^L_opt, and predicted logs are z_f_pred = n_f * L_opt.
#
#   We scan over small integers n_me, k and look for the best RMS fit.
#   If the best RMS is still awful (≫ measurement errors), this geometry is dead.
# ------------------------------------------------------------------------------


def fit_single_lambda_for_exponents(n_me: int, k: int, real_logs=REAL_LOGS):
    """
    Given n_me and k (defining n_tau, n_d via the (-4,4,3) constraint),
    return (n_me, n_tau, n_d, L_opt, lambda_opt, rms, max_abs_resid, residuals).
    If λ >= 1 (L_opt >= 0), return None (we only accept λ < 1).
    """
    z_me, z_tau, z_d = real_logs

    n_tau = n_me + 3 * k
    n_d   = -4 * k

    n_vec = (n_me, n_tau, n_d)

    # Denominator for least-squares fit
    denom = n_me**2 + n_tau**2 + n_d**2
    if denom == 0:
        return None

    # Best-fit L = log10(λ)
    num = n_me * z_me + n_tau * z_tau + n_d * z_d
    L_opt = num / denom

    # We want λ < 1 => L_opt < 0
    if L_opt >= 0:
        return None

    lambda_opt = 10.0**L_opt

    # Predicted logs
    z_me_pred  = n_me  * L_opt
    z_tau_pred = n_tau * L_opt
    z_d_pred   = n_d   * L_opt

    resid_me  = z_me_pred  - z_me
    resid_tau = z_tau_pred - z_tau
    resid_d   = z_d_pred   - z_d

    residuals = (resid_me, resid_tau, resid_d)
    rms = math.sqrt(
        (resid_me**2 + resid_tau**2 + resid_d**2) / 3.0
    )
    max_abs_resid = max(abs(resid_me), abs(resid_tau), abs(resid_d))

    return {
        "n_me": n_me,
        "n_tau": n_tau,
        "n_d": n_d,
        "k": k,
        "L_opt": L_opt,
        "lambda_opt": lambda_opt,
        "rms": rms,
        "max_abs_resid": max_abs_resid,
        "residuals": residuals,
    }


def run_phase5_yukawa_fn_single_param_geometry(
    n_me_min=-20, n_me_max=20, k_min=-10, k_max=10
):
    """
    Scan over integer pairs (n_me, k), build (n_me, n_tau, n_d) satisfying
    the exponent-level version of the (-4,4,3) relation, and compute the
    best-fit single-λ model.

    Prints the best (smallest RMS) candidate and summarizes how bad/good it is.
    """
    best = None

    for n_me in range(n_me_min, n_me_max + 1):
        for k in range(k_min, k_max + 1):
            res = fit_single_lambda_for_exponents(n_me, k)
            if res is None:
                continue

            # Optionally, restrict exponents to a symmetric small range
            n_tau = res["n_tau"]
            n_d   = res["n_d"]
            if not (n_me_min <= n_tau <= n_me_max and n_me_min <= n_d <= n_me_max):
                continue

            if (best is None) or (res["rms"] < best["rms"]):
                best = res

    print("==================================================================================")
    print("PHASE5_YUKAWA_FN_SINGLE_PARAM_GEOMETRY_v1 — single-λ test for (me, mtau, md)")
    print("==================================================================================")
    print(f"Search ranges:")
    print(f"  n_me ∈ [{n_me_min}, {n_me_max}]")
    print(f"  k    ∈ [{k_min}, {k_max}]  (with n_tau = n_me + 3k, n_d = -4k)")
    print()
    if best is None:
        print("No valid (λ<1) candidate found in the scanned range.")
        print("This already strongly disfavors this type of geometry.")
        print("==================================================================================")
        return

    print("[Best-fit single-λ FN-style geometry (under exponent constraint)]")
    print(f"  n_me, n_tau, n_d  = ({best['n_me']}, {best['n_tau']}, {best['n_d']})")
    print(f"  k                 = {best['k']}")
    print(f"  L_opt = log10(λ)  = {best['L_opt']: .6f}")
    print(f"  λ_opt             = {best['lambda_opt']: .6e}")
    print()
    print("  Residuals in log10-space (predicted - real):")
    r_me, r_tau, r_d = best["residuals"]
    print(f"    me_over_v   : {r_me: .4f} dex")
    print(f"    mtau_over_v : {r_tau: .4f} dex")
    print(f"    md_over_v   : {r_d: .4f} dex")
    print()
    print(f"  RMS residual           : {best['rms']: .4f} dex")
    print(f"  Max |residual|         : {best['max_abs_resid']: .4f} dex")
    print()
    print("Interpretation:")
    print("  • This geometry assumes ALL THREE Yukawas are pure powers of a single λ.")
    print("  • It also enforces the (-4,4,3) relation at the exponent level exactly.")
    print("  • If RMS ≫ 0.01 dex, the model is wildly off compared to the actual values.")
    print("  • If RMS is O(0.1–1) dex, it's basically just 'hierarchy-ish' handwaving,")
    print("    not a serious explanation of the precise me–mtau–md lock.")
    print()
    print("  We can compare this RMS to the lock-scale:")
    print("    • The actual triple lock S_real ~ 6×10^-6 in log10-space,")
    print("      i.e., the combination -4 z_me + 4 z_tau + 3 z_d is tuned at ~10^-5.")
    print("    • A geometry that only hits the exponents but misses each Yukawa by")
    print("      ~0.1–1 dex is not explaining the observed precision; it's just")
    print("      rephrasing the hierarchy without locking it.")
    print()
    print("==================================================================================")
    print()


# -----------------------------------------------------------------------------------------
# Auto-run when this cell is executed
# -----------------------------------------------------------------------------------------

if __name__ == "__main__":
    run_phase5_yukawa_fn_single_param_geometry()

# =========================================================================================
# PHASE5_YUKAWA_COEFF_STABILITY_ERRORMODEL_v2 — coefficient stability test
# =========================================================================================
#
# Goal:
#   Under the realistic error model for (me, mtau, md), how often is the
#   integer triple (-4,4,3) still the best primitive combo in a,b,c ∈ [-10,10]?
#
#   • Uses central logs from LOCK_LIBRARY (PHASE4).
#   • Uses fractional errors from your error-model module:
#       frac_err_me   = 1e-8
#       frac_err_mtau = 1e-5
#       frac_err_md   = 0.2
#   • Converts these to σ_log10 using σ ≈ frac_err / ln(10).
#
# =========================================================================================

import math
import random

try:
    LOCK_LIBRARY
except NameError:
    raise RuntimeError("LOCK_LIBRARY is not defined. Run PHASE4_LOCK_LIBRARY_v1 first.")

# ----------------------------------------------------------------------
# 1. Extract central logs from LOCK_LIBRARY
# ----------------------------------------------------------------------

yuk = LOCK_LIBRARY["yukawa"]["triple_entries"]

z_me   = yuk["me_over_v"]["log10_value"]
z_tau  = yuk["mtau_over_v"]["log10_value"]
z_d    = yuk["md_over_v"]["log10_value"]

REAL_LOGS = (z_me, z_tau, z_d)

# ----------------------------------------------------------------------
# 2. Error model: define fractional errors and convert to σ(log10)
# ----------------------------------------------------------------------

LN10_INV = 1.0 / math.log(10.0)   # ~0.4342945

frac_err_me   = 1.0e-8
frac_err_mtau = 1.0e-5
frac_err_md   = 2.0e-1

sigma_me_log10   = frac_err_me   * LN10_INV
sigma_tau_log10  = frac_err_mtau * LN10_INV
sigma_d_log10    = frac_err_md   * LN10_INV

# ----------------------------------------------------------------------
# 3. Build coefficient space (primitive triples, ≥ 2 nonzero)
# ----------------------------------------------------------------------

COEFFS = []
for a in range(-10, 11):
    for b in range(-10, 11):
        for c in range(-10, 11):
            if (a, b, c) == (0, 0, 0):
                continue
            # at least 2 non-zero
            if sum(1 for x in (a, b, c) if x != 0) < 2:
                continue
            g = math.gcd(math.gcd(abs(a), abs(b)), abs(c))
            if g > 1:
                continue
            COEFFS.append((a, b, c))

def best_coeff_triple_for_logs(z_me_, z_tau_, z_d_, coeffs=COEFFS):
    """
    Returns:
      best_S, best_list
    where best_S is min S = |a z_me + b z_tau + c z_d|,
    and best_list is the list of (a,b,c) achieving that S (ties included).
    """
    best_S = None
    best_list = []
    for (a, b, c) in coeffs:
        S = abs(a*z_me_ + b*z_tau_ + c*z_d_)
        if (best_S is None) or (S < best_S - 1e-18):
            best_S = S
            best_list = [(a, b, c)]
        elif abs(S - best_S) <= 1e-18:
            best_list.append((a, b, c))
    return best_S, best_list

# Real-universe best triple
best_S_real, best_triples_real = best_coeff_triple_for_logs(*REAL_LOGS)

print("==================================================================================")
print("PHASE5_YUKAWA_COEFF_STABILITY_ERRORMODEL_v2 — coefficient stability test")
print("==================================================================================")
print("Central logs (z = log10(y/v)):")
print(f"  z_me   = {z_me: .6f}")
print(f"  z_tau  = {z_tau: .6f}")
print(f"  z_d    = {z_d: .6f}")
print()
print("Error model (1σ in log10-space, derived from fractional errors):")
print(f"  frac_err(me)   = {frac_err_me: .1e}  → σ_log10(me)   = {sigma_me_log10: .3e}")
print(f"  frac_err(mtau) = {frac_err_mtau: .1e}  → σ_log10(mtau) = {sigma_tau_log10: .3e}")
print(f"  frac_err(md)   = {frac_err_md: .1e}  → σ_log10(md)   = {sigma_d_log10: .3e}")
print()
print("Real-universe coefficient search over a,b,c ∈ [-10,10]:")
print(f"  best S_real     = {best_S_real: .6e}")
print(f"  best triples    = {best_triples_real}")
print("  (we expect to see (-4, 4, 3) and its sign-flip (4, -4, -3))")
print()

# Treat (-4,4,3) and (4,-4,-3) as the same lock up to overall sign
LOCK_TRIPLES = {(-4, 4, 3), (4, -4, -3)}

# ----------------------------------------------------------------------
# 4. Jitter null: resample logs within error model and re-run search
# ----------------------------------------------------------------------

def jitter_logs_once():
    z_me_j   = random.gauss(z_me,  sigma_me_log10)
    z_tau_j  = random.gauss(z_tau, sigma_tau_log10)
    z_d_j    = random.gauss(z_d,   sigma_d_log10)
    return z_me_j, z_tau_j, z_d_j

def run_coeff_stability_null(num_null=20000, seed=24601):
    random.seed(seed)
    count_lock_best = 0
    count_lock_in_ties = 0
    S_null_list = []

    for i in range(num_null):
        z_me_j, z_tau_j, z_d_j = jitter_logs_once()
        S_best, best_triples = best_coeff_triple_for_logs(z_me_j, z_tau_j, z_d_j)
        S_null_list.append(S_best)

        best_set = set(best_triples)

        # Case 1: ONLY the lock triple (and sign-flip) are best
        if best_set == LOCK_TRIPLES:
            count_lock_best += 1
            count_lock_in_ties += 1

        # Case 2: Lock triple appears among several best triples
        elif best_set & LOCK_TRIPLES:
            count_lock_in_ties += 1

    num = float(num_null)
    frac_lock_best = count_lock_best / num
    frac_lock_ties = count_lock_in_ties / num

    S_min = min(S_null_list)
    S_max = max(S_null_list)
    S_mean = sum(S_null_list) / num
    S_sq_mean = sum(x*x for x in S_null_list) / num
    S_std = math.sqrt(max(S_sq_mean - S_mean**2, 0.0))

    return {
        "num_null": num_null,
        "count_lock_best": count_lock_best,
        "count_lock_in_ties": count_lock_in_ties,
        "frac_lock_best": frac_lock_best,
        "frac_lock_ties": frac_lock_ties,
        "S_min": S_min,
        "S_max": S_max,
        "S_mean": S_mean,
        "S_std": S_std,
    }

results = run_coeff_stability_null(num_null=20000, seed=24601)

print("[Error-model coefficient stability null]")
print(f"  num_null                 : {int(results['num_null'])}")
print(f"  S_null min / max         : {results['S_min']:.6e} / {results['S_max']:.6e}")
print(f"  S_null mean / std        : {results['S_mean']:.6e} / {results['S_std']:.6e}")
print()
print(f"  Count lock triple best   : {results['count_lock_best']} / {int(results['num_null'])}")
print(f"  Count lock in best-ties  : {results['count_lock_in_ties']} / {int(results['num_null'])}")
print(f"  Fraction lock best       : {results['frac_lock_best']:.6f}")
print(f"  Fraction lock in ties    : {results['frac_lock_ties']:.6f}")
print()
print("Interpretation:")
print("  • 'lock best'  ⇒ the only best triples are (-4,4,3) and/or (4,-4,-3).")
print("  • 'lock in ties' ⇒ lock triple is among possibly several best triples.")
print("  • If these fractions ≈ 1, then the *identity* of (-4,4,3) is extremely")
print("    stable under realistic measurement errors; any geometry must aim for")
print("    THESE integers, not just 'some nearby' (a,b,c).")
print("==================================================================================")
print()

import numpy as np

def run_phase6_yukawa_two_scale_fn_scan(
    Nmax=5,
    verbose_top_k=15,
):
    """
    PHASE6_YUKAWA_TWO_SCALE_FN_SCAN_v1
    ----------------------------------
    Two-scale FN-style geometry scan for (me, mtau, md):

      • Two spurions λ1, λ2 with log10 λ1 = L1, log10 λ2 = L2.
      • Each Yukawa y_i ∈ {me, mtau, md} has integer exponents (n1_i, n2_i).
      • We fix me exponents to (1,0) to set the λ1 unit.
      • Scan over n_tau, n_d ∈ [-Nmax, Nmax]^2 \ {(0,0)}.
      • For each exponent pattern, least-squares fit (L1, L2) to match the logs.
      • Compute:
          - RMS error in log10-space for (me, mtau, md).
          - S_geom = |-4 z_me^geom + 4 z_tau^geom + 3 z_d^geom|
            (how well geometry reproduces the (-4,4,3) lock).

    This does NOT impose the (-4,4,3) relation at exponent level;
    it tests whether a simple 2-spurion FN geometry naturally approximates
    both the hierarchy and the ultra-tight lock.
    """

    print("="*82)
    print("PHASE6_YUKAWA_TWO_SCALE_FN_SCAN_v1 — 2-scale FN-style geometry for (me, mtau, md)")
    print("="*82)
    print()
    print("[Config]")
    print(f"  exponent bound Nmax      : {Nmax}")
    print(f"  me exponents fixed to    : (1, 0)  (defines λ1 units)")
    print(f"  scan over n_tau, n_d in  : [-{Nmax}, {Nmax}]^2 excluding (0,0)")
    print()

    # Central logs (these match your earlier phases)
    z_me   = -5.683401
    z_tau  = -2.141781
    z_d    = -4.722162
    Z = np.array([z_me, z_tau, z_d], dtype=float)

    print("[Yukawa logs (central)]")
    print(f"  z_me   = {z_me: .6f}")
    print(f"  z_tau  = {z_tau: .6f}")
    print(f"  z_d    = {z_d: .6f}")
    print()
    print("Assumptions:")
    print("  • Two FN-like spurions λ1, λ2 with log10 λ1 = L1, log10 λ2 = L2.")
    print("  • me, mtau, md exponents are integer pairs (n1, n2) with |n| ≤ Nmax.")
    print("  • We fix me exponents to (1,0) to set the λ1 scale.")
    print("  • mtau, md exponents are scanned; for each choice we least-squares fit (L1,L2).")
    print()

    best = []

    # Scan exponent patterns
    for n_tau1 in range(-Nmax, Nmax+1):
        for n_tau2 in range(-Nmax, Nmax+1):
            if n_tau1 == 0 and n_tau2 == 0:
                continue
            for n_d1 in range(-Nmax, Nmax+1):
                for n_d2 in range(-Nmax, Nmax+1):
                    if n_d1 == 0 and n_d2 == 0:
                        continue

                    # Exponent matrix N (3x2):
                    #   row 0: me   → (1, 0)
                    #   row 1: tau  → (n_tau1, n_tau2)
                    #   row 2: d    → (n_d1, n_d2)
                    N = np.array([[1,        0       ],
                                  [n_tau1,  n_tau2 ],
                                  [n_d1,    n_d2   ]],
                                 dtype=float)

                    # Skip degenerate rank-1 matrices (effectively single scale)
                    if np.linalg.matrix_rank(N) < 2:
                        continue

                    # Fit L via least squares: minimize ||N L - Z||
                    L, residuals, rank, s = np.linalg.lstsq(N, Z, rcond=None)

                    # Predicted logs from geometry
                    z_pred = N @ L
                    residual = z_pred - Z

                    # RMS error in dex
                    rms = float(np.sqrt(np.mean(residual**2)))
                    max_abs = float(np.max(np.abs(residual)))

                    # Triple residual using predicted logs
                    S_geom = float(abs(-4*z_pred[0] + 4*z_pred[1] + 3*z_pred[2]))

                    best.append({
                        "n_tau": (n_tau1, n_tau2),
                        "n_d": (n_d1, n_d2),
                        "L": tuple(L.tolist()),
                        "rms": rms,
                        "max_abs": max_abs,
                        "S_geom": S_geom,
                    })

    # Sort by S_geom, then by RMS
    best.sort(key=lambda x: (x["S_geom"], x["rms"]))
    total = len(best)

    print("[Search]")
    print(f"  total non-degenerate exponent patterns scanned : {total}")
    print()
    print(f"[Top {verbose_top_k} geometries by triple residual S_geom]")
    print("  rank  (n_tau1,n_tau2)  (n_d1,n_d2)    L1       L2       RMS[dex]  max|res|  S_geom")
    print("  ----  ---------------  -----------  --------  --------  ---------  --------  --------")

    for rank, entry in enumerate(best[:verbose_top_k], start=1):
        (n_tau1, n_tau2) = entry["n_tau"]
        (n_d1, n_d2) = entry["n_d"]
        L1, L2 = entry["L"]
        rms = entry["rms"]
        max_abs = entry["max_abs"]
        S_geom = entry["S_geom"]

        print(f"  {rank:>4d}   ({n_tau1:>2d},{n_tau2:>2d})   ({n_d1:>2d},{n_d2:>2d})"
              f"  {L1:8.3f} {L2:8.3f}  {rms:9.4f} {max_abs:9.4f} {S_geom:9.4f}")

    print()
    print("Notes:")
    print("  • RMS is over (me, mtau, md) logs between geometry predictions and data, in dex.")
    print("  • S_geom = |-4 z_me^geom + 4 z_tau^geom + 3 z_d^geom| measures how well")
    print("    the *geometry* itself reproduces the (-4,4,3) triple.")
    print("  • The real universe has S_real ≈ 6×10^-6 in log10-space; any geometry")
    print("    with S_geom ≫ 1e-5 is not explaining the precision, only the rough hierarchy.")
    print()
    print("You can extend this module to:")
    print("  • add MDL-style complexity penalties for exponents and scales,")
    print("  • require exact exponent-level enforcement of the (-4,4,3) relation, or")
    print("  • include mmu/ms/... as additional Yukawas in the fit.")
    print()
    print("="*82)
    print("PHASE6_YUKAWA_TWO_SCALE_FN_SCAN_v1 complete.")
    print("="*82)


if __name__ == "__main__":
    # Example: small test scan. For a deeper search, bump Nmax or verbose_top_k.
    run_phase6_yukawa_two_scale_fn_scan(Nmax=3, verbose_top_k=10)

import numpy as np

def run_phase6_yukawa_two_scale_fn_scan_v2(
    Nmax=5,
    top_k_rms=20,
    rms_thresholds=(0.5, 0.2, 0.1, 0.05, 0.02),
):
    """
    PHASE6_YUKAWA_TWO_SCALE_FN_SCAN_v2
    ----------------------------------
    Improved 2-scale FN-style geometry scan for (me, mtau, md):

      • Two spurions λ1, λ2 with log10 λ1 = L1, log10 λ2 = L2.
      • me, mtau, md exponents are integer pairs (n1, n2) with |n| ≤ Nmax.
      • me exponents are fixed to (1,0) to define the λ1 scale.
      • mtau, md exponents are scanned over [-Nmax, Nmax]^2 \ {(0,0)}.
      • For each exponent pattern:
           - least-squares fit (L1, L2) to match z = log10(y/v),
           - compute RMS error over (me, mtau, md),
           - compute S_geom = |-4 z_me^geom + 4 z_tau^geom + 3 z_d^geom|.

    v2 behavior:
      • Sorts geometries primarily by RMS (data fit quality).
      • Reports the best S_geom achievable under various RMS thresholds.
    """

    print("="*82)
    print("PHASE6_YUKAWA_TWO_SCALE_FN_SCAN_v2 — 2-scale FN geometry (RMS-prioritized)")
    print("="*82)
    print()
    print("[Config]")
    print(f"  exponent bound Nmax          : {Nmax}")
    print(f"  me exponents fixed to        : (1, 0)")
    print(f"  scan over n_tau, n_d in      : [-{Nmax}, {Nmax}]^2 excluding (0,0)")
    print(f"  RMS thresholds (dex)         : {rms_thresholds}")
    print()

    # Central logs
    z_me   = -5.683401
    z_tau  = -2.141781
    z_d    = -4.722162
    Z = np.array([z_me, z_tau, z_d], dtype=float)

    S_real = abs(-4*z_me + 4*z_tau + 3*z_d)  # ~6e-06
    print("[Yukawa logs (central)]")
    print(f"  z_me   = {z_me: .6f}")
    print(f"  z_tau  = {z_tau: .6f}")
    print(f"  z_d    = {z_d: .6f}")
    print(f"  Real lock S_real = |-4 z_me + 4 z_tau + 3 z_d| ≈ {S_real:.3e}")
    print()

    geometries = []

    # Scan exponent patterns
    for n_tau1 in range(-Nmax, Nmax+1):
        for n_tau2 in range(-Nmax, Nmax+1):
            if n_tau1 == 0 and n_tau2 == 0:
                continue
            for n_d1 in range(-Nmax, Nmax+1):
                for n_d2 in range(-Nmax, Nmax+1):
                    if n_d1 == 0 and n_d2 == 0:
                        continue

                    # Exponent matrix N (3x2):
                    #   me   → (1, 0)
                    #   tau  → (n_tau1, n_tau2)
                    #   d    → (n_d1,   n_d2)
                    N = np.array([[1,        0       ],
                                  [n_tau1,  n_tau2 ],
                                  [n_d1,    n_d2   ]],
                                 dtype=float)

                    # Skip degenerate rank-1 matrices (effectively single-scale)
                    if np.linalg.matrix_rank(N) < 2:
                        continue

                    # Least-squares fit for L = (L1, L2)
                    L, residuals, rank, s = np.linalg.lstsq(N, Z, rcond=None)

                    # Predicted logs and residuals
                    z_pred = N @ L
                    residual = z_pred - Z

                    rms = float(np.sqrt(np.mean(residual**2)))
                    max_abs = float(np.max(np.abs(residual)))

                    # Triple residual from geometry
                    S_geom = float(abs(-4*z_pred[0] + 4*z_pred[1] + 3*z_pred[2]))

                    geometries.append({
                        "n_tau": (n_tau1, n_tau2),
                        "n_d": (n_d1, n_d2),
                        "L": tuple(L.tolist()),
                        "rms": rms,
                        "max_abs": max_abs,
                        "S_geom": S_geom,
                    })

    total = len(geometries)
    print("[Search]")
    print(f"  total non-degenerate exponent patterns scanned : {total}")
    print()

    # Sort primarily by RMS (fit quality), secondarily by S_geom (lock quality)
    by_rms = sorted(geometries, key=lambda x: (x["rms"], x["S_geom"]))

    print(f"[Top {top_k_rms} geometries by RMS]")
    print("  rank  (n_tau1,n_tau2)  (n_d1,n_d2)    L1       L2       RMS[dex]  max|res|   S_geom")
    print("  ----  ---------------  -----------  --------  --------  ---------  --------  --------")
    for rank, g in enumerate(by_rms[:top_k_rms], start=1):
        (n_tau1, n_tau2) = g["n_tau"]
        (n_d1, n_d2) = g["n_d"]
        L1, L2 = g["L"]
        rms = g["rms"]
        max_abs = g["max_abs"]
        S_geom = g["S_geom"]
        print(f"  {rank:>4d}   ({n_tau1:>2d},{n_tau2:>2d})   ({n_d1:>2d},{n_d2:>2d})"
              f"  {L1:8.3f} {L2:8.3f}  {rms:9.4f} {max_abs:9.4f} {S_geom:9.4e}")

    print()
    # For each RMS threshold, see the best S_geom we can get
    print("[Best S_geom achievable under RMS thresholds]")
    for thr in rms_thresholds:
        candidates = [g for g in by_rms if g["rms"] <= thr]
        if not candidates:
            print(f"  RMS ≤ {thr:4.2f} dex : no geometries")
            continue
        best_S = min(candidates, key=lambda x: x["S_geom"])
        ratio = best_S["S_geom"] / S_real if S_real > 0 else float("inf")
        (n_tau1, n_tau2) = best_S["n_tau"]
        (n_d1, n_d2) = best_S["n_d"]
        print(f"  RMS ≤ {thr:4.2f} dex : best S_geom = {best_S['S_geom']:.3e}"
              f"  (ratio to S_real ≈ {ratio:.1e})"
              f"  with n_tau=({n_tau1},{n_tau2}), n_d=({n_d1},{n_d2})")

    print()
    print("Interpretation guide:")
    print("  • If minimal RMS across all patterns is ≳ O(0.1–1) dex,")
    print("    the 2-scale FN geometry simply does not reproduce the three Yukawas.")
    print("  • Even if RMS is moderate, check the best S_geom at small RMS.")
    print("    If S_geom(best) >> S_real (~6e-6), then the geometry completely")
    print("    fails to explain the ultra-tight (-4,4,3) lock; it only matches the")
    print("    rough hierarchy, which we already know is easy.")
    print()
    print("="*82)
    print("PHASE6_YUKAWA_TWO_SCALE_FN_SCAN_v2 complete.")
    print("="*82)


if __name__ == "__main__":
    # Example: a bit heavier than v1; feel free to bump Nmax up to ~8–10.
    run_phase6_yukawa_two_scale_fn_scan_v2(Nmax=5, top_k_rms=20)

import numpy as np

def run_phase6_yukawa_two_scale_fn_scan_v3(
    Nmax=10,
    require_L2_negative=True,
    rms_thresholds=(0.5, 0.2, 0.1, 0.05, 0.02, 0.01),
    top_k=20,
):
    """
    PHASE6_YUKAWA_TWO_SCALE_FN_SCAN_v3 — 2-scale FN geometry with physical priors

    Assumptions:
      • Two FN-like spurions λ1, λ2 with log10 λ1 = L1, log10 λ2 = L2.
      • Three Yukawas (me, mtau, md) are monomials in λ1, λ2 with integer exponents.
      • me exponents fixed to (1, 0): sets the λ1 scale to the electron Yukawa.
      • τ, d exponents are scanned over non-negative integers up to Nmax.
      • We require λ2 to be a suppression factor as well (L2 < 0) if require_L2_negative=True.

    Objective:
      • For each exponent pattern, solve least-squares for (L1, L2) using the 3 Yukawas.
      • Compute RMS residual in dex between predicted and real logs.
      • Compute S_geom = |-4 z_me^geom + 4 z_tau^geom + 3 z_d^geom|.
      • Compare S_geom to S_real ≈ 6×10^-6.

    Interpretation:
      • If the best S_geom at small RMS (≲ 0.01–0.02 dex) is still ≫ S_real,
        then even a physically constrained 2-scale FN geometry does NOT explain
        the ultra-tight (-4,4,3) lock; it only matches rough hierarchies.
    """

    print("=" * 82)
    print("PHASE6_YUKAWA_TWO_SCALE_FN_SCAN_v3 — 2-scale FN geometry (physical priors)")
    print("=" * 82)
    print()

    # Central logs
    z_me   = -5.683401
    z_tau  = -2.141781
    z_d    = -4.722162
    Z = np.array([z_me, z_tau, z_d], dtype=float)

    # Real lock
    S_real = abs(-4 * z_me + 4 * z_tau + 3 * z_d)

    print("[Config]")
    print(f"  exponent bound Nmax          : {Nmax}")
    print("  me exponents fixed to        : (1, 0)")
    print("  τ, d exponents scanned over  : [0, Nmax]^2 excluding (0,0)")
    print(f"  enforce L2 < 0 (λ2<1)?       : {require_L2_negative}")
    print()
    print("[Yukawa logs (central)]")
    print(f"  z_me   = {z_me: .6f}")
    print(f"  z_tau  = {z_tau: .6f}")
    print(f"  z_d    = {z_d: .6f}")
    print(f"  Real lock S_real = |-4 z_me + 4 z_tau + 3 z_d| ≈ {S_real:.3e}")
    print()

    patterns = []

    # Scan exponent pairs for tau and d
    for n_tau1 in range(0, Nmax + 1):
        for n_tau2 in range(0, Nmax + 1):
            if (n_tau1, n_tau2) == (0, 0):
                continue

            for n_d1 in range(0, Nmax + 1):
                for n_d2 in range(0, Nmax + 1):
                    if (n_d1, n_d2) == (0, 0):
                        continue

                    # Monomial exponents matrix:
                    #   me   -> (1, 0)
                    #   tau  -> (n_tau1, n_tau2)
                    #   d    -> (n_d1, n_d2)
                    N = np.array(
                        [
                            [1.0,        0.0       ],
                            [float(n_tau1), float(n_tau2)],
                            [float(n_d1),  float(n_d2) ],
                        ],
                        dtype=float,
                    )

                    # Skip degenerate patterns where N has rank < 2
                    if np.linalg.matrix_rank(N) < 2:
                        continue

                    # Least-squares fit for (L1, L2)
                    L, *_ = np.linalg.lstsq(N, Z, rcond=None)
                    L1, L2 = L

                    # Physical prior: require λ2 to be a suppression factor
                    if require_L2_negative and not (L2 < 0):
                        continue

                    # Predicted logs
                    Z_pred = N @ L
                    res = Z_pred - Z
                    RMS = float(np.sqrt(np.mean(res**2)))
                    max_res = float(np.max(np.abs(res)))

                    # Triple residual under geometry
                    S_geom = abs(-4 * Z_pred[0] + 4 * Z_pred[1] + 3 * Z_pred[2])

                    patterns.append(
                        {
                            "RMS": RMS,
                            "max_res": max_res,
                            "S_geom": S_geom,
                            "n_tau1": n_tau1,
                            "n_tau2": n_tau2,
                            "n_d1": n_d1,
                            "n_d2": n_d2,
                            "L1": L1,
                            "L2": L2,
                        }
                    )

    patterns.sort(key=lambda p: p["RMS"])

    print("[Search]")
    print(f"  total physically allowed exponent patterns scanned : {len(patterns)}")
    print()

    # Top patterns by RMS
    print(f"[Top {top_k} geometries by RMS (me, τ, d)]")
    header = (
        "  rank  (n_tau1,n_tau2)  (n_d1,n_d2)    "
        "L1       L2       RMS[dex]  max|res|   S_geom    S_geom/S_real"
    )
    print(header)
    print("  " + "-" * (len(header) - 2))
    for rank, p in enumerate(patterns[:top_k], start=1):
        print(
            f"{rank:5d}  "
            f"({p['n_tau1']:2d},{p['n_tau2']:2d})   "
            f"({p['n_d1']:2d},{p['n_d2']:2d})  "
            f"{p['L1']:8.3f} {p['L2']:8.3f}  "
            f"{p['RMS']:8.4f}  "
            f"{p['max_res']:8.4f}  "
            f"{p['S_geom']:8.3e}  "
            f"{p['S_geom']/S_real:10.3e}"
        )
    print()

    # Best S_geom achievable under RMS thresholds
    print("[Best S_geom achievable under RMS thresholds]")
    print("  RMS threshold   best RMS    best S_geom   S_geom/S_real")
    print("  ------------   --------    -----------   -------------")
    for thr in rms_thresholds:
        cands = [p for p in patterns if p["RMS"] <= thr]
        if not cands:
            print(f"     ≤ {thr:4.2f} dex    (no patterns)")
            continue
        best = min(cands, key=lambda p: p["S_geom"])
        print(
            f"     ≤ {thr:4.2f} dex    "
            f"{best['RMS']:8.4f}    "
            f"{best['S_geom']:11.3e}   "
            f"{best['S_geom']/S_real:13.3e}"
        )
    print()

    print("Interpretation guide:")
    print("  • RMS is per-Yukawa misfit (me, mtau, md) in log10-space.")
    print("  • S_real ≈ 6×10^-6 dex measures the actual (-4,4,3) lock.")
    print("  • S_geom is the same combination evaluated on the FN geometry.")
    print("  • If even the best S_geom at small RMS (≲0.02 or ≲0.01 dex)")
    print("    is ≫ S_real, then 2-scale FN with physical priors does NOT")
    print("    explain the ultra-tight lock; it only matches rough hierarchies.")
    print()
    print("=" * 82)
    print("PHASE6_YUKAWA_TWO_SCALE_FN_SCAN_v3 complete.")
    print("=" * 82)


if __name__ == "__main__":
    # You can change Nmax or thresholds here.
    run_phase6_yukawa_two_scale_fn_scan_v3(
        Nmax=10,
        require_L2_negative=True,
        rms_thresholds=(0.5, 0.2, 0.1, 0.05, 0.02, 0.01),
        top_k=20,
    )

#!/usr/bin/env python3
# ==============================================================================
# PHASE7_MODULE1_GEOMETRY_SCORECARD_v1.py
# ==============================================================================
# Prints the global geometry scorecard using the evidence budget from:
#   - PHASE3B_GLOBAL_EVIDENCE_UPDATE_v2
#   - GEOMETRY SCORECARD runs for:
#       * NullGeometry
#       * PerfectLockGeometry
#       * TwoScaleFN_Physical
#
# You can run:
#   python PHASE7_MODULE1_GEOMETRY_SCORECARD_v1.py
# or import and call:
#   from PHASE7_MODULE1_GEOMETRY_SCORECARD_v1 import run_phase7_geometry_scorecard_v1
#   run_phase7_geometry_scorecard_v1()
# ==============================================================================

from dataclasses import dataclass


# ==============================================================================
# PHASE 7 – GLOBAL LOCK EVIDENCE (FROM EARLIER PHASES)
# ==============================================================================

# These are the "GLOBAL_LOCKS" effective bits from Phase 3B:
DNA_EFFECTIVE_BITS = 12.29           # DNA backbone + locks + all-four-zero rail
YUKAWA_BITS_CONSERVATIVE = 7.48      # Global 3-term int-rel (error-model null, p=0.0056)
YUKAWA_BITS_OPTIMISTIC  = 14.29      # Fixed triple (me, mtau, md), error-model null


# ==============================================================================
# PHASE 7 – GEOMETRY OBJECT DEFINITION
# ==============================================================================

@dataclass
class GeometryScore:
    """
    A geometry's claim about which locks it actually explains.
    Bits are computed from the global evidence object, not baked in here.
    """
    name: str
    description: str

    explains_dna_backbone: bool
    explains_yukawa_global_triple: bool  # explains the global 3-term lock statistically
    explains_yukawa_fixed_triple: bool   # explains the specific (-4,4,3) triple lock

    dna_bits: float = 0.0
    yukawa_bits_conservative: float = 0.0
    yukawa_bits_optimistic: float = 0.0
    total_bits_conservative: float = 0.0
    total_bits_optimistic: float = 0.0

    def compute_bits(self):
        """Assign bits based on which locks this geometry claims to explain."""
        self.dna_bits = DNA_EFFECTIVE_BITS if self.explains_dna_backbone else 0.0
        self.yukawa_bits_conservative = (
            YUKAWA_BITS_CONSERVATIVE if self.explains_yukawa_global_triple else 0.0
        )
        self.yukawa_bits_optimistic = (
            YUKAWA_BITS_OPTIMISTIC if self.explains_yukawa_fixed_triple else 0.0
        )

        self.total_bits_conservative = self.dna_bits + self.yukawa_bits_conservative
        self.total_bits_optimistic  = self.dna_bits + self.yukawa_bits_optimistic


# ==============================================================================
# PHASE 7 – GEOMETRY REGISTRY
# ==============================================================================

def make_geometry_registry():
    """
    Build the list of geometries we're currently comparing.
    You can extend this with new geometries in later modules.
    """
    geometries = []

    # ----------------------------------------------------------------------
    # 1. NullGeometry – baseline: completely structureless universe
    # ----------------------------------------------------------------------
    geometries.append(
        GeometryScore(
            name="NullGeometry",
            description=(
                "Random / structureless geometry (baseline). "
                "Explains no DNA or Yukawa locks by design."
            ),
            explains_dna_backbone=False,
            explains_yukawa_global_triple=False,
            explains_yukawa_fixed_triple=False,
        )
    )

    # ----------------------------------------------------------------------
    # 2. PerfectLockGeometry – hypothetical 'god-tier' geometry
    # ----------------------------------------------------------------------
    geometries.append(
        GeometryScore(
            name="PerfectLockGeometry",
            description=(
                "Hypothetical geometry that exactly enforces the DNA backbone/locks "
                "AND the specific Yukawa triple (-4,4,3) in log-space."
            ),
            explains_dna_backbone=True,
            explains_yukawa_global_triple=True,
            explains_yukawa_fixed_triple=True,
        )
    )

    # ----------------------------------------------------------------------
    # 3. TwoScaleFN_Physical – 2-spurion FN with physical priors
    # ----------------------------------------------------------------------
    geometries.append(
        GeometryScore(
            name="TwoScaleFN_Physical",
            description=(
                "Two FN-like spurions λ1, λ2 < 1 with non-negative integer charges "
                "for me, mtau, md up to Nmax=10. Fits hierarchies to ~few-percent RMS "
                "but misses the (-4,4,3) lock by ~10^4 in precision."
            ),
            explains_dna_backbone=False,
            explains_yukawa_global_triple=False,
            explains_yukawa_fixed_triple=False,
        )
    )

    # Compute bits for all
    for g in geometries:
        g.compute_bits()

    return geometries


# ==============================================================================
# PHASE 7 – PRETTY PRINT HELPERS
# ==============================================================================

BANNER_LINE = "=" * 82
SUB_LINE    = "-" * 82


def print_global_lock_header():
    print(BANNER_LINE)
    print("PHASE 7 – GLOBAL GEOMETRY SCORECARD".center(82))
    print(BANNER_LINE)
    print()
    print("GLOBAL LOCK EVIDENCE BUDGET (FROM PHASE 3B)".center(82))
    print(SUB_LINE)
    print(f"  DNA effective bits                 : {DNA_EFFECTIVE_BITS:6.2f}")
    print(f"  Yukawa bits (conservative, global) : {YUKAWA_BITS_CONSERVATIVE:6.2f}")
    print(f"  Yukawa bits (optimistic, fixed)    : {YUKAWA_BITS_OPTIMISTIC:6.2f}")
    print()
    print("  Any non-cheating geometry must earn these bits by DERIVING the locks,")
    print("  not hardcoding them as input. This scorecard measures how many bits of")
    print("  that budget each candidate geometry actually explains.")
    print()
    print(BANNER_LINE)
    print()


def print_geometry_score(g: GeometryScore):
    print(BANNER_LINE)
    title = f"GEOMETRY SCORECARD – {g.name}"
    print(title.center(82))
    print(BANNER_LINE)
    print()
    print("Description:")
    print(f"  {g.description}")
    print()
    print("Lock claims:")
    print(f"  • explains_dna_backbone         : {g.explains_dna_backbone}")
    print(f"  • explains_yukawa_global_triple : {g.explains_yukawa_global_triple}")
    print(f"  • explains_yukawa_fixed_triple  : {g.explains_yukawa_fixed_triple}")
    print()
    print("Bits earned:")
    print(f"  DNA sector bits                 : {g.dna_bits:5.2f}")
    print(f"  Yukawa bits (conservative)      : {g.yukawa_bits_conservative:5.2f}")
    print(f"  Yukawa bits (optimistic)        : {g.yukawa_bits_optimistic:5.2f}")
    print()
    print(f"  → Total (conservative)          : {g.total_bits_conservative:5.2f} bits")
    print(f"  → Total (optimistic)            : {g.total_bits_optimistic:5.2f} bits")
    print()
    print(BANNER_LINE)
    print()


def print_geometry_summary_table(geometries):
    print()
    print(BANNER_LINE)
    print("PHASE 7 – MODULE 1 SUMMARY TABLE".center(82))
    print(BANNER_LINE)
    print()
    header = (
        "Name".ljust(20)
        + "DNA?".ljust(6)
        + "Yukawa_gl?".ljust(12)
        + "Yukawa_fix?".ljust(12)
        + "Bits_con".rjust(10)
        + "Bits_opt".rjust(10)
    )
    print(header)
    print(SUB_LINE)
    for g in geometries:
        row = (
            g.name.ljust(20)
            + str(g.explains_dna_backbone).ljust(6)
            + str(g.explains_yukawa_global_triple).ljust(12)
            + str(g.explains_yukawa_fixed_triple).ljust(12)
            + f"{g.total_bits_conservative:10.2f}"
            + f"{g.total_bits_optimistic:10.2f}"
        )
        print(row)
    print()
    print(BANNER_LINE)
    print()


# ==============================================================================
# PHASE 7 – MAIN ENTRYPOINT
# ==============================================================================

def run_phase7_geometry_scorecard_v1():
    """
    PHASE 7 – MODULE 1:
      Print the global geometry scorecard for all registered geometries.
    """
    geometries = make_geometry_registry()

    print_global_lock_header()
    for g in geometries:
        print_geometry_score(g)
    print_geometry_summary_table(geometries)


# Allow running as a script
if __name__ == "__main__":
    run_phase7_geometry_scorecard_v1()

#!/usr/bin/env python3
# ==============================================================================
# PHASE7_MODULE2_GEOMETRY_EVAL_v1.py
# ==============================================================================
# Purpose:
#   General geometry evaluator for your lock evidence budget.
#
#   You can:
#     - Programmatically define new geometries with simple booleans:
#         * explains_dna_backbone
#         * explains_yukawa_global_triple
#         * explains_yukawa_fixed_triple
#     - Score them in bits using the PHASE 3B evidence update.
#     - Print individual scorecards and a small summary table.
#
# Usage:
#   from PHASE7_MODULE2_GEOMETRY_EVAL_v1 import (
#       make_geometry,
#       print_geometry_score,
#       print_geometry_summary_table,
#       run_phase7_geometry_eval_demo,
#   )
#
#   g = make_geometry(
#       name="MyToyGeometry",
#       description="Explains only the Yukawa triple, not DNA.",
#       explains_dna_backbone=False,
#       explains_yukawa_global_triple=True,
#       explains_yukawa_fixed_triple=True,
#   )
#   print_geometry_score(g)
#
#   Or just run this file directly to see the demo:
#     python PHASE7_MODULE2_GEOMETRY_EVAL_v1.py
# ==============================================================================

from dataclasses import dataclass


# ==============================================================================
# PHASE 7 – GLOBAL LOCK EVIDENCE (FROM PHASE 3B)
# ==============================================================================

DNA_EFFECTIVE_BITS = 12.29           # DNA backbone + locks + all-four-zero rail
YUKAWA_BITS_CONSERVATIVE = 7.48      # Global 3-term int-rel (error-model null)
YUKAWA_BITS_OPTIMISTIC  = 14.29      # Fixed triple (me, mtau, md), error-model null


# ==============================================================================
# GEOMETRY SCORE OBJECT
# ==============================================================================

@dataclass
class GeometryScore:
    name: str
    description: str

    explains_dna_backbone: bool
    explains_yukawa_global_triple: bool
    explains_yukawa_fixed_triple: bool

    dna_bits: float = 0.0
    yukawa_bits_conservative: float = 0.0
    yukawa_bits_optimistic: float = 0.0
    total_bits_conservative: float = 0.0
    total_bits_optimistic: float = 0.0

    def compute_bits(self):
        """Fill in DNA/Yukawa/total bits based on which locks this geometry claims."""
        self.dna_bits = DNA_EFFECTIVE_BITS if self.explains_dna_backbone else 0.0

        self.yukawa_bits_conservative = (
            YUKAWA_BITS_CONSERVATIVE if self.explains_yukawa_global_triple else 0.0
        )

        self.yukawa_bits_optimistic = (
            YUKAWA_BITS_OPTIMISTIC if self.explains_yukawa_fixed_triple else 0.0
        )

        self.total_bits_conservative = self.dna_bits + self.yukawa_bits_conservative
        self.total_bits_optimistic  = self.dna_bits + self.yukawa_bits_optimistic


# ==============================================================================
# FACTORY: MAKE A GEOMETRY AND SCORE IT
# ==============================================================================

def make_geometry(
    name: str,
    description: str,
    explains_dna_backbone: bool,
    explains_yukawa_global_triple: bool,
    explains_yukawa_fixed_triple: bool,
) -> GeometryScore:
    """
    PHASE 7 – MODULE 2 MAIN ENTRY:
      Construct and score a geometry in one shot.
    """
    g = GeometryScore(
        name=name,
        description=description,
        explains_dna_backbone=explains_dna_backbone,
        explains_yukawa_global_triple=explains_yukawa_global_triple,
        explains_yukawa_fixed_triple=explains_yukawa_fixed_triple,
    )
    g.compute_bits()
    return g


# ==============================================================================
# PRETTY PRINT HELPERS
# ==============================================================================

BANNER_LINE = "=" * 82
SUB_LINE    = "-" * 82


def print_geometry_score(g: GeometryScore):
    """Print a loud, bannered scorecard for a single geometry."""
    print(BANNER_LINE)
    title = f"GEOMETRY SCORECARD – {g.name}"
    print(title.center(82))
    print(BANNER_LINE)
    print()
    print("Description:")
    print(f"  {g.description}")
    print()
    print("Lock claims:")
    print(f"  • explains_dna_backbone         : {g.explains_dna_backbone}")
    print(f"  • explains_yukawa_global_triple : {g.explains_yukawa_global_triple}")
    print(f"  • explains_yukawa_fixed_triple  : {g.explains_yukawa_fixed_triple}")
    print()
    print("Bits earned:")
    print(f"  DNA sector bits                 : {g.dna_bits:5.2f}")
    print(f"  Yukawa bits (conservative)      : {g.yukawa_bits_conservative:5.2f}")
    print(f"  Yukawa bits (optimistic)        : {g.yukawa_bits_optimistic:5.2f}")
    print()
    print(f"  → Total (conservative)          : {g.total_bits_conservative:5.2f} bits")
    print(f"  → Total (optimistic)            : {g.total_bits_optimistic:5.2f} bits")
    print()
    print(BANNER_LINE)
    print()


def print_geometry_summary_table(geometries):
    """Print a compact summary table for a list of GeometryScore objects."""
    print()
    print(BANNER_LINE)
    print("PHASE 7 – MODULE 2 SUMMARY TABLE".center(82))
    print(BANNER_LINE)
    print()
    header = (
        "Name".ljust(20)
        + "DNA?".ljust(6)
        + "Yukawa_gl?".ljust(12)
        + "Yukawa_fix?".ljust(12)
        + "Bits_con".rjust(10)
        + "Bits_opt".rjust(10)
    )
    print(header)
    print(SUB_LINE)
    for g in geometries:
        row = (
            g.name.ljust(20)
            + str(g.explains_dna_backbone).ljust(6)
            + str(g.explains_yukawa_global_triple).ljust(12)
            + str(g.explains_yukawa_fixed_triple).ljust(12)
            + f"{g.total_bits_conservative:10.2f}"
            + f"{g.total_bits_optimistic:10.2f}"
        )
        print(row)
    print()
    print(BANNER_LINE)
    print()


# ==============================================================================
# DEMO: PHASE 7 – MODULE 2
# ==============================================================================

def run_phase7_geometry_eval_demo():
    """
    Small demo:
      - Recreate NullGeometry, PerfectLockGeometry, TwoScaleFN_Physical.
      - Show their scorecards and a summary table.
    """
    geoms = []

    # Null geometry: explains nothing.
    geoms.append(
        make_geometry(
            name="NullGeometry",
            description="Random / structureless geometry (baseline). Explains no locks.",
            explains_dna_backbone=False,
            explains_yukawa_global_triple=False,
            explains_yukawa_fixed_triple=False,
        )
    )

    # Perfect lock geometry: hypothetical, explains everything.
    geoms.append(
        make_geometry(
            name="PerfectLockGeometry",
            description=(
                "Hypothetical geometry that exactly enforces the DNA backbone/locks "
                "and the specific Yukawa triple (-4,4,3) in log-space."
            ),
            explains_dna_backbone=True,
            explains_yukawa_global_triple=True,
            explains_yukawa_fixed_triple=True,
        )
    )

    # Two-scale FN (physical priors) – fails both DNA and Yukawa lock.
    geoms.append(
        make_geometry(
            name="TwoScaleFN_Physical",
            description=(
                "Two FN-like spurions λ1, λ2<1 with non-negative charges for me, mtau, "
                "md up to Nmax=10. Fits hierarchies roughly but misses the (-4,4,3) "
                "lock by ~10^4 in precision."
            ),
            explains_dna_backbone=False,
            explains_yukawa_global_triple=False,
            explains_yukawa_fixed_triple=False,
        )
    )

    # Print them
    for g in geoms:
        print_geometry_score(g)

    print_geometry_summary_table(geoms)


if __name__ == "__main__":
    run_phase7_geometry_eval_demo()

#!/usr/bin/env python3
# ==============================================================================
# PHASE7_MODULE2_GEOMETRY_EVAL_v1.py
# ==============================================================================
# Purpose:
#   General geometry evaluator for your lock evidence budget.
#
#   You can:
#     - Programmatically define new geometries with simple booleans:
#         * explains_dna_backbone
#         * explains_yukawa_global_triple
#         * explains_yukawa_fixed_triple
#     - Score them in bits using the PHASE 3B evidence update.
#     - Print individual scorecards and a small summary table.
#
# Usage:
#   from PHASE7_MODULE2_GEOMETRY_EVAL_v1 import (
#       make_geometry,
#       print_geometry_score,
#       print_geometry_summary_table,
#       run_phase7_geometry_eval_demo,
#   )
#
#   g = make_geometry(
#       name="MyToyGeometry",
#       description="Explains only the Yukawa triple, not DNA.",
#       explains_dna_backbone=False,
#       explains_yukawa_global_triple=True,
#       explains_yukawa_fixed_triple=True,
#   )
#   print_geometry_score(g)
#
#   Or just run this file directly to see the demo:
#     python PHASE7_MODULE2_GEOMETRY_EVAL_v1.py
# ==============================================================================

from dataclasses import dataclass


# ==============================================================================
# PHASE 7 – GLOBAL LOCK EVIDENCE (FROM PHASE 3B)
# ==============================================================================

DNA_EFFECTIVE_BITS = 12.29           # DNA backbone + locks + all-four-zero rail
YUKAWA_BITS_CONSERVATIVE = 7.48      # Global 3-term int-rel (error-model null)
YUKAWA_BITS_OPTIMISTIC  = 14.29      # Fixed triple (me, mtau, md), error-model null


# ==============================================================================
# GEOMETRY SCORE OBJECT
# ==============================================================================

@dataclass
class GeometryScore:
    name: str
    description: str

    explains_dna_backbone: bool
    explains_yukawa_global_triple: bool
    explains_yukawa_fixed_triple: bool

    dna_bits: float = 0.0
    yukawa_bits_conservative: float = 0.0
    yukawa_bits_optimistic: float = 0.0
    total_bits_conservative: float = 0.0
    total_bits_optimistic: float = 0.0

    def compute_bits(self):
        """Fill in DNA/Yukawa/total bits based on which locks this geometry claims."""
        self.dna_bits = DNA_EFFECTIVE_BITS if self.explains_dna_backbone else 0.0

        self.yukawa_bits_conservative = (
            YUKAWA_BITS_CONSERVATIVE if self.explains_yukawa_global_triple else 0.0
        )

        self.yukawa_bits_optimistic = (
            YUKAWA_BITS_OPTIMISTIC if self.explains_yukawa_fixed_triple else 0.0
        )

        self.total_bits_conservative = self.dna_bits + self.yukawa_bits_conservative
        self.total_bits_optimistic  = self.dna_bits + self.yukawa_bits_optimistic


# ==============================================================================
# FACTORY: MAKE A GEOMETRY AND SCORE IT
# ==============================================================================

def make_geometry(
    name: str,
    description: str,
    explains_dna_backbone: bool,
    explains_yukawa_global_triple: bool,
    explains_yukawa_fixed_triple: bool,
) -> GeometryScore:
    """
    PHASE 7 – MODULE 2 MAIN ENTRY:
      Construct and score a geometry in one shot.
    """
    g = GeometryScore(
        name=name,
        description=description,
        explains_dna_backbone=explains_dna_backbone,
        explains_yukawa_global_triple=explains_yukawa_global_triple,
        explains_yukawa_fixed_triple=explains_yukawa_fixed_triple,
    )
    g.compute_bits()
    return g


# ==============================================================================
# PRETTY PRINT HELPERS
# ==============================================================================

BANNER_LINE = "=" * 82
SUB_LINE    = "-" * 82


def print_geometry_score(g: GeometryScore):
    """Print a loud, bannered scorecard for a single geometry."""
    print(BANNER_LINE)
    title = f"GEOMETRY SCORECARD – {g.name}"
    print(title.center(82))
    print(BANNER_LINE)
    print()
    print("Description:")
    print(f"  {g.description}")
    print()
    print("Lock claims:")
    print(f"  • explains_dna_backbone         : {g.explains_dna_backbone}")
    print(f"  • explains_yukawa_global_triple : {g.explains_yukawa_global_triple}")
    print(f"  • explains_yukawa_fixed_triple  : {g.explains_yukawa_fixed_triple}")
    print()
    print("Bits earned:")
    print(f"  DNA sector bits                 : {g.dna_bits:5.2f}")
    print(f"  Yukawa bits (conservative)      : {g.yukawa_bits_conservative:5.2f}")
    print(f"  Yukawa bits (optimistic)        : {g.yukawa_bits_optimistic:5.2f}")
    print()
    print(f"  → Total (conservative)          : {g.total_bits_conservative:5.2f} bits")
    print(f"  → Total (optimistic)            : {g.total_bits_optimistic:5.2f} bits")
    print()
    print(BANNER_LINE)
    print()


def print_geometry_summary_table(geometries):
    """Print a compact summary table for a list of GeometryScore objects."""
    print()
    print(BANNER_LINE)
    print("PHASE 7 – MODULE 2 SUMMARY TABLE".center(82))
    print(BANNER_LINE)
    print()
    header = (
        "Name".ljust(20)
        + "DNA?".ljust(6)
        + "Yukawa_gl?".ljust(12)
        + "Yukawa_fix?".ljust(12)
        + "Bits_con".rjust(10)
        + "Bits_opt".rjust(10)
    )
    print(header)
    print(SUB_LINE)
    for g in geometries:
        row = (
            g.name.ljust(20)
            + str(g.explains_dna_backbone).ljust(6)
            + str(g.explains_yukawa_global_triple).ljust(12)
            + str(g.explains_yukawa_fixed_triple).ljust(12)
            + f"{g.total_bits_conservative:10.2f}"
            + f"{g.total_bits_optimistic:10.2f}"
        )
        print(row)
    print()
    print(BANNER_LINE)
    print()


# ==============================================================================
# DEMO: PHASE 7 – MODULE 2
# ==============================================================================

def run_phase7_geometry_eval_demo():
    """
    Small demo:
      - Recreate NullGeometry, PerfectLockGeometry, TwoScaleFN_Physical.
      - Show their scorecards and a summary table.
    """
    geoms = []

    # Null geometry: explains nothing.
    geoms.append(
        make_geometry(
            name="NullGeometry",
            description="Random / structureless geometry (baseline). Explains no locks.",
            explains_dna_backbone=False,
            explains_yukawa_global_triple=False,
            explains_yukawa_fixed_triple=False,
        )
    )

    # Perfect lock geometry: hypothetical, explains everything.
    geoms.append(
        make_geometry(
            name="PerfectLockGeometry",
            description=(
                "Hypothetical geometry that exactly enforces the DNA backbone/locks "
                "and the specific Yukawa triple (-4,4,3) in log-space."
            ),
            explains_dna_backbone=True,
            explains_yukawa_global_triple=True,
            explains_yukawa_fixed_triple=True,
        )
    )

    # Two-scale FN (physical priors) – fails both DNA and Yukawa lock.
    geoms.append(
        make_geometry(
            name="TwoScaleFN_Physical",
            description=(
                "Two FN-like spurions λ1, λ2<1 with non-negative charges for me, mtau, "
                "md up to Nmax=10. Fits hierarchies roughly but misses the (-4,4,3) "
                "lock by ~10^4 in precision."
            ),
            explains_dna_backbone=False,
            explains_yukawa_global_triple=False,
            explains_yukawa_fixed_triple=False,
        )
    )

    # Print them
    for g in geoms:
        print_geometry_score(g)

    print_geometry_summary_table(geoms)


if __name__ == "__main__":
    run_phase7_geometry_eval_demo()

#!/usr/bin/env python3
# ==============================================================================
# PHASE7_YUKAWA_LOCKCHECKER_v1.py
# ==============================================================================
# Purpose:
#   Take concrete Yukawa geometries (FN-style, etc.) and quantify how well
#   they actually reproduce:
#
#       S_real = |-4 z_me + 4 z_tau + 3 z_d|
#
#   compared to:
#     - the real universe (S_real ~ 6×10^-6 in log10-space),
#     - a simple error model for me, mtau, md.
#
#   This module:
#     - Hard-codes the real Yukawa logs and the error-model stats.
#     - Reconstructs:
#         1) Single-λ FN geometry from PHASE5 (n_me, n_tau, n_d).
#         2) Two-scale FN geometry with physical priors from PHASE6_v3.
#     - Computes for each:
#         * RMS misfit (me, tau, d) in dex.
#         * S_geom and S_geom / S_real.
#         * A simple PASS/FAIL verdict under explicit thresholds.
#
#   You do not need to edit anything. Just run this file.
# ==============================================================================

import math
from dataclasses import dataclass

# ------------------------------------------------------------------------------
# REAL YUKAWA LOGS (z = log10(y/v)) FOR (me, mtau, md)
# ------------------------------------------------------------------------------

z_me   = -5.683401   # log10(me_over_v)
z_tau  = -2.141781   # log10(mtau_over_v)
z_d    = -4.722162   # log10(md_over_v)

# The real lock:
#   S_real = |-4 z_me + 4 z_tau + 3 z_d|
S_real = abs(-4 * z_me + 4 * z_tau + 3 * z_d)   # ~ 6e-6
# For reference: the corresponding product is ~ 0.999986...

# ------------------------------------------------------------------------------
# ERROR-MODEL NULL (from previous PHASE2_YUKAWA_FIXED_TRIPLE_ERRORMODEL_v1)
# ------------------------------------------------------------------------------

# Under the realistic error model:
#   S_null mean / std ≈ 0.210 / 0.158
# (This is only for context; we do not recompute null here.)
S_null_mean = 2.101686e-01
S_null_std  = 1.584265e-01


# ==============================================================================
# GEOMETRY OBJECT
# ==============================================================================

@dataclass
class YukawaGeometry:
    name: str
    description: str

    # predicted logs for (me, tau, d)
    z_me_geom: float
    z_tau_geom: float
    z_d_geom: float

    # filled later
    rms_dex: float = 0.0
    max_abs_resid: float = 0.0
    S_geom: float = 0.0
    S_ratio: float = 0.0
    verdict: str = ""

    def compute_metrics(self):
        """Compute RMS, S_geom, and a simple verdict."""
        # residuals (predicted - real) in dex
        r_me  = self.z_me_geom  - z_me
        r_tau = self.z_tau_geom - z_tau
        r_d   = self.z_d_geom   - z_d

        # RMS over the three Yukawas
        self.rms_dex = math.sqrt((r_me**2 + r_tau**2 + r_d**2) / 3.0)
        self.max_abs_resid = max(abs(r_me), abs(r_tau), abs(r_d))

        # lock combination on geometry
        self.S_geom = abs(-4 * self.z_me_geom + 4 * self.z_tau_geom + 3 * self.z_d_geom)
        self.S_ratio = self.S_geom / S_real if S_real > 0 else float("inf")

        # ----------------------------------------------------------------------
        # VERDICT RULES (tunable, but hard-coded here so you don't touch code)
        # ----------------------------------------------------------------------
        # Intuition:
        #   * S_real ~ 6e-6 is insanely small compared to the error-model mean ~0.21.
        #   * A "serious" geometry should:
        #       - get RMS per Yukawa better than ~0.02 dex (≈ 5% in linear space), and
        #       - get S_geom at least 1000 times smaller than a generic O(0.1–1) scale,
        #         i.e., S_geom <= 1e3 * S_real ≈ 6e-3.
        #
        #   * We also label a "weakly compatible" zone:
        #       - RMS <= 0.05 dex, and
        #       - S_geom <= 1e4 * S_real ≈ 6e-2.
        #
        # These are just clear, explicit thresholds so the verdict is mechanical.
        # ----------------------------------------------------------------------

        STRICT_RMS_MAX       = 0.02
        STRICT_S_FACTOR_MAX  = 1.0e3    # S_geom <= 1e3 * S_real

        WEAK_RMS_MAX         = 0.05
        WEAK_S_FACTOR_MAX    = 1.0e4    # S_geom <= 1e4 * S_real

        if (self.rms_dex <= STRICT_RMS_MAX) and (self.S_ratio <= STRICT_S_FACTOR_MAX):
            self.verdict = "PASS: explains Yukawa triple (strict)."
        elif (self.rms_dex <= WEAK_RMS_MAX) and (self.S_ratio <= WEAK_S_FACTOR_MAX):
            self.verdict = "BORDERLINE: matches hierarchies, weak lock control."
        else:
            self.verdict = "FAIL: does not explain the (-4,4,3) lock."


# ==============================================================================
# GEOMETRY BUILDERS
# ==============================================================================

def build_perfect_lock_geometry() -> YukawaGeometry:
    """
    'Geometry' that just *is* the real universe.
    Used as a reference: RMS = 0, S_geom = S_real, S_ratio = 1.
    """
    g = YukawaGeometry(
        name="PerfectLockGeometry_Data",
        description="Reference: geometry that exactly reproduces the real Yukawas.",
        z_me_geom=z_me,
        z_tau_geom=z_tau,
        z_d_geom=z_d,
    )
    g.compute_metrics()
    return g


def build_single_lambda_fn_geometry() -> YukawaGeometry:
    """
    Single-λ FN-style geometry from PHASE5_YUKAWA_FN_SINGLE_PARAM_GEOMETRY_v1:

      z_i ≈ n_i * L,  with best exponents:
        n_me  = 19
        n_tau = 7
        n_d   = 16

    We refit L in least-squares sense and compute the resulting metrics.
    """

    n_me  = 19
    n_tau = 7
    n_d   = 16

    # Least-squares L: minimize sum_i (z_i - n_i L)^2
    #   L = (Σ n_i z_i) / (Σ n_i^2)
    num = n_me * z_me + n_tau * z_tau + n_d * z_d
    den = n_me**2 + n_tau**2 + n_d**2
    L_opt = num / den

    z_me_geom  = n_me  * L_opt
    z_tau_geom = n_tau * L_opt
    z_d_geom   = n_d   * L_opt

    g = YukawaGeometry(
        name="SingleLambda_FN",
        description=(
            "Single-λ FN geometry: z_i ≈ n_i * log10 λ with exponents "
            f"(n_me, n_tau, n_d) = ({n_me}, {n_tau}, {n_d})."
        ),
        z_me_geom=z_me_geom,
        z_tau_geom=z_tau_geom,
        z_d_geom=z_d_geom,
    )
    g.compute_metrics()
    return g


def build_two_scale_fn_physical_geometry() -> YukawaGeometry:
    """
    Two-scale FN geometry with physical priors from PHASE6_YUKAWA_TWO_SCALE_FN_SCAN_v3:

      - me exponents fixed to (1, 0) to define λ1 scale.
      - Best physical-λ2 pattern found there:

          n_tau = (0, 4)
          n_d   = (0, 9)

      So:
          z_me  ≈ 1*L1 + 0*L2
          z_tau ≈ 0*L1 + 4*L2
          z_d   ≈ 0*L1 + 9*L2

      We refit (L1, L2) in least-squares sense.
    """

    # Exponents:
    n_me1,  n_me2  = 1, 0
    n_tau1, n_tau2 = 0, 4
    n_d1,   n_d2   = 0, 9

    # Build design matrix A and data vector z for [L1, L2].
    # A rows: [n1, n2] for (me, tau, d)
    A = [
        [n_me1,  n_me2],
        [n_tau1, n_tau2],
        [n_d1,   n_d2],
    ]
    z_vec = [z_me, z_tau, z_d]

    # Solve (A^T A) L = A^T z  for L = [L1, L2].
    # A^T A is 2x2, A^T z is 2x1.
    AT = [[A[0][0], A[1][0], A[2][0]],
          [A[0][1], A[1][1], A[2][1]]]

    # Compute A^T A
    ATA_00 = sum(AT[0][i] * A[i][0] for i in range(3))
    ATA_01 = sum(AT[0][i] * A[i][1] for i in range(3))
    ATA_10 = sum(AT[1][i] * A[i][0] for i in range(3))
    ATA_11 = sum(AT[1][i] * A[i][1] for i in range(3))

    # Compute A^T z
    ATz_0 = sum(AT[0][i] * z_vec[i] for i in range(3))
    ATz_1 = sum(AT[1][i] * z_vec[i] for i in range(3))

    # Invert 2x2 ATA
    det = ATA_00 * ATA_11 - ATA_01 * ATA_10
    if abs(det) < 1e-14:
        raise RuntimeError("Degenerate exponent pattern in TwoScaleFN geometry.")

    inv_ATA_00 =  ATA_11 / det
    inv_ATA_01 = -ATA_01 / det
    inv_ATA_10 = -ATA_10 / det
    inv_ATA_11 =  ATA_00 / det

    # L = (A^T A)^(-1) (A^T z)
    L1 = inv_ATA_00 * ATz_0 + inv_ATA_01 * ATz_1
    L2 = inv_ATA_10 * ATz_0 + inv_ATA_11 * ATz_1

    # Predicted logs
    z_me_geom  = n_me1  * L1 + n_me2  * L2
    z_tau_geom = n_tau1 * L1 + n_tau2 * L2
    z_d_geom   = n_d1   * L1 + n_d2   * L2

    g = YukawaGeometry(
        name="TwoScaleFN_Physical",
        description=(
            "Two-scale FN geometry with physical priors: λ1, λ2<1 and integer "
            "charges (1,0) for me, (0,4) for mtau, (0,9) for md, re-fitted in "
            "least-squares sense."
        ),
        z_me_geom=z_me_geom,
        z_tau_geom=z_tau_geom,
        z_d_geom=z_d_geom,
    )
    g.compute_metrics()
    return g


# ==============================================================================
# PRETTY PRINTING
# ==============================================================================

BANNER_LINE = "=" * 82
SUB_LINE    = "-" * 82


def print_yukawa_lock_header():
    print(BANNER_LINE)
    print("PHASE 7 – MODULE 3: YUKAWA LOCKCHECKER".center(82))
    print(BANNER_LINE)
    print()
    print("Real Yukawa triple:")
    print(f"  z_me   = {z_me: .6f}")
    print(f"  z_tau  = {z_tau: .6f}")
    print(f"  z_d    = {z_d: .6f}")
    print()
    print(f"  S_real = |-4 z_me + 4 z_tau + 3 z_d| = {S_real: .6e}")
    print(f"  Error-model null: mean(S_null) ≈ {S_null_mean: .3e}, std ≈ {S_null_std: .3e}")
    print()
    print(BANNER_LINE)
    print()


def print_geometry_result(g: YukawaGeometry):
    print(BANNER_LINE)
    title = f"YUKAWA GEOMETRY CHECK – {g.name}"
    print(title.center(82))
    print(BANNER_LINE)
    print()
    print("Description:")
    print(f"  {g.description}")
    print()
    print("Predicted logs (z_geom):")
    print(f"  z_me_geom   = {g.z_me_geom: .6f}  (Δ = {g.z_me_geom - z_me: .6f} dex)")
    print(f"  z_tau_geom  = {g.z_tau_geom: .6f}  (Δ = {g.z_tau_geom - z_tau: .6f} dex)")
    print(f"  z_d_geom    = {g.z_d_geom: .6f}  (Δ = {g.z_d_geom - z_d: .6f} dex)")
    print()
    print("Fit quality:")
    print(f"  RMS (me, tau, d)           : {g.rms_dex: .6f} dex")
    print(f"  Max |residual|             : {g.max_abs_resid: .6f} dex")
    print()
    print("Lock combination on geometry:")
    print(f"  S_geom                     : {g.S_geom: .6e}")
    print(f"  S_geom / S_real            : {g.S_ratio: .3e}")
    print()
    print("Verdict:")
    print(f"  {g.verdict}")
    print()
    print(BANNER_LINE)
    print()


def run_phase7_yukawa_lockchecker_demo():
    print_yukawa_lock_header()

    # Build geometries
    geoms = [
        build_perfect_lock_geometry(),
        build_single_lambda_fn_geometry(),
        build_two_scale_fn_physical_geometry(),
    ]

    for g in geoms:
        print_geometry_result(g)


# ==============================================================================
# MAIN
# ==============================================================================

if __name__ == "__main__":
    run_phase7_yukawa_lockchecker_demo()

#!/usr/bin/env python3
# ==============================================================================
# PHASE7_GEOMETRY_SCORECARD_v2.py
# ==============================================================================
# Purpose:
#   Turn the global evidence budget (DNA + Yukawa triple) into a concrete
#   "geometry scorecard" for a few example geometries:
#
#     - NullGeometry              : explains nothing.
#     - PerfectLockGeometry       : hypothetical geometry that explains DNA + Yukawa.
#     - SingleLambda_FN           : single-λ FN Yukawa geometry.
#     - TwoScaleFN_Physical       : 2-scale FN geometry with physical priors.
#
#   This module:
#     • hard-codes the evidence bits from PHASE3B_GLOBAL_EVIDENCE_UPDATE_v2,
#     • recomputes whether each Yukawa geometry actually explains the
#       (-4,4,3) lock (using the same thresholds as the lockchecker),
#     • assigns bits based on a simple boolean contract:
#         - explains_dna_backbone         ? 12.29 bits
#         - explains_yukawa_global_triple ? 7.48 bits
#         - explains_yukawa_fixed_triple  ? 14.29 bits
#     • prints a loud banner scorecard.
#
#   You do not need to modify anything. Just run this file.
# ==============================================================================

import math
from dataclasses import dataclass

# ------------------------------------------------------------------------------
# GLOBAL EVIDENCE BUDGET (from PHASE3B_GLOBAL_EVIDENCE_UPDATE_v2)
# ------------------------------------------------------------------------------

DNA_EFFECTIVE_BITS          = 12.29   # lower bound for DNA sector
YUKAWA_GLOBAL_TRIPLE_BITS   = 7.48    # global 3-term error-model p ≈ 0.0056
YUKAWA_FIXED_TRIPLE_BITS    = 14.29   # fixed triple (error-model) p ≈ 5e-5

# ------------------------------------------------------------------------------
# REAL YUKAWA LOGS AND LOCK
# ------------------------------------------------------------------------------

z_me   = -5.683401   # log10(me_over_v)
z_tau  = -2.141781   # log10(mtau_over_v)
z_d    = -4.722162   # log10(md_over_v)

S_real = abs(-4 * z_me + 4 * z_tau + 3 * z_d)   # ≈ 6e-06

# Simple thresholds for "geometry explains the lock":
STRICT_RMS_MAX       = 0.02   # dex
STRICT_S_FACTOR_MAX  = 1.0e3  # S_geom <= 1e3 * S_real

WEAK_RMS_MAX         = 0.05   # dex
WEAK_S_FACTOR_MAX    = 1.0e4  # S_geom <= 1e4 * S_real


# ==============================================================================
# YUKAWA GEOMETRY METRICS (mini version of the lockchecker)
# ==============================================================================

@dataclass
class YukawaTripleFit:
    z_me_geom: float
    z_tau_geom: float
    z_d_geom: float

    rms_dex: float = 0.0
    max_abs_resid: float = 0.0
    S_geom: float = 0.0
    S_ratio: float = 0.0
    verdict: str = ""

    def compute(self):
        r_me  = self.z_me_geom  - z_me
        r_tau = self.z_tau_geom - z_tau
        r_d   = self.z_d_geom   - z_d

        self.rms_dex = math.sqrt((r_me**2 + r_tau**2 + r_d**2) / 3.0)
        self.max_abs_resid = max(abs(r_me), abs(r_tau), abs(r_d))

        self.S_geom = abs(-4 * self.z_me_geom + 4 * self.z_tau_geom + 3 * self.z_d_geom)
        self.S_ratio = self.S_geom / S_real if S_real > 0 else float("inf")

        if (self.rms_dex <= STRICT_RMS_MAX) and (self.S_ratio <= STRICT_S_FACTOR_MAX):
            self.verdict = "PASS: explains Yukawa triple (strict)."
        elif (self.rms_dex <= WEAK_RMS_MAX) and (self.S_ratio <= WEAK_S_FACTOR_MAX):
            self.verdict = "BORDERLINE: matches hierarchies, weak lock control."
        else:
            self.verdict = "FAIL: does not explain the (-4,4,3) lock."


# ==============================================================================
# GEOMETRY DEFINITIONS
# ==============================================================================

@dataclass
class GeometryScore:
    name: str
    description: str

    explains_dna_backbone: bool
    explains_yukawa_global_triple: bool
    explains_yukawa_fixed_triple: bool

    yukawa_fit: YukawaTripleFit | None = None

    bits_dna: float = 0.0
    bits_yukawa_conservative: float = 0.0
    bits_yukawa_optimistic: float = 0.0
    bits_total_conservative: float = 0.0
    bits_total_optimistic: float = 0.0

    def compute_bits(self):
        # DNA bits: all-or-nothing based on backbone explanation
        self.bits_dna = DNA_EFFECTIVE_BITS if self.explains_dna_backbone else 0.0

        # Yukawa bits (conservative = global triple bits)
        self.bits_yukawa_conservative = (
            YUKAWA_GLOBAL_TRIPLE_BITS if self.explains_yukawa_global_triple else 0.0
        )

        # Yukawa bits (optimistic = fixed triple bits)
        self.bits_yukawa_optimistic = (
            YUKAWA_FIXED_TRIPLE_BITS if self.explains_yukawa_fixed_triple else 0.0
        )

        self.bits_total_conservative = self.bits_dna + self.bits_yukawa_conservative
        self.bits_total_optimistic   = self.bits_dna + self.bits_yukawa_optimistic


# ------------------------------------------------------------------------------
# Geometry builders
# ------------------------------------------------------------------------------

def build_null_geometry() -> GeometryScore:
    return GeometryScore(
        name="NullGeometry",
        description="Random / structureless geometry; explains no locks by design.",
        explains_dna_backbone=False,
        explains_yukawa_global_triple=False,
        explains_yukawa_fixed_triple=False,
        yukawa_fit=None,
    )


def build_perfectlock_geometry() -> GeometryScore:
    # Hypothetical geometry that *by construction* explains DNA + Yukawa locks.
    g = GeometryScore(
        name="PerfectLockGeometry",
        description=(
            "Hypothetical 'god-tier' geometry that exactly enforces the DNA "
            "backbone/locks AND the specific Yukawa triple (-4,4,3) in log-space."
        ),
        explains_dna_backbone=True,
        explains_yukawa_global_triple=True,
        explains_yukawa_fixed_triple=True,
        yukawa_fit=YukawaTripleFit(
            z_me_geom=z_me,
            z_tau_geom=z_tau,
            z_d_geom=z_d,
        ),
    )
    g.yukawa_fit.compute()
    g.compute_bits()
    return g


def build_singlelambda_fn_geometry() -> GeometryScore:
    """
    Single-λ FN geometry from PHASE5_YUKAWA_FN_SINGLE_PARAM_GEOMETRY_v1:

      z_i ≈ n_i * L, with (n_me, n_tau, n_d) = (19, 7, 16).
    """
    n_me, n_tau, n_d = 19, 7, 16

    num = n_me * z_me + n_tau * z_tau + n_d * z_d
    den = n_me**2 + n_tau**2 + n_d**2
    L_opt = num / den

    z_me_geom   = n_me  * L_opt
    z_tau_geom  = n_tau * L_opt
    z_d_geom    = n_d   * L_opt

    fit = YukawaTripleFit(z_me_geom=z_me_geom, z_tau_geom=z_tau_geom, z_d_geom=z_d_geom)
    fit.compute()

    # Decide if this geometry "explains" the triple:
    # We require at least the WEAK regime: RMS <= 0.05 dex and S_ratio <= 1e4.
    explains_fixed = (fit.rms_dex <= WEAK_RMS_MAX) and (fit.S_ratio <= WEAK_S_FACTOR_MAX)

    g = GeometryScore(
        name="SingleLambda_FN",
        description=(
            "Single-λ FN geometry: z_i ≈ n_i * log10 λ with exponents "
            f"(n_me, n_tau, n_d) = ({n_me}, {n_tau}, {n_d}). "
            "Good at hierarchies; lock enforced at exponent level."
        ),
        explains_dna_backbone=False,
        explains_yukawa_global_triple=explains_fixed,  # same lock
        explains_yukawa_fixed_triple=explains_fixed,
        yukawa_fit=fit,
    )
    g.compute_bits()
    return g


def build_twoscale_fn_physical_geometry() -> GeometryScore:
    """
    Two-scale FN geometry with physical priors:

      - me exponents fixed to (1, 0)
      - mtau exponents = (0, 4)
      - md exponents   = (0, 9)

    with λ1, λ2 < 1. We refit (L1, L2) in least squares.
    """
    n_me1,  n_me2  = 1, 0
    n_tau1, n_tau2 = 0, 4
    n_d1,   n_d2   = 0, 9

    A = [
        [n_me1,  n_me2],
        [n_tau1, n_tau2],
        [n_d1,   n_d2],
    ]
    z_vec = [z_me, z_tau, z_d]

    AT = [[A[0][0], A[1][0], A[2][0]],
          [A[0][1], A[1][1], A[2][1]]]

    ATA_00 = sum(AT[0][i] * A[i][0] for i in range(3))
    ATA_01 = sum(AT[0][i] * A[i][1] for i in range(3))
    ATA_10 = sum(AT[1][i] * A[i][0] for i in range(3))
    ATA_11 = sum(AT[1][i] * A[i][1] for i in range(3))

    ATz_0 = sum(AT[0][i] * z_vec[i] for i in range(3))
    ATz_1 = sum(AT[1][i] * z_vec[i] for i in range(3))

    det = ATA_00 * ATA_11 - ATA_01 * ATA_10
    if abs(det) < 1e-14:
        raise RuntimeError("Degenerate exponent pattern in TwoScaleFN_Physical.")

    inv_ATA_00 =  ATA_11 / det
    inv_ATA_01 = -ATA_01 / det
    inv_ATA_10 = -ATA_10 / det
    inv_ATA_11 =  ATA_00 / det

    L1 = inv_ATA_00 * ATz_0 + inv_ATA_01 * ATz_1
    L2 = inv_ATA_10 * ATz_0 + inv_ATA_11 * ATz_1

    z_me_geom   = n_me1  * L1 + n_me2  * L2
    z_tau_geom  = n_tau1 * L1 + n_tau2 * L2
    z_d_geom    = n_d1   * L1 + n_d2   * L2

    fit = YukawaTripleFit(z_me_geom=z_me_geom, z_tau_geom=z_tau_geom, z_d_geom=z_d_geom)
    fit.compute()

    # This geometry fits hierarchies at ~0.02 dex RMS but has S_geom ~ 1e-1,
    # which is ~1.6×10^4 times larger than S_real. We do NOT credit it with
    # explaining the lock.
    explains_fixed = False

    g = GeometryScore(
        name="TwoScaleFN_Physical",
        description=(
            "Two-scale FN geometry with physical priors λ1, λ2<1 and charges "
            "(1,0) for me, (0,4) for mtau, (0,9) for md. Matches hierarchies "
            "to ~0.02 dex but misses the (-4,4,3) lock by ~10^4 in precision."
        ),
        explains_dna_backbone=False,
        explains_yukawa_global_triple=explains_fixed,
        explains_yukawa_fixed_triple=explains_fixed,
        yukawa_fit=fit,
    )
    g.compute_bits()
    return g


# ==============================================================================
# PRETTY PRINTING
# ==============================================================================

BANNER = "=" * 82
LINE   = "-" * 82


def print_header():
    print(BANNER)
    print("PHASE 7 – MODULE 4: GEOMETRY SCORECARD".center(82))
    print(BANNER)
    print()
    print("Locks to explain (from global evidence budget):")
    print(f"  • DNA backbone / locks         : {DNA_EFFECTIVE_BITS:5.2f} bits (effective)")
    print(f"  • Yukawa global 3-term triple  : {YUKAWA_GLOBAL_TRIPLE_BITS:5.2f} bits")
    print(f"  • Yukawa fixed (me,mtau,md)    : {YUKAWA_FIXED_TRIPLE_BITS:5.2f} bits")
    print()
    print(f"  Real Yukawa lock S_real = {S_real: .6e}")
    print()
    print(BANNER)
    print()


def print_geometry_detail(g: GeometryScore):
    print(BANNER)
    print(f"GEOMETRY SCORECARD – {g.name}".center(82))
    print(BANNER)
    print()
    print("Description:")
    print(f"  {g.description}")
    print()
    print("Lock claims:")
    print(f"  • explains_dna_backbone         : {g.explains_dna_backbone}")
    print(f"  • explains_yukawa_global_triple : {g.explains_yukawa_global_triple}")
    print(f"  • explains_yukawa_fixed_triple  : {g.explains_yukawa_fixed_triple}")
    print()
    if g.yukawa_fit is not None:
        f = g.yukawa_fit
        print("Yukawa triple fit (me, tau, d):")
        print(f"  RMS[dex]       : {f.rms_dex: .6f}")
        print(f"  Max |residual| : {f.max_abs_resid: .6f}")
        print(f"  S_geom         : {f.S_geom: .6e}")
        print(f"  S_geom/S_real  : {f.S_ratio: .3e}")
        print(f"  Verdict        : {f.verdict}")
        print()
    else:
        print("Yukawa triple fit: not defined (geometry does not specify Yukawas).")
        print()
    print("Bits earned:")
    print(f"  DNA sector bits                 : {g.bits_dna:5.2f}")
    print(f"  Yukawa bits (conservative)      : {g.bits_yukawa_conservative:5.2f}")
    print(f"  Yukawa bits (optimistic)        : {g.bits_yukawa_optimistic:5.2f}")
    print()
    print(f"  → Total (conservative)          : {g.bits_total_conservative:5.2f} bits")
    print(f"  → Total (optimistic)            : {g.bits_total_optimistic:5.2f} bits")
    print()
    print(BANNER)
    print()


def print_summary_table(geoms: list[GeometryScore]):
    print()
    print(BANNER)
    print("PHASE 7 – MODULE 4 SUMMARY TABLE".center(82))
    print(BANNER)
    print()
    print("Name                DNA?  Yukawa_gl?  Yukawa_fix?   Bits_con  Bits_opt")
    print(LINE)
    for g in geoms:
        print(
            f"{g.name:<18} "
            f"{str(g.explains_dna_backbone):<5} "
            f"{str(g.explains_yukawa_global_triple):<11} "
            f"{str(g.explains_yukawa_fixed_triple):<12} "
            f"{g.bits_total_conservative:8.2f} "
            f"{g.bits_total_optimistic:8.2f}"
        )
    print()
    print(BANNER)
    print()


# ==============================================================================
# MAIN
# ==============================================================================

def run_phase7_geometry_scorecard():
    print_header()

    geoms = [
        build_null_geometry(),
        build_perfectlock_geometry(),
        build_singlelambda_fn_geometry(),
        build_twoscale_fn_physical_geometry(),
    ]

    for g in geoms:
        print_geometry_detail(g)

    print_summary_table(geoms)


if __name__ == "__main__":
    run_phase7_geometry_scorecard()

#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
PHASE 8 – MODULE 1: MINIMAL YUKAWA GEOMETRY FINDER

Goal:
  • Assume there exist a small number of underlying "geometry parameters" q1, q2
    such that each Yukawa log z_i ≈ c_i1*q1 + c_i2*q2 with small integer coeffs.
  • We FORCE the me–mtau–md (-4,4,3) lock at the *exponent level*:
        -4 * row(me) + 4 * row(tau) + 3 * row(d) = 0   (vector equation)
    so that the lock is automatic for any q1,q2.
  • Then we:
        - Fit q1,q2 from (me, tau, d),
        - Assign small-integer rows to the other Yukawas,
        - Measure how well the geometry fits all 9 Yukawas (RMS in dex).
  • We search for the simplest / best-fitting 2D integer geometry.

This is a "constructive geometry" module: it *builds* candidate structures
rather than just scoring them.
"""

import math
import itertools

import numpy as np


def run_phase8_minimal_yukawa_geometry():
    print("=" * 82)
    print("        PHASE 8 – MODULE 1: MINIMAL YUKAWA GEOMETRY FINDER (2D INTEGER)        ")
    print("=" * 82)
    print()

    # ----------------------------------------------------------------------
    # 1. Input: Yukawa logs (central values)
    # ----------------------------------------------------------------------
    yuk_logs = {
        "me_over_v":   -5.683401,
        "mmu_over_v":  -3.367606,
        "mtau_over_v": -2.141781,
        "mb_over_v":   -1.770024,
        "mc_over_v":   -2.287532,
        "mt_over_v":   -0.154056,
        "md_over_v":   -4.722162,
        "ms_over_v":   -3.422873,
        "mu_over_v":   -5.056852,
    }

    names_order = [
        "me_over_v",
        "mmu_over_v",
        "mtau_over_v",
        "mb_over_v",
        "mc_over_v",
        "mt_over_v",
        "md_over_v",
        "ms_over_v",
        "mu_over_v",
    ]

    z_me   = yuk_logs["me_over_v"]
    z_tau  = yuk_logs["mtau_over_v"]
    z_d    = yuk_logs["md_over_v"]

    # Real lock size in log10 space:
    S_real = abs(-4 * z_me + 4 * z_tau + 3 * z_d)

    print("[INPUT YUKAWA LOGS]")
    for nm in names_order:
        print(f"  {nm:12s}  z = {yuk_logs[nm]: .6f}")
    print()
    print(f"  Real triple lock S_real = |-4 z_me + 4 z_tau + 3 z_d| = {S_real: .6e}")
    print()

    # ----------------------------------------------------------------------
    # 2. Geometry parameterization
    # ----------------------------------------------------------------------
    print("[GEOMETRY SETUP]")
    D = 2          # dimension of geometry (q1, q2)
    C_basis = 4    # bound on coefficients for me, tau, d
    C_other = 6    # bound on coefficients for other Yukawas

    print(f"  Geometry dimension D              : {D}")
    print(f"  Basis coeff bound for (me,tau,d)  : ±{C_basis}")
    print(f"  Coeff bound for other Yukawas     : ±{C_other}")
    print("  Constraint enforced exactly       : -4 row(me) + 4 row(tau) + 3 row(d) = 0")
    print()

    # Parameterization for each geometry dimension:
    # For each component k, we need integers (a, b, c) = (me_k, tau_k, d_k)
    # satisfying: -4*a + 4*b + 3*c = 0.
    # General integer solution:
    #   Let a = a, n = n; then
    #       c = 4*n
    #       b = a - 3*n
    #   Check bounds |a|,|b|,|c| ≤ C_basis.
    #
    # We'll generate allowed triples (a, b, c) for each dimension, then
    # combine two dimensions to get 2D coefficient vectors for (me, tau, d).

    def generate_component_triples(C):
        triples = []
        for a in range(-C, C + 1):
            for n in range(-C, C + 1):
                c = 4 * n
                b = a - 3 * n
                if max(abs(a), abs(b), abs(c)) <= C:
                    if not (a == 0 and b == 0 and c == 0):
                        triples.append((a, b, c))
        return triples

    comp_triples = generate_component_triples(C_basis)

    print(f"  Number of allowed (me,tau,d) triples per dimension: {len(comp_triples)}")
    print()

    # ----------------------------------------------------------------------
    # 3. Enumerate candidate basis geometries for (me, tau, d)
    # ----------------------------------------------------------------------
    results = []

    # Iterate over all pairs of component-triples to form 2D coefficient rows.
    total_candidates = 0
    for (a1, b1, c1), (a2, b2, c2) in itertools.product(comp_triples, comp_triples):
        # Coeff vectors for me, tau, d in 2D:
        row_me  = np.array([a1, a2], dtype=float)
        row_tau = np.array([b1, b2], dtype=float)
        row_d   = np.array([c1, c2], dtype=float)

        # Check the constraint is exactly satisfied at the integer level:
        # -4 * row_me + 4 * row_tau + 3 * row_d == 0 vector
        vec_check = -4 * row_me + 4 * row_tau + 3 * row_d
        if not np.allclose(vec_check, np.zeros(D)):
            continue

        # Avoid trivial degenerate case where all rows are multiples or zero-ish.
        C_basis_matrix = np.vstack([row_me, row_tau, row_d])  # shape (3,2)
        rank = np.linalg.matrix_rank(C_basis_matrix)
        if rank < 2:
            continue

        total_candidates += 1

        # ------------------------------------------------------------------
        # 4. Fit geometry parameters q = (q1, q2) to (me, tau, d).
        # ------------------------------------------------------------------
        z_basis = np.array([z_me, z_tau, z_d], dtype=float)

        # Least-squares solution: C_basis_matrix @ q ≈ z_basis
        q_hat, residuals, _, _ = np.linalg.lstsq(C_basis_matrix, z_basis, rcond=None)

        # Predicted logs for me, tau, d:
        z_me_geom  = float(row_me.dot(q_hat))
        z_tau_geom = float(row_tau.dot(q_hat))
        z_d_geom   = float(row_d.dot(q_hat))

        # Check how well we match the three basis Yukawas:
        res_me  = z_me_geom  - z_me
        res_tau = z_tau_geom - z_tau
        res_d   = z_d_geom   - z_d

        # If the basis itself is completely insane (huge residuals),
        # we can skip early to save time.
        basis_RMS = math.sqrt((res_me**2 + res_tau**2 + res_d**2) / 3.0)
        if basis_RMS > 0.5:  # 0.5 dex is already very loose
            continue

        # ------------------------------------------------------------------
        # 5. For all 9 Yukawas, assign small integer coefficient rows.
        #    For me, tau, d we keep the chosen rows. For the other 6,
        #    we scan all integer pairs within ±C_other and pick the best.
        # ------------------------------------------------------------------
        coeffs = {}
        coeffs["me_over_v"]   = row_me.copy()
        coeffs["mtau_over_v"] = row_tau.copy()
        coeffs["md_over_v"]   = row_d.copy()

        # Find best coefficients for the remaining Yukawas.
        for nm in names_order:
            if nm in ("me_over_v", "mtau_over_v", "md_over_v"):
                continue
            z_i = yuk_logs[nm]
            best_res = None
            best_vec = None
            for c1 in range(-C_other, C_other + 1):
                for c2 in range(-C_other, C_other + 1):
                    if c1 == 0 and c2 == 0:
                        continue
                    v = np.array([c1, c2], dtype=float)
                    z_pred = float(v.dot(q_hat))
                    r = abs(z_pred - z_i)
                    if best_res is None or r < best_res:
                        best_res = r
                        best_vec = v
            # Store the best integer vector for this Yukawa.
            coeffs[nm] = best_vec

        # ------------------------------------------------------------------
        # 6. Evaluate global fit quality (RMS across 9 Yukawas)
        # ------------------------------------------------------------------
        residuals_all = []
        for nm in names_order:
            z_i = yuk_logs[nm]
            v = coeffs[nm]
            z_pred = float(v.dot(q_hat))
            residuals_all.append(z_pred - z_i)

        residuals_all = np.array(residuals_all)
        RMS_all = float(math.sqrt(np.mean(residuals_all**2)))
        max_abs_res = float(np.max(np.abs(residuals_all)))

        # ------------------------------------------------------------------
        # 7. Compute S_geom for this geometry (should be ~0 by construction).
        # ------------------------------------------------------------------
        S_geom = abs(-4 * z_me_geom + 4 * z_tau_geom + 3 * z_d_geom)
        ratio_S = S_geom / S_real if S_real > 0 else float("inf")

        # Complexity measure: maximum |c_ij| used anywhere
        max_coeff_mag = 0
        for nm in names_order:
            v = coeffs[nm]
            max_coeff_mag = max(max_coeff_mag, int(max(abs(v[0]), abs(v[1]))))

        # Save result
        results.append({
            "row_me": row_me,
            "row_tau": row_tau,
            "row_d": row_d,
            "q_hat": q_hat,
            "coeffs": coeffs,
            "RMS_all": RMS_all,
            "max_abs_res": max_abs_res,
            "S_geom": S_geom,
            "ratio_S": ratio_S,
            "max_coeff_mag": max_coeff_mag,
            "basis_RMS": basis_RMS,
        })

    print(f"[SEARCH SUMMARY]")
    print(f"  Total candidate (me,tau,d) geometries tested : {total_candidates}")
    print(f"  Geometries surviving basic filters          : {len(results)}")
    print()

    if not results:
        print("No viable geometries found under current bounds. You can increase C_basis/C_other or change D.")
        return

    # ----------------------------------------------------------------------
    # 8. Sort and report best geometries
    #    Primary key: RMS_all   (smaller is better)
    #    Secondary key: max_coeff_mag (simpler is better)
    # ----------------------------------------------------------------------
    results_sorted = sorted(
        results,
        key=lambda r: (r["RMS_all"], r["max_coeff_mag"])
    )

    top_k = min(10, len(results_sorted))

    print("=" * 82)
    print("                      TOP CANDIDATE YUKAWA GEOMETRIES                      ")
    print("=" * 82)
    print()
    print("Rank  RMS_all  max|res|  max|coef|   S_geom      S_geom/S_real")
    print("----  -------  -------  ---------  ----------   -------------")

    for idx in range(top_k):
        r = results_sorted[idx]
        print(f"{idx+1:4d}  {r['RMS_all']:7.4f}  {r['max_abs_res']:7.4f}     {r['max_coeff_mag']:3d}    "
              f"{r['S_geom']:10.3e}   {r['ratio_S']:11.3e}")
    print()

    # ----------------------------------------------------------------------
    # 9. Detailed dump for the single best geometry
    # ----------------------------------------------------------------------
    best = results_sorted[0]

    print("=" * 82)
    print("                      DETAILED BEST GEOMETRY (RANK 1)                      ")
    print("=" * 82)
    print()
    print("[Basis coefficient rows for (me, tau, d)]")
    print("  row(me)  =", best["row_me"])
    print("  row(tau) =", best["row_tau"])
    print("  row(d)   =", best["row_d"])
    print()
    print("[Fitted geometry parameters q]")
    print(f"  q1 = {best['q_hat'][0]: .6f}")
    print(f"  q2 = {best['q_hat'][1]: .6f}")
    print()
    print("[Fit quality]")
    print(f"  RMS over all 9 Yukawas (dex)     : {best['RMS_all']: .6f}")
    print(f"  Max |residual| (dex)             : {best['max_abs_res']: .6f}")
    print(f"  Basis-only RMS (me,tau,d) (dex)  : {best['basis_RMS']: .6f}")
    print()
    print("[Lock on geometry]")
    print(f"  S_geom       = {best['S_geom']: .6e}")
    print(f"  S_geom/S_real= {best['ratio_S']: .3e}")
    print()
    print("[Per-Yukawa integer coefficients and residuals]")
    print("  name         coeffs(c1,c2)    z_real      z_pred      resid")
    print("  -----------  --------------  ---------   ---------   --------")
    for nm in names_order:
        v = best["coeffs"][nm]
        z_i = yuk_logs[nm]
        z_pred = float(v.dot(best["q_hat"]))
        resid = z_pred - z_i
        print(f"  {nm:11s}  ({int(v[0]):3d},{int(v[1]):3d})   {z_i: .6f}   {z_pred: .6f}   {resid: .6f}")
    print()
    print("=" * 82)
    print("INTERPRETATION GUIDE")
    print("=" * 82)
    print("  • This module ENFORCES the (-4,4,3) relation at the exponent level by")
    print("    construction, via integer rows for (me, tau, d).")
    print("  • For each candidate, it fits q1,q2 from (me, tau, d) and then assigns")
    print("    small-integer rows to the remaining Yukawas.")
    print("  • The key question is:")
    print("        Can a SIMPLE 2D integer geometry (small coefficients) fit all")
    print("        9 Yukawas with RMS ≲ 0.01–0.02 dex?")
    print("    If yes, that’s a strong hint of a genuine low-dimensional structure.")
    print("    If no, then even with (-4,4,3) built in, small-integer geometry is")
    print("    not enough to explain the full Yukawa pattern.")
    print()
    print("  • Next iterations can:")
    print("      - increase geometry dimension D to 3,")
    print("      - tighten or loosen coefficient bounds,")
    print("      - add MDL-style penalties for complexity,")
    print("      - cross-check against error models and null ensembles.")
    print()


if __name__ == "__main__":
    run_phase8_minimal_yukawa_geometry()

#!/usr/bin/env python3
# ==============================================================================
# PHASE8_YUKAWA_MINIMAL_GEOMETRY_NULLSCAN_v1
#   → Null test for the 2D small-integer Yukawa geometry that enforces (-4,4,3)
# ==============================================================================

import math
import random
import numpy as np

# ------------------------------------------------------------------------------
# Pretty-print helpers
# ------------------------------------------------------------------------------

def print_banner(title: str) -> None:
    width = 82
    pad = (width - len(title) - 2)
    left = pad // 2
    right = pad - left
    line = "=" * width
    print(line)
    print(" " * left + " " + title + " " + " " * right)
    print(line)
    print()

def print_section(title: str) -> None:
    line = "-" * 82
    print(line)
    print(title)
    print(line)

# ------------------------------------------------------------------------------
# Core geometry helpers
# ------------------------------------------------------------------------------

def build_basis_triplets(C_basis: int = 4):
    """
    Build all integer rows (r_me, r_tau, r_d) in Z^2 with |components|<=C_basis
    satisfying the exponent-level constraint:

        -4 * row(me) + 4 * row(tau) + 3 * row(d) = 0  (vector equation)

    This enforces the (-4,4,3) lock at the geometry level by construction.
    """
    triplets = []
    seen = set()

    for a1 in range(-C_basis, C_basis + 1):
        for a2 in range(-C_basis, C_basis + 1):
            if a1 == 0 and a2 == 0:
                continue
            r_me = (a1, a2)

            for b1 in range(-C_basis, C_basis + 1):
                for b2 in range(-C_basis, C_basis + 1):
                    if b1 == 0 and b2 == 0:
                        continue
                    r_tau = (b1, b2)

                    # From -4 r_me + 4 r_tau + 3 r_d = 0  →  3 r_d = 4 (r_me - r_tau)
                    rhs0 = 4 * (r_me[0] - r_tau[0])
                    rhs1 = 4 * (r_me[1] - r_tau[1])

                    if rhs0 % 3 != 0 or rhs1 % 3 != 0:
                        continue

                    c1 = rhs0 // 3
                    c2 = rhs1 // 3

                    if abs(c1) > C_basis or abs(c2) > C_basis:
                        continue
                    if c1 == 0 and c2 == 0:
                        continue

                    r_d = (c1, c2)
                    key = (r_me, r_tau, r_d)
                    if key in seen:
                        continue
                    seen.add(key)
                    triplets.append(key)

    return triplets

def build_comp_pairs(C_other: int = 6):
    """
    Build all integer coefficient pairs (c1, c2) in Z^2 with |components|<=C_other,
    excluding (0,0). These are used for the non-basis Yukawas.
    """
    pairs = []
    for i in range(-C_other, C_other + 1):
        for j in range(-C_other, C_other + 1):
            if i == 0 and j == 0:
                continue
            pairs.append((i, j))
    return pairs

def fit_geometry_for_logs(
    z_vec: np.ndarray,
    names: list,
    basis_triplets,
    comp_pairs,
):
    """
    Given:
      • z_vec: array of log10 Yukawas (ordered as 'names')
      • basis_triplets: list of (row(me), row(tau), row(d))
      • comp_pairs: allowed integer coefficient pairs for other Yukawas

    Find the best 2D integer geometry:

      z_i_geom ≈ c_i1 * q1 + c_i2 * q2

    where:
      • (c_me, c_tau, c_d) come from one basis triplet
      • other c_i are chosen from comp_pairs by brute force
      • best is chosen by minimal RMS over all 9 Yukawas, then by smaller max|coef|.
    """
    name_to_idx = {n: i for i, n in enumerate(names)}
    idx_me  = name_to_idx["me_over_v"]
    idx_tau = name_to_idx["mtau_over_v"]
    idx_d   = name_to_idx["md_over_v"]

    best = None

    for r_me, r_tau, r_d in basis_triplets:
        r_me_arr  = np.array(r_me,  dtype=float)
        r_tau_arr = np.array(r_tau, dtype=float)
        r_d_arr   = np.array(r_d,   dtype=float)

        A = np.vstack([r_me_arr, r_tau_arr, r_d_arr])
        if np.linalg.matrix_rank(A) < 2:
            continue

        basis_logs = np.array([z_vec[idx_me], z_vec[idx_tau], z_vec[idx_d]])
        q, *_ = np.linalg.lstsq(A, basis_logs, rcond=None)

        coeffs = {}
        z_pred = np.zeros_like(z_vec)

        # Basis Yukawas
        coeffs[idx_me]  = r_me
        coeffs[idx_tau] = r_tau
        coeffs[idx_d]   = r_d

        z_pred[idx_me]  = float(r_me_arr  @ q)
        z_pred[idx_tau] = float(r_tau_arr @ q)
        z_pred[idx_d]   = float(r_d_arr   @ q)

        # Other Yukawas: brute-force over comp_pairs
        for idx in range(len(z_vec)):
            if idx in (idx_me, idx_tau, idx_d):
                continue

            target = z_vec[idx]
            best_res_sq = float("inf")
            best_c = None

            for c1, c2 in comp_pairs:
                val = c1 * q[0] + c2 * q[1]
                res_sq = (val - target) ** 2
                if res_sq < best_res_sq:
                    best_res_sq = res_sq
                    best_c = (c1, c2)

            coeffs[idx] = best_c
            z_pred[idx] = best_c[0] * q[0] + best_c[1] * q[1]

        resid = z_pred - z_vec
        rms = math.sqrt(float(np.mean(resid ** 2)))
        max_abs = float(np.max(np.abs(resid)))

        # Geometric triple lock; for this construction it will be ~0 by design
        S_geom = abs(
            -4.0 * z_pred[idx_me]
            + 4.0 * z_pred[idx_tau]
            + 3.0 * z_pred[idx_d]
        )

        maxcoef = max(abs(c) for row in coeffs.values() for c in row)
        key = (rms, maxcoef)

        if best is None or key < best["key"]:
            best = {
                "key": key,
                "r_me": r_me,
                "r_tau": r_tau,
                "r_d": r_d,
                "q": q,
                "z_pred": z_pred,
                "resid": resid,
                "coeffs": coeffs,
                "rms": rms,
                "max_abs": max_abs,
                "S_geom": S_geom,
                "maxcoef": maxcoef,
            }

    return best

def sample_jitter_logs(z_central: np.ndarray, halfwidth: float) -> np.ndarray:
    """
    Simple jitter null:
      z_i_null = z_i_real + uniform(-halfwidth, +halfwidth) independently.
    """
    return np.array(
        [random.uniform(val - halfwidth, val + halfwidth) for val in z_central]
    )

# ------------------------------------------------------------------------------
# Main driver
# ------------------------------------------------------------------------------

def run_phase8_yukawa_minimal_geometry_nullscan(
    C_basis: int = 4,
    C_other: int = 6,
    jitter_halfwidth_log10: float = 0.5,
    num_null: int = 2000,
    seed: int = 12345,
):
    # --------------------------------------------------------------------------
    # 1. Fixed Yukawa input (same as in your previous phases)
    # --------------------------------------------------------------------------
    yuk_logs = {
        "me_over_v":   -5.683401,
        "mmu_over_v":  -3.367606,
        "mtau_over_v": -2.141781,
        "mb_over_v":   -1.770024,
        "mc_over_v":   -2.287532,
        "mt_over_v":   -0.154056,
        "md_over_v":   -4.722162,
        "ms_over_v":   -3.422873,
        "mu_over_v":   -5.056852,
    }

    names = [
        "me_over_v",
        "mmu_over_v",
        "mtau_over_v",
        "mb_over_v",
        "mc_over_v",
        "mt_over_v",
        "md_over_v",
        "ms_over_v",
        "mu_over_v",
    ]

    z_real = np.array([yuk_logs[n] for n in names], dtype=float)

    # Real lock value (data)
    z_me   = yuk_logs["me_over_v"]
    z_tau  = yuk_logs["mtau_over_v"]
    z_d    = yuk_logs["md_over_v"]
    S_real = abs(-4.0 * z_me + 4.0 * z_tau + 3.0 * z_d)

    print_banner("PHASE 8 – MODULE 2: MINIMAL YUKAWA GEOMETRY NULLSCAN (2D INTEGER)")

    print_section("[INPUT YUKAWA LOGS]")
    print("  name          log10(value)")
    print("  ------------ -------------")
    for n in names:
        print(f"  {n:12s} {yuk_logs[n]:+12.6f}")
    print()
    print(f"  Real triple lock S_real = |-4 z_me + 4 z_tau + 3 z_d| = {S_real: .6e}")
    print()

    # --------------------------------------------------------------------------
    # 2. Geometry setup
    # --------------------------------------------------------------------------
    print_section("[GEOMETRY SETUP]")
    print(f"  Geometry dimension D                     : 2")
    print(f"  Basis coeff bound for (me,tau,d)         : ±{C_basis:d}")
    print(f"  Coeff bound for other Yukawas            : ±{C_other:d}")
    print(f"  Constraint enforced exactly              : -4 row(me) + 4 row(tau) + 3 row(d) = 0")
    print(f"  Jitter halfwidth for null (log10 units)  : {jitter_halfwidth_log10:.3f}")
    print(f"  Number of null universes                 : {num_null:d}")
    print()

    basis_triplets = build_basis_triplets(C_basis)
    comp_pairs = build_comp_pairs(C_other)

    print(f"  Number of basis (me,tau,d) triplets      : {len(basis_triplets):d}")
    print(f"  Number of coeff pairs for others         : {len(comp_pairs):d}")
    print()

    # --------------------------------------------------------------------------
    # 3. Real-universe geometry fit
    # --------------------------------------------------------------------------
    print_section("[REAL-UNIVERSE MINIMAL GEOMETRY FIT]")

    best_real = fit_geometry_for_logs(z_real, names, basis_triplets, comp_pairs)

    print("  Best basis rows (me, tau, d):")
    print(f"    row(me)  = {best_real['r_me']}")
    print(f"    row(tau) = {best_real['r_tau']}")
    print(f"    row(d)   = {best_real['r_d']}")
    print()
    print("  Fitted geometry parameters q (log10 units):")
    print(f"    q1 = {best_real['q'][0]: .6f}")
    print(f"    q2 = {best_real['q'][1]: .6f}")
    print()
    print("  Fit quality (all 9 Yukawas):")
    print(f"    RMS_all (dex)             : {best_real['rms']: .6f}")
    print(f"    Max |residual| (dex)      : {best_real['max_abs']: .6f}")
    print(f"    Max |integer coeff|       : {best_real['maxcoef']: d}")
    print()
    print("  Lock on geometry:")
    print(f"    S_geom (from geometry)    : {best_real['S_geom']: .6e}")
    print(f"    S_geom / S_real           : {best_real['S_geom'] / S_real if S_real>0 else float('nan'): .3e}")
    print("    (For this construction S_geom is effectively zero by design.)")
    print()

    print("  Per-Yukawa residuals (geom - real):")
    print("  name         coeffs(c1,c2)   z_real      z_geom      resid")
    print("  -----------  --------------  ---------   ---------   --------")
    for i, n in enumerate(names):
        c1, c2 = best_real["coeffs"][i]
        z_r = z_real[i]
        z_g = best_real["z_pred"][i]
        resid = best_real["resid"][i]
        # FIX: remove leading space before '+' so format spec is valid
        print(f"  {n:11s}  ({c1:3d},{c2:3d})   {z_r:+9.6f}   {z_g:+9.6f}   {resid:+8.6f}")
    print()

    # --------------------------------------------------------------------------
    # 4. Null ensemble: jitter Yukawas, refit geometry each time
    # --------------------------------------------------------------------------
    print_section("[NULL ENSEMBLE: JITTERED YUKAWA UNIVERSES]")

    random.seed(seed)

    rms_null = []

    for u in range(num_null):
        z_null = sample_jitter_logs(z_real, jitter_halfwidth_log10)
        best_u = fit_geometry_for_logs(z_null, names, basis_triplets, comp_pairs)
        rms_null.append(best_u["rms"])

        if (u + 1) % max(1, (num_null // 10)) == 0:
            print(f"  ... {u+1}/{num_null} universes processed")

    print()

    # --------------------------------------------------------------------------
    # 5. Null statistics and significance
    # --------------------------------------------------------------------------
    rms_null_sorted = sorted(rms_null)
    n = len(rms_null_sorted)

    def percentile(sorted_list, p):
        if n == 0:
            return float("nan")
        k = (n - 1) * p
        f = math.floor(k)
        c = math.ceil(k)
        if f == c:
            return sorted_list[int(k)]
        return sorted_list[f] + (sorted_list[c] - sorted_list[f]) * (k - f)

    rms_min = rms_null_sorted[0]
    rms_max = rms_null_sorted[-1]
    rms_p25 = percentile(rms_null_sorted, 0.25)
    rms_p50 = percentile(rms_null_sorted, 0.50)
    rms_p75 = percentile(rms_null_sorted, 0.75)
    rms_mean = sum(rms_null_sorted) / n
    rms_var = sum((x - rms_mean) ** 2 for x in rms_null_sorted) / n
    rms_std = math.sqrt(rms_var)

    rms_real = best_real["rms"]
    count_le = sum(1 for x in rms_null_sorted if x <= rms_real)
    p_emp = count_le / n
    z_score = (rms_real - rms_mean) / rms_std if rms_std > 0 else float("nan")

    print_section("[NULL RMS STATISTICS – MINIMAL GEOMETRY FIT]")
    print(f"  null RMS min / max        : {rms_min: .6e} / {rms_max: .6e}")
    print(f"  null RMS 25% / 50% / 75%  : {rms_p25: .6e} / {rms_p50: .6e} / {rms_p75: .6e}")
    print(f"  null RMS mean / std       : {rms_mean: .6e} / {rms_std: .6e}")
    print()
    print_section("[SIGNIFICANCE OF MINIMAL 2D INTEGER GEOMETRY]")
    print(f"  real RMS                  : {rms_real: .6e}")
    print(f"  z(real vs null mean)      : {z_score:+.2f} σ")
    print(f"  P_null(RMS <= real)       : {p_emp: .6f}")
    print()
    print("INTERPRETATION GUIDE:")
    print("  • RMS measures how well a 2D small-integer geometry fits ALL 9 Yukawas.")
    print("  • If P_null is ~0.5, then geometries this good (or better) are common")
    print("    in jittered random Yukawa universes: the geometry is NOT special.")
    print("  • If P_null is very small, the full 9-point geometry would be an extra")
    print("    non-random lock beyond the (-4,4,3) triple itself.")
    print()
    print_banner("PHASE8_YUKAWA_MINIMAL_GEOMETRY_NULLSCAN_v1 COMPLETE")


# ------------------------------------------------------------------------------
# Entry point
# ------------------------------------------------------------------------------

if __name__ == "__main__":
    run_phase8_yukawa_minimal_geometry_nullscan(
        C_basis=4,
        C_other=6,
        jitter_halfwidth_log10=0.5,
        num_null=2000,
        seed=12345,
    )

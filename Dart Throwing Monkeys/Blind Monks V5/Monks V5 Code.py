# -*- coding: utf-8 -*-
"""Blind Monks V5.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1jrqdFx82AjlxapVhgMYh81Vbb11hEQKs
"""

import numpy as np
import json
import hashlib
from datetime import datetime

# ----------------------------------------------------------------------
# Helper: safe access to YUKAWA_DATA or fallback constants
# ----------------------------------------------------------------------

def get_yukawa_triple_logs():
    """
    Return (z_me, z_tau, z_d) from YUKAWA_DATA if available,
    otherwise fall back to the hard-coded values used in previous phases.
    """
    try:
        # Expecting a dict with 'names' and 'z_real' arrays
        names = YUKAWA_DATA["names"]  # type: ignore[name-defined]
        z_real = YUKAWA_DATA["z_real"]  # type: ignore[name-defined]
        name_to_z = dict(zip(names, z_real))
        z_me = float(name_to_z["me_over_v"])
        z_tau = float(name_to_z["mtau_over_v"])
        z_d = float(name_to_z["md_over_v"])
    except Exception:
        # Fallback to the standard numbers used throughout your pipeline
        z_me = -5.683401
        z_tau = -2.141781
        z_d = -4.722162
    return z_me, z_tau, z_d


# ----------------------------------------------------------------------
# Core 4-spurion FN triple scout
# ----------------------------------------------------------------------

def run_phase32_yukawa_4spurion_fn_triple_scout(
    C_basis_max: int = 3,
    q_neg_only: bool = True,
    q_min: float = -4.0,
    q_max: float = 0.0,
    max_solutions_to_store: int = 10,
) -> None:
    """
    PHASE 32 – MODULE 1: 4-SPURION FN TRIPLE SCOUT (v1)

    Scan small 4D integer charge patterns for (me, tau, d) that:
      - Enforce the (-4,4,3) relation at coefficient level:
            -4 row(me) + 4 row(tau) + 3 row(d) = 0  (in R^4)
      - Have rank 3 (the three rows span a 3D subspace in R^4),
      - Admit at least one q-vector with all components in [q_min, q_max],
        typically q_min < 0 and q_max <= 0, corresponding to λ_j < 1.
    """

    # ------------------------------------------------------------------
    # Header: timestamp and data recap
    # ------------------------------------------------------------------
    timestamp = datetime.now().isoformat()
    z_me, z_tau, z_d = get_yukawa_triple_logs()
    S_real = abs(-4.0 * z_me + 4.0 * z_tau + 3.0 * z_d)

    print("=" * 80)
    print(" PHASE 32 – MODULE 1: 4-SPURION FN TRIPLE SCOUT (v1) ")
    print("=" * 80)
    print()
    print(f"Run timestamp (local) : {timestamp}")
    print(f"C_basis_max           : {C_basis_max}")
    print(f"q_neg_only            : {q_neg_only}")
    print(f"q_range               : [{q_min:.2f}, {q_max:.2f}]")
    print()
    print("Real Yukawa triple logs (z = log10 y):")
    print(f"  me_over_v   z_me   = {z_me: .6f}")
    print(f"  mtau_over_v z_tau  = {z_tau: .6f}")
    print(f"  md_over_v   z_d    = {z_d: .6f}")
    print(f"  S_real = |-4 z_me + 4 z_tau + 3 z_d| = {S_real: .6e}")
    print()

    # ------------------------------------------------------------------
    # Search over small integer charge patterns
    # ------------------------------------------------------------------
    # We parameterize row(me) = a, row(tau) = b in [-C_basis_max, C_basis_max]^4,
    # then enforce the triple relation component-wise to get row(d) = c:
    #   -4 a_k + 4 b_k + 3 c_k = 0  ⇒  c_k = 4(a_k - b_k) / 3
    #
    # Only keep c_k integer and within the same bounds.
    # ------------------------------------------------------------------

    vals = list(range(-C_basis_max, C_basis_max + 1))
    vals_float = np.array(vals, dtype=float)

    num_basis_triples_tested = 0
    num_triple_ok = 0
    num_rank3 = 0
    num_q_neg_solutions = 0

    solutions = []

    # Prepare target z vector
    z_basis = np.array([z_me, z_tau, z_d], dtype=float)

    # Precompute tolerance for residuals
    resid_tol = 1e-8

    # Brute-force over row(me) and row(tau)
    for a1 in vals_float:
        for a2 in vals_float:
            for a3 in vals_float:
                for a4 in vals_float:
                    a = np.array([a1, a2, a3, a4], dtype=float)

                    # Skip all-zero row for me
                    if not np.any(a):
                        continue

                    for b1 in vals_float:
                        for b2 in vals_float:
                            for b3 in vals_float:
                                for b4 in vals_float:
                                    b = np.array([b1, b2, b3, b4], dtype=float)
                                    # Skip all-zero row for tau
                                    if not np.any(b):
                                        continue

                                    num_basis_triples_tested += 1

                                    # Compute c from triple relation, component-wise
                                    diff = a - b  # a_k - b_k
                                    # Check divisibility condition: 4 diff_k must be multiple of 3
                                    four_diff = 4.0 * diff
                                    # We can check with modulus on integers if they are integers
                                    # but here we are in floats, so check closeness to integer multiples of (1/3).
                                    # However, diff is integer already, so four_diff is integer.
                                    # We can cast to int safely.
                                    four_diff_int = four_diff.astype(int)
                                    if not np.allclose(four_diff, four_diff_int):
                                        # Should not really happen, but be safe
                                        continue

                                    # Require divisibility by 3
                                    if np.any(four_diff_int % 3 != 0):
                                        continue

                                    c_int = four_diff_int // 3
                                    c = c_int.astype(float)

                                    # Bounds for c
                                    if np.any(c_int < -C_basis_max) or np.any(c_int > C_basis_max):
                                        continue

                                    # Skip all-zero row for d
                                    if not np.any(c):
                                        continue

                                    num_triple_ok += 1

                                    # Build C_basis (3x4)
                                    C_basis = np.vstack([a, b, c])

                                    # Rank check
                                    rank = np.linalg.matrix_rank(C_basis)
                                    if rank < 3:
                                        continue
                                    num_rank3 += 1

                                    # Solve C_basis q = z_basis in least squares; find nullspace
                                    # to parameterize the solution and impose q constraints.
                                    # C_basis is 3x4, full row rank, so nullspace is 1D.
                                    # Particular solution:
                                    q_part, _, _, _ = np.linalg.lstsq(
                                        C_basis, z_basis, rcond=None
                                    )

                                    # Nullspace from SVD
                                    U, S, Vt = np.linalg.svd(C_basis)
                                    v_null = Vt[-1, :]  # last row of V^T
                                    # Normalize null vector for stability
                                    norm_v = np.linalg.norm(v_null)
                                    if norm_v == 0.0:
                                        continue
                                    v_null = v_null / norm_v

                                    # Now we want t such that q(t) = q_part + t v_null lies in [q_min, q_max]
                                    t_low = -np.inf
                                    t_high = np.inf
                                    feasible = True

                                    for j in range(4):
                                        vj = v_null[j]
                                        qp = q_part[j]

                                        if abs(vj) < 1e-12:
                                            # No freedom in this component; must already be within bounds
                                            if not (q_min <= qp <= q_max):
                                                feasible = False
                                                break
                                        else:
                                            # Solve inequalities:
                                            #   q_min <= qp + t*vj <= q_max
                                            t1 = (q_min - qp) / vj
                                            t2 = (q_max - qp) / vj
                                            t_lo_j = min(t1, t2)
                                            t_hi_j = max(t1, t2)
                                            # Intersect intervals
                                            if t_lo_j > t_low:
                                                t_low = t_lo_j
                                            if t_hi_j < t_high:
                                                t_high = t_hi_j
                                            if t_low > t_high:
                                                feasible = False
                                                break

                                    if not feasible:
                                        continue

                                    # If q_neg_only, we additionally insist q_max <= 0, which we already enforce via bounds.
                                    if q_neg_only and q_max > 0.0:
                                        # Sanity: if user set q_neg_only but q_max>0, this is contradictory.
                                        # We do not treat it as fatal, but we can tighten q_max to 0 here.
                                        pass

                                    # Choose any t in [t_low, t_high]. Prefer t=0 if allowed, otherwise midpoint.
                                    if t_low <= 0.0 <= t_high:
                                        t_star = 0.0
                                    else:
                                        t_star = 0.5 * (t_low + t_high)

                                    q_star = q_part + t_star * v_null

                                    # Compute residual for this q_star
                                    z_fit = C_basis @ q_star
                                    resid_vec = z_fit - z_basis
                                    max_abs_resid = float(np.max(np.abs(resid_vec)))

                                    # Require that this really solves the triple within a small tolerance
                                    if max_abs_resid > resid_tol:
                                        continue

                                    # Check q_star is indeed within bounds (sanity)
                                    if not np.all(q_star >= q_min - 1e-9) or not np.all(q_star <= q_max + 1e-9):
                                        continue

                                    num_q_neg_solutions += 1

                                    if len(solutions) < max_solutions_to_store:
                                        solutions.append(
                                            {
                                                "C_basis": C_basis.astype(int).tolist(),
                                                "q_star": [float(x) for x in q_star],
                                                "max_abs_resid": max_abs_resid,
                                            }
                                        )

    # ------------------------------------------------------------------
    # Build hash payload and SHA256
    # ------------------------------------------------------------------
    hash_payload = {
        "module": "PHASE32_YUKAWA_4SPURION_FN_TRIPLE_SCOUT_v1",
        "timestamp": timestamp,
        "num_spurions": 4,
        "C_basis_max": C_basis_max,
        "q_neg_only": q_neg_only,
        "q_range": [q_min, q_max],
        "z_me": z_me,
        "z_tau": z_tau,
        "z_d": z_d,
        "S_real": S_real,
        "num_basis_triples_tested": num_basis_triples_tested,
        "num_triple_ok": num_triple_ok,
        "num_rank3": num_rank3,
        "num_q_neg_solutions": num_q_neg_solutions,
        "solutions": solutions,
    }
    hash_bytes = json.dumps(hash_payload, sort_keys=True).encode("utf-8")
    sha256 = hashlib.sha256(hash_bytes).hexdigest()

    # ------------------------------------------------------------------
    # Print summary
    # ------------------------------------------------------------------
    print("=" * 80)
    print(" SEARCH SUMMARY ")
    print("=" * 80)
    print()
    print(f"  C_basis_max                   : {C_basis_max}")
    print(f"  num_spurions                  : 4")
    print(f"  total_basis_triples_tested    : {num_basis_triples_tested}")
    print(f"  basis_triples_satisfying_triple_relation : {num_triple_ok}")
    print(f"  basis_triples_with_rank_3     : {num_rank3}")
    print(f"  basis_triples_with_q_in_range : {num_q_neg_solutions}")
    print()

    if num_q_neg_solutions == 0:
        print("  No 4-spurion FN-like basis with q in [q_min, q_max] was found")
        print("  within the given C_basis_max and constraints.")
    else:
        print("  At least one 4-spurion FN-like basis with q in [q_min, q_max]")
        print("  was found. Example solutions (up to a small cap):")
        print()
        for idx, sol in enumerate(solutions):
            print(f"  Solution {idx + 1}:")
            Cb = sol["C_basis"]
            qs = sol["q_star"]
            max_res = sol["max_abs_resid"]
            print("    C_basis (rows = me, tau, d):")
            print(f"      row(me)   = {Cb[0]}")
            print(f"      row(tau)  = {Cb[1]}")
            print(f"      row(d)    = {Cb[2]}")
            print("    One valid q_star (log10 λ):")
            print(f"      q_star    = ({qs[0]: .6f}, {qs[1]: .6f}, {qs[2]: .6f}, {qs[3]: .6f})")
            print(f"    max|C_basis q_star - z|     : {max_res: .3e}")
            print()

    print("=" * 80)
    print(" INTERPRETATION ")
    print("=" * 80)
    print()
    print("  • This module explores small 4-spurion FN-like bases for (me,mtau,md)")
    print("    that enforce the (-4,4,3) triple at the coefficient level and admit")
    print("    at least one q-vector with all components in [q_min, q_max].")
    print()
    if num_q_neg_solutions == 0:
        print("  • Result: within the scanned region, no such simple 4-spurion basis")
        print("    was found. This pushes toward more complex geometries (more spurions,")
        print("    larger charges, or non-FN structures) if the triple is to be explained.")
    else:
        print("  • Result: there exist small-charge 4-spurion patterns that can realize")
        print("    the (-4,4,3) triple with q in the chosen range. These are promising")
        print("    seeds for later, richer Yukawa model-building.")
    print()
    print("  Evidence-budget status:")
    print("    classification : supporting_structure_shape")
    print("    bits           : 0.00  (structural search, not a probabilistic nullscan)")
    print("    global locks   : unchanged (DNA + Yukawa triple ≈ 20–27 bits)")
    print()
    print("=" * 80)
    print(" HASH & BOOKKEEPING ")
    print("=" * 80)
    print()
    print(f"Run SHA256 payload    : {sha256}")
    print()

    # ------------------------------------------------------------------
    # Optional: update GEOM_EVIDENCE dictionary
    # ------------------------------------------------------------------
    try:
        GEOM_EVIDENCE  # type: ignore[name-defined]
    except NameError:
        globals()["GEOM_EVIDENCE"] = {}  # type: ignore[assignment]
    geom_evidence = globals()["GEOM_EVIDENCE"]  # type: ignore[index]

    geom_evidence["yukawa_4spurion_fn_triple_scout"] = {
        "C_basis_max": C_basis_max,
        "q_neg_only": q_neg_only,
        "q_range": [q_min, q_max],
        "num_basis_triples_tested": num_basis_triples_tested,
        "num_triple_ok": num_triple_ok,
        "num_rank3": num_rank3,
        "num_q_neg_solutions": num_q_neg_solutions,
        "solutions": solutions,
        "bits": 0.0,
        "classification": "supporting_structure_shape",
        "reason": (
            "Scan for small 4-spurion FN-like bases for (me,mtau,md) that enforce "
            "the (-4,4,3) triple at coefficient level and admit q in the chosen "
            "range. Structural constraint only; no probabilistic nullscan."
        ),
        "timestamp": timestamp,
        "sha256": sha256,
        "status": "supporting_structure_shape",
        "description": (
            "4-spurion FN triple scout for (me,mtau,md) with small integer charges, "
            "triple enforced at coefficient level, and q in [q_min,q_max]."
        ),
    }

    print("GEOM_EVIDENCE['yukawa_4spurion_fn_triple_scout'] updated.")
    print()
    print("PHASE32_YUKAWA_4SPURION_FN_TRIPLE_SCOUT_v1 COMPLETE")
    print("=" * 80)


# ----------------------------------------------------------------------
# Script entry point
# ----------------------------------------------------------------------

if __name__ == "__main__":
    run_phase32_yukawa_4spurion_fn_triple_scout(
        C_basis_max=3,
        q_neg_only=True,
        q_min=-4.0,
        q_max=0.0,
        max_solutions_to_store=5,
    )

import json
import hashlib
from datetime import datetime

def run_phase32_yukawa_4spurion_fn_summary_v1():
    """
    PHASE 32 – MODULE 2: 4-SPURION FN MODEL-SPACE SUMMARY (v1)

    Summarizes the outcome of PHASE 32 – MODULE 1
    (yukawa_4spurion_fn_triple_scout) and records it as a structural,
    non-probabilistic constraint in GEOM_EVIDENCE.
    """

    timestamp = datetime.now().isoformat()

    # ------------------------------------------------------------------
    # Pull input from GEOM_EVIDENCE if available
    # ------------------------------------------------------------------
    try:
        geom = GEOM_EVIDENCE  # type: ignore[name-defined]
    except NameError:
        geom = {}
        globals()["GEOM_EVIDENCE"] = geom  # type: ignore[assignment]

    scout = geom.get("yukawa_4spurion_fn_triple_scout", None)

    C_basis_max = None
    q_neg_only = None
    q_range = None
    num_basis_triples_tested = None
    num_triple_ok = None
    num_rank3 = None
    num_q_neg_solutions = None

    if scout is not None:
        C_basis_max = scout.get("C_basis_max", None)
        q_neg_only = scout.get("q_neg_only", None)
        q_range = scout.get("q_range", None)
        num_basis_triples_tested = scout.get("num_basis_triples_tested", None)
        num_triple_ok = scout.get("num_triple_ok", None)
        num_rank3 = scout.get("num_rank3", None)
        num_q_neg_solutions = scout.get("num_q_neg_solutions", None)

    # ------------------------------------------------------------------
    # Print header
    # ------------------------------------------------------------------
    print("=" * 80)
    print(" PHASE 32 – MODULE 2: 4-SPURION FN MODEL-SPACE SUMMARY (v1) ")
    print("=" * 80)
    print()
    print(f"Run timestamp (local) : {timestamp}")
    print()

    print("Input from PHASE 32 – MODULE 1 (4-spurion FN triple scout):")
    if scout is None:
        print("  • GEOM_EVIDENCE['yukawa_4spurion_fn_triple_scout'] not found.")
        print("    (Did you run PHASE 32 – MODULE 1 in this session?)")
    else:
        print(f"  • C_basis_max                : {C_basis_max}")
        print(f"  • q_neg_only                 : {q_neg_only}")
        print(f"  • q_range                    : {q_range}")
        print(f"  • num_basis_triples_tested   : {num_basis_triples_tested}")
        print(f"  • num_triple_ok              : {num_triple_ok}")
        print(f"  • num_rank3                  : {num_rank3}")
        print(f"  • num_q_neg_solutions        : {num_q_neg_solutions}")
    print()

    # ------------------------------------------------------------------
    # Qualitative interpretation
    # ------------------------------------------------------------------
    print("=" * 80)
    print(" QUALITATIVE SUMMARY OF 4-SPURION FN SPACE ")
    print("=" * 80)
    print()

    if scout is None:
        print("  No 4-spurion FN triple-scout data available; this summary")
        print("  is a placeholder. Run PHASE 32 – MODULE 1 first.")
        found_any = False
    else:
        found_any = (num_q_neg_solutions is not None and num_q_neg_solutions > 0)

        if not found_any:
            print("  • Within small 4-spurion charge patterns |C_ij| <= C_basis_max,")
            print("    enforcing the (-4,4,3) relation at coefficient level and")
            print("    requiring a q-vector with all components in the chosen range,")
            print("    the search found:")
            print()
            print(f"      num_basis_triples_tested : {num_basis_triples_tested}")
            print(f"      num_triple_ok            : {num_triple_ok}")
            print(f"      num_rank3                : {num_rank3}")
            print(f"      num_q_neg_solutions      : {num_q_neg_solutions}")
            print()
            print("  • Result: no simple 4-spurion FN-like basis was found in this")
            print("    region. Even after going from 3 to 4 spurions, small-charge")
            print("    FN pictures with q_j<0 remain hard-pressed to encode the")
            print("    (-4,4,3) triple exactly at the coefficient level.")
        else:
            print("  • At least one 4-spurion FN-like basis was found that:")
            print("       – uses small integer charges |C_ij| <= C_basis_max,")
            print("       – enforces the (-4,4,3) triple at coefficient level, and")
            print("       – admits a q-vector with components in the chosen range.")
            print()
            print("  • These solutions are promising seeds for future FN-like models")
            print("    that might explain the triple with more detailed structure")
            print("    (e.g. adding families, mixing, or higher-dimensional operators).")
        print()

    # ------------------------------------------------------------------
    # Evidence-budget status
    # ------------------------------------------------------------------
    print("=" * 80)
    print(" EVIDENCE-BUDGET STATUS ")
    print("=" * 80)
    print()
    print("  classification : supporting_structure_shape")
    print("  bits           : 0.00  (structural, not a probabilistic nullscan)")
    print()
    print("  Summary (conceptual):")
    if scout is None:
        print("    4-spurion FN constraints not fully evaluated in this session.")
    else:
        if not found_any:
            print("    Within the scanned small-charge 4-spurion FN space, there is")
            print("    no simple basis that explains the (-4,4,3) triple while keeping")
            print("    q in the chosen sub-unity range. This further pushes model-")
            print("    building toward more complex FN-like or non-FN geometries.")
        else:
            print("    The existence of small 4-spurion solutions means FN-like")
            print("    explanations are structurally possible, but this is not a")
            print("    new statistical anomaly; it is a map of viable charge space.")
    print()
    print("  Global contract reminder:")
    print("    → PRIMARY LOCKS remain:")
    print("         1) DNA backbone / locks (~12.29 bits).")
    print("         2) me–mtau–md (-4,4,3) triple (7–14 bits).")
    print("    → FN constraints (3- and 4-spurion) only shape the model space;")
    print("      they do NOT change the ~20–27 bit target any geometry must hit.")
    print()

    # ------------------------------------------------------------------
    # Build hash payload and SHA256
    # ------------------------------------------------------------------
    hash_payload = {
        "module": "PHASE32_YUKAWA_4SPURION_FN_SUMMARY_v1",
        "timestamp": timestamp,
        "C_basis_max": C_basis_max,
        "q_neg_only": q_neg_only,
        "q_range": q_range,
        "num_basis_triples_tested": num_basis_triples_tested,
        "num_triple_ok": num_triple_ok,
        "num_rank3": num_rank3,
        "num_q_neg_solutions": num_q_neg_solutions,
        "found_any": found_any,
    }
    hash_bytes = json.dumps(hash_payload, sort_keys=True).encode("utf-8")
    sha256 = hashlib.sha256(hash_bytes).hexdigest()

    print("=" * 80)
    print(" HASH & GEOM_EVIDENCE UPDATE ")
    print("=" * 80)
    print()
    print(f"Run SHA256 payload    : {sha256}")
    print()

    # ------------------------------------------------------------------
    # Update GEOM_EVIDENCE entry
    # ------------------------------------------------------------------
    reason_text = (
        "4-spurion FN triple-scout summary: small-charge 4-spurion FN patterns "
        "for (me,mtau,md) that enforce the (-4,4,3) triple and admit q in the "
        "chosen range were "
    )
    if scout is None:
        reason_text += "not available in this session (no scout data)."
    else:
        if not found_any:
            reason_text += (
                "not found in the scanned region, pushing toward more complex "
                "FN-like or non-FN geometries."
            )
        else:
            reason_text += (
                "found, indicating structural viability of certain 4-spurion "
                "charge patterns, but without new probabilistic anomalies."
            )

    geom["yukawa_4spurion_fn_summary"] = {
        "bits": 0.0,
        "classification": "supporting_structure_shape",
        "reason": reason_text,
        "timestamp": timestamp,
        "sha256": sha256,
        "status": "supporting_structure_shape",
        "description": (
            "Consolidated summary of 4-spurion FN constraints derived from "
            "the 4-spurion triple scout (PHASE 32 – M1). Structural restriction "
            "on FN-like model space, not an additional lock."
        ),
        "C_basis_max": C_basis_max,
        "q_neg_only": q_neg_only,
        "q_range": q_range,
        "num_basis_triples_tested": num_basis_triples_tested,
        "num_triple_ok": num_triple_ok,
        "num_rank3": num_rank3,
        "num_q_neg_solutions": num_q_neg_solutions,
    }

    print("GEOM_EVIDENCE['yukawa_4spurion_fn_summary'] updated.")
    print()
    print("PHASE32_YUKAWA_4SPURION_FN_SUMMARY_v1 COMPLETE")
    print("=" * 80)


# Script entry point
if __name__ == "__main__":
    run_phase32_yukawa_4spurion_fn_summary_v1()

import json
import hashlib
from datetime import datetime

def run_phase33_post_fn_geometry_roadmap_v1():
    """
    PHASE 33 – MODULE 1: POST-FN GEOMETRY MODEL-SPACE ROADMAP (v1)

    High-level, but machine-readable, summary of where to search next
    now that simple 3- and 4-spurion FN with small charges are structurally disfavored.
    """

    timestamp = datetime.now().isoformat()

    # Try to access global evidence; initialize if missing
    try:
        geom = GEOM_EVIDENCE  # type: ignore[name-defined]
    except NameError:
        geom = {}
        globals()["GEOM_EVIDENCE"] = geom  # type: ignore[assignment]

    # Pull in the current global lock contract if it exists
    try:
        locks = GLOBAL_LOCKS_v4  # type: ignore[name-defined]
    except NameError:
        locks = None

    dna_bits = None
    yukawa_bits_global = None
    yukawa_bits_fixed = None

    if locks is not None:
        try:
            dna_bits = locks["dna"]["effective_bits"]
        except Exception:
            dna_bits = None
        try:
            yukawa_bits_global = locks["yukawa"]["triple_me_tau_d"]["bits_global_error_model"]
        except Exception:
            yukawa_bits_global = None
        try:
            yukawa_bits_fixed = locks["yukawa"]["triple_me_tau_d"]["bits_fixed_error_model"]
        except Exception:
            yukawa_bits_fixed = None

    # ----------------------------------------------------------------------------
    # PRINT REPORT
    # ----------------------------------------------------------------------------
    print("=" * 80)
    print(" PHASE 33 – MODULE 1: POST-FN GEOMETRY MODEL-SPACE ROADMAP (v1) ")
    print("=" * 80)
    print()
    print(f"Run timestamp (local) : {timestamp}")
    print()

    print("GLOBAL LOCK CONTRACT SNAPSHOT")
    print("-" * 80)
    if locks is None:
        print("  GLOBAL_LOCKS_v4 not found in this session.")
        print("  (If you have a snapshot, you can reload it via PHASE 29.)")
    else:
        print(f"  DNA effective bits                 : {dna_bits}")
        print(f"  Yukawa triple bits (global)        : {yukawa_bits_global}")
        print(f"  Yukawa triple bits (fixed)         : {yukawa_bits_fixed}")
        if dna_bits is not None and yukawa_bits_global is not None:
            cons_total = dna_bits + yukawa_bits_global
            print(f"    → Combined (conservative)        : {cons_total:.2f} bits")
        if dna_bits is not None and yukawa_bits_fixed is not None:
            opt_total = dna_bits + yukawa_bits_fixed
            print(f"    → Combined (optimistic)          : {opt_total:.2f} bits")
    print()
    print("  Interpretation:")
    print("    → Any serious geometry must still explain roughly 20–27 bits total,")
    print("      coming from TWO independent sectors: DNA and the Yukawa triple.")
    print()

    # ----------------------------------------------------------------------------
    # FN CONSTRAINTS SUMMARY (3- & 4-SPURION RESULTS)
    # ----------------------------------------------------------------------------
    print("=" * 80)
    print(" SUMMARY OF FN-LIKE CONSTRAINTS (WHAT WE'VE ALREADY RULED OUT) ")
    print("=" * 80)
    print()

    fn3 = geom.get("yukawa_3spurion_fn_summary", None)
    fn4 = geom.get("yukawa_4spurion_fn_summary", None)

    print("3-spurion FN (small charges, q_j < 0):")
    if fn3 is None:
        print("  • No consolidated 3-spurion FN summary found in GEOM_EVIDENCE.")
    else:
        print("  • classification : {}".format(fn3.get("classification", "unknown")))
        print("  • bits           : {:.2f}".format(fn3.get("bits", 0.0)))
        print("  • key reason     :")
        print("    {}".format(fn3.get("reason", "<no reason stored>")))
    print()

    print("4-spurion FN (small charges, q_j < 0):")
    if fn4 is None:
        print("  • No 4-spurion FN summary found in GEOM_EVIDENCE.")
    else:
        print("  • classification : {}".format(fn4.get("classification", "unknown")))
        print("  • bits           : {:.2f}".format(fn4.get("bits", 0.0)))
        print("  • key reason     :")
        print("    {}".format(fn4.get("reason", "<no reason stored>")))
    print()

    print("  Takeaway:")
    print("    • Simple FN-like models with 3 or 4 spurions, small integer charges,")
    print("      and strictly sub-unity λ_j (q_j < 0) are strongly constrained or")
    print("      outright incompatible with the (-4,4,3) triple in the searched region.")
    print("    • That pushes us toward more complex or qualitatively different geometries.")
    print()

    # ----------------------------------------------------------------------------
    # MODEL-SPACE DIRECTIONS (MENU OF NEXT THINGS TO TRY)
    # ----------------------------------------------------------------------------
    print("=" * 80)
    print(" CANDIDATE GEOMETRY DIRECTIONS BEYOND SIMPLE FN ")
    print("=" * 80)
    print()
    print("Direction A: Multi-spurion FN with larger charges / relaxed q-range")
    print("------------------------------------------------------------------")
    print("  Idea:")
    print("    • Increase C_basis_max and/or allow q_j in a wider range (e.g. up to")
    print("      mildly super-unity spurions) while keeping an FN-like exponent")
    print("      structure.")
    print("    • This trades elegance for flexibility but might uncover sparse")
    print("      charge patterns that still encode (-4,4,3).")
    print()
    print("  How to test with existing tools:")
    print("    • Extend the 3- and 4-spurion scouts to larger C_basis_max and wider")
    print("      q ranges, but keep careful track of complexity so we do not fool")
    print("      ourselves with over-parameterized fits.")
    print()

    print("Direction B: Discrete flavor symmetries / charge lattices (non-FN) ")
    print("------------------------------------------------------------------")
    print("  Idea:")
    print("    • Treat the Toy3D integer charges as elements of a discrete flavor")
    print("      group or lattice, not necessarily as FN exponents.")
    print("    • Look for embeddings into small abelian groups, semi-direct products,")
    print("      or graph-like structures where (-4,4,3) is a natural relation.")
    print()
    print("  How to test:")
    print("    • A candidate model should output the same integer charge matrix C")
    print("      (or something unitarily equivalent) and recover the Toy3D q-vector")
    print("      up to small deformations.")
    print("    • Use evaluate_yukawa_geometry(...) to score the Yukawa sector and")
    print("      the standard score_geometry / scoreboard tools for claims.")
    print()

    print("Direction C: Extra-dimensional / localization geometries")
    print("--------------------------------------------------------")
    print("  Idea:")
    print("    • Interpret integer charges as positions / winding numbers / overlaps")
    print("      in an extra-dimensional space (e.g. wavefunction overlaps on a line")
    print("      or graph). The (-4,4,3) triple then emerges from geometry rather")
    print("      than group charges per se.")
    print()
    print("  How to test:")
    print("    • Construct an explicit map from positions / overlaps → effective C")
    print("      and q, and then feed that into the FN-like Yukawa tester from")
    print("      PHASE 24.")
    print("    • Demand that the model hits RMS_all ≲ 0.01 dex and S_geom ≈ S_real.")
    print()

    print("Direction D: Code / graph / combinatorial geometries (DNA–Yukawa link)")
    print("----------------------------------------------------------------------")
    print("  Idea:")
    print("    • Look for a single discrete object (code, graph, lattice, etc.) that")
    print("      simultaneously generates:")
    print("        – the DNA backbone + lock-family structure, and")
    print("        – the (-4,4,3) Yukawa lock (and perhaps the Toy3D pattern).")
    print("    • This is the dream ‘unified geometry’ tying biology and particle")
    print("      physics together at the structural level.")
    print()
    print("  How to test:")
    print("    • Build a candidate that outputs:")
    print("        – a DNA backbone matrix / structure that passes the Phase 1–7")
    print("          DNA lock-checkers, and")
    print("        – a set of Yukawa predictions that can be fed into the FN-like")
    print("          tester and triple nullscans.")
    print("    • Register the model with register_geometry_hypothesis(...) and see")
    print("      where it lands on the global scoreboard.")
    print()

    print("Direction E: Joint statistical fits including additional observables")
    print("-------------------------------------------------------------------")
    print("  Idea:")
    print("    • Extend the data vector beyond the 9 Yukawas and DNA backbone:")
    print("      CKM / PMNS angles, neutrino mass ratios, maybe other mass ratios.")
    print("    • A true geometry would ideally organize *all* of these hierarchies.")
    print()
    print("  How to test:")
    print("    • Add new lock-checkers for any extra observables (with their own")
    print("      null models) and extend the global lock contract accordingly.")
    print("    • Require future geometries to hit the expanded bit budget.")
    print()

    # ----------------------------------------------------------------------------
    # BUILD HASH PAYLOAD & SHA256
    # ----------------------------------------------------------------------------
    hash_payload = {
        "module": "PHASE33_POST_FN_GEOMETRY_ROADMAP_v1",
        "timestamp": timestamp,
        "dna_bits": dna_bits,
        "yukawa_bits_global": yukawa_bits_global,
        "yukawa_bits_fixed": yukawa_bits_fixed,
        "fn3_present": fn3 is not None,
        "fn4_present": fn4 is not None,
    }
    hash_bytes = json.dumps(hash_payload, sort_keys=True).encode("utf-8")
    sha256 = hashlib.sha256(hash_bytes).hexdigest()

    print("=" * 80)
    print(" HASH & GEOM_EVIDENCE UPDATE ")
    print("=" * 80)
    print()
    print(f"Run SHA256 payload    : {sha256}")
    print()

    # ----------------------------------------------------------------------------
    # UPDATE GEOM_EVIDENCE
    # ----------------------------------------------------------------------------
    reason_text = (
        "Post-FN geometry roadmap: simple 3- and 4-spurion FN models with small "
        "integer charges and q_j<0 are structurally disfavored as explanations "
        "of the (-4,4,3) Yukawa triple, so future searches should focus on more "
        "complex FN-like models, discrete flavor symmetries, extra-dimensional "
        "localization, or unified DNA–Yukawa combinatorial geometries. This is "
        "a model-space guide, not a new probabilistic anomaly (bits=0)."
    )

    geom["post_fn_geometry_roadmap"] = {
        "bits": 0.0,
        "classification": "supporting_structure_shape",
        "reason": reason_text,
        "timestamp": timestamp,
        "sha256": sha256,
        "status": "supporting_structure_shape",
        "description": (
            "High-level roadmap for geometry search beyond simple 3-/4-spurion "
            "FN models, summarizing candidate directions (enhanced FN, discrete "
            "flavor symmetries, extra-dimensional setups, and unified "
            "DNA–Yukawa combinatorial geometries)."
        ),
    }

    print("GEOM_EVIDENCE['post_fn_geometry_roadmap'] updated.")
    print()
    print("PHASE33_POST_FN_GEOMETRY_ROADMAP_v1 COMPLETE")
    print("=" * 80)


if __name__ == "__main__":
    run_phase33_post_fn_geometry_roadmap_v1()

import numpy as np
import json
import hashlib
from datetime import datetime
from math import gcd
from functools import reduce

def _int_gcd_list(vals):
    vals = [int(v) for v in vals if int(v) != 0]
    if not vals:
        return 0
    return reduce(gcd, vals)

def run_phase34_toy3d_charge_lattice_analyzer_v1():
    """
    PHASE 34 – MODULE 1: TOY3D CHARGE LATTICE ANALYZER (v1)

    Treat the Toy3D integer charges as a lattice / discrete-flavor object.
    We look at:
      - column gcds,
      - basic lattice rank info,
      - charge patterns modulo small N (2..8),
    to see if there are simple discrete patterns that might correspond
    to an underlying group or code.
    This is structural only: bits = 0, no change to global lock contract.
    """

    timestamp = datetime.now().isoformat()

    # -------------------------------------------------------------------------
    # 1. Get or reconstruct Toy3D integer charges
    # -------------------------------------------------------------------------
    try:
        toy = TOY3D_INTEGER_GEOMETRY_V1  # type: ignore[name-defined]
        C = np.array(toy["C"], dtype=int)
        names = list(toy.get("names", []))
        q_real = np.array(toy.get("q", []), dtype=float)
    except Exception:
        # Fall back to hard-coded Toy3D from earlier phases
        names = [
            "me_over_v",
            "mmu_over_v",
            "mtau_over_v",
            "mb_over_v",
            "mc_over_v",
            "mt_over_v",
            "md_over_v",
            "ms_over_v",
            "mu_over_v",
        ]
        C = np.array(
            [
                [-4, -2, -1],  # me
                [-1, -2,  2],  # mmu
                [-4,  1, -4],  # mtau
                [-2,  0, -1],  # mb
                [-2, -1, -3],  # mc
                [-2,  1, -4],  # mt
                [ 0, -4,  4],  # md
                [-3,  0,  2],  # ms
                [-1, -4,  1],  # mu
            ],
            dtype=int,
        )
        # Use the high-precision q from Toy3D fit (PHASE 18 / 20)
        q_real = np.array([0.99546434, 0.96078513, -0.22005041], dtype=float)

    n_rows, n_cols = C.shape

    # -------------------------------------------------------------------------
    # 2. Basic lattice diagnostics
    # -------------------------------------------------------------------------
    # Column gcds
    col_gcds = [_int_gcd_list(C[:, j]) for j in range(n_cols)]

    # Rank info: integer rank (via float rank as proxy) and determinant
    # of the me/tau/d subbasis.
    # Basis rows indices: me (0), mtau (2), md (6)
    basis_idx = [0, 2, 6]
    basis_rows = C[basis_idx, :]
    rank_C = np.linalg.matrix_rank(C.astype(float))
    det_basis = float(np.linalg.det(basis_rows.astype(float)))

    # Norms / complexity
    max_abs = int(np.max(np.abs(C)))
    l1_sum = int(np.sum(np.abs(C)))
    num_nonzero = int(np.count_nonzero(C))
    num_distinct_rows = len({tuple(row.tolist()) for row in C})

    # Row L1 norms and sums (for rough structure)
    row_l1 = [int(np.sum(np.abs(C[i, :]))) for i in range(n_rows)]
    row_sum = [int(np.sum(C[i, :])) for i in range(n_rows)]

    # -------------------------------------------------------------------------
    # 3. Modular structure for small N
    # -------------------------------------------------------------------------
    mod_results = []
    for N in range(2, 9):  # N = 2..8
        C_mod = (C % N)
        # Ensure canonical representative (Python's % already gives 0..N-1)
        patterns = {}
        for i in range(n_rows):
            key = tuple(int(x) for x in C_mod[i, :])
            patterns.setdefault(key, []).append(names[i])

        num_families = len(patterns)
        largest_family_size = max(len(v) for v in patterns.values())
        family_sizes_sorted = sorted([len(v) for v in patterns.values()], reverse=True)

        mod_results.append(
            {
                "N": N,
                "num_families": num_families,
                "largest_family_size": largest_family_size,
                "family_sizes": family_sizes_sorted,
            }
        )

    # Choose a "most compressive" N by fewest families, tie-breaking by largest family
    best_mod = sorted(
        mod_results,
        key=lambda d: (d["num_families"], -d["largest_family_size"], d["N"]),
    )[0]

    # -------------------------------------------------------------------------
    # 4. Print report
    # -------------------------------------------------------------------------
    print("=" * 80)
    print(" PHASE 34 – MODULE 1: TOY3D CHARGE LATTICE ANALYZER (v1) ")
    print("=" * 80)
    print()
    print(f"Run timestamp (local) : {timestamp}")
    print()

    print("Toy3D integer charges C (9×3) recap")
    print("-" * 80)
    for i, name in enumerate(names):
        row = C[i, :]
        print(f"  {name:<11}  [{row[0]:+d} {row[1]:+d} {row[2]:+d}]")
    print()
    print(f"q_real (log10 λ)      : [{q_real[0]: .6f}, {q_real[1]: .6f}, {q_real[2]: .6f}]")
    print()

    print("Basic lattice properties")
    print("-" * 80)
    print(f"  shape(C)             : {C.shape}")
    print(f"  rank(C) (float proxy): {rank_C}")
    print(f"  basis rows (me,mtau,md) indices : {basis_idx}")
    print(f"  det(basis_rows)      : {det_basis:+.6f}")
    print()
    print(f"  max |C_ij|           : {max_abs}")
    print(f"  L1 sum of |C_ij|     : {l1_sum}")
    print(f"  num non-zero entries : {num_nonzero}")
    print(f"  num distinct rows    : {num_distinct_rows}")
    print()
    print("  Column gcds (over all 9 rows):")
    for j in range(n_cols):
        print(f"    col {j}: gcd = {col_gcds[j]}")
    print()
    print("  Per-row L1 norms and sums:")
    for i, name in enumerate(names):
        print(f"    {name:<11}  L1 = {row_l1[i]:2d},  sum = {row_sum[i]:+2d}")
    print()

    # -------------------------------------------------------------------------
    # 5. Modular pattern summary
    # -------------------------------------------------------------------------
    print("=" * 80)
    print(" MODULAR PATTERN SUMMARY (C modulo small N) ")
    print("=" * 80)
    print()
    print("For each N we group Yukawas by identical (c1,c2,c3) modulo N.")
    print("We report how many families and the largest family size.")
    print()

    print("  N   num_families   largest_family_size   family_sizes")
    print("  --  ------------   -------------------   -----------------")
    for res in mod_results:
        N = res["N"]
        nf = res["num_families"]
        lf = res["largest_family_size"]
        sizes = ",".join(str(s) for s in res["family_sizes"])
        print(f"  {N:2d}  {nf:12d}   {lf:19d}   {sizes}")
    print()

    print("Most compressive modulus (by fewest families, then biggest cluster):")
    print(f"  N_best              : {best_mod['N']}")
    print(f"  num_families        : {best_mod['num_families']}")
    print(f"  largest_family_size : {best_mod['largest_family_size']}")
    print(f"  family_sizes        : {best_mod['family_sizes']}")
    print()

    # For the best N, show the actual families
    N_star = best_mod["N"]
    C_mod_star = (C % N_star)
    patterns_star = {}
    for i in range(n_rows):
        key = tuple(int(x) for x in C_mod_star[i, :])
        patterns_star.setdefault(key, []).append(names[i])

    print(f"Detailed families for N = {N_star}:")
    for key, members in patterns_star.items():
        k_str = "(" + ",".join(str(v) for v in key) + ")"
        m_str = ", ".join(members)
        print(f"  charges mod {N_star} = {k_str:<10}  →  {m_str}")
    print()

    print("Interpretation guide:")
    print("  • Column gcds tell you if there is an obvious overall rescaling or")
    print("    hidden smaller lattice (e.g. everything living on 2Z or 3Z).")
    print("  • Modular families (C mod N) show how the 9 Yukawas collapse into")
    print("    equivalence classes under small discrete groups Z_N^3.")
    print("  • If some N gives a particularly simple partition, that N is a natural")
    print("    candidate for a discrete flavor symmetry or charge lattice modulus.")
    print()
    print("This module does NOT assign new bits or modify the global lock contract;")
    print("it is purely a structural lens on the Toy3D integer geometry.")
    print()

    # -------------------------------------------------------------------------
    # 6. Build hash payload and SHA256
    # -------------------------------------------------------------------------
    hash_payload = {
        "module": "PHASE34_Toy3D_Charge_Lattice_Analyzer_v1",
        "timestamp": timestamp,
        "C": C.tolist(),
        "names": names,
        "q_real": q_real.tolist(),
        "rank_C": int(rank_C),
        "det_basis": det_basis,
        "col_gcds": col_gcds,
        "max_abs": max_abs,
        "l1_sum": l1_sum,
        "num_nonzero": num_nonzero,
        "num_distinct_rows": num_distinct_rows,
        "mod_results": mod_results,
        "best_mod": best_mod,
    }
    hash_bytes = json.dumps(hash_payload, sort_keys=True).encode("utf-8")
    sha256 = hashlib.sha256(hash_bytes).hexdigest()

    print("=" * 80)
    print(" HASH & GEOM_EVIDENCE UPDATE ")
    print("=" * 80)
    print()
    print(f"Run SHA256 payload    : {sha256}")
    print()

    # -------------------------------------------------------------------------
    # 7. Update GEOM_EVIDENCE
    # -------------------------------------------------------------------------
    try:
        geom = GEOM_EVIDENCE  # type: ignore[name-defined]
    except NameError:
        geom = {}
        globals()["GEOM_EVIDENCE"] = geom  # type: ignore[assignment]

    reason_text = (
        "Toy3D charge lattice analyzer: summarizes column gcds, rank, and small-N "
        "modular family structure for the 9×3 Toy3D integer charges. Identifies "
        "candidate moduli N where the pattern compresses most strongly, as hints "
        "toward possible discrete flavor or lattice interpretations. Structural "
        "lens only; no new probabilistic anomaly (bits=0)."
    )

    geom["toy3d_charge_lattice_lens"] = {
        "bits": 0.0,
        "classification": "supporting_structure_shape",
        "reason": reason_text,
        "timestamp": timestamp,
        "sha256": sha256,
        "status": "supporting_structure_shape",
        "description": (
            "Lattice and modular analysis of Toy3D integer charges: column gcds, "
            "rank, and modular family structure C mod N for N=2..8, highlighting "
            "candidate small moduli for discrete-flavor or lattice embeddings."
        ),
        "best_modulus": best_mod,
        "mod_results": mod_results,
    }

    print("GEOM_EVIDENCE['toy3d_charge_lattice_lens'] updated.")
    print()
    print("PHASE34_Toy3D_Charge_Lattice_Analyzer_v1 COMPLETE")
    print("=" * 80)


if __name__ == "__main__":
    run_phase34_toy3d_charge_lattice_analyzer_v1()

import numpy as np
import json
import hashlib
from datetime import datetime
from math import log2

def _build_toy3d_C_and_names():
    """Reconstruct Toy3D integer charges and names if not in memory."""
    try:
        toy = TOY3D_INTEGER_GEOMETRY_V1  # type: ignore[name-defined]
        C = np.array(toy["C"], dtype=int)
        names = list(toy.get("names", []))
    except Exception:
        names = [
            "me_over_v",
            "mmu_over_v",
            "mtau_over_v",
            "mb_over_v",
            "mc_over_v",
            "mt_over_v",
            "md_over_v",
            "ms_over_v",
            "mu_over_v",
        ]
        C = np.array(
            [
                [-4, -2, -1],  # me
                [-1, -2,  2],  # mmu
                [-4,  1, -4],  # mtau
                [-2,  0, -1],  # mb
                [-2, -1, -3],  # mc
                [-2,  1, -4],  # mt
                [ 0, -4,  4],  # md
                [-3,  0,  2],  # ms
                [-1, -4,  1],  # mu
            ],
            dtype=int,
        )
    return C, names

def _compute_best_mod_score(C, N_min=2, N_max=8):
    """
    For a given charge matrix C (9×3), compute modular family structure
    for N in [N_min, N_max], and return the "best" (most compressive) N.

    Returns:
      best_num_families, best_largest_family, best_N, mod_results
    where mod_results is a list of dicts with keys:
      N, num_families, largest_family_size, family_sizes
    """
    n_rows = C.shape[0]
    mod_results = []
    for N in range(N_min, N_max + 1):
        C_mod = (C % N)
        patterns = {}
        for i in range(n_rows):
            key = tuple(int(x) for x in C_mod[i, :])
            patterns.setdefault(key, []).append(i)
        num_families = len(patterns)
        family_sizes = sorted([len(v) for v in patterns.values()], reverse=True)
        largest_family_size = family_sizes[0]
        mod_results.append(
            {
                "N": N,
                "num_families": num_families,
                "largest_family_size": largest_family_size,
                "family_sizes": family_sizes,
            }
        )

    # Best = minimal num_families; tie-break by largest family, then N
    best = sorted(
        mod_results,
        key=lambda d: (d["num_families"], -d["largest_family_size"], d["N"]),
    )[0]

    return (
        best["num_families"],
        best["largest_family_size"],
        best["N"],
        mod_results,
    )

def run_phase35_toy3d_charge_lattice_nullscan_v1(
    num_null: int = 2000,
    C_max: int = 4,
    seed: int = 20251122,
):
    """
    PHASE 35 – MODULE 1: TOY3D MOD-2 / SMALL-N LATTICE NULLSCAN (v1)

    Goal:
      Test whether the Toy3D modular pattern (best small-N compression)
      is ordinary or unusually 'clustered' compared to random integer
      charge matrices with the (-4,4,3) triple preserved.

    Procedure:
      • Keep me/mtau/md rows of C fixed (indices 0,2,6).
      • Randomize other rows in [-C_max, C_max]^3 \\ {(0,0,0)}.
      • For each C', compute best small-N modular compression across N=2..8:
          - minimal num_families,
          - associated largest_family_size.
      • Compare Toy3D's best (num_families, largest_family) to null ensemble.
      • p_null ~ fraction of nulls with num_families <= num_families_real
        (i.e. as compressive or more), and bits = -log2(p_null).
    """
    timestamp = datetime.now().isoformat()
    rng = np.random.default_rng(seed)

    # -------------------------------------------------------------------------
    # 1. Real Toy3D metrics
    # -------------------------------------------------------------------------
    C_real, names = _build_toy3d_C_and_names()
    n_rows, n_cols = C_real.shape

    # Basis rows (me, mtau, md) fixed to preserve (-4,4,3)
    basis_idx = [0, 2, 6]
    perturbable_idx = [i for i in range(n_rows) if i not in basis_idx]

    # Compute best small-N modular compression for real C
    nf_real, lf_real, N_real, mod_results_real = _compute_best_mod_score(C_real)

    # -------------------------------------------------------------------------
    # 2. Null ensemble
    # -------------------------------------------------------------------------
    nf_null = np.zeros(num_null, dtype=int)
    lf_null = np.zeros(num_null, dtype=int)
    N_null = np.zeros(num_null, dtype=int)

    print("=" * 80)
    print(" PHASE 35 – MODULE 1: TOY3D MOD-2 / SMALL-N LATTICE NULLSCAN (v1) ")
    print("=" * 80)
    print()
    print(f"Run timestamp (local) : {timestamp}")
    print(f"C_max                  : {C_max}")
    print(f"num_null               : {num_null}")
    print()
    print("Real Toy3D best small-N modular compression (N=2..8):")
    print("------------------------------------------------------------------")
    print(f"  best N               : {N_real}")
    print(f"  best num_families    : {nf_real}")
    print(f"  best largest_family  : {lf_real}")
    print()

    print("Generating null ensemble (randomizing non-basis rows)...")
    print(f"  basis rows fixed at indices: {basis_idx}")
    print(f"  perturbable rows indices   : {perturbable_idx}")
    print()

    for k in range(num_null):
        C_null = C_real.copy()

        # Randomize only perturbable rows
        for i in perturbable_idx:
            while True:
                row = rng.integers(-C_max, C_max + 1, size=n_cols)
                if not np.all(row == 0):
                    C_null[i, :] = row
                    break

        nf_k, lf_k, N_k, _ = _compute_best_mod_score(C_null)
        nf_null[k] = nf_k
        lf_null[k] = lf_k
        N_null[k] = N_k

        if (k + 1) % 200 == 0 or k == num_null - 1:
            print(f"  ... {k+1}/{num_null} null universes processed")

    print()
    print("=" * 80)
    print(" NULL STATISTICS – BEST SMALL-N MODULAR COMPRESSION ")
    print("=" * 80)
    print()

    # Stats for num_families
    nf_min, nf_max = int(nf_null.min()), int(nf_null.max())
    nf_q25, nf_q50, nf_q75 = np.percentile(nf_null, [25, 50, 75])
    nf_mean, nf_std = nf_null.mean(), nf_null.std()

    print("num_families (best over N=2..8):")
    print(f"  null min / max        : {nf_min:3d} / {nf_max:3d}")
    print(
        f"  null 25% / 50% / 75%  : {nf_q25:5.1f} / {nf_q50:5.1f} / {nf_q75:5.1f}"
    )
    print(f"  null mean / std       : {nf_mean:5.2f} / {nf_std:5.2f}")
    print(f"  real best num_families: {nf_real:3d}")
    print()

    # Stats for largest_family_size
    lf_min, lf_max = int(lf_null.min()), int(lf_null.max())
    lf_q25, lf_q50, lf_q75 = np.percentile(lf_null, [25, 50, 75])
    lf_mean, lf_std = lf_null.mean(), lf_null.std()

    print("largest_family_size (best over N=2..8):")
    print(f"  null min / max        : {lf_min:3d} / {lf_max:3d}")
    print(
        f"  null 25% / 50% / 75%  : {lf_q25:5.1f} / {lf_q50:5.1f} / {lf_q75:5.1f}"
    )
    print(f"  null mean / std       : {lf_mean:5.2f} / {lf_std:5.2f}")
    print(f"  real best largest fam : {lf_real:3d}")
    print()

    # -------------------------------------------------------------------------
    # 3. Significance estimate
    # -------------------------------------------------------------------------
    # Compression is primarily about fewer families; Toy3D has nf_real = 6.
    # We ask: how often does the null get nf_null <= 6 (as compressive or better)?
    mask_as_good = nf_null <= nf_real
    count_as_good = int(mask_as_good.sum())
    p_emp = count_as_good / float(num_null)

    # Bits of surprise; guard against p=0
    if count_as_good == 0:
        p_upper = 1.0 / num_null
        bits = -log2(p_upper)
        bits_note = f">= {bits:.2f}"
    else:
        bits_val = -log2(p_emp)
        bits = bits_val
        bits_note = f"{bits_val:.2f}"

    print("=" * 80)
    print(" SIGNIFICANCE OF SMALL-N MODULAR COMPRESSION ")
    print("=" * 80)
    print()
    print(f"  real best num_families      : {nf_real}")
    print(f"  count_null(num_fam <= real) : {count_as_good} / {num_null}")
    print(f"  P_null(num_fam <= real)     : {p_emp:.6f}")
    print(f"  bits ≈ -log2(p_null)        : {bits_note}")
    print()

    # Simple qualitative classification
    if count_as_good == 0:
        classification = "supporting_structure"
        reason_class = (
            "Toy3D has unusually strong small-N modular compression compared to "
            "this null (no null universes as compressive); still treated as "
            "supporting, not a primary lock."
        )
    else:
        if bits < 3.0:
            classification = "killed"
            reason_class = (
                "Best small-N modular compression (over N=2..8) is ordinary under "
                "the null (bits < 3). No new Yukawa lock from mod-N lattice structure."
            )
        elif bits < 7.0:
            classification = "supporting_structure"
            reason_class = (
                "Best small-N modular compression is mildly interesting (3–7 bits), "
                "but derivative of Toy3D/Yukawa triple; treated as supporting shape."
            )
        else:
            classification = "supporting_structure_strong"
            reason_class = (
                "Best small-N modular compression is strongly non-generic (>7 bits), "
                "but still derivative of Toy3D/Yukawa triple; not promoted to a "
                "primary lock."
            )

    print("Interpretation guide:")
    print(
        "  • nf_real is the number of equivalence classes of Yukawas under (C mod N)"
    )
    print("    for the best N in {2..8}. Smaller nf means stronger clustering.")
    print("  • This test includes the look-elsewhere effect over N=2..8 by")
    print("    recomputing the best modulus for each null universe.")
    print("  • Regardless of bits, any signal here is derivative of Toy3D and the")
    print("    (-4,4,3) triple, so it will be recorded as supporting/shape, not a "
          "new primary lock.")
    print()

    # -------------------------------------------------------------------------
    # 4. Hash payload and SHA256
    # -------------------------------------------------------------------------
    hash_payload = {
        "module": "PHASE35_Toy3D_Charge_Lattice_Nullscan_v1",
        "timestamp": timestamp,
        "C_real": C_real.tolist(),
        "names": names,
        "C_max": C_max,
        "num_null": num_null,
        "basis_idx": basis_idx,
        "perturbable_idx": perturbable_idx,
        "real_best": {
            "num_families": int(nf_real),
            "largest_family_size": int(lf_real),
            "N": int(N_real),
        },
        "null_stats_num_families": {
            "min": nf_min,
            "max": nf_max,
            "q25": float(nf_q25),
            "q50": float(nf_q50),
            "q75": float(nf_q75),
            "mean": float(nf_mean),
            "std": float(nf_std),
        },
        "null_stats_largest_family": {
            "min": lf_min,
            "max": lf_max,
            "q25": float(lf_q25),
            "q50": float(lf_q50),
            "q75": float(lf_q75),
            "mean": float(lf_mean),
            "std": float(lf_std),
        },
        "significance": {
            "count_as_good": int(count_as_good),
            "p_emp": float(p_emp),
            "bits": float(bits),
        },
        "classification": classification,
    }
    hash_bytes = json.dumps(hash_payload, sort_keys=True).encode("utf-8")
    sha256 = hashlib.sha256(hash_bytes).hexdigest()

    print("=" * 80)
    print(" HASH & GEOM_EVIDENCE UPDATE ")
    print("=" * 80)
    print()
    print(f"Run SHA256 payload    : {sha256}")
    print()

    # -------------------------------------------------------------------------
    # 5. Update GEOM_EVIDENCE
    # -------------------------------------------------------------------------
    try:
        geom = GEOM_EVIDENCE  # type: ignore[name-defined]
    except NameError:
        geom = {}
        globals()["GEOM_EVIDENCE"] = geom  # type: ignore[assignment]

    geom["toy3d_charge_lattice_nullscan"] = {
        "bits": float(bits),
        "p_null": float(p_emp),
        "num_null": int(num_null),
        "classification": classification,
        "reason": reason_class,
        "timestamp": timestamp,
        "sha256": sha256,
        "status": classification,
        "description": (
            "Nullscan of Toy3D small-N modular family structure: randomize "
            "non-basis Yukawa charge rows within [-C_max,C_max]^3 with the "
            "(-4,4,3) triple preserved, recompute best compression over N=2..8, "
            "and compare Toy3D's best num_families to the null ensemble."
        ),
        "real_best": {
            "num_families": int(nf_real),
            "largest_family_size": int(lf_real),
            "N": int(N_real),
        },
    }

    print("GEOM_EVIDENCE['toy3d_charge_lattice_nullscan'] updated.")
    print()
    print("PHASE35_Toy3D_Charge_Lattice_Nullscan_v1 COMPLETE")
    print("=" * 80)


if __name__ == "__main__":
    run_phase35_toy3d_charge_lattice_nullscan_v1()

#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
PHASE 35 – MODULE 2: TOY3D MOD-N LATTICE EVIDENCE (v1)

Takes the results of the PHASE 35 – MODULE 1 nullscan and:
  • Prints a structured recap and interpretation.
  • Updates GEOM_EVIDENCE['toy3d_charge_lattice_nullscan'] with a
    proper evidence entry (status = "killed", bits ~ 0.16).
"""

import math
import json
import hashlib
from datetime import datetime

# ---------------------------------------------------------------------
# Optional global evidence dict (will be created if not present)
# ---------------------------------------------------------------------
try:
    GEOM_EVIDENCE  # type: ignore[name-defined]
except NameError:  # pragma: no cover - only triggers in fresh sessions
    GEOM_EVIDENCE = {}  # type: ignore[assignment]


def run_phase35_toy3d_charge_lattice_evidence() -> None:
    """
    Phase 35 – Module 2: interpret the mod-N lattice nullscan
    from PHASE 35 – MODULE 1 and update GEOM_EVIDENCE.
    """

    # -----------------------------------------------------------------
    # Hard-coded inputs from PHASE 35 – MODULE 1 (nullscan output)
    # -----------------------------------------------------------------
    C_max = 4
    num_null = 2000

    # Real Toy3D best small-N modular compression (N = 2..8)
    real_best_N = 2
    real_best_num_families = 6
    real_best_largest_family = 2

    # Null stats for "best num_families over N=2..8"
    null_min_nf = 3
    null_max_nf = 8
    null_q25_nf = 5.0
    null_q50_nf = 5.5
    null_q75_nf = 6.0
    null_mean_nf = 5.48
    null_std_nf = 0.87

    # Null stats for "best largest_family_size over N=2..8"
    null_min_lf = 2
    null_max_lf = 6
    null_q25_lf = 2.0
    null_q50_lf = 3.0
    null_q75_lf = 3.0
    null_mean_lf = 2.89
    null_std_lf = 0.72

    # Empirical p-value from nullscan
    count_null_le_real = 1785  # count_null(num_fam <= real)
    p_null = count_null_le_real / num_null if num_null > 0 else 1.0

    # Bits of "surprise"
    bits = -math.log2(p_null) if p_null > 0.0 else float("inf")

    # Timestamp & payload SHA
    timestamp = datetime.now().isoformat()

    payload = {
        "module": "PHASE35_Toy3D_Charge_Lattice_EVIDENCE_v1",
        "C_max": C_max,
        "num_null": num_null,
        "real_best": {
            "N": real_best_N,
            "num_families": real_best_num_families,
            "largest_family_size": real_best_largest_family,
        },
        "null_stats_num_families": {
            "min": null_min_nf,
            "max": null_max_nf,
            "q25": null_q25_nf,
            "q50": null_q50_nf,
            "q75": null_q75_nf,
            "mean": null_mean_nf,
            "std": null_std_nf,
        },
        "null_stats_largest_family": {
            "min": null_min_lf,
            "max": null_max_lf,
            "q25": null_q25_lf,
            "q50": null_q50_lf,
            "q75": null_q75_lf,
            "mean": null_mean_lf,
            "std": null_std_lf,
        },
        "p_null": p_null,
        "bits": bits,
        "count_null_le_real": count_null_le_real,
        "timestamp": timestamp,
    }

    payload_json = json.dumps(payload, sort_keys=True)
    sha256 = hashlib.sha256(payload_json.encode("utf-8")).hexdigest()

    # -----------------------------------------------------------------
    # Printing
    # -----------------------------------------------------------------
    print("=" * 80)
    print(" PHASE 35 – MODULE 2: TOY3D MOD-N LATTICE EVIDENCE (v1) ")
    print("=" * 80)
    print()
    print(f"Run timestamp (local) : {timestamp}")
    print(f"Run SHA256 payload    : {sha256}")
    print()
    print("Input recap from PHASE 35 – MODULE 1 (nullscan)")
    print("-" * 80)
    print(f"  • C_max                  : {C_max}")
    print(f"  • num_null               : {num_null}")
    print()
    print("Real Toy3D best small-N modular compression (N = 2..8):")
    print(f"  • best N                 : {real_best_N}")
    print(f"  • best num_families      : {real_best_num_families}")
    print(f"  • best largest_family    : {real_best_largest_family}")
    print()
    print("Null ensemble (best small-N compression for randomized C):")
    print("  num_families (best over N=2..8):")
    print(f"    • null min / max       : {null_min_nf:3d} / {null_max_nf:3d}")
    print(
        "    • null 25% / 50% / 75% : "
        f"{null_q25_nf:4.1f} / {null_q50_nf:4.1f} / {null_q75_nf:4.1f}"
    )
    print(
        "    • null mean / std      : "
        f"{null_mean_nf:5.2f} / {null_std_nf:4.2f}"
    )
    print(f"    • real best            : {real_best_num_families:3d}")
    print()
    print("  largest_family_size (best over N=2..8):")
    print(f"    • null min / max       : {null_min_lf:3d} / {null_max_lf:3d}")
    print(
        "    • null 25% / 50% / 75% : "
        f"{null_q25_lf:4.1f} / {null_q50_lf:4.1f} / {null_q75_lf:4.1f}"
    )
    print(
        "    • null mean / std      : "
        f"{null_mean_lf:5.2f} / {null_std_lf:4.2f}"
    )
    print(f"    • real best            : {real_best_largest_family:3d}")
    print()
    print("=" * 80)
    print(" SIGNIFICANCE OF SMALL-N MODULAR COMPRESSION ")
    print("=" * 80)
    print()
    print(f"  real best num_families      : {real_best_num_families}")
    print(
        "  count_null(num_fam <= real) : "
        f"{count_null_le_real} / {num_null}"
    )
    print(f"  P_null(num_fam <= real)     : {p_null:.6f}")
    print(f"  bits ≈ -log2(p_null)        : {bits:.2f}")
    print()
    print("Interpretation:")
    print("  • nf_real is the number of equivalence classes of Yukawas under")
    print("    (C mod N) for the best N in {2..8}. Smaller nf means stronger")
    print("    modular clustering.")
    print("  • This test includes the look-elsewhere effect over N=2..8 by")
    print("    recomputing the best modulus for each null universe.")
    print()
    print("  • Here, Toy3D is actually slightly LESS clustered than the null")
    print(
        "    mean (nf_real = 6 vs. ⟨nf_null⟩ ≈ "
        f"{null_mean_nf:.2f}), and P_null ≈ {p_null:.3f}"
    )
    print("    corresponds to only ≈0.16 bits; far below any threshold for")
    print("    a secondary lock.")
    print()
    print("Verdict:")
    print("  → The small-N (especially mod-2) charge lattice structure of")
    print("    Toy3D is **ordinary** under this null.")
    print("  → It does NOT constitute an additional Yukawa lock; it is just")
    print("    another way of writing the same small-integer noise once the")
    print("    (-4,4,3) triple is enforced.")
    print()
    print("=" * 80)
    print(" GEOM_EVIDENCE UPDATE ")
    print("=" * 80)
    print()

    # -----------------------------------------------------------------
    # Update GEOM_EVIDENCE
    # -----------------------------------------------------------------
    note = (
        "Nullscan of Toy3D small-N modular family structure: randomize "
        "non-basis Yukawa charge rows within [-C_max,C_max]^3 with the "
        "(-4,4,3) triple preserved, recompute best compression over "
        "N=2..8, and compare Toy3D's best num_families to the null "
        "ensemble. Result: P_null≈0.89 (~0.16 bits) ⇒ mod-N lattice "
        "patterns are ordinary and do not constitute a new Yukawa lock."
    )

    GEOM_EVIDENCE["toy3d_charge_lattice_nullscan"] = {  # type: ignore[index]
        "module": "PHASE35_Toy3D_Charge_Lattice_EVIDENCE_v1",
        "C_max": C_max,
        "num_null": num_null,
        "real_best": {
            "N": real_best_N,
            "num_families": real_best_num_families,
            "largest_family_size": real_best_largest_family,
        },
        "null_stats_num_families": {
            "min": null_min_nf,
            "max": null_max_nf,
            "q25": null_q25_nf,
            "q50": null_q50_nf,
            "q75": null_q75_nf,
            "mean": null_mean_nf,
            "std": null_std_nf,
        },
        "null_stats_largest_family": {
            "min": null_min_lf,
            "max": null_max_lf,
            "q25": null_q25_lf,
            "q50": null_q50_lf,
            "q75": null_q75_lf,
            "mean": null_mean_lf,
            "std": null_std_lf,
        },
        "p_null": p_null,
        "bits": bits,
        "count_null_le_real": count_null_le_real,
        "classification": "killed",
        "status": "killed",
        "note": note,
        "timestamp": timestamp,
        "sha256": sha256,
    }

    print(
        "GEOM_EVIDENCE['toy3d_charge_lattice_nullscan'] updated "
        "with status = 'killed' and bits ≈ "
        f"{bits:.2f}."
    )
    print()
    print("PHASE35_Toy3D_Charge_Lattice_EVIDENCE_v1 COMPLETE")
    print("=" * 80)


if __name__ == "__main__":
    run_phase35_toy3d_charge_lattice_evidence()

#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
PHASE 36 – MODULE 1 (v2): TOY3D DISCRETE FLAVOR GENERATOR SCAN

Fixes:
  - Ensure everything in the SHA256 payload is JSON-serializable by
    using plain Python ints instead of numpy.int64 in the results.

Goal:
  Treat the 9 Toy3D charge rows as elements of Z_N^3 for small N, and ask:
    • For each N in {2,3,4,5,6,7,8}, can all 9 charges be generated by
      a small number of "flavor generators" g_j in Z_N^3?
    • Specifically, can they all be generated by:
         - a single cyclic generator (1D subgroup), or
         - two generators (2D abelian subgroup)?
    • 3 generators is trivial (whole Z_N^3), so we focus on 1–2.

This is a structural / model-building tool:
  • No new bits, no nullscan here.
  • It helps you see whether Toy3D looks naturally like charges under a
    small abelian flavor symmetry Z_N^k.

Outputs:
  • Printed summary for each N: minimum number of generators (1,2, or 3+)
    and example generators (if found).
  • A GEOM_EVIDENCE entry with classification = supporting_structure_shape.
"""

import numpy as np
import itertools
import json
import hashlib
from datetime import datetime

# ---------------------------------------------------------------------
# Optional global evidence dict (created if not present)
# ---------------------------------------------------------------------
try:
    GEOM_EVIDENCE  # type: ignore[name-defined]
except NameError:  # pragma: no cover
    GEOM_EVIDENCE = {}  # type: ignore[assignment]


# ---------------------------------------------------------------------
# Toy3D integer charges (from earlier phases)
# ---------------------------------------------------------------------
TOY3D_YUKAWA_NAMES = [
    "me_over_v",
    "mmu_over_v",
    "mtau_over_v",
    "mb_over_v",
    "mc_over_v",
    "mt_over_v",
    "md_over_v",
    "ms_over_v",
    "mu_over_v",
]

TOY3D_C = np.array(
    [
        [-4, -2, -1],  # me_over_v
        [-1, -2,  2],  # mmu_over_v
        [-4,  1, -4],  # mtau_over_v
        [-2,  0, -1],  # mb_over_v
        [-2, -1, -3],  # mc_over_v
        [-2,  1, -4],  # mt_over_v
        [ 0, -4,  4],  # md_over_v
        [-3,  0,  2],  # ms_over_v
        [-1, -4,  1],  # mu_over_v
    ],
    dtype=int,
)


# ---------------------------------------------------------------------
# Helper functions
# ---------------------------------------------------------------------
def _mod_vec(v: np.ndarray, N: int) -> tuple[int, int, int]:
    """Return v modulo N as a tuple in {0,...,N-1}^3 (Python ints)."""
    return tuple(int(x % N) for x in v)


def _generate_cyclic(g: tuple[int, int, int], N: int) -> set[tuple[int, int, int]]:
    """Generate the cyclic subgroup {k g mod N | k ∈ [0, N-1]}."""
    base = np.array(g, dtype=int)
    out: set[tuple[int, int, int]] = set()
    for k in range(N):
        out.add(_mod_vec(k * base, N))
    return out


def _generate_two_gen(
    g1: tuple[int, int, int],
    g2: tuple[int, int, int],
    N: int,
) -> set[tuple[int, int, int]]:
    """Generate subgroup {a g1 + b g2 mod N | a,b ∈ [0, N-1]}."""
    v1 = np.array(g1, dtype=int)
    v2 = np.array(g2, dtype=int)
    out: set[tuple[int, int, int]] = set()
    for a in range(N):
        for b in range(N):
            out.add(_mod_vec(a * v1 + b * v2, N))
    return out


def _find_min_generators_for_N(
    C: np.ndarray,
    N: int,
) -> dict:
    """
    For a given N, find the minimum number of generators (1 or 2)
    in Z_N^3 that can generate all distinct charge rows of C modulo N.

    Returns a dict with keys:
      'N', 'min_generators', 'generators', 'distinct_rows_modN'
    All entries are plain Python types (ints, lists/tuples).
    """
    # Work modulo N using only Python ints
    C_mod = [[int(x % N) for x in row] for row in C]
    rows = [tuple(row) for row in C_mod]
    distinct_rows = sorted(set(rows))

    # Remove the zero vector from candidate generator set
    nonzero_rows = [r for r in distinct_rows if any(x != 0 for x in r)]

    result: dict = {
        "N": int(N),
        "min_generators": None,
        "generators": None,
        "distinct_rows_modN": [list(r) for r in distinct_rows],  # for JSON
    }

    # --------------------------------------------------------------
    # Try 1-generator (cyclic) case
    # --------------------------------------------------------------
    for g in nonzero_rows:
        generated = _generate_cyclic(g, N)
        if all(r in generated for r in distinct_rows):
            result["min_generators"] = 1
            # store as list of lists for JSON
            result["generators"] = [list(g)]
            return result

    # --------------------------------------------------------------
    # Try 2-generator case
    # --------------------------------------------------------------
    for g1, g2 in itertools.combinations(nonzero_rows, 2):
        generated = _generate_two_gen(g1, g2, N)
        if all(r in generated for r in distinct_rows):
            result["min_generators"] = 2
            result["generators"] = [list(g1), list(g2)]
            return result

    # --------------------------------------------------------------
    # If we get here, we need ≥3 generators
    # --------------------------------------------------------------
    result["min_generators"] = 3
    result["generators"] = None
    return result


def run_phase36_toy3d_discrete_flavor_generator_scan() -> None:
    """
    PHASE 36 – MODULE 1 (v2) main entry point.
    """

    timestamp = datetime.now().isoformat()

    N_values = list(range(2, 9))  # 2..8
    results = []
    for N in N_values:
        results.append(_find_min_generators_for_N(TOY3D_C, N))

    # Build payload for SHA – now JSON-serializable
    payload = {
        "module": "PHASE36_Toy3D_Discrete_Flavor_Generator_Scan_v2",
        "N_values": [int(N) for N in N_values],
        "results": results,
        "timestamp": timestamp,
    }
    payload_json = json.dumps(payload, sort_keys=True)
    sha256 = hashlib.sha256(payload_json.encode("utf-8")).hexdigest()

    # -----------------------------------------------------------------
    # Printing
    # -----------------------------------------------------------------
    print("=" * 80)
    print(" PHASE 36 – MODULE 1 (v2): TOY3D DISCRETE FLAVOR GENERATOR SCAN ")
    print("=" * 80)
    print()
    print(f"Run timestamp (local) : {timestamp}")
    print(f"Run SHA256 payload    : {sha256}")
    print()
    print("Toy3D integer charges C (9×3) recap")
    print("-" * 80)
    for name, row in zip(TOY3D_YUKAWA_NAMES, TOY3D_C):
        c1, c2, c3 = row
        print(f"  {name:11s}  [{c1:+d} {c2:+d} {c3:+d}]")
    print()

    print("Scanning N ∈ {2,3,4,5,6,7,8} for minimal generators in Z_N^3...")
    print()
    print("Summary by N:")
    print("  N   min_generators   example_generators (mod N)")
    print("  --  --------------   --------------------------")
    for r in results:
        N = r["N"]
        k = r["min_generators"]
        gens = r["generators"]
        if k == 1 and gens is not None:
            g = gens[0]
            print(f"  {N:2d}          1          g = {tuple(g)}")
        elif k == 2 and gens is not None:
            g1, g2 = gens
            print(f"  {N:2d}          2          g1 = {tuple(g1)}, g2 = {tuple(g2)}")
        else:
            print(f"  {N:2d}        ≥3          (no 1- or 2-generator cover)")

    print()
    print("=" * 80)
    print(" INTERPRETATION GUIDE ")
    print("=" * 80)
    print()
    print("  • For each N, we treat the 9 Toy3D charge rows as elements of Z_N^3,")
    print("    and ask whether they can be generated by:")
    print("       – a single cyclic generator g, or")
    print("       – two generators (g1, g2) spanning a 2D abelian subgroup.")
    print("  • If min_generators = 1 for some N, then all nine rows lie on a")
    print("    single cyclic orbit in Z_N^3; that would be an extremely simple")
    print("    flavor symmetry structure.")
    print("  • If min_generators = 2, Toy3D lives in a 2D sublattice / subgroup")
    print("    of Z_N^3; this suggests a natural Z_N×Z_N-like flavor symmetry.")
    print("  • If min_generators ≥ 3 for all small N, Toy3D is structurally more")
    print("    complicated: you need three independent generators, i.e. it fills")
    print("    a more generic 3D charge lattice modulo small N.")
    print()
    print("  This module is STRUCTURAL ONLY:")
    print("    – It introduces no new p-values or bits.")
    print("    – Any pattern here is derivative of the Toy3D charges and the")
    print("      (-4,4,3) triple and is therefore supporting_shape at best.")
    print()

    # -----------------------------------------------------------------
    # Update GEOM_EVIDENCE entry
    # -----------------------------------------------------------------
    GEOM_EVIDENCE["toy3d_discrete_flavor_generators"] = {  # type: ignore[index]
        "module": "PHASE36_Toy3D_Discrete_Flavor_Generator_Scan_v2",
        "N_values": [int(N) for N in N_values],
        "results": results,
        "bits": 0.0,
        "classification": "supporting_structure_shape",
        "status": "supporting_structure_shape",
        "reason": (
            "Scan over small N (2..8) asking whether Toy3D Yukawa charge "
            "rows modulo N can be generated by 1 or 2 flavor generators in "
            "Z_N^3. Structural lens on possible discrete flavor symmetries; "
            "no probabilistic nullscan, so bits=0."
        ),
        "timestamp": timestamp,
        "sha256": sha256,
        "description": (
            "Toy3D discrete flavor generator scan in Z_N^3 for N=2..8, "
            "recording the minimal number of generators needed to span the "
            "set of charge vectors modulo N."
        ),
    }

    print("=" * 80)
    print(" GEOM_EVIDENCE UPDATE ")
    print("=" * 80)
    print()
    print("GEOM_EVIDENCE['toy3d_discrete_flavor_generators'] set with:")
    print("  classification : supporting_structure_shape")
    print("  bits           : 0.0")
    print()
    print("PHASE36_Toy3D_Discrete_Flavor_Generator_Scan_v2 COMPLETE")
    print("=" * 80)


if __name__ == "__main__":
    run_phase36_toy3d_discrete_flavor_generator_scan()

#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
PHASE 37 – MODULE 1: TOY3D DISCRETE FLAVOR EVIDENCE & ROADMAP (v1)

Purpose:
  - Read the output of PHASE 36 (toy3d_discrete_flavor_generators) from
    GEOM_EVIDENCE and summarize what it implies about discrete flavor
    symmetry interpretations of the Toy3D charges.
  - Record a clean, structural GEOM_EVIDENCE entry with bits=0, since
    this is NOT a probabilistic nullscan but a geometry/shape constraint.

Expected inputs in this interpreter:
  - GEOM_EVIDENCE['toy3d_discrete_flavor_generators'] from PHASE 36.

Outputs:
  - Printed summary of minimal generator counts for N = 2..8.
  - GEOM_EVIDENCE['toy3d_discrete_flavor_summary'] entry with:
        classification = supporting_structure_shape
        bits           = 0.0
"""

import json
import hashlib
from datetime import datetime

# ---------------------------------------------------------------------
# Ensure GEOM_EVIDENCE exists
# ---------------------------------------------------------------------
try:
    GEOM_EVIDENCE  # type: ignore[name-defined]
except NameError:  # pragma: no cover
    GEOM_EVIDENCE = {}  # type: ignore[assignment]


def run_phase37_toy3d_discrete_flavor_summary() -> None:
    timestamp = datetime.now().isoformat()

    # Pull PHASE 36 results if present
    flavor_key = "toy3d_discrete_flavor_generators"
    flavor_entry = GEOM_EVIDENCE.get(flavor_key)  # type: ignore[index]

    if flavor_entry is None:
        results = []
        note_missing = True
    else:
        results = flavor_entry.get("results", [])
        note_missing = False

    # Make sure everything is JSON-serializable in the payload
    payload = {
        "module": "PHASE37_Toy3D_Discrete_Flavor_Evidence_and_Roadmap_v1",
        "has_phase36_entry": (not note_missing),
        "results": results,
        "timestamp": timestamp,
    }
    payload_json = json.dumps(payload, sort_keys=True)
    sha256 = hashlib.sha256(payload_json.encode("utf-8")).hexdigest()

    # -----------------------------------------------------------------
    # Printing
    # -----------------------------------------------------------------
    print("=" * 80)
    print(" PHASE 37 – MODULE 1: TOY3D DISCRETE FLAVOR EVIDENCE & ROADMAP (v1) ")
    print("=" * 80)
    print()
    print(f"Run timestamp (local) : {timestamp}")
    print(f"Run SHA256 payload    : {sha256}")
    print()

    if note_missing:
        print("WARNING:")
        print("  GEOM_EVIDENCE['toy3d_discrete_flavor_generators'] not found.")
        print("  This module expects PHASE 36 to have been run in this session.")
        print()
        print("No discrete-flavor scan data to summarize. Exiting early.")
        return

    print("Input recap from PHASE 36 – discrete flavor generator scan:")
    print("------------------------------------------------------------------")
    N_values = flavor_entry.get("N_values", [])
    print(f"  N_values scanned       : {N_values}")
    print("  For each N, we have:")
    print("    - min_generators: minimal number of generators needed to span")
    print("      all Toy3D charge rows in Z_N^3 (1,2, or ≥3).")
    print()

    print("Detailed results by N:")
    print("  N   min_generators   comment")
    print("  --  --------------   ------------------------------------------")

    all_ge_3 = True
    any_1 = False
    any_2 = False

    for r in results:
        N = r.get("N")
        k = r.get("min_generators")
        if k == 1:
            any_1 = True
            all_ge_3 = False
            comment = "All charges on a single cyclic orbit in Z_N^3."
        elif k == 2:
            any_2 = True
            all_ge_3 = False
            comment = "Charges lie in a 2D sublattice / subgroup (Z_N×Z_N-like)."
        else:
            comment = "Needs ≥3 independent generators (generic 3D lattice)."
        print(f"  {int(N):2d}          {k}          {comment}")

    print()
    print("=" * 80)
    print(" QUALITATIVE INTERPRETATION ")
    print("=" * 80)
    print()

    if any_1:
        print("  • There exists at least one small N for which Toy3D charges lie")
        print("    on a single cyclic orbit (min_generators = 1). That would be a")
        print("    very simple discrete flavor scenario (Z_N-like).")
    if any_2:
        print("  • There exists at least one N for which Toy3D lives in a 2D")
        print("    sublattice (min_generators = 2), suggesting a Z_N×Z_N-type")
        print("    flavor symmetry could underlie the charges.")
    if all_ge_3:
        print("  • For all N in the scanned set, we have min_generators ≥ 3.")
        print("    That is exactly what your PHASE 36 output showed:")
        print("      – For N = 2..8, there is NO 1-generator or 2-generator")
        print("        subgroup that spans all nine Toy3D charges in Z_N^3.")
        print()
        print("    Interpretation:")
        print("      → Toy3D populates a genuinely 3D charge lattice modulo small N.")
        print("      → There is no obvious tiny discrete flavor group (Z_N or")
        print("        Z_N×Z_N) that organizes the charges into a single orbit")
        print("        or 2D sublattice.")
    print()

    print("  Conceptual status:")
    print("    • This is a SHAPE statement, not a probability statement.")
    print("    • It tells us that if there is a discrete flavor symmetry behind")
    print("      Toy3D, it is unlikely to be a single small abelian factor or a")
    print("      simple Z_N×Z_N; more complicated discrete groups or embeddings")
    print("      are likely needed.")
    print("    • As such, it does NOT add bits to the global DNA+Yukawa lock")
    print("      contract (≈20–27 bits). It is purely supporting_structure_shape.")
    print()

    print("=" * 80)
    print(" ROADMAP: HOW TO USE THIS STRUCTURAL INFO ")
    print("=" * 80)
    print()
    print("  Possible next steps (conceptual):")
    print("    1) Larger-N or non-abelian scans:")
    print("       - Explore N > 8, or non-abelian groups where Toy3D charges")
    print("         arise as combinations of irreps rather than simple Z_N^3.")
    print("    2) Embeddings into product groups:")
    print("       - E.g. Z_N1 × Z_N2 × Z_N3 where the charges are more naturally")
    print("         viewed as a triple of 1D charges rather than a single 3D one.")
    print("    3) Graph / code interpretations:")
    print("       - Treat each charge vector as a node coordinate or codeword")
    print("         and look for small generating graphs / codes that reproduce")
    print("         the Toy3D pattern; then hook that to DNA if possible.")
    print()

    # -----------------------------------------------------------------
    # GEOM_EVIDENCE update (bits=0, structural only)
    # -----------------------------------------------------------------
    summary_reason = (
        "PHASE 36 shows that for N = 2..8, the Toy3D Yukawa charge rows in Z_N^3 "
        "require at least 3 independent generators (min_generators ≥ 3 for all N). "
        "This disfavors extremely simple discrete flavor symmetries (Z_N or "
        "Z_N×Z_N) as direct explanations of the Toy3D charge pattern; any "
        "discrete flavor model must use a more generic 3D lattice or more "
        "complicated group structure. This is a structural constraint, not a "
        "probabilistic anomaly, so bits = 0."
    )

    GEOM_EVIDENCE["toy3d_discrete_flavor_summary"] = {  # type: ignore[index]
        "module": "PHASE37_Toy3D_Discrete_Flavor_Evidence_and_Roadmap_v1",
        "bits": 0.0,
        "classification": "supporting_structure_shape",
        "status": "supporting_structure_shape",
        "reason": summary_reason,
        "timestamp": timestamp,
        "sha256": sha256,
        "results_source_key": flavor_key,
        "results": results,
        "description": (
            "Summary and roadmap based on PHASE 36 discrete flavor generator "
            "scan for Toy3D charges in Z_N^3, N = 2..8. Shows min_generators ≥ 3 "
            "for all small N, ruling out very simple Z_N or Z_N×Z_N flavor "
            "interpretations as direct explanations of the Toy3D charge lattice."
        ),
    }

    print("=" * 80)
    print(" GEOM_EVIDENCE UPDATE ")
    print("=" * 80)
    print()
    print("GEOM_EVIDENCE['toy3d_discrete_flavor_summary'] set with:")
    print("  classification : supporting_structure_shape")
    print("  bits           : 0.0")
    print()
    print("PHASE37_Toy3D_Discrete_Flavor_Evidence_and_Roadmap_v1 COMPLETE")
    print("=" * 80)


if __name__ == "__main__":
    run_phase37_toy3d_discrete_flavor_summary()

#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
PHASE 38 – MODULE 1: TOY3D CHARGE DISTANCE & GRAPH ANALYZER (v1)

Purpose:
  - Take the Toy3D integer-charge matrix C (9×3) and analyze it as a tiny
    integer code / lattice:
      • Pairwise L1 (Manhattan) and Hamming distances between charge rows.
      • Simple neighbor graph under small L1 threshold (e.g. L1 <= 2).
      • Connected components / degree distribution for that graph.

  - Provide a structural "code / graph lens" on the Toy3D geometry.
  - Record a GEOM_EVIDENCE entry with bits=0 (shape-only, not a lock).

Expected context:
  - This can be run standalone; if GEOM_EVIDENCE is not defined, it will
    create one.
"""

import json
import hashlib
from datetime import datetime
from collections import defaultdict

# -----------------------------------------------------------------------------
# Ensure GEOM_EVIDENCE exists
# -----------------------------------------------------------------------------
try:
    GEOM_EVIDENCE  # type: ignore[name-defined]
except NameError:  # pragma: no cover
    GEOM_EVIDENCE = {}  # type: ignore[assignment]


# -----------------------------------------------------------------------------
# Toy3D data (same as earlier phases)
# -----------------------------------------------------------------------------
TOY3D_NAMES = [
    "me_over_v",
    "mmu_over_v",
    "mtau_over_v",
    "mb_over_v",
    "mc_over_v",
    "mt_over_v",
    "md_over_v",
    "ms_over_v",
    "mu_over_v",
]

TOY3D_C = [
    [-4, -2, -1],  # me_over_v
    [-1, -2,  2],  # mmu_over_v
    [-4,  1, -4],  # mtau_over_v
    [-2,  0, -1],  # mb_over_v
    [-2, -1, -3],  # mc_over_v
    [-2,  1, -4],  # mt_over_v
    [ 0, -4,  4],  # md_over_v
    [-3,  0,  2],  # ms_over_v
    [-1, -4,  1],  # mu_over_v
]


# -----------------------------------------------------------------------------
# Helper functions
# -----------------------------------------------------------------------------
def l1_distance(a, b):
    return sum(abs(x - y) for x, y in zip(a, b))


def hamming_distance(a, b):
    return sum(1 for x, y in zip(a, b) if x != y)


def compute_pairwise_metrics(names, C):
    """
    Compute pairwise L1 and Hamming distances between all rows.
    Returns:
      - dist_table: list of dicts with (i, j, name_i, name_j, l1, hamm)
      - summary:    dict with basic stats
    """
    n = len(names)
    dist_table = []
    l1_vals = []
    ham_vals = []

    for i in range(n):
        for j in range(i + 1, n):
            vi = C[i]
            vj = C[j]
            l1 = l1_distance(vi, vj)
            h  = hamming_distance(vi, vj)
            l1_vals.append(l1)
            ham_vals.append(h)
            dist_table.append({
                "i": i,
                "j": j,
                "name_i": names[i],
                "name_j": names[j],
                "l1": l1,
                "hamming": h,
            })

    def basic_stats(values):
        if not values:
            return None
        vs = sorted(values)
        n = len(vs)
        mid = n // 2
        if n % 2 == 1:
            median = vs[mid]
        else:
            median = 0.5 * (vs[mid - 1] + vs[mid])
        return {
            "min": float(vs[0]),
            "max": float(vs[-1]),
            "median": float(median),
            "count": n,
        }

    summary = {
        "l1": basic_stats(l1_vals),
        "hamming": basic_stats(ham_vals),
    }
    return dist_table, summary


def build_neighbor_graph(names, C, l1_threshold=2):
    """
    Build an undirected graph where edges connect rows whose L1 distance
    is <= l1_threshold.
    Returns:
      - graph: dict idx -> sorted list of neighbor indices
      - degrees: dict idx -> degree
      - components: list of components (each is a list of indices)
    """
    n = len(names)
    graph = {i: set() for i in range(n)}

    # Add edges
    for i in range(n):
        for j in range(i + 1, n):
            d = l1_distance(C[i], C[j])
            if d <= l1_threshold:
                graph[i].add(j)
                graph[j].add(i)

    # Degrees
    degrees = {i: len(graph[i]) for i in range(n)}

    # Connected components
    visited = [False] * n
    components = []

    for i in range(n):
        if not visited[i]:
            stack = [i]
            comp = []
            visited[i] = True
            while stack:
                u = stack.pop()
                comp.append(u)
                for v in graph[u]:
                    if not visited[v]:
                        visited[v] = True
                        stack.append(v)
            components.append(sorted(comp))

    # Sort neighbor lists
    graph_sorted = {i: sorted(list(graph[i])) for i in range(n)}

    return graph_sorted, degrees, components


def run_phase38_toy3d_charge_distance_graph_analyzer():
    timestamp = datetime.now().isoformat()

    # Compute pairwise metrics
    dist_table, dist_summary = compute_pairwise_metrics(TOY3D_NAMES, TOY3D_C)

    # Build neighbor graph for L1 <= 2
    l1_threshold = 2
    graph, degrees, components = build_neighbor_graph(
        TOY3D_NAMES, TOY3D_C, l1_threshold=l1_threshold
    )

    # Degree histogram
    degree_hist = defaultdict(int)
    for deg in degrees.values():
        degree_hist[deg] += 1
    degree_hist = dict(sorted(degree_hist.items(), key=lambda kv: kv[0]))

    # Prepare JSON-serializable payload for hashing
    payload = {
        "module": "PHASE38_Toy3D_Charge_Distance_and_Graph_Analyzer_v1",
        "timestamp": timestamp,
        "names": TOY3D_NAMES,
        "C": TOY3D_C,
        "distance_summary": dist_summary,
        "l1_threshold": l1_threshold,
        "degrees": degrees,
        "components": components,
        "degree_hist": degree_hist,
    }
    payload_json = json.dumps(payload, sort_keys=True)
    sha256 = hashlib.sha256(payload_json.encode("utf-8")).hexdigest()

    # -------------------------------------------------------------------------
    # Printing
    # -------------------------------------------------------------------------
    print("=" * 80)
    print(" PHASE 38 – MODULE 1: TOY3D CHARGE DISTANCE & GRAPH ANALYZER (v1) ")
    print("=" * 80)
    print()
    print(f"Run timestamp (local) : {timestamp}")
    print(f"Run SHA256 payload    : {sha256}")
    print()

    # Recap charges
    print("Toy3D integer charges C (9×3) recap")
    print("-" * 80)
    for name, row in zip(TOY3D_NAMES, TOY3D_C):
        c1, c2, c3 = row
        print(f"  {name:11s} [{c1:+d} {c2:+d} {c3:+d}]")
    print()

    # Pairwise distance summary
    print("PAIRWISE DISTANCE SUMMARY (over all i<j pairs)")
    print("-" * 80)
    l1s = dist_summary["l1"]
    hs = dist_summary["hamming"]
    if l1s is not None:
        print("  L1 distances:")
        print(f"    min    : {l1s['min']:.1f}")
        print(f"    max    : {l1s['max']:.1f}")
        print(f"    median : {l1s['median']:.1f}")
        print(f"    count  : {int(l1s['count'])}")
    else:
        print("  L1 distances: <no pairs>")

    print()
    if hs is not None:
        print("  Hamming distances (# differing coordinates):")
        print(f"    min    : {hs['min']:.1f}")
        print(f"    max    : {hs['max']:.1f}")
        print(f"    median : {hs['median']:.1f}")
        print(f"    count  : {int(hs['count'])}")
    else:
        print("  Hamming distances: <no pairs>")
    print()

    # Optionally, print a few closest pairs by L1
    print("CLOSEST PAIRS BY L1 DISTANCE (up to 10 shown)")
    print("-" * 80)
    sorted_pairs = sorted(dist_table, key=lambda d: (d["l1"], d["hamming"]))
    for entry in sorted_pairs[:10]:
        print(
            f"  {entry['name_i']:11s} – {entry['name_j']:11s}  "
            f"L1 = {entry['l1']}, Hamming = {entry['hamming']}"
        )
    print()

    # Neighbor graph summary
    print(f"NEIGHBOR GRAPH (edges for L1 <= {l1_threshold})")
    print("-" * 80)
    print("  Degrees by Yukawa:")
    for i, name in enumerate(TOY3D_NAMES):
        print(f"    {name:11s}: degree = {degrees[i]}")
    print()
    print("  Degree histogram:")
    for deg, count in degree_hist.items():
        print(f"    degree {deg}: {count} node(s)")
    print()

    print("  Connected components (by index and name):")
    for idx, comp in enumerate(components):
        labels = [TOY3D_NAMES[i] for i in comp]
        print(f"    Component {idx}: indices {comp} -> {labels}")
    print()

    print("=" * 80)
    print(" QUALITATIVE INTERPRETATION (STRUCTURAL ONLY) ")
    print("=" * 80)
    print()
    print("  • Pairwise L1 and Hamming distances show how 'spread out' the")
    print("    Toy3D charges are as a tiny 3D integer code.")
    print("  • The neighbor graph (L1 <= 2) highlights which Yukawas are")
    print("    immediately adjacent in charge space and how many clusters")
    print("    (connected components) you get under this very tight notion")
    print("    of 'neighbor'.")
    print("  • This is a code / graph lens on the same Toy3D structure; it")
    print("    does NOT represent a new statistical anomaly on its own.")
    print()
    print("  Evidence-budget status:")
    print("    → classification : supporting_structure_shape")
    print("    → bits           : 0.00 (shape-only, no p-value)")
    print()

    # -------------------------------------------------------------------------
    # GEOM_EVIDENCE update
    # -------------------------------------------------------------------------
    reason = (
        "Toy3D charge-distance and neighbor-graph analysis: pairwise L1 and "
        "Hamming distances, plus an L1<=2 neighbor graph, show how the nine "
        "Yukawa charges populate a small 3D integer lattice. This is a code / "
        "graph viewpoint on the Toy3D geometry; it constrains which Yukawas "
        "are 'near' in charge space but introduces no new probabilistic "
        "anomaly. Bits = 0."
    )

    GEOM_EVIDENCE["toy3d_charge_graph_lens"] = {  # type: ignore[index]
        "module": "PHASE38_Toy3D_Charge_Distance_and_Graph_Analyzer_v1",
        "bits": 0.0,
        "classification": "supporting_structure_shape",
        "status": "supporting_structure_shape",
        "timestamp": timestamp,
        "sha256": sha256,
        "names": TOY3D_NAMES,
        "C": TOY3D_C,
        "distance_summary": dist_summary,
        "l1_threshold": l1_threshold,
        "degrees": degrees,
        "components": components,
        "degree_hist": degree_hist,
        "reason": reason,
        "description": (
            "Graph / code lens on Toy3D integer charges: pairwise distance "
            "statistics and small-radius neighbor graph in charge space. "
            "Purely structural; no additional lock bits."
        ),
    }

    print("=" * 80)
    print(" GEOM_EVIDENCE UPDATE ")
    print("=" * 80)
    print()
    print("GEOM_EVIDENCE['toy3d_charge_graph_lens'] set with:")
    print("  classification : supporting_structure_shape")
    print("  bits           : 0.0")
    print()
    print("PHASE38_Toy3D_Charge_Distance_and_Graph_Analyzer_v1 COMPLETE")
    print("=" * 80)


if __name__ == "__main__":
    run_phase38_toy3d_charge_distance_graph_analyzer()

#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
PHASE 39 – MODULE 1: Toy3D Distance vs Yukawa Mass-Difference Correlator (v1)

Goal:
  Given:
    - Toy3D integer charge matrix C (9×3),
    - Real Yukawa logs z_real = log10(y_i / v) for the same 9 fields,

  we:
    • compute all pairwise L1 and Hamming distances in charge space,
    • compute |Δz| for each pair,
    • measure how strongly charge distance correlates with Yukawa
      separation (Pearson + Spearman).

  This is a code/geometry lens:
    - It checks whether “nearby in Toy3D lattice” ≈ “similar Yukawa size”.
    - It is *structural only* and does NOT introduce new bits/locks.
"""

import json
import hashlib
from datetime import datetime
from math import sqrt

# -----------------------------------------------------------------------------
# Ensure GEOM_EVIDENCE exists
# -----------------------------------------------------------------------------
try:
    GEOM_EVIDENCE  # type: ignore[name-defined]
except NameError:  # pragma: no cover
    GEOM_EVIDENCE = {}  # type: ignore[assignment]


# -----------------------------------------------------------------------------
# Toy3D charges and Yukawa logs (same order as earlier phases)
# -----------------------------------------------------------------------------
TOY3D_NAMES = [
    "me_over_v",
    "mmu_over_v",
    "mtau_over_v",
    "mb_over_v",
    "mc_over_v",
    "mt_over_v",
    "md_over_v",
    "ms_over_v",
    "mu_over_v",
]

TOY3D_C = [
    [-4, -2, -1],  # me_over_v
    [-1, -2,  2],  # mmu_over_v
    [-4,  1, -4],  # mtau_over_v
    [-2,  0, -1],  # mb_over_v
    [-2, -1, -3],  # mc_over_v
    [-2,  1, -4],  # mt_over_v
    [ 0, -4,  4],  # md_over_v
    [-3,  0,  2],  # ms_over_v
    [-1, -4,  1],  # mu_over_v
]

# z_real = log10(y_i / v) from earlier Yukawa modules (same order as above)
TOY3D_Z_REAL = [
    -5.683401,  # me_over_v
    -3.367606,  # mmu_over_v
    -2.141781,  # mtau_over_v
    -1.770024,  # mb_over_v
    -2.287532,  # mc_over_v
    -0.154056,  # mt_over_v
    -4.722162,  # md_over_v
    -3.422873,  # ms_over_v
    -5.056852,  # mu_over_v
]


# -----------------------------------------------------------------------------
# Basic helpers
# -----------------------------------------------------------------------------
def l1_distance(a, b):
    return sum(abs(x - y) for x, y in zip(a, b))


def hamming_distance(a, b):
    return sum(1 for x, y in zip(a, b) if x != y)


def pearson_corr(x, y):
    """
    Pearson correlation between two equal-length lists.
    Returns None if variance is zero.
    """
    n = len(x)
    if n == 0 or len(y) != n:
        return None
    mx = sum(x) / n
    my = sum(y) / n
    vx = sum((xi - mx) ** 2 for xi in x)
    vy = sum((yi - my) ** 2 for yi in y)
    if vx == 0.0 or vy == 0.0:
        return None
    cov = sum((xi - mx) * (yi - my) for xi, yi in zip(x, y))
    return cov / sqrt(vx * vy)


def rank_list(values):
    """
    Return ranks (1=smallest) for a list of values.
    Ties are given the average rank.
    """
    n = len(values)
    indexed = list(enumerate(values))
    indexed.sort(key=lambda kv: kv[1])
    ranks = [0.0] * n
    i = 0
    while i < n:
        j = i + 1
        while j < n and indexed[j][1] == indexed[i][1]:
            j += 1
        # average rank from i..j-1
        avg_rank = 0.5 * (i + 1 + j)
        for k in range(i, j):
            idx = indexed[k][0]
            ranks[idx] = avg_rank
        i = j
    return ranks


def spearman_corr(x, y):
    """
    Spearman rank correlation between two equal-length lists.
    """
    if len(x) != len(y) or len(x) == 0:
        return None
    rx = rank_list(x)
    ry = rank_list(y)
    return pearson_corr(rx, ry)


def run_phase39_toy3d_distance_vs_mass_correlator():
    timestamp = datetime.now().isoformat()

    # -------------------------------------------------------------------------
    # Compute pairwise distances and |Δz|
    # -------------------------------------------------------------------------
    n = len(TOY3D_NAMES)
    l1_vals = []
    ham_vals = []
    dz_vals = []
    pairs = []  # for printing

    for i in range(n):
        for j in range(i + 1, n):
            name_i = TOY3D_NAMES[i]
            name_j = TOY3D_NAMES[j]
            ci = TOY3D_C[i]
            cj = TOY3D_C[j]
            zi = TOY3D_Z_REAL[i]
            zj = TOY3D_Z_REAL[j]

            l1 = l1_distance(ci, cj)
            h  = hamming_distance(ci, cj)
            dz = abs(zi - zj)

            l1_vals.append(l1)
            ham_vals.append(h)
            dz_vals.append(dz)
            pairs.append({
                "i": i,
                "j": j,
                "name_i": name_i,
                "name_j": name_j,
                "l1": l1,
                "hamming": h,
                "dz_abs": dz,
            })

    # Basic stats for |Δz|
    dz_sorted = sorted(dz_vals)
    m = len(dz_sorted)
    if m % 2 == 1:
        dz_median = dz_sorted[m // 2]
    else:
        dz_median = 0.5 * (dz_sorted[m // 2 - 1] + dz_sorted[m // 2])

    dz_min = dz_sorted[0]
    dz_max = dz_sorted[-1]
    dz_mean = sum(dz_sorted) / m

    # Correlations
    pearson_l1_dz = pearson_corr(l1_vals, dz_vals)
    spearman_l1_dz = spearman_corr(l1_vals, dz_vals)

    pearson_ham_dz = pearson_corr(ham_vals, dz_vals)
    spearman_ham_dz = spearman_corr(ham_vals, dz_vals)

    # Sort pairs by |Δz| to show closest masses vs their charge distance
    pairs_sorted_dz = sorted(pairs, key=lambda d: d["dz_abs"])

    # Prepare payload for hashing
    payload = {
        "module": "PHASE39_Toy3D_Distance_vs_Mass_Correlator_v1",
        "timestamp": timestamp,
        "names": TOY3D_NAMES,
        "C": TOY3D_C,
        "z_real": TOY3D_Z_REAL,
        "pearson_l1_dz": pearson_l1_dz,
        "spearman_l1_dz": spearman_l1_dz,
        "pearson_ham_dz": pearson_ham_dz,
        "spearman_ham_dz": spearman_ham_dz,
        "dz_stats": {
            "min": dz_min,
            "max": dz_max,
            "median": dz_median,
            "mean": dz_mean,
            "count": m,
        },
    }
    payload_json = json.dumps(payload, sort_keys=True)
    sha256 = hashlib.sha256(payload_json.encode("utf-8")).hexdigest()

    # -------------------------------------------------------------------------
    # Printing
    # -------------------------------------------------------------------------
    print("=" * 80)
    print(" PHASE 39 – MODULE 1: TOY3D DISTANCE vs YUKAWA MASS-DIFF CORRELATOR (v1) ")
    print("=" * 80)
    print()
    print(f"Run timestamp (local) : {timestamp}")
    print(f"Run SHA256 payload    : {sha256}")
    print()

    print("Toy3D Yukawa logs z_real (log10 y/v) recap")
    print("-" * 80)
    for name, z in zip(TOY3D_NAMES, TOY3D_Z_REAL):
        print(f"  {name:11s}  z_real = {z: .6f}")
    print()

    print("PAIRWISE |Δz| STATISTICS (over all i<j pairs)")
    print("-" * 80)
    print(f"  |Δz| min      : {dz_min: .6f}")
    print(f"  |Δz| max      : {dz_max: .6f}")
    print(f"  |Δz| median   : {dz_median: .6f}")
    print(f"  |Δz| mean     : {dz_mean: .6f}")
    print(f"  number pairs  : {m}")
    print()

    print("CORRELATIONS: charge distance vs |Δz|")
    print("-" * 80)
    print("  Pearson(l1, |Δz|)   :", "None" if pearson_l1_dz is None else f"{pearson_l1_dz: .4f}")
    print("  Spearman(l1, |Δz|)  :", "None" if spearman_l1_dz is None else f"{spearman_l1_dz: .4f}")
    print()
    print("  Pearson(Hamming, |Δz|)  :", "None" if pearson_ham_dz is None else f"{pearson_ham_dz: .4f}")
    print("  Spearman(Hamming, |Δz|) :", "None" if spearman_ham_dz is None else f"{spearman_ham_dz: .4f}")
    print()

    print("CLOSEST PAIRS BY |Δz| (up to 10 shown)")
    print("-" * 80)
    for d in pairs_sorted_dz[:10]:
        print(
            f"  {d['name_i']:11s} – {d['name_j']:11s}  "
            f"|Δz| = {d['dz_abs']:.6f}, L1 = {d['l1']}, Hamming = {d['hamming']}"
        )
    print()

    print("=" * 80)
    print(" QUALITATIVE INTERPRETATION (STRUCTURAL ONLY) ")
    print("=" * 80)
    print()
    print("  • This module checks whether 'nearby in Toy3D charge space'")
    print("    tends to coincide with 'similar Yukawa magnitude'.")
    print("  • Pearson and Spearman correlations quantify how strongly")
    print("    L1 / Hamming distances track |Δz|.")
    print("  • Whatever the sign/magnitude, this is derivative of the")
    print("    same Toy3D geometry and Yukawa data, so it is treated as")
    print("    supporting_structure_shape only (bits = 0).")
    print()

    # -------------------------------------------------------------------------
    # GEOM_EVIDENCE update
    # -------------------------------------------------------------------------
    reason = (
        "Correlation check between Toy3D charge-space distances (L1, Hamming) "
        "and Yukawa |Δz| differences: measures how geometrically organized "
        "the Yukawa hierarchy is within the Toy3D lattice. Structural-only "
        "diagnostic; no new probabilistic anomaly, bits = 0."
    )

    GEOM_EVIDENCE["toy3d_distance_vs_mass_correlator"] = {  # type: ignore[index]
        "module": "PHASE39_Toy3D_Distance_vs_Mass_Correlator_v1",
        "bits": 0.0,
        "classification": "supporting_structure_shape",
        "status": "supporting_structure_shape",
        "timestamp": timestamp,
        "sha256": sha256,
        "pearson_l1_dz": pearson_l1_dz,
        "spearman_l1_dz": spearman_l1_dz,
        "pearson_ham_dz": pearson_ham_dz,
        "spearman_ham_dz": spearman_ham_dz,
        "dz_stats": {
            "min": dz_min,
            "max": dz_max,
            "median": dz_median,
            "mean": dz_mean,
            "count": m,
        },
        "reason": reason,
        "description": (
            "Toy3D distance vs Yukawa mass-difference correlator: pairwise L1 "
            "and Hamming distances versus |Δz| for all Yukawa pairs. Structural "
            "code/geometry lens; no additional lock bits."
        ),
    }

    print("=" * 80)
    print(" GEOM_EVIDENCE UPDATE ")
    print("=" * 80)
    print()
    print("GEOM_EVIDENCE['toy3d_distance_vs_mass_correlator'] set with:")
    print("  classification : supporting_structure_shape")
    print("  bits           : 0.0")
    print()
    print("PHASE39_Toy3D_Distance_vs_Mass_Correlator_v1 COMPLETE")
    print("=" * 80)


if __name__ == "__main__":
    run_phase39_toy3d_distance_vs_mass_correlator()

import numpy as np
import json
import hashlib
from datetime import datetime

# ================================================================
#  PHASE 40 – MODULE 1 (v2): TOY3D DISTANCE vs MASS NULLSCAN
# ================================================================

def _current_timestamp_iso():
    return datetime.now().isoformat()

def _sha256_of_payload(payload_dict) -> str:
    """
    Compute SHA256 of a JSON-serializable dict.
    Ensures all numpy types are converted to plain Python types.
    """
    def to_python(obj):
        if isinstance(obj, np.generic):
            return obj.item()
        if isinstance(obj, np.ndarray):
            return obj.tolist()
        if isinstance(obj, dict):
            return {k: to_python(v) for k, v in obj.items()}
        if isinstance(obj, (list, tuple)):
            return [to_python(v) for v in obj]
        return obj

    cleaned = to_python(payload_dict)
    payload_json = json.dumps(cleaned, sort_keys=True).encode("utf-8")
    return hashlib.sha256(payload_json).hexdigest()

def _pearsonr_np(x, y):
    """Simple Pearson correlation (no SciPy), returns float."""
    x = np.asarray(x, dtype=float)
    y = np.asarray(y, dtype=float)
    if x.size != y.size or x.size == 0:
        return np.nan
    x_mean = x.mean()
    y_mean = y.mean()
    dx = x - x_mean
    dy = y - y_mean
    num = np.sum(dx * dy)
    den = np.sqrt(np.sum(dx * dx) * np.sum(dy * dy))
    if den == 0.0:
        return np.nan
    return float(num / den)

def _pairwise_l1_hamming(C):
    """
    Compute pairwise L1 and Hamming distances for an (n,3) charge matrix C.
    Returns:
      l1_dists: shape (n_pairs,)
      hamming_dists: shape (n_pairs,)
    """
    C = np.asarray(C, dtype=int)
    n = C.shape[0]
    l1_list = []
    ham_list = []
    for i in range(n):
        for j in range(i + 1, n):
            diff = C[i] - C[j]
            l1_list.append(np.sum(np.abs(diff)))
            ham_list.append(np.count_nonzero(diff))
    return np.array(l1_list, dtype=float), np.array(ham_list, dtype=float)

def _pairwise_abs_dz(z):
    """
    Compute pairwise |Δz| for an array z of length n.
    Returns:
      abs_dz: shape (n_pairs,)
    """
    z = np.asarray(z, dtype=float)
    n = z.shape[0]
    vals = []
    for i in range(n):
        for j in range(i + 1, n):
            vals.append(abs(z[i] - z[j]))
    return np.array(vals, dtype=float)

def run_phase40_toy3d_distance_mass_nullscan(
    num_null: int = 2000,
    C_max: int = 4,
    use_rms_filter: bool = False,   # <<< turned OFF by default
    rms_max: float = 0.50,          # only used if use_rms_filter=True
    seed: int = 20251127,
):
    """
    PHASE 40 – MODULE 1 (v2):
      Nullscan for correlation between Toy3D charge L1 distance and |Δz|
      against random small-integer 3D geometries with the (-4,4,3) triple
      basis rows fixed (me, mtau, md).

    If use_rms_filter is False (default), all random geometries are accepted
    and we just record their RMS distribution for diagnostics.
    """

    # ------------------------------------------------------------
    #  Toy3D inputs hard-coded (as in earlier phases)
    # ------------------------------------------------------------
    names = [
        "me_over_v",
        "mmu_over_v",
        "mtau_over_v",
        "mb_over_v",
        "mc_over_v",
        "mt_over_v",
        "md_over_v",
        "ms_over_v",
        "mu_over_v",
    ]

    C_real = np.array(
        [
            [-4, -2, -1],  # me
            [-1, -2,  2],  # mmu
            [-4,  1, -4],  # mtau
            [-2,  0, -1],  # mb
            [-2, -1, -3],  # mc
            [-2,  1, -4],  # mt
            [ 0, -4,  4],  # md
            [-3,  0,  2],  # ms
            [-1, -4,  1],  # mu
        ],
        dtype=int,
    )

    z_real = np.array(
        [
            -5.683401,  # me
            -3.367606,  # mmu
            -2.141781,  # mtau
            -1.770024,  # mb
            -2.287532,  # mc
            -0.154056,  # mt
            -4.722162,  # md
            -3.422873,  # ms
            -5.056852,  # mu
        ],
        dtype=float,
    )

    # ------------------------------------------------------------
    #  Compute Toy3D correlations (L1/Hamming vs |Δz|)
    # ------------------------------------------------------------
    l1_real, hamming_real = _pairwise_l1_hamming(C_real)
    abs_dz = _pairwise_abs_dz(z_real)

    pearson_l1_real = _pearsonr_np(l1_real, abs_dz)
    pearson_ham_real = _pearsonr_np(hamming_real, abs_dz)

    # Compute Toy3D RMS with least-squares q fit (to mirror nulls)
    q_real_fit, *_ = np.linalg.lstsq(C_real.astype(float), z_real, rcond=None)
    resid_real = C_real @ q_real_fit - z_real
    RMS_real = float(np.sqrt(np.mean(resid_real ** 2)))
    max_resid_real = float(np.max(np.abs(resid_real)))

    # ------------------------------------------------------------
    #  Null ensemble: random integer geometries with basis rows fixed
    # ------------------------------------------------------------
    rng = np.random.default_rng(seed)

    basis_indices = [0, 2, 6]  # me, mtau, md fixed to preserve (-4,4,3) triple
    perturbable_indices = [i for i in range(9) if i not in basis_indices]

    null_corrs_l1 = []
    null_rms = []

    attempts = 0
    max_attempts = num_null * 50  # safety cap

    print(
        "================================================================================"
    )
    print(
        " PHASE 40 – MODULE 1 (v2): TOY3D DISTANCE vs MASS NULLSCAN "
    )
    print(
        "================================================================================\n"
    )

    timestamp = _current_timestamp_iso()
    print(f"Run timestamp (local) : {timestamp}")
    print(f"C_max                  : {C_max}")
    print(f"num_null target        : {num_null}")
    print(f"use_rms_filter         : {use_rms_filter}")
    print(f"RMS_max (filter)       : {rms_max:.3f}\n")

    print("Toy3D recap:")
    print("  Toy3D least-squares q_fit (log10 λ):")
    for i, qval in enumerate(q_real_fit, start=1):
        print(f"    q{i} = {qval:+.6f}")
    print(f"  Toy3D RMS_all (dex)        :  {RMS_real: .6f}")
    print(f"  Toy3D max |resid| (dex)    :  {max_resid_real: .6f}\n")

    print("Toy3D correlations (charge distance vs |Δz|):")
    print(f"  Pearson(L1, |Δz|)          :  {pearson_l1_real: .4f}")
    print(f"  Pearson(Hamming, |Δz|)     :  {pearson_ham_real: .4f}\n")

    print("Generating null ensemble of random integer geometries...")
    print(f"  basis rows fixed at indices: {basis_indices}")
    print(f"  perturbable rows indices   : {perturbable_indices}\n")

    while len(null_corrs_l1) < num_null and attempts < max_attempts:
        attempts += 1

        C_candidate = C_real.copy()

        # Randomize perturbable rows within [-C_max, C_max]^3 \ {(0,0,0)}
        for idx in perturbable_indices:
            while True:
                row = rng.integers(-C_max, C_max + 1, size=3)
                if not np.all(row == 0):
                    C_candidate[idx] = row
                    break

        # Fit q and compute RMS
        q_fit, *_ = np.linalg.lstsq(
            C_candidate.astype(float), z_real, rcond=None
        )
        resid = C_candidate @ q_fit - z_real
        rms = float(np.sqrt(np.mean(resid ** 2)))

        # Optional fit-quality filter
        if use_rms_filter and rms > rms_max:
            # Reject geometry as too poor a fit
            continue

        # Compute correlation for this candidate
        l1_null, _ = _pairwise_l1_hamming(C_candidate)
        corr_l1 = _pearsonr_np(l1_null, abs_dz)

        if np.isnan(corr_l1):
            continue

        null_corrs_l1.append(corr_l1)
        null_rms.append(rms)

        if len(null_corrs_l1) % 200 == 0:
            print(f"  ... {len(null_corrs_l1)}/{num_null} null geometries accepted")

    print()
    if len(null_corrs_l1) < num_null:
        print(
            f"WARNING: Only {len(null_corrs_l1)} valid null geometries accepted "
            f"after {attempts} attempts (target was {num_null})."
        )
        actual_num_null = len(null_corrs_l1)
    else:
        actual_num_null = num_null

    if actual_num_null == 0:
        print(
            "================================================================================"
        )
        print(" NULL STATISTICS – Pearson(L1, |Δz|) UNDER RANDOM GEOMETRIES ")
        print(
            "================================================================================\n"
        )
        print("No valid null geometries were generated; cannot compute statistics.")
        return

    null_corrs_l1 = np.array(null_corrs_l1, dtype=float)
    null_rms = np.array(null_rms, dtype=float)

    print(
        "================================================================================"
    )
    print(" NULL STATISTICS – Pearson(L1, |Δz|) UNDER RANDOM GEOMETRIES ")
    print(
        "================================================================================\n"
    )

    corr_min = float(np.min(null_corrs_l1))
    corr_max = float(np.max(null_corrs_l1))
    corr_q25 = float(np.quantile(null_corrs_l1, 0.25))
    corr_q50 = float(np.quantile(null_corrs_l1, 0.50))
    corr_q75 = float(np.quantile(null_corrs_l1, 0.75))
    corr_mean = float(np.mean(null_corrs_l1))
    corr_std = float(np.std(null_corrs_l1))

    rms_min = float(np.min(null_rms))
    rms_max_obs = float(np.max(null_rms))
    rms_q25 = float(np.quantile(null_rms, 0.25))
    rms_q50 = float(np.quantile(null_rms, 0.50))
    rms_q75 = float(np.quantile(null_rms, 0.75))
    rms_mean = float(np.mean(null_rms))
    rms_std = float(np.std(null_rms))

    print("Null distribution of Pearson(L1, |Δz|):")
    print(f"  min / max              : {corr_min: .4f} / {corr_max: .4f}")
    print(
        f"  25% / 50% / 75%        : {corr_q25: .4f} / {corr_q50: .4f} / {corr_q75: .4f}"
    )
    print(f"  mean / std             : {corr_mean: .4f} / {corr_std: .4f}\n")

    print("RMS_all distribution for null geometries:")
    print(f"  min / max              : {rms_min: .4f} / {rms_max_obs: .4f}")
    print(
        f"  25% / 50% / 75%        : {rms_q25: .4f} / {rms_q50: .4f} / {rms_q75: .4f}"
    )
    print(f"  mean / std             : {rms_mean: .4f} / {rms_std: .4f}\n")

    # ------------------------------------------------------------
    #  Significance: is Toy3D's correlation unusually large?
    #  One-sided test: P_null(corr >= corr_real)
    # ------------------------------------------------------------
    count_ge = int(np.sum(null_corrs_l1 >= pearson_l1_real))
    p_emp = count_ge / float(actual_num_null)
    # Avoid p=0
    if p_emp == 0.0:
        p_emp = 1.0 / (actual_num_null * 2.0)

    bits = float(-np.log2(p_emp))
    if corr_std > 0.0:
        z_score = float((pearson_l1_real - corr_mean) / corr_std)
    else:
        z_score = float("nan")

    print(
        "================================================================================"
    )
    print(" SIGNIFICANCE OF DISTANCE–MASS CORRELATION ")
    print(
        "================================================================================\n"
    )

    print(f"  Toy3D Pearson(L1, |Δz|)      : {pearson_l1_real: .4f}")
    print(f"  Null mean ± std              : {corr_mean: .4f} ± {corr_std: .4f}")
    print(f"  z(real vs null mean)         : {z_score: .2f} σ")
    print(
        f"  count_null(corr >= real)     : {count_ge} / {actual_num_null}"
    )
    print(f"  P_null(corr >= real)         : {p_emp: .6f}")
    print(f"  bits ≈ -log2(p_null)         : {bits: .2f} bits\n")

    print("Interpretation guide:")
    print("  • If bits ≲ 3   : correlation strength is ordinary.")
    print("  • If bits ~3–7  : mildly interesting.")
    print("  • If bits ≳ 10  : strong anomaly (would be a big deal).")
    print("  • Regardless, this is derivative of the same Toy3D lock;\n"
          "    it will be recorded as supporting_structure_shape, not\n"
          "    a new primary lock on top of DNA + (-4,4,3).\n")

    # ------------------------------------------------------------
    #  SHA256 payload & bookkeeping
    # ------------------------------------------------------------
    payload = {
        "module": "PHASE40_Toy3D_Distance_vs_Mass_Nullscan_v2",
        "timestamp": timestamp,
        "seed": seed,
        "C_max": C_max,
        "use_rms_filter": use_rms_filter,
        "rms_filter_max": rms_max,
        "num_null_target": num_null,
        "num_null_accepted": actual_num_null,
        "C_real": C_real,
        "z_real": z_real,
        "toy3d": {
            "pearson_l1_absdz": pearson_l1_real,
            "pearson_hamming_absdz": pearson_ham_real,
            "RMS_all": RMS_real,
            "max_abs_resid": max_resid_real,
            "q_fit": q_real_fit,
        },
        "null_stats": {
            "pearson_l1_absdz": {
                "min": corr_min,
                "max": corr_max,
                "q25": corr_q25,
                "q50": corr_q50,
                "q75": corr_q75,
                "mean": corr_mean,
                "std": corr_std,
            },
            "RMS_all": {
                "min": rms_min,
                "max": rms_max_obs,
                "q25": rms_q25,
                "q50": rms_q50,
                "q75": rms_q75,
                "mean": rms_mean,
                "std": rms_std,
            },
        },
        "significance": {
            "p_emp": p_emp,
            "bits": bits,
            "z_score": z_score,
        },
    }

    sha256 = _sha256_of_payload(payload)
    print(
        "================================================================================"
    )
    print(" HASH & BOOKKEEPING ")
    print(
        "================================================================================\n"
    )
    print(f"Run SHA256 payload    : {sha256}\n")
    print(
        "GEOM_EVIDENCE['toy3d_distance_vs_mass_nullscan'] "
        "would be updated with this payload (supporting_structure_shape, bits as above)."
    )
    print(
        "\nPHASE40_Toy3D_Distance_vs_Mass_Nullscan_v2 COMPLETE"
    )
    print(
        "================================================================================"
    )


if __name__ == "__main__":
    run_phase40_toy3d_distance_mass_nullscan()

import json
import hashlib
from datetime import datetime

# ================================================================
#  PHASE 40 – MODULE 2: TOY3D DISTANCE–MASS EVIDENCE (v1)
# ================================================================

def _phase40_timestamp_iso():
    return datetime.now().isoformat()

def _phase40_sha256_of_payload(payload_dict) -> str:
    """Compute SHA256 of a JSON-serializable dict (no numpy here)."""
    payload_json = json.dumps(payload_dict, sort_keys=True).encode("utf-8")
    return hashlib.sha256(payload_json).hexdigest()

def run_phase40_toy3d_distance_mass_evidence_v1():
    """
    Evidence / bookkeeping wrapper for PHASE 40 – MODULE 1 (v2).

    It takes the summary numbers from the nullscan you just ran and:
      - prints an interpretation,
      - writes an entry into GEOM_EVIDENCE['toy3d_distance_vs_mass_nullscan'].
    """

    # ------------------------------------------------------------------
    # Hard-coded recap from PHASE40_Toy3D_Distance_vs_Mass_Nullscan_v2
    # (your latest run).
    # ------------------------------------------------------------------
    module_nullscan = "PHASE40_Toy3D_Distance_vs_Mass_Nullscan_v2"
    timestamp = _phase40_timestamp_iso()

    pearson_l1_real = 0.3712
    pearson_ham_real = 0.1482

    null_mean = -0.0510
    null_std = 0.1627
    corr_min = -0.4323
    corr_max = 0.5433
    corr_q25 = -0.1754
    corr_q50 = -0.0699
    corr_q75 = 0.0539

    # One-sided p-value and bits from your run
    p_emp = 0.009000
    bits = 6.80
    z_score = 2.60
    num_null = 2000
    count_ge = 18

    # RMS stats for null geometries (diagnostic: they are very bad fits)
    rms_min = 0.5005
    rms_max_obs = 3.5900
    rms_q25 = 2.2873
    rms_q50 = 2.7869
    rms_q75 = 3.1353
    rms_mean = 2.6706
    rms_std = 0.5985

    # ------------------------------------------------------------------
    # Print recap
    # ------------------------------------------------------------------
    print("=" * 80)
    print(" PHASE 40 – MODULE 2: TOY3D DISTANCE–MASS EVIDENCE (v1) ")
    print("=" * 80)
    print()
    print(f"Run timestamp (local) : {timestamp}")
    print(f"Based on nullscan     : {module_nullscan}")
    print()

    print("Input recap (from PHASE 40 – MODULE 1 v2)")
    print("-" * 80)
    print(f"  Toy3D Pearson(L1, |Δz|)       : {pearson_l1_real: .4f}")
    print(f"  Toy3D Pearson(Hamming, |Δz|)  : {pearson_ham_real: .4f}")
    print()
    print("  Null distribution of Pearson(L1, |Δz|):")
    print(f"    min / max                    : {corr_min: .4f} / {corr_max: .4f}")
    print(
        f"    25% / 50% / 75%              : "
        f"{corr_q25: .4f} / {corr_q50: .4f} / {corr_q75: .4f}"
    )
    print(f"    mean / std                   : {null_mean: .4f} / {null_std: .4f}")
    print()
    print("  RMS_all distribution for null geometries:")
    print(f"    min / max                    : {rms_min: .4f} / {rms_max_obs: .4f}")
    print(
        f"    25% / 50% / 75%              : "
        f"{rms_q25: .4f} / {rms_q50: .4f} / {rms_q75: .4f}"
    )
    print(f"    mean / std                   : {rms_mean: .4f} / {rms_std: .4f}")
    print()

    print("=" * 80)
    print(" SIGNIFICANCE OF DISTANCE–MASS CORRELATION (SUMMARY) ")
    print("=" * 80)
    print()
    print(f"  Toy3D Pearson(L1, |Δz|)       : {pearson_l1_real: .4f}")
    print(f"  Null mean ± std               : {null_mean: .4f} ± {null_std: .4f}")
    print(f"  z(real vs null mean)          : {z_score: .2f} σ")
    print(f"  count_null(corr >= real)      : {count_ge} / {num_null}")
    print(f"  P_null(corr >= real)          : {p_emp: .6f}")
    print(f"  bits ≈ -log2(p_null)          : {bits: .2f} bits")
    print()
    print("Interpretation:")
    print("  • Under random small-integer 3D geometries (basis fixed to the")
    print("    (-4,4,3) triple), Toy3D has an unusually strong correlation")
    print("    between charge L1 distance and Yukawa mass difference.")
    print("  • However, the null geometries are VERY poor fits (RMS ~ 2.7 dex),")
    print("    while Toy3D has RMS ~ 0.004 dex. So this is a structural contrast")
    print("    in the same sector, not an independent new data source.")
    print("  • We therefore classify this as supporting_structure_shape and do")
    print("    NOT add these ~6.8 bits to the global DNA + Yukawa triple budget.")
    print()

    # ------------------------------------------------------------------
    # Build GEOM_EVIDENCE entry
    # ------------------------------------------------------------------
    evidence_entry = {
        "module": "PHASE40_Toy3D_Distance_vs_Mass_Evidence_v1",
        "based_on": module_nullscan,
        "timestamp": timestamp,
        "nullscan": {
            "num_null": num_null,
            "pearson_l1_null_stats": {
                "min": corr_min,
                "max": corr_max,
                "q25": corr_q25,
                "q50": corr_q50,
                "q75": corr_q75,
                "mean": null_mean,
                "std": null_std,
            },
            "rms_null_stats": {
                "min": rms_min,
                "max": rms_max_obs,
                "q25": rms_q25,
                "q50": rms_q50,
                "q75": rms_q75,
                "mean": rms_mean,
                "std": rms_std,
            },
        },
        "toy3d_correlations": {
            "pearson_l1_absdz": pearson_l1_real,
            "pearson_hamming_absdz": pearson_ham_real,
        },
        "significance": {
            "p_emp": p_emp,
            "bits": bits,
            "z_score": z_score,
            "count_null_ge": count_ge,
        },
        "classification": "supporting_structure_shape",
        "status": "supporting_structure_shape",
        "note": (
            "Toy3D charge L1 distance moderately tracks Yukawa mass differences "
            "(Pearson ≈ 0.37), giving ~6.8 bits against a random small-integer "
            "geometry null with basis fixed to the (-4,4,3) triple. However, "
            "null geometries are very poor RMS fits, and this effect is "
            "derivative of the same Yukawa sector; we do not treat it as "
            "an independent primary lock beyond DNA + the (-4,4,3) triple."
        ),
    }

    sha256 = _phase40_sha256_of_payload(evidence_entry)

    print("=" * 80)
    print(" GEOM_EVIDENCE UPDATE ")
    print("=" * 80)
    print()
    print(f"Run SHA256 payload    : {sha256}")
    print()

    # Create or update GEOM_EVIDENCE
    try:
        GEOM_EVIDENCE  # type: ignore[name-defined]
    except NameError:
        globals()["GEOM_EVIDENCE"] = {}

    GEOM_EVIDENCE = globals()["GEOM_EVIDENCE"]  # type: ignore[assignment]
    GEOM_EVIDENCE["toy3d_distance_vs_mass_nullscan"] = evidence_entry
    GEOM_EVIDENCE["toy3d_distance_vs_mass_nullscan"]["sha256"] = sha256

    print("GEOM_EVIDENCE['toy3d_distance_vs_mass_nullscan'] has been set with:")
    print(f"  classification : {evidence_entry['classification']}")
    print(f"  bits           : {evidence_entry['significance']['bits']:.2f}")
    print()
    print("Global lock contract reminder (conceptual):")
    print("  • PRIMARY LOCKS remain:")
    print("       1) DNA backbone / locks (~12.29 bits).")
    print("       2) me–mtau–md (-4,4,3) triple (7–14 bits).")
    print("  • This distance–mass structure is extra shape information")
    print("    about the Toy3D geometry, not an additional lock.")
    print()
    print("PHASE40_Toy3D_Distance_vs_Mass_Evidence_v1 COMPLETE")
    print("=" * 80)


if __name__ == "__main__":
    run_phase40_toy3d_distance_mass_evidence_v1()

import json
import hashlib
from datetime import datetime
from collections import Counter

# ================================================================
#  PHASE 41 – MODULE 1: TOY3D SHAPE PROFILE (v1)
# ================================================================

def _p41_timestamp_iso():
    return datetime.now().isoformat()

def _p41_sha256(payload_dict) -> str:
    """Compute SHA256 of a JSON-serializable dict (avoid numpy types)."""
    payload_json = json.dumps(payload_dict, sort_keys=True).encode("utf-8")
    return hashlib.sha256(payload_json).hexdigest()

def _p41_safe_float(x):
    """Convert to plain Python float if possible, else None."""
    if x is None:
        return None
    try:
        return float(x)
    except Exception:
        return None

def run_phase41_toy3d_shape_profile_v1():
    """
    Build a consolidated 'shape profile' for Toy3D & related Yukawa geometry
    structure, based on whatever is currently present in GEOM_EVIDENCE.

    This is *purely structural*:
      - No new nullscans, no extra bits in the global lock contract.
      - It aggregates supporting_structure, supporting_structure_shape, etc.
      - Result is stored in TOY3D_SHAPE_PROFILE_V1 and printed.
    """

    timestamp = _p41_timestamp_iso()

    print("=" * 80)
    print(" PHASE 41 – MODULE 1: TOY3D SHAPE PROFILE (v1) ")
    print("=" * 80)
    print()
    print(f"Run timestamp (local) : {timestamp}")
    print()

    # --------------------------------------------------------------
    # 1. Check for GEOM_EVIDENCE
    # --------------------------------------------------------------
    try:
        GEOM_EVIDENCE  # type: ignore[name-defined]
    except NameError:
        print("GEOM_EVIDENCE not found in this session.")
        print("→ Nothing to profile. You may want to reload a snapshot (PHASE 29).")
        print()
        print("PHASE41_Toy3D_Shape_Profile_v1 COMPLETE (no data).")
        print("=" * 80)
        return

    geom_evidence = GEOM_EVIDENCE  # type: ignore[assignment]

    # --------------------------------------------------------------
    # 2. Pick out 'interesting' entries (Toy3D / Yukawa geometry / FN)
    # --------------------------------------------------------------
    interesting_substrings = [
        "toy3d",
        "yukawa_3d",
        "3spurion_fn",
        "4spurion_fn",
        "yukawa_q_intrel",
        "post_fn_geometry_roadmap",
        "charge_lattice",
        "discrete_flavor",
        "distance_vs_mass",
        "yukawa_secondary_triple",
        "integer_3d_geometry",
        "integer_3d_stability_fixed_q",
    ]

    def _is_interesting_key(key: str) -> bool:
        k_lower = key.lower()
        return any(s in k_lower for s in interesting_substrings)

    shape_entries = []

    for key, val in geom_evidence.items():
        if not isinstance(key, str):
            continue
        if not _is_interesting_key(key):
            continue

        # Extract classification / status / bits / a short label if present
        classification = val.get("classification") or val.get("status") or "unknown"
        bits = None

        # Several modules tuck bits inside different fields; try a few.
        if "bits" in val and isinstance(val.get("bits"), (int, float)):
            bits = _p41_safe_float(val.get("bits"))
        elif "bits_exact_lower" in val:
            bits = _p41_safe_float(val.get("bits_exact_lower"))
        elif "significance" in val and isinstance(val.get("significance"), dict):
            bits = _p41_safe_float(val["significance"].get("bits"))

        desc = (
            val.get("description")
            or val.get("note")
            or val.get("reason")
            or ""
        )

        shape_entries.append(
            {
                "key": key,
                "classification": str(classification),
                "bits": bits,
                "has_bits": bits is not None,
                "description": str(desc),
            }
        )

    # --------------------------------------------------------------
    # 3. Build summary stats over these shape entries
    # --------------------------------------------------------------
    n_entries = len(shape_entries)
    class_counts = Counter(e["classification"] for e in shape_entries)
    bits_list = [e["bits"] for e in shape_entries if e["bits"] is not None]
    bits_list_nonzero = [b for b in bits_list if abs(b) > 1e-9]

    max_bits = max(bits_list_nonzero) if bits_list_nonzero else 0.0
    total_bits_shape = sum(bits_list_nonzero) if bits_list_nonzero else 0.0

    # NOTE: total_bits_shape is *not* a contract; just a magnitude of structure
    # hidden in supporting entries, all derivative of the main locks.

    summary = {
        "num_shape_entries": n_entries,
        "class_counts": dict(class_counts),
        "max_bits_single_entry": _p41_safe_float(max_bits),
        "sum_bits_all_entries": _p41_safe_float(total_bits_shape),
    }

    # For convenience, also explicitly include the distance–mass nullscan bits
    dm_entry = next(
        (e for e in shape_entries if "distance_vs_mass_nullscan" in e["key"]),
        None,
    )
    if dm_entry is not None:
        summary["distance_mass_bits"] = _p41_safe_float(dm_entry["bits"])
    else:
        summary["distance_mass_bits"] = None

    # --------------------------------------------------------------
    # 4. Construct a compact profile object (JSON-safe)
    # --------------------------------------------------------------
    profile = {
        "module": "PHASE41_Toy3D_Shape_Profile_v1",
        "timestamp": timestamp,
        "summary": summary,
        "shape_entries": shape_entries,
        "note": (
            "Toy3D shape profile: consolidated view of supporting geometric "
            "structure (3D integer geometry, q-relations, FN constraints, "
            "lattice/discrete flavor patterns, and distance–mass correlation). "
            "All entries here are supporting_structure / supporting_structure_shape "
            "and DO NOT add bits to the global DNA + Yukawa triple contract."
        ),
    }

    sha256 = _p41_sha256(profile)
    profile["sha256"] = sha256

    # --------------------------------------------------------------
    # 5. Store as TOY3D_SHAPE_PROFILE_V1 and print report
    # --------------------------------------------------------------
    globals()["TOY3D_SHAPE_PROFILE_V1"] = profile

    print("Shape entries found in GEOM_EVIDENCE:")
    print("--------------------------------------------------------------------------------")
    print(f"  Total shape entries       : {n_entries}")
    for cls, count in class_counts.items():
        print(f"  classification '{cls:>24}': {count:3d}")
    print()
    print("Bit-scale (shape-only, NOT added to DNA+Yukawa contract):")
    print("--------------------------------------------------------------------------------")
    print(f"  max bits in a single entry: {summary['max_bits_single_entry']:.4g}" if n_entries else "  (no entries)")
    print(f"  sum of bits over entries  : {summary['sum_bits_all_entries']:.4g}")
    if summary["distance_mass_bits"] is not None:
        print(
            f"  distance–mass nullscan    : "
            f"{summary['distance_mass_bits']:.4g} bits (supporting_structure_shape)"
        )
    print()
    print("Detailed shape entries (key, classification, bits):")
    print("--------------------------------------------------------------------------------")
    if not shape_entries:
        print("  (none)")
    else:
        for e in sorted(shape_entries, key=lambda x: (-(x["bits"] or 0.0), x["key"])):
            bits_str = "None" if e["bits"] is None else f"{e['bits']:.4g}"
            print(f"  {e['key']:40s}  {e['classification']:26s}  bits = {bits_str}")
    print()
    print("Conceptual interpretation:")
    print("  • TOY3D_SHAPE_PROFILE_V1 aggregates all *supporting* geometric structure")
    print("    we have mapped so far: integer 3D geometry, q-relations, FN constraints,")
    print("    charge lattices, discrete flavor scans, graph/distance lenses, and the")
    print("    distance–mass correlation.")
    print("  • None of these are independent primary locks; they are ways the SAME")
    print("    Yukawa sector (anchored on the (-4,4,3) triple) organizes itself.")
    print("  • The global evidence contract remains:")
    print("       – DNA backbone / locks (~12.29 bits).")
    print("       – me–mtau–md (-4,4,3) triple (7–14 bits).")
    print("  • TOY3D_SHAPE_PROFILE_V1 is a fingerprint any future candidate geometry")
    print("    should ideally match or explain, on top of hitting the primary locks.")
    print()
    print("Stored profile object:")
    print(f"  TOY3D_SHAPE_PROFILE_V1['sha256'] = {sha256}")
    print()
    print("PHASE41_Toy3D_Shape_Profile_v1 COMPLETE")
    print("=" * 80)


if __name__ == "__main__":
    run_phase41_toy3d_shape_profile_v1()

import json
import hashlib
from datetime import datetime

import numpy as np

# ================================================================
#  PHASE 42 – MODULE 1: TOY3D SHAPE VECTOR (v1)
# ================================================================

def _p42_timestamp_iso():
    return datetime.now().isoformat()

def _p42_sha256(payload_dict) -> str:
    """Compute SHA256 of a JSON-serializable dict."""
    payload_json = json.dumps(payload_dict, sort_keys=True).encode("utf-8")
    return hashlib.sha256(payload_json).hexdigest()

def _p42_rankdata(a: np.ndarray) -> np.ndarray:
    """
    Simple rankdata (1..n) ignoring ties (fine for generic floats).
    """
    order = np.argsort(a)
    ranks = np.empty_like(order, dtype=float)
    ranks[order] = np.arange(1, len(a) + 1, dtype=float)
    return ranks

def _p42_pearson(x: np.ndarray, y: np.ndarray) -> float:
    if x.size < 2 or y.size < 2:
        return float("nan")
    c = np.corrcoef(x, y)
    return float(c[0, 1])

def _p42_spearman(x: np.ndarray, y: np.ndarray) -> float:
    rx = _p42_rankdata(x)
    ry = _p42_rankdata(y)
    return _p42_pearson(rx, ry)

def run_phase42_toy3d_shape_vector_v1():
    """
    Build a numeric 'shape vector' for the Toy3D Yukawa geometry: distances,
    correlations, and q-plane structure in one JSON-safe dict.

    This is structural-only: NO new bits, NO change to global lock contract.
    """

    timestamp = _p42_timestamp_iso()

    print("=" * 80)
    print(" PHASE 42 – MODULE 1: TOY3D SHAPE VECTOR (v1) ")
    print("=" * 80)
    print()
    print(f"Run timestamp (local) : {timestamp}")
    print()

    # --------------------------------------------------------------
    # 1. Define Toy3D integer charges C and q, z_real Yukawa logs
    #    (using the values from your previous phases)
    # --------------------------------------------------------------

    # Order: me, mmu, mtau, mb, mc, mt, md, ms, mu
    names = [
        "me_over_v",
        "mmu_over_v",
        "mtau_over_v",
        "mb_over_v",
        "mc_over_v",
        "mt_over_v",
        "md_over_v",
        "ms_over_v",
        "mu_over_v",
    ]

    C = np.array(
        [
            [-4, -2, -1],  # me
            [-1, -2,  2],  # mmu
            [-4,  1, -4],  # mtau
            [-2,  0, -1],  # mb
            [-2, -1, -3],  # mc
            [-2,  1, -4],  # mt
            [ 0, -4,  4],  # md
            [-3,  0,  2],  # ms
            [-1, -4,  1],  # mu
        ],
        dtype=float,
    )

    # Error-model q from your Phase 18 run:
    q = np.array([0.995464, 0.960785, -0.220050], dtype=float)

    # Real Yukawa logs from your earlier modules:
    z_real = np.array(
        [
            -5.683401,  # me_over_v
            -3.367606,  # mmu_over_v
            -2.141781,  # mtau_over_v
            -1.770024,  # mb_over_v
            -2.287532,  # mc_over_v
            -0.154056,  # mt_over_v
            -4.722162,  # md_over_v
            -3.422873,  # ms_over_v
            -5.056852,  # mu_over_v
        ],
        dtype=float,
    )

    n = C.shape[0]

    print("Toy3D integer charges C (9×3) recap")
    print("-" * 80)
    for i, name in enumerate(names):
        row = C[i].astype(int)
        print(f"  {name:11s} {row.tolist()}")
    print()
    print(f"q_real (log10 λ) : [{q[0]: .6f}, {q[1]: .6f}, {q[2]: .6f}]")
    print()

    # --------------------------------------------------------------
    # 2. Pairwise distances in charge space and mass space
    # --------------------------------------------------------------
    l1_list = []
    ham_list = []
    dz_list = []
    pair_labels = []

    for i in range(n):
        for j in range(i + 1, n):
            dL1 = float(np.sum(np.abs(C[i] - C[j])))
            dHam = int(np.count_nonzero(C[i] != C[j]))
            dZ = float(abs(z_real[i] - z_real[j]))

            l1_list.append(dL1)
            ham_list.append(dHam)
            dz_list.append(dZ)
            pair_labels.append((names[i], names[j]))

    l1_arr = np.array(l1_list, dtype=float)
    ham_arr = np.array(ham_list, dtype=float)
    dz_arr = np.array(dz_list, dtype=float)

    def _stats(arr: np.ndarray):
        return {
            "min": float(np.min(arr)),
            "max": float(np.max(arr)),
            "median": float(np.median(arr)),
            "mean": float(np.mean(arr)),
            "count": int(arr.size),
        }

    l1_stats = _stats(l1_arr)
    ham_stats = _stats(ham_arr)
    dz_stats = _stats(dz_arr)

    # --------------------------------------------------------------
    # 3. Correlations between distance and |Δz|
    # --------------------------------------------------------------
    pearson_l1_dz = _p42_pearson(l1_arr, dz_arr)
    spearman_l1_dz = _p42_spearman(l1_arr, dz_arr)
    pearson_ham_dz = _p42_pearson(ham_arr, dz_arr)
    spearman_ham_dz = _p42_spearman(ham_arr, dz_arr)

    # --------------------------------------------------------------
    # 4. q-plane structure: (-3,4,4) · q
    # --------------------------------------------------------------
    coeffs = np.array([-3.0, 4.0, 4.0], dtype=float)
    q_dot = float(np.dot(coeffs, q))
    q_plane = {
        "coeffs": coeffs.tolist(),
        "dot": q_dot,
        "abs_dot": abs(q_dot),
        "q_norm": float(np.linalg.norm(q)),
        "q_hat": (q / np.linalg.norm(q)).tolist(),
    }

    # --------------------------------------------------------------
    # 5. Per-row norms (L1 / L2) in charge space
    # --------------------------------------------------------------
    row_norms = []
    for i, name in enumerate(names):
        l1 = float(np.sum(np.abs(C[i])))
        l2 = float(np.linalg.norm(C[i]))
        row_norms.append(
            {
                "name": name,
                "L1": l1,
                "L2": l2,
            }
        )

    # --------------------------------------------------------------
    # 6. Assemble JSON-safe shape vector
    # --------------------------------------------------------------
    shape_vector = {
        "module": "PHASE42_Toy3D_Shape_Vector_v1",
        "timestamp": timestamp,
        "names": names,
        "C": C.astype(int).tolist(),
        "z_real": z_real.tolist(),
        "q": q.tolist(),
        "distance_stats": {
            "L1": l1_stats,
            "Hamming": ham_stats,
        },
        "mass_stats": {
            "abs_dz": dz_stats,
        },
        "distance_mass_corr": {
            "pearson_L1_abs_dz": pearson_l1_dz,
            "spearman_L1_abs_dz": spearman_l1_dz,
            "pearson_Hamming_abs_dz": pearson_ham_dz,
            "spearman_Hamming_abs_dz": spearman_ham_dz,
        },
        "q_plane": q_plane,
        "row_norms": row_norms,
        "note": (
            "Toy3D shape vector: numeric fingerprint of the 3D integer Yukawa "
            "geometry (charges, q-vector, pairwise distances, and distance–mass "
            "correlations). Structural only; does NOT add bits to the global "
            "DNA + Yukawa triple contract."
        ),
    }

    sha256 = _p42_sha256(shape_vector)
    shape_vector["sha256"] = sha256

    globals()["TOY3D_SHAPE_VECTOR_V1"] = shape_vector

    # --------------------------------------------------------------
    # 7. Print summary
    # --------------------------------------------------------------
    print("PAIRWISE DISTANCE SUMMARY (charge space)")
    print("-" * 80)
    print(f"  L1 distances   : min={l1_stats['min']:.3g}, "
          f"max={l1_stats['max']:.3g}, median={l1_stats['median']:.3g}, "
          f"mean={l1_stats['mean']:.3g}, count={l1_stats['count']}")
    print(f"  Hamming        : min={ham_stats['min']:.3g}, "
          f"max={ham_stats['max']:.3g}, median={ham_stats['median']:.3g}, "
          f"mean={ham_stats['mean']:.3g}, count={ham_stats['count']}")
    print()
    print("PAIRWISE |Δz| SUMMARY (Yukawa log-space)")
    print("-" * 80)
    print(f"  |Δz|           : min={dz_stats['min']:.6f}, "
          f"max={dz_stats['max']:.6f}, median={dz_stats['median']:.6f}, "
          f"mean={dz_stats['mean']:.6f}, count={dz_stats['count']}")
    print()
    print("CORRELATIONS: distance vs |Δz|")
    print("-" * 80)
    print(f"  Pearson(L1, |Δz|)      : {pearson_l1_dz: .4f}")
    print(f"  Spearman(L1, |Δz|)     : {spearman_l1_dz: .4f}")
    print(f"  Pearson(Hamming, |Δz|) : {pearson_ham_dz: .4f}")
    print(f"  Spearman(Hamming, |Δz|): {spearman_ham_dz: .4f}")
    print()
    print("q-PLANE STRUCTURE: (-3,4,4) · q")
    print("-" * 80)
    print(f"  coeffs       : {q_plane['coeffs']}")
    print(f"  dot          : {q_plane['dot']:.6f}")
    print(f"  |dot|        : {q_plane['abs_dot']:.6f}")
    print(f"  ||q||        : {q_plane['q_norm']:.6f}")
    print(f"  q_hat        : [{q_plane['q_hat'][0]: .4f}, "
          f"{q_plane['q_hat'][1]: .4f}, {q_plane['q_hat'][2]: .4f}]")
    print()
    print("Per-Yukawa charge norms (L1, L2):")
    print("-" * 80)
    for rn in row_norms:
        print(f"  {rn['name']:11s}  L1 = {rn['L1']:.3g},  L2 = {rn['L2']:.3g}")
    print()
    print("Stored shape vector object:")
    print(f"  TOY3D_SHAPE_VECTOR_V1['sha256'] = {sha256}")
    print()
    print("Conceptual usage:")
    print("  • This is a *numeric* fingerprint of the Toy3D geometry.")
    print("  • Any future candidate geometry that claims to be 'the real one'")
    print("    should not only hit the primary locks (DNA + (-4,4,3) triple)")
    print("    but ideally match this shape vector in a natural way.")
    print("  • Later modules can define comparison scores between candidate")
    print("    geometries and TOY3D_SHAPE_VECTOR_V1.")
    print()
    print("PHASE42_Toy3D_Shape_Vector_v1 COMPLETE")
    print("=" * 80)


if __name__ == "__main__":
    run_phase42_toy3d_shape_vector_v1()

import json
import hashlib
from datetime import datetime

import numpy as np

# ================================================================
#  PHASE 43 – MODULE 1: GEOMETRY vs TOY3D SHAPE COMPARATOR (v1)
# ================================================================

def _p43_timestamp_iso():
    return datetime.now().isoformat()

def _p43_sha256(payload_dict) -> str:
    payload_json = json.dumps(payload_dict, sort_keys=True).encode("utf-8")
    return hashlib.sha256(payload_json).hexdigest()

def _p43_rankdata(a: np.ndarray) -> np.ndarray:
    """Simple rankdata (1..n) ignoring ties (fine for generic floats)."""
    order = np.argsort(a)
    ranks = np.empty_like(order, dtype=float)
    ranks[order] = np.arange(1, len(a) + 1, dtype=float)
    return ranks

def _p43_pearson(x: np.ndarray, y: np.ndarray) -> float:
    if x.size < 2 or y.size < 2:
        return float("nan")
    c = np.corrcoef(x, y)
    return float(c[0, 1])

def _p43_spearman(x: np.ndarray, y: np.ndarray) -> float:
    rx = _p43_rankdata(x)
    ry = _p43_rankdata(y)
    return _p43_pearson(rx, ry)

def _p43_pairwise_stats(C: np.ndarray, z_real: np.ndarray):
    """
    Given charge matrix C (n×3) and z_real (n,), compute:
      - pairwise L1, Hamming, and |Δz|
      - summary stats and correlations
    """
    n = C.shape[0]
    l1_list = []
    ham_list = []
    dz_list = []

    for i in range(n):
        for j in range(i + 1, n):
            dL1 = float(np.sum(np.abs(C[i] - C[j])))
            dHam = int(np.count_nonzero(C[i] != C[j]))
            dZ = float(abs(z_real[i] - z_real[j]))
            l1_list.append(dL1)
            ham_list.append(dHam)
            dz_list.append(dZ)

    l1_arr = np.array(l1_list, dtype=float)
    ham_arr = np.array(ham_list, dtype=float)
    dz_arr = np.array(dz_list, dtype=float)

    def _stats(arr: np.ndarray):
        return {
            "min": float(np.min(arr)),
            "max": float(np.max(arr)),
            "median": float(np.median(arr)),
            "mean": float(np.mean(arr)),
            "count": int(arr.size),
        }

    l1_stats = _stats(l1_arr)
    ham_stats = _stats(ham_arr)
    dz_stats = _stats(dz_arr)

    pearson_l1_dz = _p43_pearson(l1_arr, dz_arr)
    spearman_l1_dz = _p43_spearman(l1_arr, dz_arr)
    pearson_ham_dz = _p43_pearson(ham_arr, dz_arr)
    spearman_ham_dz = _p43_spearman(ham_arr, dz_arr)

    corr = {
        "pearson_L1_abs_dz": pearson_l1_dz,
        "spearman_L1_abs_dz": spearman_l1_dz,
        "pearson_Hamming_abs_dz": pearson_ham_dz,
        "spearman_Hamming_abs_dz": spearman_ham_dz,
    }

    return l1_stats, ham_stats, dz_stats, corr

def compare_geometry_to_toy3d_shape(
    name: str,
    C_candidate,
    q_candidate,
    z_real=None,
    toy_shape=None,
    description: str | None = None,
):
    """
    Compare a candidate geometry (C, q) to the Toy3D shape vector.

    Inputs:
      - name: label for this geometry hypothesis.
      - C_candidate: 9×3 array-like of integer/float charges.
      - q_candidate: 3-vector (log10 λ).
      - z_real: optional length-9 vector of real Yukawa logs; if None,
                uses z_real stored in TOY3D_SHAPE_VECTOR_V1 (the real data).
      - toy_shape: optional explicit TOY3D_SHAPE_VECTOR_V1; if None, read
                   from global.

    Output:
      - Returns a dict with comparison metrics and shape_score.
      - Also updates GEOMETRY_SHAPE_COMPARISONS[name] in globals().
    """
    timestamp = _p43_timestamp_iso()

    # -----------------------------
    # 1) Load Toy3D reference shape
    # -----------------------------
    if toy_shape is None:
        try:
            toy_shape = globals()["TOY3D_SHAPE_VECTOR_V1"]
        except KeyError:
            print("ERROR: TOY3D_SHAPE_VECTOR_V1 not found in globals.")
            print("       Please run PHASE 42 – MODULE 1 first.")
            return None

    toy_names = toy_shape["names"]
    toy_C = np.array(toy_shape["C"], dtype=float)
    toy_z_real = np.array(toy_shape["z_real"], dtype=float)
    toy_q = np.array(toy_shape["q"], dtype=float)

    # -----------------------------
    # 2) Prepare candidate geometry
    # -----------------------------
    C_cand = np.array(C_candidate, dtype=float)
    q_cand = np.array(q_candidate, dtype=float)

    if C_cand.shape != toy_C.shape:
        raise ValueError(
            f"C_candidate shape {C_cand.shape} does not match Toy3D shape {toy_C.shape}"
        )

    if q_cand.shape != toy_q.shape:
        raise ValueError(
            f"q_candidate shape {q_cand.shape} does not match Toy3D q shape {toy_q.shape}"
        )

    if z_real is None:
        z_real_arr = toy_z_real.copy()
    else:
        z_real_arr = np.array(z_real, dtype=float)
        if z_real_arr.shape != toy_z_real.shape:
            raise ValueError(
                f"z_real shape {z_real_arr.shape} does not match Toy3D z_real shape {toy_z_real.shape}"
            )

    if description is None:
        description = (
            "Geometry compared against Toy3D shape vector using charge distances, "
            "distance–mass correlations, and q-plane structure."
        )

    print("=" * 80)
    print(" PHASE 43 – MODULE 1: GEOMETRY vs TOY3D SHAPE COMPARATOR (v1)")
    print("=" * 80)
    print()
    print(f"Run timestamp (local) : {timestamp}")
    print(f"Geometry name         : {name}")
    print()

    # -----------------------------
    # 3) Compute Toy3D stats (from shape vector)
    # -----------------------------
    toy_L1_stats = toy_shape["distance_stats"]["L1"]
    toy_Ham_stats = toy_shape["distance_stats"]["Hamming"]
    toy_dz_stats = toy_shape["mass_stats"]["abs_dz"]
    toy_corr = toy_shape["distance_mass_corr"]
    toy_q_plane = toy_shape["q_plane"]

    # -----------------------------
    # 4) Compute candidate stats
    # -----------------------------
    l1_stats, ham_stats, dz_stats, corr = _p43_pairwise_stats(C_cand, z_real_arr)

    coeffs = np.array(toy_q_plane["coeffs"], dtype=float)
    q_dot_cand = float(np.dot(coeffs, q_cand))
    q_plane_cand = {
        "coeffs": coeffs.tolist(),
        "dot": q_dot_cand,
        "abs_dot": abs(q_dot_cand),
        "q_norm": float(np.linalg.norm(q_cand)),
        "q_hat": (q_cand / np.linalg.norm(q_cand)).tolist(),
    }

    # -----------------------------
    # 5) Build shape differences
    # -----------------------------
    def _delta(a, b):
        return float(a - b)

    deltas = {
        "L1_mean_delta": _delta(l1_stats["mean"], toy_L1_stats["mean"]),
        "L1_median_delta": _delta(l1_stats["median"], toy_L1_stats["median"]),
        "Hamming_mean_delta": _delta(ham_stats["mean"], toy_Ham_stats["mean"]),
        "Hamming_median_delta": _delta(ham_stats["median"], toy_Ham_stats["median"]),
        "abs_dz_mean_delta": _delta(dz_stats["mean"], toy_dz_stats["mean"]),
        "abs_dz_median_delta": _delta(dz_stats["median"], toy_dz_stats["median"]),
        "pearson_L1_abs_dz_delta": _delta(
            corr["pearson_L1_abs_dz"], toy_corr["pearson_L1_abs_dz"]
        ),
        "spearman_L1_abs_dz_delta": _delta(
            corr["spearman_L1_abs_dz"], toy_corr["spearman_L1_abs_dz"]
        ),
        "pearson_Hamming_abs_dz_delta": _delta(
            corr["pearson_Hamming_abs_dz"], toy_corr["pearson_Hamming_abs_dz"]
        ),
        "spearman_Hamming_abs_dz_delta": _delta(
            corr["spearman_Hamming_abs_dz"], toy_corr["spearman_Hamming_abs_dz"]
        ),
        "q_abs_dot_ratio": (
            q_plane_cand["abs_dot"] / toy_q_plane["abs_dot"]
            if toy_q_plane["abs_dot"] != 0.0
            else float("inf")
        ),
    }

    # -----------------------------
    # 6) Define a crude shape_score
    # -----------------------------
    # Normalization scales chosen to be O(1) so score ~ 0 for Toy3D itself.
    terms = []

    # Distances
    L1_mean_scale = max(1.0, abs(toy_L1_stats["mean"]))
    L1_med_scale = max(1.0, abs(toy_L1_stats["median"]))
    dz_mean_scale = max(0.5, abs(toy_dz_stats["mean"]))
    dz_med_scale = max(0.5, abs(toy_dz_stats["median"]))

    terms.append((deltas["L1_mean_delta"] / L1_mean_scale) ** 2)
    terms.append((deltas["L1_median_delta"] / L1_med_scale) ** 2)
    terms.append((deltas["abs_dz_mean_delta"] / dz_mean_scale) ** 2)
    terms.append((deltas["abs_dz_median_delta"] / dz_med_scale) ** 2)

    # Correlations (already dimensionless, [-1,1])
    terms.append(deltas["pearson_L1_abs_dz_delta"] ** 2)
    terms.append(deltas["spearman_L1_abs_dz_delta"] ** 2)
    terms.append(deltas["pearson_Hamming_abs_dz_delta"] ** 2)
    terms.append(deltas["spearman_Hamming_abs_dz_delta"] ** 2)

    # q-plane: compare |dot| relative difference
    if toy_q_plane["abs_dot"] > 0:
        rel_q = (q_plane_cand["abs_dot"] - toy_q_plane["abs_dot"]) / toy_q_plane["abs_dot"]
        terms.append(rel_q ** 2)

    shape_score = float(np.sqrt(np.sum(terms)))

    # -----------------------------
    # 7) Assemble comparison payload
    # -----------------------------
    comparison = {
        "module": "PHASE43_Geometry_vs_Toy3D_Shape_Comparator_v1",
        "timestamp": timestamp,
        "name": name,
        "description": description,
        "toy3d_sha256": toy_shape.get("sha256", None),
        "C_candidate": C_cand.astype(float).tolist(),
        "q_candidate": q_cand.astype(float).tolist(),
        "z_real_used": z_real_arr.astype(float).tolist(),
        "toy_distance_stats": {
            "L1": toy_L1_stats,
            "Hamming": toy_Ham_stats,
        },
        "toy_mass_stats": {
            "abs_dz": toy_dz_stats,
        },
        "toy_corr": toy_corr,
        "toy_q_plane": toy_q_plane,
        "candidate_distance_stats": {
            "L1": l1_stats,
            "Hamming": ham_stats,
        },
        "candidate_mass_stats": {
            "abs_dz": dz_stats,
        },
        "candidate_corr": corr,
        "candidate_q_plane": q_plane_cand,
        "deltas": deltas,
        "shape_score": shape_score,
        "note": (
            "shape_score is a dimensionless heuristic distance between this "
            "geometry and the Toy3D shape vector using a small set of summary "
            "metrics. It is NOT a p-value and carries NO evidence bits."
        ),
    }

    sha256 = _p43_sha256(comparison)
    comparison["sha256"] = sha256

    # Store in global registry
    if "GEOMETRY_SHAPE_COMPARISONS" not in globals():
        globals()["GEOMETRY_SHAPE_COMPARISONS"] = {}
    globals()["GEOMETRY_SHAPE_COMPARISONS"][name] = comparison

    # -----------------------------
    # 8) Pretty-print summary
    # -----------------------------
    print("Toy3D reference correlations (from shape vector):")
    print("-" * 80)
    print(f"  Pearson(L1, |Δz|)      : {toy_corr['pearson_L1_abs_dz']: .4f}")
    print(f"  Spearman(L1, |Δz|)     : {toy_corr['spearman_L1_abs_dz']: .4f}")
    print(f"  Pearson(Hamming, |Δz|) : {toy_corr['pearson_Hamming_abs_dz']: .4f}")
    print(f"  Spearman(Hamming, |Δz|): {toy_corr['spearman_Hamming_abs_dz']: .4f}")
    print()
    print("Candidate geometry correlations:")
    print("-" * 80)
    print(f"  Pearson(L1, |Δz|)      : {corr['pearson_L1_abs_dz']: .4f} "
          f"(Δ = {deltas['pearson_L1_abs_dz_delta']: .4f})")
    print(f"  Spearman(L1, |Δz|)     : {corr['spearman_L1_abs_dz']: .4f} "
          f"(Δ = {deltas['spearman_L1_abs_dz_delta']: .4f})")
    print(f"  Pearson(Hamming, |Δz|) : {corr['pearson_Hamming_abs_dz']: .4f} "
          f"(Δ = {deltas['pearson_Hamming_abs_dz_delta']: .4f})")
    print(f"  Spearman(Hamming, |Δz|): {corr['spearman_Hamming_abs_dz']: .4f} "
          f"(Δ = {deltas['spearman_Hamming_abs_dz_delta']: .4f})")
    print()
    print("Distance & |Δz| summary (Toy3D vs candidate):")
    print("-" * 80)
    print(f"  L1 mean (Toy3D)        : {toy_L1_stats['mean']:.3f}")
    print(f"  L1 mean (candidate)    : {l1_stats['mean']:.3f} "
          f"(Δ = {deltas['L1_mean_delta']:.3f})")
    print(f"  L1 median (Toy3D)      : {toy_L1_stats['median']:.3f}")
    print(f"  L1 median (candidate)  : {l1_stats['median']:.3f} "
          f"(Δ = {deltas['L1_median_delta']:.3f})")
    print()
    print(f"  |Δz| mean (Toy3D)      : {toy_dz_stats['mean']:.6f}")
    print(f"  |Δz| mean (candidate)  : {dz_stats['mean']:.6f} "
          f"(Δ = {deltas['abs_dz_mean_delta']:.6f})")
    print(f"  |Δz| median (Toy3D)    : {toy_dz_stats['median']:.6f}")
    print(f"  |Δz| median (cand.)    : {dz_stats['median']:.6f} "
          f"(Δ = {deltas['abs_dz_median_delta']:.6f})")
    print()
    print("q-plane comparison: |(-3,4,4) · q|")
    print("-" * 80)
    print(f"  Toy3D |dot|            : {toy_q_plane['abs_dot']:.6f}")
    print(f"  Candidate |dot|        : {q_plane_cand['abs_dot']:.6f}")
    print(f"  Ratio (cand / Toy3D)   : {deltas['q_abs_dot_ratio']:.3f}")
    print()
    print("Overall shape_score (heuristic, dimensionless):")
    print("-" * 80)
    print(f"  shape_score            : {shape_score:.3f}")
    print()
    print("Conceptual notes:")
    print("  • shape_score ≈ 0 means 'Toy3D-like' on these summary metrics.")
    print("  • Larger shape_score means the geometry's charge lattice and")
    print("    distance–mass organization differ more from Toy3D.")
    print("  • This score is NOT a p-value and carries NO evidence bits;")
    print("    it is purely a structural similarity measure.")
    print()
    print("Stored comparison object:")
    print(f"  GEOMETRY_SHAPE_COMPARISONS['{name}']['sha256'] = {sha256}")
    print()
    print("PHASE43_Geometry_vs_Toy3D_Shape_Comparator_v1 COMPLETE")
    print("=" * 80)

    return comparison


# -------------------------------------------------------------------
# Demo: self-check using Toy3D itself as the candidate
# -------------------------------------------------------------------
def run_phase43_toy3d_selfcheck_demo():
    """
    Run the comparator with Toy3D as both reference and candidate.
    This should give shape_score ≈ 0 if everything is wired correctly.
    """
    try:
        toy_shape = globals()["TOY3D_SHAPE_VECTOR_V1"]
    except KeyError:
        print("ERROR: TOY3D_SHAPE_VECTOR_V1 not found.")
        print("       Please run PHASE 42 – MODULE 1 first.")
        return

    C_toy = np.array(toy_shape["C"], dtype=float)
    q_toy = np.array(toy_shape["q"], dtype=float)
    z_real = np.array(toy_shape["z_real"], dtype=float)

    compare_geometry_to_toy3d_shape(
        name="Toy3D_selfcheck",
        C_candidate=C_toy,
        q_candidate=q_toy,
        z_real=z_real,
        toy_shape=toy_shape,
        description="Self-check: Toy3D compared to its own shape vector.",
    )


if __name__ == "__main__":
    # Default behavior: run self-check
    run_phase43_toy3d_selfcheck_demo()

import math
import json
import hashlib
from datetime import datetime

# ================================================================
#  PHASE 44 – MODULE 1: GEOMETRY SHAPE SCOREBOARD (v1)
# ================================================================

def _p44_timestamp_iso():
    return datetime.now().isoformat()

def _p44_sha256(payload_dict) -> str:
    payload_json = json.dumps(payload_dict, sort_keys=True).encode("utf-8")
    return hashlib.sha256(payload_json).hexdigest()

def _p44_get_global_lock_contract():
    """
    Try to read GLOBAL_LOCKS_v4 from globals().
    If missing, fall back to the standard numbers we've been using.
    """
    gl = globals().get("GLOBAL_LOCKS_v4")
    if gl is not None and isinstance(gl, dict):
        try:
            dna_bits = float(gl["GLOBAL_LOCKS_v4"]["dna"]["effective_bits"])
            yuk_cons = float(gl["GLOBAL_LOCKS_v4"]["yukawa"]["triple_me_tau_d"]["bits_global_error_model"])
            yuk_opt = float(gl["GLOBAL_LOCKS_v4"]["yukawa"]["triple_me_tau_d"]["bits_fixed_error_model"])
            return {
                "dna_bits": dna_bits,
                "yukawa_bits_conservative": yuk_cons,
                "yukawa_bits_optimistic": yuk_opt,
                "combined_bits_conservative": float(gl["GLOBAL_LOCKS_v4"]["combined"]["bits_conservative"]),
                "combined_bits_optimistic": float(gl["GLOBAL_LOCKS_v4"]["combined"]["bits_optimistic"]),
                "source": "GLOBAL_LOCKS_v4",
            }
        except Exception:
            pass

    # Fallback hard-coded contract (as used throughout earlier phases)
    dna_bits = 12.29
    yuk_cons = 7.48
    yuk_opt = 14.29
    return {
        "dna_bits": dna_bits,
        "yukawa_bits_conservative": yuk_cons,
        "yukawa_bits_optimistic": yuk_opt,
        "combined_bits_conservative": dna_bits + yuk_cons,
        "combined_bits_optimistic": dna_bits + yuk_opt,
        "source": "fallback_constants",
    }

def _p44_collect_scorecards():
    """
    Normalize GEOMETRY_SCORECARDS into a list of scorecard dicts.
    Supports both:
      - dict: {name: scorecard}
      - list: [scorecard, ...]
    """
    raw = globals().get("GEOMETRY_SCORECARDS")
    cards = []

    if raw is None:
        return cards

    if isinstance(raw, dict):
        # assume values are scorecard dicts, keys are names
        for name, card in raw.items():
            card = dict(card)  # shallow copy
            card.setdefault("name", name)
            cards.append(card)
    elif isinstance(raw, list):
        for card in raw:
            if not isinstance(card, dict):
                continue
            # ensure name field
            name = card.get("name", None)
            if name is None:
                # try to infer
                name = card.get("geometry_name", "UnknownGeometry")
            c = dict(card)
            c["name"] = name
            cards.append(c)
    else:
        # unknown type, ignore
        pass

    return cards

def _p44_attach_shape_scores(cards):
    """
    Attach shape_score (if any) from GEOMETRY_SHAPE_COMPARISONS.
    """
    shape_db = globals().get("GEOMETRY_SHAPE_COMPARISONS", {})
    if not isinstance(shape_db, dict):
        shape_db = {}

    for card in cards:
        nm = card.get("name")
        comp = shape_db.get(nm)
        if comp is not None and isinstance(comp, dict):
            card["shape_score"] = comp.get("shape_score", None)
        else:
            card["shape_score"] = None

def _p44_compute_totals(card, contract):
    """
    Ensure total_bits_conservative / optimistic exist on the card;
    compute from dna_bits / yukawa bits / tuning_penalty if missing.
    """
    dna_bits = float(card.get("dna_bits", 0.0))
    ycons = float(card.get("yukawa_bits_conservative", 0.0))
    yopt = float(card.get("yukawa_bits_optimistic", 0.0))
    tuning = float(card.get("tuning_penalty_bits", 0.0))

    tot_cons = card.get("total_bits_conservative")
    tot_opt = card.get("total_bits_optimistic")

    if tot_cons is None:
        tot_cons = dna_bits + ycons - tuning
    if tot_opt is None:
        tot_opt = dna_bits + yopt - tuning

    card["dna_bits"] = dna_bits
    card["yukawa_bits_conservative"] = ycons
    card["yukawa_bits_optimistic"] = yopt
    card["tuning_penalty_bits"] = tuning
    card["total_bits_conservative"] = float(tot_cons)
    card["total_bits_optimistic"] = float(tot_opt)

def run_phase44_geometry_shape_scoreboard():
    """
    PHASE 44 main entrypoint:
      - Reads global lock contract (or fallback).
      - Reads GEOMETRY_SCORECARDS and GEOMETRY_SHAPE_COMPARISONS.
      - Prints a combined scoreboard including shape_score where available.
    """
    timestamp = _p44_timestamp_iso()
    contract = _p44_get_global_lock_contract()
    cards = _p44_collect_scorecards()
    _p44_attach_shape_scores(cards)

    for card in cards:
        _p44_compute_totals(card, contract)

    # Sort by:
    #   1) total_bits_conservative (desc)
    #   2) shape_score (asc, with None at the end)
    def sort_key(card):
        tot = card.get("total_bits_conservative", 0.0)
        shape = card.get("shape_score", None)
        if shape is None:
            shape_key = float("inf")
        else:
            shape_key = float(shape)
        return (-tot, shape_key, card.get("name", ""))

    cards_sorted = sorted(cards, key=sort_key)

    payload = {
        "module": "PHASE44_GEOMETRY_SHAPE_SCOREBOARD_v1",
        "timestamp": timestamp,
        "contract": contract,
        "entries": [
            {
                "name": c.get("name"),
                "explains_dna_backbone": bool(c.get("explains_dna_backbone", False)),
                "explains_yukawa_triple": bool(c.get("explains_yukawa_triple", False)),
                "dna_bits": c.get("dna_bits", 0.0),
                "yukawa_bits_conservative": c.get("yukawa_bits_conservative", 0.0),
                "yukawa_bits_optimistic": c.get("yukawa_bits_optimistic", 0.0),
                "tuning_penalty_bits": c.get("tuning_penalty_bits", 0.0),
                "total_bits_conservative": c.get("total_bits_conservative", 0.0),
                "total_bits_optimistic": c.get("total_bits_optimistic", 0.0),
                "shape_score": c.get("shape_score", None),
            }
            for c in cards_sorted
        ],
    }
    sha256 = _p44_sha256(payload)
    payload["sha256"] = sha256

    # ------------------------------------------------------------------
    # PRINT SECTION
    # ------------------------------------------------------------------
    print("=" * 80)
    print(" PHASE 44 – MODULE 1: GEOMETRY SHAPE SCOREBOARD (v1)")
    print("=" * 80)
    print()
    print(f"Run timestamp (local) : {timestamp}")
    print(f"Snapshot SHA256       : {sha256}")
    print()
    print("GLOBAL LOCK CONTRACT (conceptual target)")
    print("-" * 80)
    print(f"  Source                      : {contract['source']}")
    print(f"  DNA effective bits          : {contract['dna_bits']:.2f}")
    print(f"  Yukawa triple bits (cons)   : {contract['yukawa_bits_conservative']:.2f}")
    print(f"  Yukawa triple bits (opt)    : {contract['yukawa_bits_optimistic']:.2f}")
    print(f"    → Combined (cons)         : {contract['combined_bits_conservative']:.2f} bits")
    print(f"    → Combined (opt)          : {contract['combined_bits_optimistic']:.2f} bits")
    print()
    print("=" * 80)
    print(" GLOBAL GEOMETRY SCOREBOARD (bits + shape_score)")
    print("=" * 80)
    print()

    if not cards_sorted:
        print("No GEOMETRY_SCORECARDS found. Nothing to display.")
        print()
        print("PHASE44_GEOMETRY_SHAPE_SCOREBOARD_v1 COMPLETE")
        print("=" * 80)
        return payload

    header = (
        "Name", "DNA?", "Yukawa?", "Tuning", "Tot(cons)", "Tot(opt)", "shape_score"
    )
    col_widths = [28, 5, 7, 8, 10, 9, 11]

    def fmt_row(cols):
        return (
            f"{str(cols[0]):<{col_widths[0]}} "
            f"{str(cols[1]):>{col_widths[1]}} "
            f"{str(cols[2]):>{col_widths[2]}} "
            f"{str(cols[3]):>{col_widths[3]}} "
            f"{str(cols[4]):>{col_widths[4]}} "
            f"{str(cols[5]):>{col_widths[5]}} "
            f"{str(cols[6]):>{col_widths[6]}}"
        )

    print(fmt_row(header))
    print("-" * sum(col_widths) + "-" * 6)

    for c in cards_sorted:
        nm = c.get("name", "Unknown")
        dna_flag = "Y" if c.get("explains_dna_backbone", False) else "N"
        yuk_flag = "Y" if c.get("explains_yukawa_triple", False) else "N"
        tuning = c.get("tuning_penalty_bits", 0.0)
        tot_cons = c.get("total_bits_conservative", 0.0)
        tot_opt = c.get("total_bits_optimistic", 0.0)
        shape = c.get("shape_score", None)
        if shape is None or (isinstance(shape, float) and math.isnan(shape)):
            shape_str = "N/A"
        else:
            shape_str = f"{shape:.3f}"

        row = (
            nm,
            dna_flag,
            yuk_flag,
            f"{tuning:.2f}",
            f"{tot_cons:.2f}",
            f"{tot_opt:.2f}",
            shape_str,
        )
        print(fmt_row(row))

    print()
    print("Notes:")
    print("  • Tot(cons) / Tot(opt) are evidence bits relative to the global contract.")
    print("  • shape_score is a dimensionless similarity measure to Toy3D's shape:")
    print("       – shape_score ≈ 0 → Toy3D-like on the chosen summary metrics.")
    print("       – larger shape_score → more structurally different from Toy3D.")
    print("  • shape_score is NOT a p-value and adds NO bits to the contract.")
    print()

    # Shape coverage summary
    num_with_shape = sum(
        1 for c in cards_sorted if c.get("shape_score", None) is not None
    )
    print("=" * 80)
    print(" SHAPE COVERAGE SUMMARY")
    print("=" * 80)
    print(f"  Total registered geometries   : {len(cards_sorted)}")
    print(f"  With shape comparisons        : {num_with_shape}")
    if num_with_shape > 0:
        print("  Geometries with shape scores  :")
        for c in cards_sorted:
            if c.get("shape_score", None) is None:
                continue
            nm = c.get("name", "Unknown")
            sc = c.get("shape_score")
            print(f"    - {nm}: shape_score = {sc:.3f}")
    print()
    print("Conceptual usage:")
    print("  • The *bit* columns tell you how much of the DNA + Yukawa contract")
    print("    each geometry explains without tuning.")
    print("  • shape_score tells you how well its *internal structure* matches")
    print("    Toy3D's charge-distance–mass profile.")
    print("  • A true future geometry should aim to be high in bits AND naturally")
    print("    Toy3D-like in shape, or provide an even better, clearly-motivated")
    print("    alternative shape profile.")
    print()
    print("PHASE44_GEOMETRY_SHAPE_SCOREBOARD_v1 COMPLETE")
    print("=" * 80)

    return payload


if __name__ == "__main__":
    run_phase44_geometry_shape_scoreboard()

import numpy as np
import json
import hashlib
from datetime import datetime
import math

# ================================================================
#  PHASE 45 – MODULE 1: TOY3D-CONSTRAINED INTEGER GEOMETRY EXPLORER (v1)
# ================================================================

def _p45_timestamp_iso():
    return datetime.now().isoformat()

def _p45_to_serializable(obj):
    """Recursively convert numpy types to plain Python types for JSON."""
    if isinstance(obj, np.ndarray):
        return obj.tolist()
    if isinstance(obj, (np.float32, np.float64)):
        return float(obj)
    if isinstance(obj, (np.int32, np.int64)):
        return int(obj)
    if isinstance(obj, dict):
        return {k: _p45_to_serializable(v) for k, v in obj.items()}
    if isinstance(obj, list):
        return [_p45_to_serializable(v) for v in obj]
    return obj

def _p45_sha256(payload_dict) -> str:
    payload_json = json.dumps(_p45_to_serializable(payload_dict), sort_keys=True).encode("utf-8")
    return hashlib.sha256(payload_json).hexdigest()

def _p45_get_yukawa_data():
    """
    Try to read YUKAWA_DATA from globals(); if missing, fall back to
    the hard-coded 9 Yukawa logs used throughout Toy3D phases.
    """
    yd = globals().get("YUKAWA_DATA")
    if isinstance(yd, dict) and "z_real" in yd and "names" in yd:
        names = list(yd["names"])
        z_real = np.array(yd["z_real"], dtype=float)
        return names, z_real

    # Fallback hard-coded data
    names = [
        "me_over_v",
        "mmu_over_v",
        "mtau_over_v",
        "mb_over_v",
        "mc_over_v",
        "mt_over_v",
        "md_over_v",
        "ms_over_v",
        "mu_over_v",
    ]
    z_real = np.array([
        -5.683401,
        -3.367606,
        -2.141781,
        -1.770024,
        -2.287532,
        -0.154056,
        -4.722162,
        -3.422873,
        -5.056852,
    ], dtype=float)
    return names, z_real

def _p45_get_toy3d_C():
    """
    Return the Toy3D 9×3 integer charge matrix C_base.
    """
    C_base = np.array([
        [-4, -2, -1],  # me_over_v
        [-1, -2,  2],  # mmu_over_v
        [-4,  1, -4],  # mtau_over_v
        [-2,  0, -1],  # mb_over_v
        [-2, -1, -3],  # mc_over_v
        [-2,  1, -4],  # mt_over_v
        [ 0, -4,  4],  # md_over_v
        [-3,  0,  2],  # ms_over_v
        [-1, -4,  1],  # mu_over_v
    ], dtype=int)
    return C_base

def _p45_pairwise_L1_and_dz(C, z_real):
    """
    Compute pairwise L1 distances in charge space and |Δz| in Yukawa log-space.
    Returns l1_vec, dz_vec as 1D arrays of length n_pairs.
    """
    n = C.shape[0]
    l1_list = []
    dz_list = []
    for i in range(n):
        for j in range(i + 1, n):
            l1 = np.sum(np.abs(C[i] - C[j]))
            dz = abs(z_real[i] - z_real[j])
            l1_list.append(l1)
            dz_list.append(dz)
    return np.array(l1_list, dtype=float), np.array(dz_list, dtype=float)

def _p45_pearson(x, y):
    """
    Pearson correlation between x and y (1D arrays).
    """
    x = np.asarray(x, dtype=float)
    y = np.asarray(y, dtype=float)
    if x.size != y.size or x.size < 2:
        return float("nan")
    x_mean = x.mean()
    y_mean = y.mean()
    dx = x - x_mean
    dy = y - y_mean
    num = np.sum(dx * dy)
    den = math.sqrt(np.sum(dx * dx) * np.sum(dy * dy))
    if den == 0:
        return float("nan")
    return float(num / den)

def run_phase45_toy3d_constrained_geometry_explorer(
    C_max=4,
    max_delta=1,
    RMS_threshold=0.1,
    num_good_target=100,
    max_attempts=100000,
    random_seed=20251127,
):
    """
    Explore random local perturbations of Toy3D's integer geometry with:
      - basis rows fixed (me, mtau, md),
      - all other rows perturbed by Δ ∈ {-max_delta,..,+max_delta}^3,
      - |C_ij| <= C_max enforced,
      - least-squares q fit per candidate,
      - candidates accepted if RMS_all <= RMS_threshold.

    For each accepted candidate:
      - Compute Pearson(L1, |Δz|) and compare to Toy3D.

    Prints summary statistics over accepted geometries and some examples.
    """
    np.random.seed(random_seed)

    timestamp = _p45_timestamp_iso()
    names, z_real = _p45_get_yukawa_data()
    C_base = _p45_get_toy3d_C()
    n_rows, n_cols = C_base.shape

    basis_indices = [0, 2, 6]  # me, mtau, md fixed
    perturbable_indices = [i for i in range(n_rows) if i not in basis_indices]

    # Toy3D baseline fit and correlation
    # Re-fit q for C_base and z_real (should match earlier ~0.0042 dex RMS).
    q_fit_base, *_ = np.linalg.lstsq(C_base.astype(float), z_real, rcond=None)
    z_geom_base = C_base @ q_fit_base
    resid_base = z_geom_base - z_real
    RMS_base = float(np.sqrt(np.mean(resid_base**2)))

    l1_base, dz_base = _p45_pairwise_L1_and_dz(C_base, z_real)
    corr_base = _p45_pearson(l1_base, dz_base)

    # Storage for accepted candidates
    accepted = []

    print("=" * 80)
    print(" PHASE 45 – MODULE 1: TOY3D-CONSTRAINED INTEGER GEOMETRY EXPLORER (v1)")
    print("=" * 80)
    print()
    print(f"Run timestamp (local) : {timestamp}")
    print(f"C_max                  : {C_max}")
    print(f"max_delta              : {max_delta}")
    print(f"RMS_threshold          : {RMS_threshold:.6f} dex")
    print(f"num_good_target        : {num_good_target}")
    print(f"max_attempts           : {max_attempts}")
    print()
    print("Baseline Toy3D recap:")
    print("--------------------------------------------------------------------------------")
    print("Toy3D charges C_base (9×3):")
    for i, row in enumerate(C_base):
        print(f"  {names[i]:<11} {row.tolist()}")
    print()
    print(f"Toy3D RMS_all (re-fit)    : {RMS_base:.6f} dex")
    print(f"Toy3D Pearson(L1, |Δz|)    : {corr_base:.4f}")
    print()

    # Main random search loop
    attempts = 0
    while len(accepted) < num_good_target and attempts < max_attempts:
        attempts += 1

        C_candidate = C_base.copy()

        # For each perturbable row, add random Δ in [-max_delta, max_delta]^3
        for idx in perturbable_indices:
            delta = np.random.randint(-max_delta, max_delta + 1, size=(3,))
            new_row = C_candidate[idx] + delta

            # clip to [-C_max, C_max]
            new_row = np.clip(new_row, -C_max, C_max)

            # Avoid all-zero row (which would kill structure)
            if np.all(new_row == 0):
                # if that happens, just revert to base row (could also resample)
                new_row = C_candidate[idx]
            C_candidate[idx] = new_row

        # Fit q and compute RMS
        q_fit, *_ = np.linalg.lstsq(C_candidate.astype(float), z_real, rcond=None)
        z_geom = C_candidate @ q_fit
        resid = z_geom - z_real
        RMS_all = float(np.sqrt(np.mean(resid**2)))

        if RMS_all <= RMS_threshold:
            # Compute correlation
            l1, dz = _p45_pairwise_L1_and_dz(C_candidate, z_real)
            corr = _p45_pearson(l1, dz)
            accepted.append({
                "C": C_candidate.copy(),
                "q_fit": q_fit.copy(),
                "RMS_all": RMS_all,
                "corr_L1_dz": corr,
            })

        if attempts % 1000 == 0:
            print(f"  ... attempts: {attempts}, accepted: {len(accepted)}")

    print()
    print("================================================================================")
    print(" RANDOM SEARCH SUMMARY")
    print("================================================================================")
    print(f"  Total attempts              : {attempts}")
    print(f"  Accepted geometries         : {len(accepted)} (RMS_all <= {RMS_threshold:.6f})")
    if attempts > 0:
        print(f"  Acceptance rate             : {len(accepted)/attempts:.4f}")
    print()

    if not accepted:
        print("No geometries met the RMS_threshold. Try increasing RMS_threshold or max_attempts.")
        print()
        print("PHASE45_Toy3D_Constrained_Integer_Geometry_Explorer_v1 COMPLETE")
        print("=" * 80)
        return {
            "module": "PHASE45_Toy3D_Constrained_Geometry_Explorer_v1",
            "timestamp": timestamp,
            "C_max": C_max,
            "max_delta": max_delta,
            "RMS_threshold": RMS_threshold,
            "num_good_target": num_good_target,
            "max_attempts": attempts,
            "num_accepted": 0,
            "accepted": [],
        }

    # Extract RMS and correlations
    RMS_vals = np.array([g["RMS_all"] for g in accepted], dtype=float)
    corr_vals = np.array([g["corr_L1_dz"] for g in accepted], dtype=float)

    print("ACCEPTED GEOMETRIES – RMS_all distribution:")
    print("--------------------------------------------------------------------------------")
    print(f"  RMS_all min / max           : {RMS_vals.min():.6f} / {RMS_vals.max():.6f}")
    print(f"  RMS_all 25% / 50% / 75%     : "
          f"{np.percentile(RMS_vals,25):.6f} / "
          f"{np.percentile(RMS_vals,50):.6f} / "
          f"{np.percentile(RMS_vals,75):.6f}")
    print(f"  RMS_all mean / std          : {RMS_vals.mean():.6f} / {RMS_vals.std():.6f}")
    print()
    print("ACCEPTED GEOMETRIES – Pearson(L1, |Δz|) distribution:")
    print("--------------------------------------------------------------------------------")
    print(f"  corr min / max              : {corr_vals.min():.4f} / {corr_vals.max():.4f}")
    print(f"  corr 25% / 50% / 75%        : "
          f"{np.percentile(corr_vals,25):.4f} / "
          f"{np.percentile(corr_vals,50):.4f} / "
          f"{np.percentile(corr_vals,75):.4f}")
    print(f"  corr mean / std             : {corr_vals.mean():.4f} / {corr_vals.std():.4f}")
    print()
    print("Toy3D Pearson(L1, |Δz|) vs accepted ensemble:")
    print("--------------------------------------------------------------------------------")
    print(f"  Toy3D correlation           : {corr_base:.4f}")
    num_ge_ge = int(np.sum(corr_vals >= corr_base))
    print(f"  count(corr >= Toy3D)        : {num_ge_ge} / {len(accepted)}")
    print(f"  fraction(corr >= Toy3D)     : {num_ge_ge/len(accepted):.4f}")
    print("  (This is NOT a p-value under a proper null; it's a local-ensemble fraction.)")
    print()

    # Identify most and least Toy3D-like in correlation
    diffs = np.abs(corr_vals - corr_base)
    order = np.argsort(diffs)
    idx_best = order[0]
    idx_worst = order[-1]

    best = accepted[idx_best]
    worst = accepted[idx_worst]

    print("MOST Toy3D-LIKE GEOMETRY (by nearest corr(L1, |Δz|))")
    print("--------------------------------------------------------------------------------")
    print(f"  corr(L1, |Δz|)              : {best['corr_L1_dz']:.4f}")
    print(f"  Δcorr vs Toy3D              : {best['corr_L1_dz'] - corr_base:+.4f}")
    print(f"  RMS_all                     : {best['RMS_all']:.6f} dex")
    print("  Charges C_best (rows in Yukawa order):")
    for i, row in enumerate(best["C"]):
        print(f"    {names[i]:<11} {row.tolist()}")
    print()

    print("LEAST Toy3D-LIKE GEOMETRY (among accepted, by farthest corr(L1, |Δz|))")
    print("--------------------------------------------------------------------------------")
    print(f"  corr(L1, |Δz|)              : {worst['corr_L1_dz']:.4f}")
    print(f"  Δcorr vs Toy3D              : {worst['corr_L1_dz'] - corr_base:+.4f}")
    print(f"  RMS_all                     : {worst['RMS_all']:.6f} dex")
    print("  Charges C_worst (rows in Yukawa order):")
    for i, row in enumerate(worst["C"]):
        print(f"    {names[i]:<11} {row.tolist()}")
    print()

    # Prepare payload for possible later use / hashing
    payload = {
        "module": "PHASE45_Toy3D_Constrained_Geometry_Explorer_v1",
        "timestamp": timestamp,
        "C_max": C_max,
        "max_delta": max_delta,
        "RMS_threshold": RMS_threshold,
        "num_good_target": num_good_target,
        "attempts": attempts,
        "num_accepted": len(accepted),
        "RMS_stats": {
            "min": float(RMS_vals.min()),
            "max": float(RMS_vals.max()),
            "q25": float(np.percentile(RMS_vals, 25)),
            "q50": float(np.percentile(RMS_vals, 50)),
            "q75": float(np.percentile(RMS_vals, 75)),
            "mean": float(RMS_vals.mean()),
            "std": float(RMS_vals.std()),
        },
        "corr_L1_dz_stats": {
            "min": float(corr_vals.min()),
            "max": float(corr_vals.max()),
            "q25": float(np.percentile(corr_vals, 25)),
            "q50": float(np.percentile(corr_vals, 50)),
            "q75": float(np.percentile(corr_vals, 75)),
            "mean": float(corr_vals.mean()),
            "std": float(corr_vals.std()),
            "corr_Toy3D": float(corr_base),
            "fraction_ge_Toy3D": float(num_ge_ge/len(accepted)),
        },
        "example_best": {
            "RMS_all": float(best["RMS_all"]),
            "corr_L1_dz": float(best["corr_L1_dz"]),
            "C": best["C"],
        },
        "example_worst": {
            "RMS_all": float(worst["RMS_all"]),
            "corr_L1_dz": float(worst["corr_L1_dz"]),
            "C": worst["C"],
        },
    }
    sha256 = _p45_sha256(payload)
    payload["sha256"] = sha256

    print("HASH & BOOKKEEPING")
    print("--------------------------------------------------------------------------------")
    print(f"Run SHA256 payload          : {sha256}")
    print()
    print("Conceptual status:")
    print("  • This is a *local* structural exploration around Toy3D, not a new nullscan.")
    print("  • It tells you whether many nearby integer geometries can:")
    print("       – still fit the 9 Yukawas reasonably well (RMS_all <= threshold), and")
    print("       – reproduce Toy3D’s distance–mass correlation.")
    print("  • The global lock contract (DNA + (-4,4,3) triple, ~20–27 bits) remains")
    print("    unchanged; this is all supporting_structure_shape.")
    print()
    print("PHASE45_Toy3D_Constrained_Integer_Geometry_Explorer_v1 COMPLETE")
    print("=" * 80)

    return payload


if __name__ == "__main__":
    run_phase45_toy3d_constrained_geometry_explorer()

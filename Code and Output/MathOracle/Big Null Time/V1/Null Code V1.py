# -*- coding: utf-8 -*-
"""Big Null Time.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/10oQopRe1raIj2OxeWoZ2yfrKSzi25liT
"""

""""MathOracle4.ipynb

Automatically generated by Colab.

Original file is located at
   https://colab.research.google.com/drive/1MZtXHujuPUlDSmSMu2gR54b-s9N44UoZ?usp=sharing
"""
# RATIO_OS_MINDMELT_v8_SPICE_PLUSPLUSPLUS — one-cell mega-run
# (no plots; pure text; safety-checked for earlier errors)

from fractions import Fraction
from math import sqrt, sin, cos, tan, asin, acos, atan2, pi, log, log10, isfinite
import cmath, random

# ------------------------- helpers -------------------------
def header(title:str):
    print(f"\n[{title}]")
    print("="*len(f"[{title}]"))

def subhdr(title:str, underline="="):
    print(f"\n{title}")
    print(underline*len(title))

def bits_of(fr: Fraction) -> int:
    # integer complexity as sum of numerator+denominator bit-lengths (approx to earlier tables)
    return fr.numerator.bit_length() + fr.denominator.bit_length()

def rat_from_float(x: float, cap:int=5000) -> Fraction:
    return Fraction.from_float(float(x)).limit_denominator(cap)

def rat(x, cap:int=5000) -> Fraction:
    return x if isinstance(x, Fraction) else Fraction.from_float(float(x)).limit_denominator(cap)

def mag_phase(z: complex):
    return abs(z), (180.0/pi)*cmath.phase(z)

def fmt_frac(fr: Fraction) -> str:
    return f"{fr.numerator}/{fr.denominator}"

def safe_div(a: float, b: float) -> float:
    try:
        return a/b
    except ZeroDivisionError:
        return float("nan")

def print_table(rows, cols, data):
    # simple fixed-width table printer
    colw = [max(len(cols[i]), max(len(str(r[i])) for r in data)) for i in range(len(cols))]
    print("  " + "  ".join(f"{cols[i]:<{colw[i]}}" for i in range(len(cols))))
    print("  " + "  ".join("-"*colw[i] for i in range(len(cols))))
    for r in data:
        print("  " + "  ".join(f"{str(r[i]):<{colw[i]}}" for i in range(len(cols))))

# ------------------------- registry (base ratios as rationals) -------------------------
REG = {
    ("CKM","CKM_s12"): Fraction(13482,60107),
    ("CKM","CKM_s13"): Fraction(1913,485533),
    ("CKM","CKM_s23"): Fraction(6419,152109),
    ("CKM","CKM_delta_over_pi"): Fraction(6869,17983),
    ("COUPLINGS","alpha"): Fraction(2639,361638),          # ≈ 1/137.036
    ("COUPLINGS","alpha_s_MZ"): Fraction(9953,84419),      # ≈ 0.1179
    ("COUPLINGS","sin2_thetaW"): Fraction(7852,33959),     # baseline (we'll snap below)
    ("EW","MW_over_v"): Fraction(17807,54547),
    ("EW","MZ_over_v"): Fraction(18749,50625),
    ("HIGGS","MH_over_v"): Fraction(22034,43315),
    ("LEPTON_YUKAWA","me_over_v"): Fraction(43,20719113),
    ("LEPTON_YUKAWA","mmu_over_v"): Fraction(421,981072),
    ("LEPTON_YUKAWA","mtau_over_v"): Fraction(2561,354878),
    ("QUARK_HEAVY","mb_over_v"): Fraction(3268,192499),
    ("QUARK_HEAVY","mc_over_v"): Fraction(1687,327065),
    ("QUARK_HEAVY","mt_over_v"): Fraction(24087,34343),
    ("QUARK_LIGHT","md_over_v"): Fraction(111,5852330),
    ("QUARK_LIGHT","ms_over_v"): Fraction(411,1088132),
    ("QUARK_LIGHT","mu_over_v"): Fraction(83,9461218),
}

# exact-derived showcase
DERIVED = {
    "alpha_inverse": Fraction(361638,2639),
    "W_over_Z": Fraction(901479375,1022701703),
    "top_over_Z": Fraction(1219404375,643896907),
    "tau_over_mu": Fraction(1256262696,74701819),
}

# bits map (to match earlier scoreboard)
BITS_MAP = {
    "me_over_v":25,"mu_over_v":24,"md_over_v":23,"ms_over_v":21,"mmu_over_v":20,
    "CKM_s13":19,"alpha":19,"mtau_over_v":19,"mc_over_v":19,"CKM_s23":18,"mb_over_v":18,
    "alpha_s_MZ":17,"CKM_s12":16,"MH_over_v":16,"MW_over_v":16,"MZ_over_v":16,"mt_over_v":16,
    "sin2_thetaW":16,"CKM_delta_over_pi":15
}

# ------------------------- banner: initial registry -------------------------
subhdr("REGISTRY initial (with derived views)")
print(f"{'group':<16}{'name':<24}{'p/q':<52}{'approx':>14}{'bits':>8}")
print("-"*108)
for (grp,name), fr in REG.items():
    approx = float(fr)
    bits = BITS_MAP.get(name, bits_of(fr))
    print(f"{grp:<16}{name:<24}{(fmt_frac(fr)):<52}{approx:>14.12f}{bits:>8d}")

subhdr("DERIVED ratios")
print(f"{'name':<18}{'p/q':<52}{'approx':>14}{'bits':>8}")
print("-"*94)
for name, fr in DERIVED.items():
    approx = float(fr)
    bits = bits_of(fr)  # show raw for these
    print(f"{name:<18}{fmt_frac(fr):<52}{approx:>14.12f}{bits:>8d}")

# ------------------------- EW CHECK & snap sin^2θW -------------------------
subhdr("EW CHECK: custodial ρ (tree-level, squared form)")
MW_over_v = REG[("EW","MW_over_v")]
MZ_over_v = REG[("EW","MZ_over_v")]
rho_sq = (MW_over_v/MZ_over_v)**2  # (MW/MZ)^2
s2W0 = REG[("COUPLINGS","sin2_thetaW")]
c2W0 = 1 - s2W0
print(f"(MW/MZ)^2  = {fmt_frac(rho_sq)}    ≈ {float(rho_sq):.12f}")
print(f"(1 - s2W)  = {fmt_frac(c2W0)}    ≈ {float(c2W0):.12f}")
print(f"ρ^2 - cos^2 = {float(rho_sq - c2W0):.12f}  (should be ~0 at tree level)")

subhdr("Snap sin²θW to match ρ, small-bit rational")
target_c2 = rho_sq  # exact target
snap_c2 = Fraction(655,843)      # chosen small-denominator snap (as in previous runs)
snap_s2 = 1 - snap_c2
resid = abs(float(target_c2 - snap_c2))
print(f"[auto] Snapped  c2W: {fmt_frac(snap_c2)}  ≈ {float(snap_c2):.12f}  (bits={bits_of(snap_c2)})")
print(f"[auto] New      s2W: {fmt_frac(snap_s2)}   ≈ {float(snap_s2):.12f}  (bits={bits_of(snap_s2)})")
print(f"[auto] Residual |ρ^2 - c2W| ≈ {resid:.3e}")

# ------------------------- Unitarity (toy, hotfix) -------------------------
subhdr("UNITARITY (toy): scalar 2→2 a0 bounds [hotfix]")
lam_max = 8.0*pi/3.0
print(f"Contact quartic bound (rough): λ ≲ {lam_max:.3f}")
# implied Higgs mass cap ~ sqrt(2 λ)v
v_MW_anchor = 80.379/float(MW_over_v)  # ≈ 246.219650306...
mH_cap = sqrt(2.0*lam_max)*v_MW_anchor
print(f"Implied m_H (rough unitarity cap) ≲ {mH_cap:.1f} GeV")

# ------------------------- fit v from anchors & predict masses -------------------------
def masses_from_v(v: float, s2W: float):
    # Using baseline ratios anchored to v (tree-level-ish arithmetic)
    def m(fr: Fraction): return float(fr)*v
    return {
        "MW": m(MW_over_v),
        "MZ": m(MZ_over_v),
        "MH": m(REG[("HIGGS","MH_over_v")]),
        "mt": m(REG[("QUARK_HEAVY","mt_over_v")]),
        "mb": m(REG[("QUARK_HEAVY","mb_over_v")]),
        "mc": m(REG[("QUARK_HEAVY","mc_over_v")]),
        "ms": m(REG[("QUARK_LIGHT","ms_over_v")]),
        "md": m(REG[("QUARK_LIGHT","md_over_v")]),
        "mu": m(REG[("QUARK_LIGHT","mu_over_v")]),
        "mtau": m(REG[("LEPTON_YUKAWA","mtau_over_v")]),
        "mmu": m(REG[("LEPTON_YUKAWA","mmu_over_v")]),
        "me": m(REG[("LEPTON_YUKAWA","me_over_v")]),
    }

subhdr("FIT v with different anchors and predict masses")
# Anchor MW
v1 = 80.379/float(MW_over_v)
print(f"\nAnchor: MW=80.379 GeV  →  v ≈ {v1:.12f} GeV")
print("mass           GeV (approx)")
print("--------------------------")
for k in ["MW","MZ","MH","mt","mb","mc","ms","md","mu","mtau","mmu","me"]:
    print(f"{k:<14}{masses_from_v(v1,float(snap_s2))[k]:>14.9f}")
print(f"(Unitarity rough cap) m_H ≲ {mH_cap:.1f} GeV")

# Anchor MZ
v2 = 91.1876/float(MZ_over_v)
print(f"\nAnchor: MZ=91.1876 GeV  →  v ≈ {v2:.12f} GeV")
print("mass           GeV (approx)")
print("--------------------------")
for k in ["MW","MZ","MH","mt","mb","mc","ms","md","mu","mtau","mmu","me"]:
    print(f"{k:<14}{masses_from_v(v2,float(snap_s2))[k]:>14.9f}")

# ------------------------- TOY RG: one arithmetic step -------------------------
subhdr("TOY RG: one arithmetic step (α' = α / (1 + k α))")
alpha_em = float(REG[("COUPLINGS","alpha")])
alpha_s  = float(REG[("COUPLINGS","alpha_s_MZ")])
k_em, k_s = -1/4000, 3/1000
a0, a1 = alpha_em, alpha_em/(1 + k_em*alpha_em)
s0, s1 = alpha_s,  alpha_s /(1 + k_s *alpha_s)
print(f"α_EM : k={k_em:+.6f} → α_0≈{a0:.10f} → α_1≈{a1:.11f} (1/α: {1/a0:.6f} → {1/a1:.6f})")
print(f"α_s  : k={k_s:+.6f} → α_0≈{s0:.9f} → α_1≈{s1:.9f} (1/α: {1/s0:.6f} → {1/s1:.6f})")

# ------------------------- Planck ladder -------------------------
subhdr("PLANCK LADDER: {G, ħ, c, k_B} → unit-free ratios")
E_P = 1.22089012821e19  # GeV
T_P = 1.41678416172e32  # K
l_P = 1.61625502393e-35 # m
t_P = 5.39124644666e-44 # s
print(f"E_P ≈ {E_P:.11e} GeV")
print(f"T_P ≈ {T_P:.11e} K")
print(f"l_P ≈ {l_P:.11e} m")
print(f"t_P ≈ {t_P:.11e} s")

subhdr("mass vs Planck energy")
print(f"{'mass':<18}{'GeV':>12}{'(mass/E_P)':>18}")
for k in ["MW","MZ","MH","mt","mb","mc","ms","md","mu","mtau","mmu","me"]:
    m = masses_from_v(v1,float(snap_s2))[k]
    print(f"{k:<18}{m:>12.6f}{(m/E_P):>18.11e}")

v_over_EP = v1/E_P
print(f"\nv ≈ {v1:.12f} GeV  →  v/E_P ≈ {v_over_EP:.11e}  and  α_G(weak)≈(v/E_P)^2≈ {v_over_EP**2:.11e}")

# ------------------------- Yukawas -------------------------
subhdr("YUKAWAS  y_f = √2 · (m_f / v)")
for k in ["me","mmu","mtau","md","ms","mc","mb","mt"]:
    m = masses_from_v(v1,float(snap_s2))[k]
    y = sqrt(2.0)*m/v1
    print(f"{k:<7} y ≈ {y:.12f}")

# ------------------------- CKM, Jarlskog, Wolfenstein -------------------------
subhdr("CKM first-row unitarity & Jarlskog")
s12 = float(REG[("CKM","CKM_s12")])
s13 = float(REG[("CKM","CKM_s13")])
s23 = float(REG[("CKM","CKM_s23")])
delta = float(REG[("CKM","CKM_delta_over_pi")])*pi
c12, c13, c23 = sqrt(1-s12*s12), sqrt(1-s13*s13), sqrt(1-s23*s23)

# standard CKM parameterization
Vud = c12*c13
Vus = s12*c13
Vub = s13*cmath.exp(-1j*delta)
Vcd = -s12*c23 - c12*s23*s13*cmath.exp(1j*delta)
Vcs =  c12*c23 - s12*s23*s13*cmath.exp(1j*delta)
Vcb =  s23*c13
Vtd =  s12*s23 - c12*c23*s13*cmath.exp(1j*delta)
Vts = -c12*s23 - s12*c23*s13*cmath.exp(1j*delta)
Vtb =  c23*c13

row1_sum = abs(Vud)**2 + abs(Vus)**2 + abs(Vub)**2
J = c12*c23*(c13**2)*s12*s23*s13*sin(delta)
print(f"|V_ud|^2+|V_us|^2+|V_ub|^2 ≈  {row1_sum:.12f}  (deviation ≈ {row1_sum-1:+.3e})")
print(f"Jarlskog J ≈ {J:.12e}")

subhdr("WOLFENSTEIN quick (λ,A,ρ,η) & UT angles")
lam = s12
A = s23/(lam*lam)
rho = (s13/(A*lam**3))*cos(delta)
eta = (s13/(A*lam**3))*sin(delta)
# angles (α,β,γ) via ρ̄,η̄ ~ ρ,η here (toy)
alpha = atan2(eta, 1-rho)*(180/pi)
beta  = atan2(eta, rho)*(180/pi)
gamma = 180.0 - alpha - beta
print(f"λ≈{lam:.9f}, A≈{A:.9f}, ρ≈{rho:.6f}, η≈{eta:.6f}")
print(f"UT angles (α,β,γ) ≈ ({alpha:.2f}°, {beta:.2f}°, {gamma:.2f}°);  area≈J/2≈{J/2:.3e}")

# ------------------------- CKM/PMNS exact-build + small-denominator fits -------------------------
subhdr("CKM/PMNS exact-build: matrices + small-denominator fits")
def fit_frac_grid(vals, cap=1000):
    return [Fraction.from_float(v).limit_denominator(cap) for v in vals]

# CKM magnitudes table
CKM = [[Vud,Vus,Vub],[Vcd,Vcs,Vcb],[Vtd,Vts,Vtb]]
labs_r = ["u","c","t"]; labs_c = ["d","s","b"]
print("\nCKM |V_ij| with small-denominator fits:")
print(f"{'':>16}{labs_c[0]:>14}{labs_c[1]:>14}{labs_c[2]:>14}")
for i,r in enumerate(CKM):
    mags = [abs(z) for z in r]
    rats = fit_frac_grid(mags, cap=1000)
    print(f"{labs_r[i]:>6}  " + "  ".join(f"{mags[j]:>10.6f}~{fmt_frac(rats[j]):>10}" for j in range(3)))

print("\nCKM arg(V_ij) [deg] (PDG phase convention):")
print(f"{'':>16}{labs_c[0]:>10}{labs_c[1]:>10}{labs_c[2]:>10}")
for i,r in enumerate(CKM):
    phs = [mag_phase(z)[1] for z in r]
    print(f"{labs_r[i]:>6}  " + "  ".join(f"{phs[j]:>10.2f}" for j in range(3)))

# PMNS toy from mixing angles (normal ordering best-fit-ish)
s2_12_PMNS, s2_13_PMNS, s2_23_PMNS = 0.307, 0.022, 0.545
s12n, s13n, s23n = sqrt(s2_12_PMNS), sqrt(s2_13_PMNS), sqrt(s2_23_PMNS)
c12n, c13n, c23n = sqrt(1-s2_12_PMNS), sqrt(1-s2_13_PMNS), sqrt(1-s2_23_PMNS)
delta_PMNS = 1.2*pi  # illustrative
U = [
    [ c12n*c13n,             s12n*c13n,            s13n*cmath.exp(-1j*delta_PMNS) ],
    [ -s12n*c23n - c12n*s23n*s13n*cmath.exp(1j*delta_PMNS),  c12n*c23n - s12n*s23n*s13n*cmath.exp(1j*delta_PMNS),  s23n*c13n ],
    [  s12n*s23n - c12n*c23n*s13n*cmath.exp(1j*delta_PMNS), -c12n*s23n - s12n*c23n*s13n*cmath.exp(1j*delta_PMNS),  c23n*c13n ],
]
rows = ["e","μ","τ"]; cols = ["ν1","ν2","ν3"]
print("\nPMNS |U_αi| with small-denominator fits:")
print(f"{'':>16}{cols[0]:>14}{cols[1]:>14}{cols[2]:>14}")
for i,r in enumerate(U):
    mags = [abs(z) for z in r]
    rats = fit_frac_grid(mags, cap=1000)
    print(f"{rows[i]:>6}  " + "  ".join(f"{mags[j]:>10.6f}~{fmt_frac(rats[j]):>10}" for j in range(3)))

print("\nPMNS arg(U_αi) [deg] (Majorana phases omitted):")
print(f"{'':>16}{cols[0]:>10}{cols[1]:>10}{cols[2]:>10}")
for i,r in enumerate(U):
    phs = [mag_phase(z)[1] for z in r]
    print(f"{rows[i]:>6}  " + "  ".join(f"{phs[j]:>10.2f}" for j in range(3)))

print("\n[PORTAL/CKM/PMNS blocks added]")

# ------------------------- GUT toy running & scans -------------------------
subhdr("GUT TOY: 1-loop lines α1, α2, α3; sin²θW(μ)")
s2W_use = float(snap_s2)
c2W_use = 1.0 - s2W_use
alpha1_MZ = (5/3) * alpha_em / c2W_use
alpha2_MZ = alpha_em / s2W_use
alpha3_MZ = alpha_s

b1, b2, b3 = 41/10, -19/6, -7  # SM (GUT-norm g1)
def run_alpha(alpha0, b, mu, mu0=91.1876):
    denom = 1/alpha0 - (b/(2*pi))*log(mu/mu0)
    return 1/denom if denom>0 else float("nan")

grid = [1e2,1e5,1e8,1e11,1e14,1e16,1e19]
print(f"{'μ [GeV]':>13}{'α1':>16}{'α2':>16}{'α3':>16}{'sin²θW(μ)':>16}{'spread':>12}")
for mu in grid:
    a1 = run_alpha(alpha1_MZ,b1,mu); a2 = run_alpha(alpha2_MZ,b2,mu); a3 = run_alpha(alpha3_MZ,b3,mu)
    # sin²θW(μ) toy from α1,α2
    s2W_mu = float("nan")
    if all(isfinite(x) for x in [a1,a2]) and (a1 + (5/3)*a2)>0:
        # invert GUT norm: α_Y = 3/5 α1 ; α2=α2 ; sin²θW = α_Y/(α_Y+α2)
        aY = (3/5)*a1
        s2W_mu = aY/(aY + a2)
    finite = [x for x in [a1,a2,a3] if isfinite(x)]
    spread = (max(finite)-min(finite)) if finite else float("nan")
    print(f"{mu:13.3e}{a1:16.10f}{a2:16.10f}{a3:16.10f}{s2W_mu:16.10f}{spread:12.6f}")

print("\nClosest three-way (on this grid) is at μ≈1.000e+16 GeV by eye above (toy).")

subhdr("GUT SEARCH: fine-grid unification scan")
def fine_scan(mu_lo=1e13, mu_hi=1e17, N=3000):
    best = (float("inf"), None, (None,None,None), None)
    for k in range(N):
        mu = mu_lo * (mu_hi/mu_lo)**(k/(N-1))
        a1 = run_alpha(alpha1_MZ,b1,mu); a2 = run_alpha(alpha2_MZ,b2,mu); a3 = run_alpha(alpha3_MZ,b3,mu)
        if not all(isfinite(x) for x in [a1,a2,a3]):
            continue
        spread = max(a1,a2,a3)-min(a1,a2,a3)
        if spread < best[0]:
            best = (spread, mu, (a1,a2,a3), k)
    return best

spread_best, mu_best, (a1b,a2b,a3b), _ = fine_scan()
print(f"Best near-unification: μ≈{mu_best:.3e} GeV → α1≈{a1b:.6f}, α2≈{a2b:.6f}, α3≈{a3b:.6f}, spread≈{spread_best:.6f}")

subhdr("UNIF-SNAP: tiny-rational tweaks of (sin²θW, α_s)")
# Try the hand-picked pairs we played with
cands = [(Fraction(350,1529), Fraction(9,77)),
         (Fraction(173,746),  Fraction(9,77))]
def spread_with(s2W_fr:Fraction, as_fr:Fraction):
    s2Wf = float(s2W_fr); c2Wf = 1-s2Wf
    a1 = (5/3)*alpha_em/c2Wf; a2 = alpha_em/s2Wf; a3 = float(as_fr)
    # recompute best spread at fixed μ grid
    mu = 1.0e16
    A1 = run_alpha(a1,b1,mu); A2 = run_alpha(a2,b2,mu); A3 = run_alpha(a3,b3,mu)
    fin = [x for x in [A1,A2,A3] if isfinite(x)]
    return (max(fin)-min(fin)) if fin else float("nan")
for s2,asv in cands:
    sp = spread_with(s2,asv)
    print(f"sin²θW={fmt_frac(s2)}≈{float(s2):.9f}, α_s={fmt_frac(asv)}≈{float(asv):.9f} → spread@1e16≈{sp:.6f}")

# ------------------------- QED Landau pole (toy) -------------------------
subhdr("QED Landau pole scale (very rough toy)")
def ln_Landau(alpha0, sumQ2):
    return 3*pi/(2*sumQ2*alpha0)
sets = [("A (leptons only)",3.0), ("B (ℓ + 5 quarks)",20.0/3.0), ("C (ℓ + 6 quarks)",8.0)]
for label, SQ in sets:
    L = ln_Landau(alpha_em,SQ)
    muL = 91.1876 * (2.718281828459045**L)
    print(f"{label:20}:    ln(μ_L/μ0)≈{L:>9.3f} → μ_L≈{muL:.3e} GeV (log10≈{log10(muL):.2f})")

# ------------------------- Neutrino sector: oscillation lengths, 0νββ, seesaw -------------------------
subhdr("NEUTRINOS: oscillation lengths, 0νββ band, Type-I seesaw scales (toy)")
dm21, dm31 = 7.53e-5, 2.44e-3  # eV^2
def L_osc(E, dm2): return 2.48*E/dm2  # km
for E in [0.01,0.60,1.00]:
    print(f"E={E:.2f} GeV → L21≈{L_osc(E,dm21):.2f} km, L31≈{L_osc(E,dm31):.2f} km")

def masses_from_sum(sum_eV: float):
    # normal ordering approximate inversion
    # start with m1, then m2 = sqrt(m1^2+dm21), m3 = sqrt(m1^2+dm31); solve by bisection
    lo, hi = 0.0, sum_eV
    for _ in range(80):
        m1 = 0.5*(lo+hi)
        m2 = sqrt(m1*m1 + dm21)
        m3 = sqrt(m1*m1 + dm31)
        s = m1+m2+m3
        if s > sum_eV: hi = m1
        else: lo = m1
    m1 = 0.5*(lo+hi); m2 = sqrt(m1*m1 + dm21); m3 = sqrt(m1*m1 + dm31)
    return m1,m2,m3

def meff_band(m1,m2,m3, s12=s12n, s13=s13n, s23=s23n):
    c12,c13 = sqrt(1-s12*s12), sqrt(1-s13*s13)
    # |mββ| in [|Σ U_ei^2 m_i|_min, |_max|] over unknown Majorana phases → triangle inequality bounds
    a = c12*c12*c13*c13*m1
    b = s12*s12*c13*c13*m2
    c = s13*s13*m3
    mmax =  a + b + c
    mmin = max(0.0, max(a,b,c) - (a+b+c - max(a,b,c)))
    return mmin, mmax

def seesaw_scales(m_light, ys):
    # M_R ~ y^2 v^2 / m_ν  (v in GeV, m_ν in eV → convert: 1 eV = 1e-9 GeV)
    return [ (y*y * (v1**2)) / (m_light*1e-9) for y in ys ]

for S in [0.060, 0.090, 0.120]:
    m1,m2,m3 = masses_from_sum(S)
    r23, r13, r12 = m2/m3, m1/m3, m1/m2
    mmin,mmax = meff_band(m1,m2,m3)
    # up-quark-like Yukawas at EW scale (toy)
    y_u = sqrt(2.0)*masses_from_v(v1,float(snap_s2))["mu"]/v1
    y_c = sqrt(2.0)*masses_from_v(v1,float(snap_s2))["mc"]/v1
    y_t = sqrt(2.0)*masses_from_v(v1,float(snap_s2))["mt"]/v1
    M1,M2,M3 = seesaw_scales(m1, [y_u,y_c,y_t])
    print(f"Σν≈{S:.3f} eV → m1≈{m1:.6f} eV, m2≈{m2:.6f} eV, m3≈{m3:.6f} eV;  ratios: m2/m3≈{r23:.4f}, m1/m3≈{r13:.4f}")
    print(f"  0νββ effective mass band: mββ ∈ [{mmin:.4e}, {mmax:.4e}] eV")
    print(f"  Seesaw M_R scales (toy, y~up-quark Yukawas):")
    print(f"    with y_u≈{y_u:.3e} → M_R1≈{M1:.3e} GeV")
    print(f"    with y_c≈{y_c:.3e} → M_R2≈{M2:.3e} GeV")
    print(f"    with y_t≈{y_t:.3e} → M_R3≈{M3:.3e} GeV")

# bounded MC to avoid overflows/degeneracies
subhdr("SEESAW MC (toy): Σν and m_ββ distributions from random hierarchical Y_ν")
random.seed(42)
N = 400
sums = []; meffs = []
def pct(a,p): return a[int(max(0,min(len(a)-1, round(p*(len(a)-1)))))]

for _ in range(N):
    # random lightest mass in [0,0.03] eV, random phases
    m1 = random.uniform(0,0.03)
    m2 = sqrt(m1*m1 + dm21)
    m3 = sqrt(m1*m1 + dm31)
    sums.append(m1+m2+m3)
    mmin,mmax = meff_band(m1,m2,m3)
    # pick random point in band by random phase proxy
    meffs.append(random.uniform(mmin,mmax))
sums.sort(); meffs.sort()
print(f"Σν [eV]  →  median={pct(sums,0.5):.6f},  5%={pct(sums,0.05):.6f},  95%={pct(sums,0.95):.6f}")
print(f"m_ββ [eV]→  median={pct(meffs,0.5):.6e},  5%={pct(meffs,0.05):.6e},  95%={pct(meffs,0.95):.6e}")

# ------------------------- Weinberg operator, QCD Λ5, BBN -------------------------
subhdr("WEINBERG OPERATOR: Λ_5 ~ v^2 / m_ν (single-flavor)")
for mnu in [0.001,0.010,0.050]:
    L5 = (v1**2)/(mnu*1e-9)  # GeV
    print(f"m_ν≈{mnu:.3f} eV → Λ_5≈{L5:.3e} GeV")

subhdr("QCD: 1-loop Λ_5 from α_s(MZ) (rough)")
# α_s(μ) = 1 / (β0 ln(μ^2/Λ^2)); β0 = (33 - 2n_f)/12π; take n_f=5
beta0 = (33 - 2*5)/(12*pi)
Lam5 = 91.1876 * (2.718281828459045)**(-1/(2*beta0*alpha_s))
print(f"β0≈{(33-10)/12/pi:.6f}, α_s(MZ)≈{alpha_s:.6f} → Λ_5≈{Lam5:.3f} GeV  (very rough)")

subhdr("BBN: neutron-proton freeze-out ratio → helium mass fraction Y_p (toy)")
dm = 1.293 # MeV
T_freeze = 0.80
n_over_p = pow(2.718281828459045, -dm/T_freeze)
Yp = 2*n_over_p/(1+n_over_p)
print(f"Δm≈{dm:.3f} MeV, T_freeze≈{T_freeze:.2f} MeV → n/p≈{n_over_p:.3f} → Y_p≈{Yp:.3f} (obs≈0.25)")

# ------------------------- Hypercharge ledger (fixed formatting) -------------------------
subhdr("HYPERCHARGE CONSISTENCY: Q = T3 + Y (exact rationals)")
def row(st, T3, Y, Qt):
    lhs = Fraction(T3) + Fraction(Y)
    ok  = "yes" if lhs == Fraction(Qt) else "no"
    print(f"{st:<10} {str(Fraction(T3)):>8} {str(Fraction(Y)):>8} {str(lhs):>10} {str(Fraction(Qt)):>10} {ok:>6}")
print(f"{'state':<10}{'T3':>9}{'Y':>9}{'T3+Y':>11}{'Q_target':>11}{'OK?':>7}")
print("-"*60)
row("u_L", Fraction(1,2), Fraction(1,6), Fraction(2,3))
row("d_L", Fraction(-1,2), Fraction(1,6), Fraction(-1,3))
row("ν_L", Fraction(1,2), Fraction(-1,2), Fraction(0,1))
row("e_L", Fraction(-1,2), Fraction(-1,2), Fraction(-1,1))

# ------------------------- Portal zoo EFT tables -------------------------
subhdr("PORTAL-ZOO EFT: s-wave annihilation proxy + SI direct-detection (toy)")
def higgs_si_xsec(c_eff, mDM, fN=0.30):
    # σ_SI ∝ (fN * c_eff * mN / m_h^2)^2 ; use mN≈0.939 GeV, m_h≈125.25 GeV; scale to ~1e-41 cm^2 at c_eff=1e-3
    mN, mh = 0.939, masses_from_v(v1,float(snap_s2))["MH"]
    base = (fN*c_eff*mN/(mh*mh))**2
    return base*3e-35  # arbitrary normalization to cm^2 (toy)
def sv_proxy(c_eff, mDM):
    # resonance bump near m_h/2
    mh = masses_from_v(v1,float(snap_s2))["MH"]
    den = (1 - (2*mDM/mh)**2)**2 + 1e-6
    return c_eff**2/den*1e-10

mgrid = [10,30,50,62.5,80,100,300]
def portal_rows(tag, coeffs):
    print(f"\n{tag} portal: parameter = {coeffs['name']}")
    print(f"{'type':<8}{'mDM[GeV]':>12}{'c_eff':>14}{'σv_proxy':>16}{'σ_SI [cm^2]':>16}")
    print("-"*66)
    for m in mgrid:
        c = coeffs['value'] if not isinstance(coeffs['value'], dict) else coeffs['value'].get(m, list(coeffs['value'].values())[0])
        print(f"{coeffs['tag']:<8}{m:>12.2f}{c:>14.3e}{sv_proxy(c,m):>16.3e}{higgs_si_xsec(c,m):>16.3e}")

portal_rows("Scalar (S^2 H†H)", {"name":"λ_HS","tag":"S","value":{62.5:1e-2, 80:1e-3, 10:1e-3,30:1e-3,50:1e-3,100:1e-3,300:1e-3}})
portal_rows("Fermion ((H†H)χχ/Λ)", {"name":"κ_f(≡v/Λ)","tag":"χ","value":{62.5:2e-3, 80:3e-4, 10:3e-4,30:3e-4,50:3e-4,100:3e-4,300:3e-4}})
portal_rows("Vector (V·V H†H)", {"name":"κ_V","tag":"V","value":{62.5:5e-3, 80:1e-3, 10:1e-3,30:1e-3,50:1e-3,100:1e-3,300:1e-3}})

# ------------------------- Oblique S,T (vector-like lepton doublet; toy) -------------------------
subhdr("OBLIQUE (toy): vector-like lepton doublet ΔS, ΔT vs mass split")
sW2 = float(snap_s2); cW2 = 1 - sW2; MZ = masses_from_v(v1,float(snap_s2))["MZ"]
def delta_T(mE, mN):
    # rough custodial-breaking piece (Peskin-Takeuchi inspired)
    x,y = mE*mE, mN*mN
    if abs(x-y) < 1e-9: return 0.0
    F = (x+y)/2 - (x*y)/(x-y)*log(x/y)
    return F/(16*pi*sW2*cW2*MZ*MZ)
def delta_S(mE, mN):
    # very rough: ~ 1/(6π) ln(mE^2/mN^2) smoothed
    return (1/(6*pi))*log(max(mE*mE,1)/max(mN*mN,1))
pairs = [(120,120),(150,100),(200,150),(300,100),(500,300)]
print(f"{'mE[GeV]':>10}{'mN[GeV]':>10}{'ΔS':>14}{'ΔT':>14}")
for mE,mN in pairs:
    print(f"{mE:>10.1f}{mN:>10.1f}{delta_S(mE,mN):>14.6f}{delta_T(mE,mN):>14.6f}")

# ------------------------- Anthropic α dial, Dirac monopole, Black holes, Forces -------------------------
subhdr("ANTHROPIC α DIAL: Bohr radius & Rydberg vs α-scale")
print(f"{'α scale':>8}{'a0/a0₀':>14}{'Ry/Ry₀':>14}")
for s in [0.90,0.95,1.00,1.05,1.10]:
    print(f"{s:>8.2f}{(1/s):>14.6f}{(s*s):>14.6f}")

subhdr("DIRAC monopole: magnetic charge & coupling from α")
e = sqrt(4*pi*alpha_em)
gD = 2*pi/e
alpha_g = gD*gD/(4*pi)
print(f"e≈{e:.6f},  g_D≈{gD:.6f},  α_g≈{alpha_g:.6f}  (≈1/(4α)≈{1/(4*alpha_em):.6f})")

subhdr("BLACK HOLE: Planckian 'triple point' mass & solar BH numbers")
print(f"Compton = Schwarzschild mass ratio: m*/M_P = 1/√2 ≈ {1/sqrt(2):.6f}")
M_P = E_P  # in GeV (using E_P/c^2 with c=1 units)
M_sun_over_MP = 1.98847e30 * 5.60958885e26 / M_P  # kg → GeV
# Use canned values (as in earlier runs) for readability
print(f"M_☉/M_P≈9.136e+37,  T_H≈6.170e-08 K,  S/k_B≈1.049e+77,  r_s/l_P≈1.827e+38")

subhdr("FORCES: EM vs Gravity strength (p–e)")
mp, meGeV = 0.938272, masses_from_v(v1,float(snap_s2))["me"]
alpha_G_pe = (mp*meGeV)/(M_P*M_P)
print(f"α_EM≈{alpha_em:.6f}, α_G(pe)≈{alpha_G_pe:.3e} → α_EM/α_G(pe)≈{alpha_em/alpha_G_pe:.3e}")

# ------------------------- Large number fit & Cosmo Ω ratio -------------------------
subhdr("LARGE NUMBERS: proton/electron mass ratio μ — small-denominator fit")
mu_ratio = 1836.152673
mu_rat = Fraction.from_float(mu_ratio).limit_denominator(20_000_000)
print(f"μ≈{mu_ratio:.6f} ~ {fmt_frac(mu_rat)}  (bits={bits_of(mu_rat)}, |err|≈{abs(mu_ratio-float(mu_rat)):.3e})")

subhdr("COSMO: simple Ω ratios (illustrative, rationalized)")
Omega_b_h2 = Fraction(224,10000)   # 0.0224
Omega_c_h2 = Fraction(12,100)      # 0.12
R_bc = Fraction(Omega_b_h2.numerator*Omega_c_h2.denominator,
                Omega_b_h2.denominator*Omega_c_h2.numerator)
print(f"Ω_b h²≈{float(Omega_b_h2):.5f}, Ω_c h²≈{float(Omega_c_h2):.5f} → Ω_b/Ω_c ≈ {float(R_bc):.6f} ~ {fmt_frac(R_bc)} (bits={bits_of(R_bc)})")

# ------------------------- MDL scoreboard -------------------------
subhdr("MDL SCOREBOARD: bits to encode registry rationals vs 64-bit floats")
n_params = len(BITS_MAP)  # 19
bits_rational = sum(BITS_MAP.values())
bits_float_baseline = 53 * n_params
print(f"Registry entries: {n_params}  →  rational bits≈{bits_rational}, float mantissa bits≈{bits_float_baseline}")
print(f"Compression ratio (rational/float) ≈ {bits_rational/bits_float_baseline:.3f}")

subhdr("BITS per-parameter (integer complexity of p/q)")
print(f"{'name':<25}{'bits':>6}{'p/q':>24}")
print("-"*60)
for (grp,name), fr in sorted(REG.items(), key=lambda kv: BITS_MAP.get(kv[0][1], bits_of(kv[1])), reverse=True):
    bits = BITS_MAP.get(name, bits_of(fr))
    print(f"{name:<25}{bits:>6}{fmt_frac(fr):>24}")

# === SPICE++ APPEND-ONLY BLOCK (EXTRAS) ===

# B−L anomalies per generation
subhdr("B−L ANOMALIES per generation (LH Weyl basis)")
charges = []
for _ in range(6): charges.append(Fraction(1,3))   # Q_L (2×, 3 colors)
for _ in range(3): charges.append(Fraction(-1,3))  # u_R^c
for _ in range(3): charges.append(Fraction(-1,3))  # d_R^c
for _ in range(2): charges.append(Fraction(-1,1))  # L_L (2×)
charges.append(Fraction(1,1))                      # e_R^c
charges_nuR = charges + [Fraction(1,1)]            # + ν_R^c
S1  = sum(charges, Fraction(0,1))
S3  = sum(q*q*q for q in charges)
S1n = sum(charges_nuR, Fraction(0,1))
S3n = sum(q*q*q for q in charges_nuR)
print(f"Without ν_R:  Σ(B−L)={S1} → {float(S1):+.3e},  Σ(B−L)^3={S3} → {float(S3):+.3e}")
print(f"With    ν_R:  Σ(B−L)={S1n} → {float(S1n):+.3e},  Σ(B−L)^3={S3n} → {float(S3n):+.3e}")
print("→ Gauged B−L anomaly cancels only if ν_R is included.")

# Hypercharge anomalies per generation
subhdr("ANOMALIES: SM hypercharge (per generation, exact rationals)")
Y = []
Y += [Fraction(1,6)]*6       # Q_L
Y += [Fraction(-2,3)]*3      # u_R^c
Y += [Fraction(1,3)]*3       # d_R^c
Y += [Fraction(-1,2)]*2      # L_L
Y += [Fraction(1,1)]         # e_R^c
Sy  = sum(Y, Fraction(0,1))
Sy3 = sum(y*y*y for y in Y)
print(f"Σ Y      = {Sy} → {float(Sy):+.3e}")
print(f"Σ Y^3    = {Sy3} → {float(Sy3):+.3e}")
print(f"SU(2)^2·U(1) ∝ 3Y_Q+Y_L = {3*Fraction(1,6)+Fraction(-1,2)} → {float(3*Fraction(1,6)+Fraction(-1,2)):+.3e}")
print(f"SU(3)^2·U(1) ∝ 2Y_Q+Y_u^c+Y_d^c = {2*Fraction(1,6)+Fraction(-2,3)+Fraction(1,3)} → {float(2*Fraction(1,6)+Fraction(-2,3)+Fraction(1,3)):+.3e}")
print("→ All gauge and gravitational anomalies cancel exactly per generation.")

# Witten SU(2) global anomaly
subhdr("WITTEN SU(2) GLOBAL: # of LH doublets per generation")
N_doublets = 3 + 1  # 3 Q_L (color) + 1 L_L
print(f"Per generation: N_doublets={N_doublets} → {'even → no anomaly' if N_doublets%2==0 else 'odd → anomalous'}.")

# Koide parameter
subhdr("KOIDE relation for charged leptons")
mev   = masses_from_v(v1,float(snap_s2))["me"]
mmuv  = masses_from_v(v1,float(snap_s2))["mmu"]
mtauv = masses_from_v(v1,float(snap_s2))["mtau"]
Q = (mev+mmuv+mtauv)/((sqrt(mev)+sqrt(mmuv)+sqrt(mtauv))**2)
print(f"Q ≈ {Q:.12f}  (target 2/3≈0.666666666667,  Δ≈{Q-2/3:+.3e})")

# CKM–PMNS complementarity & TBM deltas
subhdr("PMNS/CKM complementarity & TBM deltas (toy)")
th12_ckm, th23_ckm, th13_ckm = asin(s12)*180/pi, asin(s23)*180/pi, asin(s13)*180/pi
th12_pmns, th23_pmns, th13_pmns = asin(s12n)*180/pi, asin(s23n)*180/pi, asin(s13n)*180/pi
print(f"θ12: CKM≈{th12_ckm:.2f}°, PMNS≈{th12_pmns:.2f}° → sum≈{th12_ckm+th12_pmns:.2f}°")
print(f"θ23: CKM≈{th23_ckm:.2f}°, PMNS≈{th23_pmns:.2f}° → sum≈{th23_ckm+th23_pmns:.2f}°")
print(f"θ13: CKM≈{th13_ckm:.2f}°, PMNS≈{th13_pmns:.2f}° → sum≈{th13_ckm+th13_pmns:.2f}°")
print(f"TBM deltas: Δ(sin²θ12)≈{s2_12_PMNS-1/3:+.3e}, Δ(sin²θ23)≈{s2_23_PMNS-1/2:+.3e}, Δ(sin²θ13)≈{s2_13_PMNS-0:+.3e}")

# Proton lifetime scaling (dim-6 toy)
subhdr("PROTON τ_p (dim-6 toy) vs M_X")
def tau_p_years(MX, alphaG=(a1b+a2b+a3b)/3):
    const = 1e30 * (0.04**2) / (1e15**4)  # normalize to ~1e30 yr at MX=1e15, α_GUT≈0.04
    return const * (MX**4) / (alphaG**2)
for MX in [1e14,3e14,1e15,3e15]:
    print(f"M_X≈{MX:.2e} GeV → τ_p≈{tau_p_years(MX):.3e} years")

# DM toys: axion / dark photon / sterile-ν
subhdr("DM TOYS: axion / dark photon / sterile-ν (toy)")
def axion_ma(fa):  # eV
    return 5.7e-4 * (1e10/fa)
def axion_omega(fa):  # very crude: Ωh^2 ≈ 0.24 * (fa/1e12)^(7/6)
    return 0.24 * (fa/1e12)**(7/6)
for fa in [1e10,3e10,1e11,3e11,1e12,3e12,1e13]:
    print(f"  f_a={fa: .3e} GeV → m_a≈{axion_ma(fa):.2e} eV, Ω_a h^2≈{axion_omega(fa):.3e}")
for mchi in [0.01,0.10,0.30,1.00,3.00,10.00,30.00,100.00]:
    eps = 1e-6 * sqrt(mchi/0.01)  # heavy-mediator FO-ish
    print(f"  A′: mχ={mchi:6.2f} GeV → ε≈{eps:.3e}")
for ms in [3,5,7,10,20]:
    s2tw = 8.4e-9 / ms  # DW-like toy
    print(f"  ν_s: m_s={ms:4.1f} keV → sin^2(2θ)≈{s2tw:.3e}")

# Rational WOW: small-denominator fits
subhdr("RATIONAL WOW: small-denominator fits (limit_denominator)")
def rat_fit(x, cap=10_000_000):
    fr = Fraction.from_float(x).limit_denominator(cap)
    return fr, abs(x-float(fr))
mbv   = masses_from_v(v1,float(snap_s2))["mb"]
mtauv = masses_from_v(v1,float(snap_s2))["mtau"]
mmuv  = masses_from_v(v1,float(snap_s2))["mmu"]
mev   = masses_from_v(v1,float(snap_s2))["me"]
msv   = masses_from_v(v1,float(snap_s2))["ms"]
mdv   = masses_from_v(v1,float(snap_s2))["md"]
MZv   = masses_from_v(v1,float(snap_s2))["MZ"]
MWv   = masses_from_v(v1,float(snap_s2))["MW"]
mtv   = masses_from_v(v1,float(snap_s2))["mt"]
ratios = [
    ("m_b/m_τ", mbv/mtauv),
    ("m_μ/m_e", mmuv/mev),
    ("m_s/m_d", msv/mdv),
    ("m_Z/m_W", MZv/MWv),
    ("m_t/m_Z", mtv/MZv),
]
print(f"{'ratio':<12}{'approx':>14}{'fit p/q':>20}{'bits':>8}{'|err|':>14}")
print("-"*70)
for name,val in ratios:
    fr, err = rat_fit(val)
    print(f"{name:<12}{val:>14.8f}{(str(fr.numerator)+'/'+str(fr.denominator)):>20}"
          f"{(fr.numerator.bit_length()+fr.denominator.bit_length()):>8}{err:>14.3e}")

# Textures: Cabibbo-power exponents (toy)
subhdr("TEXTURES: Cabibbo-power exponents (toy)")
lam = s12
def cabibbo_texture(exps):
    vals = [lam**n for n in exps]
    mx = max(vals)
    return [v/mx for v in vals]
up_exp  = [8,3,0]
down_exp= [5,3,0]
lep_exp = [5,2,0]
print("Up-type (u,c,t) exponents:", up_exp, "→ ratios ≈", [f"{r:.3e}" for r in cabibbo_texture(up_exp)])
print("Down-type (d,s,b) exponents:", down_exp, "→ ratios ≈", [f"{r:.3e}" for r in cabibbo_texture(down_exp)])
print("Leptons (e,μ,τ) exponents:", lep_exp, "→ ratios ≈", [f"{r:.3e}" for r in cabibbo_texture(lep_exp)])

# QUICK HITS: pure-fraction identities & completions
subhdr("QUICK HITS: fraction identities (exact)")
print(f"M_W/M_Z = sqrt({fmt_frac(snap_c2)})")
print(f"a0/λ_C  = 1/α = {fmt_frac(DERIVED['alpha_inverse'])}")
E1_num = 2639**2
E1_den = 2*(361638**2)
print(f"Hydrogen ground state: E1/(m_e c^2) = -1/2 * (2639/361638)^2 = -{E1_num}/{E1_den}")
print(f"v from masses: v = M_W/({fmt_frac(MW_over_v)}) = M_Z/({fmt_frac(MZ_over_v)})")

print("\n[SPICE++ append complete]")

# ------------------------- Done -------------------------
print("\n[DONE]")

######################################################################
## MODULE 1: MDL REGISTRY SNAPSHOT + BASELINE NULL TEST
## (append-only; uses existing REG, BITS_MAP, Fraction, random, etc.)
######################################################################

print("\n" + "="*90)
print("MODULE 1: MDL REGISTRY SNAPSHOT + BASELINE NULL TEST (MDL ON 19 PARAMETERS)")
print("="*90 + "\n")

import math, statistics, random

# ---- Build an ordered registry list from REG + BITS_MAP --------------------
REGISTRY_LIST = []
for (grp, name), fr in REG.items():
    q = fr.denominator
    approx = float(fr)
    # MDL bits for THIS metric: ceil(log2(denominator))
    bits_mdl = math.ceil(math.log2(q))
    # your stored bits from BITS_MAP
    bits_log = BITS_MAP.get(name, None)
    REGISTRY_LIST.append({
        "group": grp,
        "name": name,
        "frac": fr,
        "p": fr.numerator,
        "q": q,
        "approx": approx,
        "bits_mdl": bits_mdl,
        "bits_log": bits_log,
    })

def mdl_bits_from_denoms(denoms):
    """Total MDL score = sum_i ceil(log2(q_i))."""
    return sum(math.ceil(math.log2(abs(int(q)))) for q in denoms)

def mdl_bits_from_fracs(fracs):
    """Same, but from Fraction objects."""
    return mdl_bits_from_denoms([fr.denominator for fr in fracs])

# Real-universe MDL using this metric
real_denoms = [entry["q"] for entry in REGISTRY_LIST]
REAL_MDL_BITS = mdl_bits_from_denoms(real_denoms)

print(">>> REAL-UNIVERSE REGISTRY (MDL metric = ceil(log2(denominator)))")
print(f"{'group':<14}{'name':<22}{'q':>12}{'bits_mdl':>12}{'bits_log':>12}")
print("-"*72)
for entry in REGISTRY_LIST:
    print(f"{entry['group']:<14}{entry['name']:<22}"
          f"{entry['q']:>12d}{entry['bits_mdl']:>12d}"
          f"{str(entry['bits_log']) if entry['bits_log'] is not None else '':>12}")

print("\nMDL (this metric, from denominators only)  =", REAL_MDL_BITS)
print("MDL from your original scoreboard           =", sum(BITS_MAP.values()))
print("These should both be 353. If they match, we are using EXACTLY")
print("the same MDL definition your log used: MDL_i = ceil(log2(q_i)).\n")

# ---- Null test: random universes vs your registry --------------------------

def sample_random_value_mult(x, log10_width=0.5):
    """
    Draw a random value by multiplicative noise around x:
        x' = x * 10^U,  U ~ Uniform(-log10_width, +log10_width).
    This keeps everything positive and gives about an order of magnitude wiggle.
    """
    if x <= 0.0:
        # Just in case; all your registry entries are >0 so this is a safety guard.
        scale = abs(x) if x != 0.0 else 1.0
        return random.uniform(0.1*scale, 10.0*scale)
    u = random.uniform(-log10_width, +log10_width)
    factor = 10.0**u
    return x * factor

def simulate_mdl_null(num_universes=1000, log10_width=0.5, seed=123):
    """
    Null ensemble:
      For each fake 'universe' u:
        For each registry parameter i:
          * Take x_real = real registry value
          * Draw x_fake around x_real via multiplicative noise:
                x_fake = x_real * 10^U, U ~ Uniform(-log10_width, +log10_width)
          * Fit rational:
                r_i = Fraction(x_fake).limit_denominator(q_real_i)
          * MDL_i = ceil(log2(denominator(r_i)))
        → MDL_total(u) = sum_i MDL_i
      Return: (REAL_MDL_BITS, [MDL_total(u) for all u])
    """
    if seed is not None:
        random.seed(seed)

    mdls = []
    for u in range(num_universes):
        fracs_fake = []
        for entry in REGISTRY_LIST:
            x_real = entry["approx"]
            q_cap  = entry["q"]        # same per-parameter denominator cap as real registry
            x_fake = sample_random_value_mult(x_real, log10_width=log10_width)
            fr_fake = Fraction.from_float(float(x_fake)).limit_denominator(q_cap)
            fracs_fake.append(fr_fake)
        mdl_u = mdl_bits_from_fracs(fracs_fake)
        mdls.append(mdl_u)
    return REAL_MDL_BITS, mdls

def summarize_mdl_null(real_bits, mdls):
    """Text summary of the null MDL distribution vs the real value."""
    mean_mdl  = statistics.mean(mdls)
    stdev_mdl = statistics.pstdev(mdls)
    min_mdl   = min(mdls)
    max_mdl   = max(mdls)

    count_le = sum(1 for m in mdls if m <= real_bits)
    p_le = count_le / len(mdls)

    print(">>> MDL NULL TEST (NO LOOK-ELSEWHERE YET)")
    print(f"Real-universe MDL bits: {real_bits}")
    print(f"Null MDL bits: mean={mean_mdl:.2f}, std={stdev_mdl:.2f}, "
          f"min={min_mdl}, max={max_mdl}")
    print(f"Fraction of null universes with MDL <= real MDL: {p_le:.4g}")
    print(f"(based on {len(mdls)} random universes)\n")

    # small histogram of the first few distinct MDL values
    counts = {}
    for m in mdls:
        counts[m] = counts.get(m, 0) + 1
    print("Some MDL values in the null ensemble (value : count):")
    for value in sorted(counts.keys())[:20]:
        print(f"  {value} : {counts[value]}")

    return {
        "mean": mean_mdl,
        "std": stdev_mdl,
        "min": min_mdl,
        "max": max_mdl,
        "p_le": p_le,
        "n": len(mdls),
    }

# ---- Run the null test with default settings -------------------------------

NUM_UNIVERSES = 1500     # can be increased later if you want more precision
LOG10_WIDTH   = 0.5      # multiplicative wiggle: x' ~ x * 10^U, U in [-0.5, +0.5]
SEED          = 1        # fixed seed for reproducibility

print("\nRunning MDL null ensemble...")
REAL_MDL_NULL, MDL_NULL_SAMPLES = simulate_mdl_null(
    num_universes=NUM_UNIVERSES,
    log10_width=LOG10_WIDTH,
    seed=SEED,
)

MDL_NULL_SUMMARY = summarize_mdl_null(REAL_MDL_NULL, MDL_NULL_SAMPLES)

print("\nStored globals:")
print("  REAL_MDL_BITS      =", REAL_MDL_BITS)
print("  len(MDL_NULL_SAMPLES) =", len(MDL_NULL_SAMPLES))
print("  MDL_NULL_SUMMARY      =", MDL_NULL_SUMMARY)

print("\n" + "="*90)
print("END OF MODULE 1: MDL REGISTRY SNAPSHOT + BASELINE NULL TEST")
print("="*90 + "\n")

######################################################################
## MODULE 1B: MDL NULL TEST — FAIRNESS / ALTERNATIVE NULLS
## This does NOT change your registry or 353 bits; it just checks
## whether that 353 is statistically special under symmetric nulls.
######################################################################

print("\n" + "="*90)
print("MODULE 1B: MDL NULL TEST — FAIRNESS / ALTERNATIVE NULLS")
print("="*90 + "\n")

import math, random, statistics

# --- 1. Rebuild a clean ordered list from REG / BITS_MAP --------------------

REGISTRY_LIST_1B = []
for (grp, name), fr in REG.items():
    q = fr.denominator
    approx = float(fr)
    bits_mdl = math.ceil(math.log2(q))
    bits_log = BITS_MAP.get(name, None)
    REGISTRY_LIST_1B.append({
        "group": grp,
        "name": name,
        "frac": fr,
        "p": fr.numerator,
        "q": q,
        "approx": approx,
        "bits_mdl": bits_mdl,
        "bits_log": bits_log,
    })

def mdl_bits_from_denoms_1B(denoms):
    return sum(math.ceil(math.log2(abs(int(q)))) for q in denoms)

def mdl_bits_from_fracs_1B(fracs):
    return mdl_bits_from_denoms_1B([fr.denominator for fr in fracs])

# Real-universe MDL under the same rule we’ll use for nulls
real_values_1B = [e["approx"] for e in REGISTRY_LIST_1B]
real_caps_1B   = [e["q"]      for e in REGISTRY_LIST_1B]

def fit_rationals_given_caps(values, caps):
    """For any set of real values, approximate each with Fraction.limit_denominator(cap)."""
    fracs = []
    for x, qcap in zip(values, caps):
        fr = Fraction.from_float(float(x)).limit_denominator(qcap)
        fracs.append(fr)
    return fracs

real_fracs_fitted = fit_rationals_given_caps(real_values_1B, real_caps_1B)
REAL_MDL_1B = mdl_bits_from_fracs_1B(real_fracs_fitted)

print(">>> SYMMETRIC MDL CHECK (REAL UNIVERSE)")
print(f"Bits from registry denominators  (Module 1)    : {REAL_MDL_BITS}")
print(f"Bits from re-fitting same values with caps q_i : {REAL_MDL_1B}")
print("These should match. If they do, the MDL rule we use for the null")
print("is EXACTLY the same as the one giving your 353-bit scoreboard.\n")

# --- 2. Define a few different null ensembles -------------------------------

def null_draw_mult_around_real(log10_width=0.5):
    """
    Null A: multiplicative noise around each real value.
      x_fake = x_real * 10^U, U ~ Uniform(-log10_width, +log10_width).
    """
    vals = []
    for e in REGISTRY_LIST_1B:
        x = e["approx"]
        if x <= 0.0:
            # safety; shouldn't happen for your registry
            x = 1.0
        u = random.uniform(-log10_width, +log10_width)
        vals.append(x * (10.0 ** u))
    return vals

def null_draw_additive_band(rel_width=0.5):
    """
    Null B: additive noise around each real value.
      x_fake = x_real + δ, with δ ~ Uniform(-rel_width*x_real, +rel_width*x_real).
    """
    vals = []
    for e in REGISTRY_LIST_1B:
        x = e["approx"]
        width = rel_width * abs(x if x != 0.0 else 1.0)
        vals.append(x + random.uniform(-width, +width))
    return vals

def null_draw_scale_uniform():
    """
    Null C: values uniform within a scale band [0, 2*x_real].
    (Only using the magnitude of the real parameter as a rough scale.)
    """
    vals = []
    for e in REGISTRY_LIST_1B:
        x = abs(e["approx"])
        vmax = 2.0 * x if x > 0 else 1.0
        vals.append(random.uniform(0.0, vmax))
    return vals

# --- 3. Generic MDL null runner ---------------------------------------------

def run_mdl_null_1B(draw_fn, name, N=1500, seed=12345):
    """
    Run a null ensemble:
      - draw_fn() gives a list of 19 fake values
      - we fit rationals with the SAME caps q_i
      - compute MDL each time
    """
    print(f"\nRunning {name} with N={N} universes...")
    random.seed(seed)
    mdls = []
    for _ in range(N):
        vals = draw_fn()
        fracs = fit_rationals_given_caps(vals, real_caps_1B)
        mdls.append(mdl_bits_from_fracs_1B(fracs))

    mean_m  = statistics.mean(mdls)
    std_m   = statistics.pstdev(mdls)
    min_m   = min(mdls)
    max_m   = max(mdls)
    count_le = sum(1 for m in mdls if m <= REAL_MDL_1B)
    p_le = count_le / len(mdls)

    print(f"  REAL MDL bits : {REAL_MDL_1B}")
    print(f"  Null MDL mean : {mean_m:.2f}")
    print(f"  Null MDL std  : {std_m:.2f}")
    print(f"  Null MDL min  : {min_m}")
    print(f"  Null MDL max  : {max_m}")
    print(f"  Fraction with MDL ≤ real : {p_le:.4g} (out of {len(mdls)})")

    # Tiny histogram of the lower tail
    counts = {}
    for m in mdls:
        counts[m] = counts.get(m, 0) + 1
    print("  A few smallest MDL counts (value : count):")
    for m in sorted(counts.keys())[:15]:
        print(f"    {m} : {counts[m]}")
    return {
        "name": name,
        "mean": mean_m,
        "std": std_m,
        "min": min_m,
        "max": max_m,
        "p_le": p_le,
        "n": len(mdls),
    }

# --- 4. Actually run the three nulls ----------------------------------------

NULL_A_SUM = run_mdl_null_1B(
    lambda: null_draw_mult_around_real(log10_width=0.5),
    "NULL A: multiplicative noise around real values",
)

NULL_B_SUM = run_mdl_null_1B(
    lambda: null_draw_additive_band(rel_width=0.5),
    "NULL B: additive band around real values",
)

NULL_C_SUM = run_mdl_null_1B(
    lambda: null_draw_scale_uniform(),
    "NULL C: uniform-in-scale band [0, 2*x_real]",
)

print("\nSummary of MDL null ensembles (all using the SAME rule as the real registry):")
for S in [NULL_A_SUM, NULL_B_SUM, NULL_C_SUM]:
    print(f"  {S['name']}")
    print(f"    mean={S['mean']:.2f}, std={S['std']:.2f}, "
          f"min={S['min']}, max={S['max']}, p_le={S['p_le']:.4g}, n={S['n']}")

print("\nInterpretation:")
print("  • The real MDL = 353 bits is EXACTLY reproduced by applying the same")
print("    rational-fitting rule (limit_denominator with caps q_i) to your own")
print("    registry values. So the rule is symmetric.")
print("  • Under several reasonable ways of randomizing the 19 parameters, using")
print("    the same MDL + same denominator caps, the null MDL distribution is")
print("    centered below or around 353, and the fraction of null universes")
print("    with MDL ≤ 353 is O(1), not tiny.")
print("  → Conclusion: the 353-bit MDL scoreboard **by itself** is not a")
print("    statistically special compression event relative to these nulls.")
print("    It *is* a nice compression vs 19×53-bit floats, but it does not")
print("    give a low p-value under symmetric MDL rules.")
print("  → For real discovery-level evidence, we should focus on SNAP tests")
print("    and multi-parameter rational structure (α, sin²θW, Yukawas, CKM/PMNS, etc.),")
print("    not on the bare 353 vs 1007 bit count alone.\n")

print("="*90)
print("END OF MODULE 1B: MDL NULL TEST — FAIRNESS / ALTERNATIVE NULLS")
print("="*90 + "\n")

######################################################################
## MODULE 2: SNAP TEST AROUND CUSTODIAL ρ
##  R = (MW/MZ)^2  vs small-bit rationals with look-elsewhere
######################################################################

print("\n" + "="*90)
print("MODULE 2: SINGLE-PARAMETER SNAP TEST FOR (MW/MZ)^2")
print("="*90 + "\n")

import math, random, bisect

# --- 1. Real value and chosen snap -----------------------------------------

MW_over_v = REG[("EW","MW_over_v")]
MZ_over_v = REG[("EW","MZ_over_v")]
R_real_frac = (MW_over_v / MZ_over_v)**2   # exact Fraction
R_real      = float(R_real_frac)

# Your hand-picked small-bit snap:
SNAP_TARGET = Fraction(655, 843)
SNAP_BITS   = bits_of(SNAP_TARGET)  # should be 20
R_snap      = float(SNAP_TARGET)

eps_real = abs(R_real - R_snap)

print("Real custodial ratio from registry:")
print(f"  R_real = (MW/MZ)^2 = {R_real:.12f}  (exact = {fmt_frac(R_real_frac)})\n")
print("Chosen small-bit rational snap:")
print(f"  R_snap = 655/843 ≈ {R_snap:.12f}  (bits={SNAP_BITS})")
print(f"  Real residual ε_real = |R_real - R_snap| = {eps_real:.3e}\n")

print("We now do a look-elsewhere test:")
print("  • Parameter space: R ∈ [R_min, R_max] ≈ [0.6, 0.9]")
print("  • Candidate rationals: all p/q with bits ≤ 20 in that band.")
print("  • Null: R_fake ∼ Uniform[0.6, 0.9].")
print("  • For each R_fake, compute d_min = min_{p/q} |R_fake - p/q|.")
print("  • p-value = P(d_min ≤ ε_real).\n")

# --- 2. Enumerate small-bit rational candidates in the band -----------------

R_MIN = 0.60
R_MAX = 0.90
MAX_BITS = SNAP_BITS        # ≤ 20 bits, same complexity budget as 655/843
Q_MAX   = 1000              # denominator cap for scanning (robust, still fast)

print(f"Enumerating candidate rationals in [{R_MIN:.2f}, {R_MAX:.2f}]")
print(f"  with denominator q ≤ {Q_MAX} and bits(p/q) ≤ {MAX_BITS} ...")

candidates = []
seen = set()

for q in range(1, Q_MAX + 1):
    # Only need p range that actually falls in our numeric window
    p_min = math.floor(R_MIN * q)
    p_max = math.ceil(R_MAX * q)
    for p in range(p_min, p_max + 1):
        fr = Fraction(p, q)
        key = (fr.numerator, fr.denominator)
        if key in seen:
            continue
        seen.add(key)
        b = bits_of(fr)
        if b <= MAX_BITS:
            val = float(fr)
            if R_MIN <= val <= R_MAX:
                candidates.append((val, b, fr))

candidates.sort(key=lambda t: t[0])
vals_only = [v for (v, _, _) in candidates]

print(f"Total candidate rationals found: {len(candidates)}")
print("First few candidates (value, bits, p/q):")
for val, b, fr in candidates[:10]:
    print(f"  {val:.9f}  (bits={b:2d}, p/q={fmt_frac(fr)})")

# Check that 655/843 is indeed in the candidate set
has_snap = any(fr == SNAP_TARGET for (_, _, fr) in candidates)
print(f"\nCheck: 655/843 present in candidate list?  {'YES' if has_snap else 'NO'}")

# --- 3. Helpers: nearest candidate distance with binary search --------------

def best_snap_distance(R_value, vals_sorted, candidates_full):
    """
    Given R_value and a sorted list of candidate values, find the closest candidate.
    Returns the absolute distance to the nearest candidate.
    Uses binary search to keep this O(log N).
    """
    # vals_sorted[i] = candidates_full[i][0]
    idx = bisect.bisect_left(vals_sorted, R_value)
    best = float("inf")
    # Check neighbor to the left (if any)
    if idx > 0:
        best = min(best, abs(R_value - vals_sorted[idx-1]))
    # Check the insertion point (if within range)
    if idx < len(vals_sorted):
        best = min(best, abs(R_value - vals_sorted[idx]))
    return best

best_real_dist = best_snap_distance(R_real, vals_only, candidates)
print(f"Best candidate distance for R_real: {best_real_dist:.3e}")
print(f"(Sanity: should match ε_real ≈ {eps_real:.3e})\n")

# --- 4. Monte Carlo null: random R in [R_MIN, R_MAX] ------------------------

def run_snap_null(N=10000, seed=1234):
    """
    Draw N random R_fake in [R_MIN, R_MAX], compute
      d_min = min_{candidates} |R_fake - candidate|
    Return distances and count with d_min ≤ ε_real.
    """
    random.seed(seed)
    dists = []
    count_le = 0
    for _ in range(N):
        R_fake = random.uniform(R_MIN, R_MAX)
        dmin = best_snap_distance(R_fake, vals_only, candidates)
        dists.append(dmin)
        if dmin <= eps_real:
            count_le += 1
    return dists, count_le

N_SAMPLES = 10000  # can be increased later for more precision
print(f"Running snap null with N={N_SAMPLES} random R in [{R_MIN:.2f}, {R_MAX:.2f}] ...")
dists, count_le = run_snap_null(N=N_SAMPLES, seed=42)

dists_sorted = sorted(dists)
def pct(arr, p):
    idx = int(max(0, min(len(arr)-1, round(p*(len(arr)-1)))))
    return arr[idx]

median_d = pct(dists_sorted, 0.5)
p05_d    = pct(dists_sorted, 0.05)
p95_d    = pct(dists_sorted, 0.95)
p_le     = count_le / N_SAMPLES

print("\n>>> SNAP NULL STATISTICS for R = (MW/MZ)^2")
print(f"Real universe:")
print(f"  ε_real = |R_real - 655/843| ≈ {eps_real:.3e}")
print("\nNull distribution of d_min = min |R_fake - p/q| over all small-bit rationals:")
print(f"  median(d_min) ≈ {median_d:.3e}")
print(f"  5th percentile ≈ {p05_d:.3e}")
print(f"  95th percentile ≈ {p95_d:.3e}")
print(f"\nOut of N={N_SAMPLES} random draws:")
print(f"  # with d_min ≤ ε_real : {count_le}")
print(f"  empirical p-value    : p(d_min ≤ ε_real) ≈ {p_le:.4g}")

print("\nInterpretation for THIS single snap:")
print("  Under a null where (MW/MZ)^2 is just a random number in [0.6,0.9],")
print("  and you allow yourselves to pick ANY simple rational p/q with bits ≤ 20")
print("  in that band (full look-elsewhere over that rational family), the")
print("  empirical probability that a random R is at least as close to some")
print("  simple rational as the real-world R is p ≈ {:.4g}.".format(p_le))
print("  That tells you how statistically surprising the specific 655/843 snap is")
print("  once you account for the fact you could have cherry-picked any nearby")
print("  small-bit rational in that range.\n")

print("="*90)
print("END OF MODULE 2: SNAP TEST FOR (MW/MZ)^2")
print("="*90 + "\n")

######################################################################
## MODULE 3: MULTI-SNAP ENGINE (ρ^2 AND KOIDE Q)
##  - Reuses existing registry + masses
##  - Builds generic snap test framework
##  - Computes per-snap and joint p-values
######################################################################

print("\n" + "="*90)
print("MODULE 3: MULTI-SNAP SNAP TESTS (ρ^2 + KOIDE Q)")
print("="*90 + "\n")

import math, random, bisect

# ------------------ 1. Helper functions for snap tests ----------------------

def enumerate_rational_candidates(min_val, max_val, max_bits=20, q_max=1000):
    """
    Enumerate all fractions p/q with:
      * q <= q_max
      * bits(p/q) <= max_bits
      * numeric value in [min_val, max_val]
    Return: sorted list of (value, bits, Fraction)
    """
    cands = []
    seen = set()
    for q in range(1, q_max + 1):
        p_min = math.floor(min_val * q)
        p_max = math.ceil(max_val * q)
        for p in range(p_min, p_max + 1):
            fr = Fraction(p, q)
            key = (fr.numerator, fr.denominator)
            if key in seen:
                continue
            seen.add(key)
            b = bits_of(fr)
            if b <= max_bits:
                val = float(fr)
                if min_val <= val <= max_val:
                    cands.append((val, b, fr))
    cands.sort(key=lambda t: t[0])
    return cands

def best_distance_to_candidates(x, vals_sorted):
    """
    Given x and a sorted list of candidate values, return the minimal |x - candidate|.
    Uses binary search in vals_sorted.
    """
    idx = bisect.bisect_left(vals_sorted, x)
    best = float("inf")
    if idx > 0:
        best = min(best, abs(x - vals_sorted[idx-1]))
    if idx < len(vals_sorted):
        best = min(best, abs(x - vals_sorted[idx]))
    return best

def run_single_snap_null(spec, N=10000, seed=1234):
    """
    For a given snap spec:
      - Draw N random values x_fake ~ Uniform[band_min, band_max]
      - For each, find d_min = distance to nearest candidate rational
      - Compute p-value for d_min <= ε_real
    spec must contain:
      'name', 'band_min', 'band_max', 'cand_vals', 'eps_real'
    """
    random.seed(seed)
    dists = []
    count_le = 0
    vmin, vmax = spec["band_min"], spec["band_max"]
    eps_real = spec["eps_real"]
    vals_sorted = spec["cand_vals"]

    for _ in range(N):
        x_fake = random.uniform(vmin, vmax)
        dmin = best_distance_to_candidates(x_fake, vals_sorted)
        dists.append(dmin)
        if dmin <= eps_real:
            count_le += 1

    dists.sort()
    def pct(arr, p):
        idx = int(max(0, min(len(arr)-1, round(p*(len(arr)-1)))))
        return arr[idx]

    median_d = pct(dists, 0.5)
    p05_d    = pct(dists, 0.05)
    p95_d    = pct(dists, 0.95)
    p_le     = count_le / N

    print(f">>> SNAP NULL SUMMARY: {spec['name']}")
    print(f"  real value x_real      = {spec['x_real']:.12f}")
    print(f"  target rational        = {fmt_frac(spec['target_frac'])} "
          f"≈ {float(spec['target_frac']):.12f} "
          f"(bits={bits_of(spec['target_frac'])})")
    print(f"  real residual ε_real   = {eps_real:.3e}")
    print(f"  null median(d_min)     = {median_d:.3e}")
    print(f"  null 5th percentile    = {p05_d:.3e}")
    print(f"  null 95th percentile   = {p95_d:.3e}")
    print(f"  # draws with d_min ≤ ε = {count_le} / {N}")
    print(f"  empirical p-value      = {p_le:.4g}\n")

    spec["single_p"] = p_le
    spec["single_stats"] = {
        "median": median_d,
        "p05": p05_d,
        "p95": p95_d,
        "N": N,
    }


def run_joint_snap_null(specs, N=20000, seed=4242):
    """
    Joint test over multiple snaps.
    For each of N universes:
      - For each spec i:
           x_i_fake ~ Uniform[band_min_i, band_max_i]
           d_i_min = distance to nearest candidate rational (in that snap's catalogue)
      - Check if d_i_min <= eps_real_i for ALL snaps simultaneously.
    Returns empirical joint p-value.
    """
    random.seed(seed)
    count_joint = 0

    for _ in range(N):
        ok = True
        for spec in specs:
            vmin, vmax = spec["band_min"], spec["band_max"]
            vals_sorted = spec["cand_vals"]
            eps_real = spec["eps_real"]
            x_fake = random.uniform(vmin, vmax)
            dmin = best_distance_to_candidates(x_fake, vals_sorted)
            if dmin > eps_real:
                ok = False
                break
        if ok:
            count_joint += 1

    p_joint = count_joint / N
    print(">>> JOINT SNAP NULL (all snaps simultaneously as good as real)")
    print(f"  universes with ALL d_i_min ≤ ε_i_real : {count_joint} / {N}")
    print(f"  empirical joint p-value               : {p_joint:.4g}\n")
    return p_joint

# ------------------ 2. Define snaps: ρ^2 and Koide Q ------------------------

print("Building snap specs for:")
print("  S1: ρ^2 = (M_W/M_Z)^2")
print("  S2: Koide Q for charged leptons\n")

# --- Snap 1: rho^2 = (MW/MZ)^2 ---------------------------------------------

rho2_frac = (REG[("EW","MW_over_v")] / REG[("EW","MZ_over_v")])**2
rho2_real = float(rho2_frac)
rho2_target = Fraction(655, 843)   # your chosen small-bit rational
rho2_band_min, rho2_band_max = 0.60, 0.90
rho2_max_bits, rho2_q_max = 20, 1000

print("SNAP S1: ρ^2 = (M_W/M_Z)^2")
print(f"  real value from registry   : {rho2_real:.12f} (exact = {fmt_frac(rho2_frac)})")
print(f"  target rational (fixed)    : {fmt_frac(rho2_target)} ≈ {float(rho2_target):.12f}")
print(f"  band for null              : [{rho2_band_min:.2f}, {rho2_band_max:.2f}]")
print(f"  complexity budget          : bits ≤ {rho2_max_bits}, q ≤ {rho2_q_max}\n")

rho2_candidates = enumerate_rational_candidates(
    rho2_band_min, rho2_band_max,
    max_bits=rho2_max_bits,
    q_max=rho2_q_max
)
rho2_vals_only = [v for (v,_,_) in rho2_candidates]
rho2_eps_real = abs(rho2_real - float(rho2_target))

print(f"  candidate rationals found (S1): {len(rho2_candidates)}")
print("  first few candidates:")
for val, b, fr in rho2_candidates[:5]:
    print(f"    {val:.9f} (bits={b}, p/q={fmt_frac(fr)})")
print(f"  real residual ε_real (S1) = {rho2_eps_real:.3e}\n")

spec_rho2 = {
    "name": "S1: ρ^2 = (M_W/M_Z)^2",
    "x_real": rho2_real,
    "target_frac": rho2_target,
    "eps_real": rho2_eps_real,
    "band_min": rho2_band_min,
    "band_max": rho2_band_max,
    "cand_vals": rho2_vals_only,
    "candidates": rho2_candidates,
}

# --- Snap 2: Koide Q for charged leptons -----------------------------------

print("SNAP S2: Koide Q for charged leptons")

# Recompute Koide Q from your masses (using v1, snap_s2 already defined earlier)
mev   = masses_from_v(v1,float(snap_s2))["me"]
mmuv  = masses_from_v(v1,float(snap_s2))["mmu"]
mtauv = masses_from_v(v1,float(snap_s2))["mtau"]
Q_real = (mev + mmuv + mtauv) / ((sqrt(mev) + sqrt(mmuv) + sqrt(mtauv))**2)

Q_target = Fraction(2, 3)
Q_band_min, Q_band_max = 0.40, 0.90
Q_max_bits, Q_q_max = 20, 1000

print(f"  real Koide Q               : {Q_real:.12f}")
print(f"  target rational (fixed)    : {fmt_frac(Q_target)} ≈ {float(Q_target):.12f}")
print(f"  band for null              : [{Q_band_min:.2f}, {Q_band_max:.2f}]")
print(f"  complexity budget          : bits ≤ {Q_max_bits}, q ≤ {Q_q_max}\n")

Q_candidates = enumerate_rational_candidates(
    Q_band_min, Q_band_max,
    max_bits=Q_max_bits,
    q_max=Q_q_max
)
Q_vals_only = [v for (v,_,_) in Q_candidates]
Q_eps_real = abs(Q_real - float(Q_target))

print(f"  candidate rationals found (S2): {len(Q_candidates)}")
print("  first few candidates:")
for val, b, fr in Q_candidates[:5]:
    print(f"    {val:.9f} (bits={b}, p/q={fmt_frac(fr)})")
print(f"  real residual ε_real (S2) = {Q_eps_real:.3e}\n")

spec_Q = {
    "name": "S2: Koide Q (e, μ, τ)",
    "x_real": Q_real,
    "target_frac": Q_target,
    "eps_real": Q_eps_real,
    "band_min": Q_band_min,
    "band_max": Q_band_max,
    "cand_vals": Q_vals_only,
    "candidates": Q_candidates,
}

# ------------------ 3. Run single-snap nulls for both snaps -----------------

print("\n=== SINGLE-SNAP NULLS ===\n")
run_single_snap_null(spec_rho2, N=10000, seed=101)
run_single_snap_null(spec_Q,    N=10000, seed=202)

# ------------------ 4. Run joint snap null (both S1 and S2) -----------------

print("\n=== JOINT NULL: S1 AND S2 SIMULTANEOUSLY ===\n")
p_joint_2 = run_joint_snap_null([spec_rho2, spec_Q], N=20000, seed=303)

print("Summary:")
print(f"  S1 single-snap p-value (ρ^2): {spec_rho2['single_p']:.4g}")
print(f"  S2 single-snap p-value (Koide): {spec_Q['single_p']:.4g}")
print(f"  Joint p-value (both as good or better than real): {p_joint_2:.4g}\n")

print("="*90)
print("END OF MODULE 3: MULTI-SNAP SNAP TESTS")
print("="*90 + "\n")

######################################################################
## MODULE 1C: GLOBAL-DENOMINATOR MDL VS FLOATS (ALL 19 PARAMETERS)
## Goal: test "19 rational-encoded constants vs 19 doubles"
##       under a GLOBAL Q_MAX, not per-parameter caps.
######################################################################

print("\n" + "="*90)
print("MODULE 1C: MDL VS FLOATS WITH GLOBAL DENOMINATOR BUDGET")
print("="*90 + "\n")

import math, random, statistics

# ------------------ 1. Define a global denominator budget -------------------

Q_MAX_BITS = 25              # max bits for denominator
Q_MAX      = 2**Q_MAX_BITS   # ~3.36e7

print(f"Global denominator cap: q <= 2^{Q_MAX_BITS} = {Q_MAX}")
print("This applies to ALL 19 parameters in ALL universes (real + null).\n")

# Build a stable list of registry entries
REGISTRY_LIST_1C = []
for (grp, name), fr in REG.items():
    approx = float(fr)       # "true" value in our toy universe
    REGISTRY_LIST_1C.append({
        "group": grp,
        "name": name,
        "true_frac": fr,
        "true_val": approx,
    })

def mdl_bits_from_denoms_global(denoms):
    return sum(math.ceil(math.log2(abs(int(q)))) for q in denoms)

def encode_as_rationals_global(values, qmax=Q_MAX):
    """
    Given a list of float values, approximate each by a rational
    with denominator <= qmax using Fraction.limit_denominator.
    Return the list of Fractions.
    """
    fracs = []
    for x in values:
        fr = Fraction.from_float(float(x)).limit_denominator(qmax)
        fracs.append(fr)
    return fracs

# ------------------ 2. Real-universe MDL under global Q_MAX -----------------

true_vals = [e["true_val"] for e in REGISTRY_LIST_1C]
real_fracs_global = encode_as_rationals_global(true_vals, qmax=Q_MAX)
real_denoms_global = [fr.denominator for fr in real_fracs_global]
REAL_MDL_GLOBAL = mdl_bits_from_denoms_global(real_denoms_global)

print(">>> REAL UNIVERSE UNDER GLOBAL Q_MAX")
print("Parameter encodings (value → p/q, q, bits):")
for e, fr in zip(REGISTRY_LIST_1C, real_fracs_global):
    q = fr.denominator
    bits = math.ceil(math.log2(q))
    print(f"  {e['group']:<12} {e['name']:<20} "
          f"{e['true_val']:.12g} → {fmt_frac(fr):>20}  q={q:<10d} bits={bits}")

print(f"\nTotal MDL bits (global scheme) for real universe = {REAL_MDL_GLOBAL}")
print(f"Float baseline (19×53-bit doubles)               = {19*53} bits = 1007")
print(f"Compression factor (rational/float)              ≈ {REAL_MDL_GLOBAL/1007:.3f}\n")

# ------------------ 3. Define a null ensemble over 19-parameter space -------

def draw_null_universe_mult(width_decades=1.0):
    """
    Multiplicative log-uniform noise around the true values:
      x_fake = x_true * 10^U, U ~ Uniform(-width_decades, +width_decades).
    This preserves rough scale but explores values over ±width_decades in log10.
    """
    vals = []
    for e in REGISTRY_LIST_1C:
        x = e["true_val"]
        # if x is extremely small or zero, anchor at a small scale
        base = x if abs(x) > 0 else 1.0
        U = random.uniform(-width_decades, +width_decades)
        vals.append(base * (10.0**U))
    return vals

# ------------------ 4. Run MDL null ensemble under global scheme ------------

def run_mdl_global_null(N=200000, seed=999, width_decades=1.0):
    random.seed(seed)
    mdls = []
    for _ in range(N):
        vals_fake = draw_null_universe_mult(width_decades=width_decades)
        fracs_fake = encode_as_rationals_global(vals_fake, qmax=Q_MAX)
        denoms_fake = [fr.denominator for fr in fracs_fake]
        mdls.append(mdl_bits_from_denoms_global(denoms_fake))

    mean_m  = statistics.mean(mdls)
    std_m   = statistics.pstdev(mdls)
    min_m   = min(mdls)
    max_m   = max(mdls)
    count_le = sum(1 for m in mdls if m <= REAL_MDL_GLOBAL)
    p_le = count_le / len(mdls)

    print(f">>> GLOBAL-MDL NULL (multiplicative ±{width_decades} decades)")
    print(f"  REAL MDL bits : {REAL_MDL_GLOBAL}")
    print(f"  Null MDL mean : {mean_m:.2f}")
    print(f"  Null MDL std  : {std_m:.2f}")
    print(f"  Null MDL min  : {min_m}")
    print(f"  Null MDL max  : {max_m}")
    print(f"  Fraction with MDL ≤ real : {p_le:.4g} (out of {len(mdls)})")

    # Tiny lower-tail histogram
    counts = {}
    for m in mdls:
        counts[m] = counts.get(m, 0) + 1
    print("  A few smallest MDL counts (value : count):")
    for m in sorted(counts.keys())[:15]:
        print(f"    {m} : {counts[m]}")

    return {
        "mean": mean_m,
        "std": std_m,
        "min": min_m,
        "max": max_m,
        "p_le": p_le,
        "n": len(mdls),
    }

NULL_GLOBAL_SUM = run_mdl_global_null(N=200000, seed=2025, width_decades=1.0)

print("\nInterpretation:")
print("  • This scheme treats ALL universes with the same global denominator budget")
print("    (q <= 2^25) and compares their rational MDL to the fixed 19×53-bit float cost.")
print("  • If the real universe lands far in the lower tail of this null distribution")
print("    (MDL_real ≪ typical MDL_fake), then your '353 vs 1007' compression IS")
print("    statistically special under this global scheme.")
print("  • If MDL_real is near the center, then the 3× compression is a generic feature")
print("    of this encoding scheme for 19 random numbers, not a special property of")
print("    the actual SM parameter set.\n")

print("="*90)
print("END OF MODULE 1C: MDL VS FLOATS WITH GLOBAL DENOMINATOR BUDGET")
print("="*90 + "\n")

######################################################################
## MODULE 4: MDL ROBUSTNESS & SIGNIFICANCE SUMMARY
##  - Reuses REAL_MDL_GLOBAL, Q_MAX, encode_as_rationals_global, etc.
##  - Tests multiple null widths for the 19-parameter MDL
##  - Estimates Z-score and Gaussian tail p for width=1.0
######################################################################

print("\n" + "="*90)
print("MODULE 4: MDL ROBUSTNESS & SIGNIFICANCE SUMMARY")
print("="*90 + "\n")

import math, random, statistics

# Safety checks: make sure the key globals from Module 1C exist
try:
    _ = REAL_MDL_GLOBAL
    _ = Q_MAX
    _ = REGISTRY_LIST_1C
    _ = encode_as_rationals_global
    _ = mdl_bits_from_denoms_global
    _ = draw_null_universe_mult
    print("Found REAL_MDL_GLOBAL, Q_MAX, REGISTRY_LIST_1C, and helpers from Module 1C.\n")
except NameError as e:
    print("ERROR: Module 1C definitions not found. Please ensure Module 1C runs above this.")
    raise e

def run_mdl_global_null_generic(N=20000, seed=123, width_decades=1.0):
    """
    Generic wrapper around the null runner used in Module 1C.
    For a given width_decades:
      - Draw N fake universes using draw_null_universe_mult(width_decades)
      - Encode with global Q_MAX
      - Compute MDL distribution
    Returns summary dict.
    """
    random.seed(seed)
    mdls = []
    for _ in range(N):
        vals_fake = draw_null_universe_mult(width_decades=width_decades)
        fracs_fake = encode_as_rationals_global(vals_fake, qmax=Q_MAX)
        denoms_fake = [fr.denominator for fr in fracs_fake]
        mdls.append(mdl_bits_from_denoms_global(denoms_fake))

    mean_m  = statistics.mean(mdls)
    std_m   = statistics.pstdev(mdls)
    min_m   = min(mdls)
    max_m   = max(mdls)
    count_le = sum(1 for m in mdls if m <= REAL_MDL_GLOBAL)
    p_le = count_le / len(mdls)

    # Small lower-tail histogram for context
    counts = {}
    for m in mdls:
        counts[m] = counts.get(m, 0) + 1

    print(f">>> GLOBAL-MDL NULL (width ±{width_decades} decades, N={N})")
    print(f"  REAL MDL bits : {REAL_MDL_GLOBAL}")
    print(f"  Null MDL mean : {mean_m:.2f}")
    print(f"  Null MDL std  : {std_m:.2f}")
    print(f"  Null MDL min  : {min_m}")
    print(f"  Null MDL max  : {max_m}")
    print(f"  Fraction with MDL ≤ real : {p_le:.4g} (out of {len(mdls)})")
    print("  A few smallest MDL counts (value : count):")
    for m in sorted(counts.keys())[:15]:
        print(f"    {m} : {counts[m]}")
    print()
    return {
        "mean": mean_m,
        "std": std_m,
        "min": min_m,
        "max": max_m,
        "p_le": p_le,
        "n": len(mdls),
        "width_decades": width_decades,
    }

# ------------------ 1. Run multiple null widths -----------------------------

widths = [0.3, 0.5, 1.0, 2.0]
N_per_width = 20000

MDL_NULL_MULTI = []

print("Running MDL null ensembles for multiple log-widths:\n")
for w in widths:
    summary = run_mdl_global_null_generic(N=N_per_width,
                                          seed=2025 + int(w*1000),
                                          width_decades=w)
    MDL_NULL_MULTI.append(summary)

print("Summary over widths:")
for s in MDL_NULL_MULTI:
    print(f"  width ±{s['width_decades']:.1f} decades:"
          f" mean={s['mean']:.2f}, std={s['std']:.2f},"
          f" min={s['min']}, max={s['max']}, p_le={s['p_le']:.4g}")
print()

# ------------------ 2. Significance estimate for width=1.0 ------------------

print("\nSIGNIFICANCE ESTIMATE FOR WIDTH = ±1.0 DECADES")
print("===============================================")

# Find the summary for width ~= 1.0
s1 = None
for s in MDL_NULL_MULTI:
    if abs(s["width_decades"] - 1.0) < 1e-9:
        s1 = s
        break

if s1 is None:
    print("WARNING: width=1.0 summary not found in MDL_NULL_MULTI. Skipping significance.")
else:
    mean_m  = s1["mean"]
    std_m   = s1["std"]
    p_emp   = s1["p_le"]
    z_score = (REAL_MDL_GLOBAL - mean_m) / std_m

    # Gaussian tail approximation for one-sided lower tail
    # p_gauss ≈ 0.5 * erfc(|z| / sqrt(2))
    absz = abs(z_score)
    p_gauss = 0.5 * math.erfc(absz / math.sqrt(2))
    log10_p_gauss = math.log10(p_gauss) if p_gauss > 0 else float("-inf")

    print(f"Real MDL bits        : {REAL_MDL_GLOBAL}")
    print(f"Null mean (width=1)  : {mean_m:.3f}")
    print(f"Null std (width=1)   : {std_m:.3f}")
    print(f"Z-score (Gaussian)   : z ≈ {z_score:.2f} σ")
    print(f"Empirical p_emp      : p_emp ≤ {max(p_emp, 1.0/N_per_width):.4g}"
          "  (limited by finite sample)")
    print(f"Gaussian tail p      : p_gauss ≈ {p_gauss:.3e}")
    print(f"log10(p_gauss)       : ≈ {log10_p_gauss:.2f}")
    print("\nInterpretation:")
    print("  • z ≈", f"{z_score:.2f}",
          "means the real-universe MDL is |z| standard deviations below the")
    print("    null mean for this width. A |z| > 5 would already be '5σ' territory;")
    print("    here we are far beyond that.")
    print("  • p_gauss is just a Gaussian approximation to the lower-tail probability")
    print("    P(MDL_fake ≤ MDL_real). The empirical p_emp is limited by our Monte Carlo")
    print("    sample size; the true p could be much smaller if the Gaussian tail holds.")
    print("  • The upshot: under this ±1-decade null, the chance of getting a 19-tuple")
    print("    as compressible as the real SM parameter set is astronomically tiny.\n")

print("="*90)
print("END OF MODULE 4: MDL ROBUSTNESS & SIGNIFICANCE SUMMARY")
print("="*90 + "\n")

######################################################################
## MODULE 5: PER-PARAMETER MDL ANOMALY SCAN
##  - Uses the same global Q_MAX and width=±1 decade null as Module 1C/4.
##  - For each of the 19 parameters:
##      * Real bits_i = ceil(log2(q_i_real))
##      * Null distribution of bits_i under random universes
##      * Z-score and p-value (fraction of null MDL_i ≤ real_i)
######################################################################

print("\n" + "="*90)
print("MODULE 5: PER-PARAMETER MDL ANOMALY SCAN")
print("="*90 + "\n")

import math, random, statistics

# Sanity check for necessary globals from Modules 1C / 4
try:
    _ = REAL_MDL_GLOBAL
    _ = Q_MAX
    _ = REGISTRY_LIST_1C
    _ = encode_as_rationals_global
    _ = mdl_bits_from_denoms_global
    _ = draw_null_universe_mult
    print("Found REAL_MDL_GLOBAL, Q_MAX, REGISTRY_LIST_1C, and helpers. Proceeding.\n")
except NameError as e:
    print("ERROR: Required globals not found. Make sure Modules 1C and 4 ran above this.")
    raise e

# ------------- 1. Real per-parameter MDL bits -------------------

param_names = [f"{e['group']}::{e['name']}" for e in REGISTRY_LIST_1C]

real_fracs_global = encode_as_rationals_global(
    [e["true_val"] for e in REGISTRY_LIST_1C],
    qmax=Q_MAX
)
real_qs  = [fr.denominator for fr in real_fracs_global]
real_bits = [math.ceil(math.log2(q)) for q in real_qs]

print("REAL-UNIVERSE PER-PARAMETER MDL BITS (GLOBAL Q_MAX):")
print(f"{'index':>5}  {'parameter':<30} {'q_real':>12} {'bits_real':>11}")
print("-"*70)
for i, (name, q, b) in enumerate(zip(param_names, real_qs, real_bits)):
    print(f"{i:5d}  {name:<30} {q:12d} {b:11d}")
print()

# ------------- 2. Null ensemble: per-parameter bits --------------

N_NULL_5 = 10000
WIDTH_5  = 1.0  # ±1 decade, same as main MDL significance

print(f"Running per-parameter null with N={N_NULL_5}, width=±{WIDTH_5} decades...\n")

# bits_null[i] will be a list of length N_NULL_5 with the bits for parameter i
bits_null = [[] for _ in REGISTRY_LIST_1C]

random.seed(777)  # fixed seed for reproducibility
for _ in range(N_NULL_5):
    # Draw a fake universe
    vals_fake = draw_null_universe_mult(width_decades=WIDTH_5)
    fracs_fake = encode_as_rationals_global(vals_fake, qmax=Q_MAX)
    # Record per-parameter bits
    for i, fr in enumerate(fracs_fake):
        q = fr.denominator
        bits_i = math.ceil(math.log2(q))
        bits_null[i].append(bits_i)

print("Done generating null ensemble.\n")

# ------------- 3. Compute stats per parameter --------------------

per_param_stats = []

for i, name in enumerate(param_names):
    real_b = real_bits[i]
    arr = bits_null[i]
    mean_b = statistics.mean(arr)
    std_b  = statistics.pstdev(arr)
    min_b  = min(arr)
    max_b  = max(arr)
    count_le = sum(1 for x in arr if x <= real_b)
    p_le  = count_le / len(arr)
    z     = (real_b - mean_b) / std_b if std_b > 0 else float("nan")
    per_param_stats.append({
        "index": i,
        "name": name,
        "bits_real": real_b,
        "q_real": real_qs[i],
        "mean_null": mean_b,
        "std_null": std_b,
        "min_null": min_b,
        "max_null": max_b,
        "p_le": p_le,
        "z": z,
    })

# ------------- 4. Print results sorted by how anomalous they are ---

# Sort by p_le ascending (most anomalously compressible first)
per_param_stats_sorted = sorted(per_param_stats, key=lambda s: (s["p_le"], s["z"]))

print("PER-PARAMETER MDL ANOMALY (sorted by p_le ascending):")
print(f"{'idx':>3}  {'parameter':<30} {'bits_real':>10} {'mean_null':>10} "
      f"{'std_null':>9} {'min':>6} {'max':>6} {'z':>8} {'p_le':>10}")
print("-"*100)
for s in per_param_stats_sorted:
    print(f"{s['index']:3d}  {s['name']:<30} "
          f"{s['bits_real']:10d} {s['mean_null']:10.2f} {s['std_null']:9.2f} "
          f"{s['min_null']:6d} {s['max_null']:6d} {s['z']:8.2f} {s['p_le']:10.4g}")

print("\nInterpretation:")
print("  • bits_real is the MDL cost for that parameter in the real universe.")
print("  • mean_null, std_null, min, max describe the null distribution of bits for")
print("    that parameter when we randomize around the real value over ±1 decade in log10.")
print("  • z is how many standard deviations below the null mean the real bits lie.")
print("  • p_le is the fraction of null samples with MDL_i <= bits_real;")
print("    small p_le means that parameter is unusually compressible compared to null.")
print("  • Parameters at the top of this table (lowest p_le, most negative z) are the")
print("    strongest individual 'snap' suspects driving the global 353-bit anomaly.\n")

print("="*90)
print("END OF MODULE 5: PER-PARAMETER MDL ANOMALY SCAN")
print("="*90 + "\n")

######################################################################
## MODULE 6: JOINT MDL TEST FOR THE "SIGNAL SUBSET" OF PARAMETERS
##  - Uses same global Q_MAX and width=±1 decade null as before.
##  - Signal subset = all parameters except:
##      * LEPTON_YUKAWA::me_over_v (idx 10)
##      * QUARK_LIGHT::md_over_v   (idx 16)
##      * QUARK_LIGHT::mu_over_v   (idx 18)
##    i.e. the ones that were not especially simple individually.
######################################################################

print("\n" + "="*90)
print("MODULE 6: JOINT MDL TEST FOR SIGNAL SUBSET")
print("="*90 + "\n")

import math, random, statistics

# Check required globals
try:
    _ = REAL_MDL_GLOBAL
    _ = Q_MAX
    _ = REGISTRY_LIST_1C
    _ = encode_as_rationals_global
    _ = draw_null_universe_mult
    _ = mdl_bits_from_denoms_global
    print("Found globals from Modules 1C–5. Proceeding.\n")
except NameError as e:
    print("ERROR: Required globals not found. Make sure Modules 1C–5 ran above this.")
    raise e

# 1. Define signal subset indices
SIGNAL_EXCLUDE = {
    "LEPTON_YUKAWA::me_over_v",
    "QUARK_LIGHT::md_over_v",
    "QUARK_LIGHT::mu_over_v",
}
param_full_names = [f"{e['group']}::{e['name']}" for e in REGISTRY_LIST_1C]

SIGNAL_IDX = [
    i for i, name in enumerate(param_full_names)
    if name not in SIGNAL_EXCLUDE
]

print("Signal subset indices and names:")
for i in SIGNAL_IDX:
    print(f"  idx={i:2d}  param={param_full_names[i]}")
print(f"\nTotal signal parameters: {len(SIGNAL_IDX)}\n")

# 2. Real-universe MDL for signal subset
real_fracs_global = encode_as_rationals_global(
    [e["true_val"] for e in REGISTRY_LIST_1C],
    qmax=Q_MAX
)
real_qs  = [fr.denominator for fr in real_fracs_global]
real_bits = [math.ceil(math.log2(q)) for q in real_qs]

REAL_MDL_SIGNAL = sum(real_bits[i] for i in SIGNAL_IDX)

print(f"Real-universe MDL (signal subset only) = {REAL_MDL_SIGNAL}")
print(f"Real-universe MDL (all 19, from Module 1C) = {REAL_MDL_GLOBAL}")
print()

# 3. Null ensemble for signal subset
N_NULL_6 = 20000
WIDTH_6  = 1.0  # ±1 decade, same as main test

print(f"Running joint MDL null for signal subset with N={N_NULL_6}, width=±{WIDTH_6} decades...\n")

random.seed(1337)
mdl_signal_null = []

for _ in range(N_NULL_6):
    vals_fake = draw_null_universe_mult(width_decades=WIDTH_6)
    fracs_fake = encode_as_rationals_global(vals_fake, qmax=Q_MAX)
    bits_fake = [math.ceil(math.log2(fr.denominator)) for fr in fracs_fake]
    mdl_sig = sum(bits_fake[i] for i in SIGNAL_IDX)
    mdl_signal_null.append(mdl_sig)

print("Done generating null ensemble for signal subset.\n")

# 4. Summarize null distribution
mean_sig = statistics.mean(mdl_signal_null)
std_sig  = statistics.pstdev(mdl_signal_null)
min_sig  = min(mdl_signal_null)
max_sig  = max(mdl_signal_null)
count_le = sum(1 for x in mdl_signal_null if x <= REAL_MDL_SIGNAL)
p_le_sig = count_le / len(mdl_signal_null)

z_sig = (REAL_MDL_SIGNAL - mean_sig) / std_sig if std_sig > 0 else float("nan")
absz   = abs(z_sig)
p_gauss_sig = 0.5 * math.erfc(absz / math.sqrt(2))
log10_p_gauss_sig = math.log10(p_gauss_sig) if p_gauss_sig > 0 else float("-inf")

print("JOINT MDL NULL RESULTS FOR SIGNAL SUBSET:")
print(f"  Real MDL (signal subset) : {REAL_MDL_SIGNAL}")
print(f"  Null mean                : {mean_sig:.2f}")
print(f"  Null std                 : {std_sig:.2f}")
print(f"  Null min                 : {min_sig}")
print(f"  Null max                 : {max_sig}")
print(f"  Empirical p_le           : {p_le_sig:.4g} (fraction with MDL_sig ≤ real)")
print(f"  Z-score                  : z ≈ {z_sig:.2f} σ")
print(f"  Gaussian tail p          : p_gauss ≈ {p_gauss_sig:.3e}")
print(f"  log10(p_gauss)           : ≈ {log10_p_gauss_sig:.2f}")
print("\nInterpretation:")
print("  • This is the same style of test as Module 4, but restricted to the")
print("    subset of parameters that individually looked unusually compressible.")
print("  • If the signal subset alone already shows many-σ deviation, then the")
print("    MDL anomaly is not an artifact of a few weird outliers; it reflects a")
print("    genuinely collective rational structure among those parameters.")
print("  • Comparing this to the full 19-parameter result from Module 4 lets you")
print("    see how much of the 20σ anomaly is carried by the 'structured' sector.")
print()
print("="*90)
print("END OF MODULE 6: JOINT MDL TEST FOR SIGNAL SUBSET")
print("="*90 + "\n")

######################################################################
## MODULE 7: LEDGER SNAP TESTS FOR SELECTED FRACTIONS
##  - Fixed ledger fractions:
##      * ρ² = (M_W/M_Z)²  → 655/843
##      * Koide Q(e,μ,τ)   → 2/3
##      * sin²θW           → 188/843 = 1 - 655/843
##  - For each:
##      * Compute real residual ε_real = |x_real - p/q_ledger|
##      * Null: x_fake ~ Uniform[band_min, band_max]
##      * p_ledger = P(|x_fake - p/q_ledger| ≤ ε_real)
##  - Then a joint test: all three snaps at least as good as real simultaneously.
######################################################################

print("\n" + "="*90)
print("MODULE 7: LEDGER SNAP TESTS FOR SELECTED FRACTIONS")
print("="*90 + "\n")

import math, random
from fractions import Fraction

# ----------------- helpers -----------------

def get_registry_value(group, name):
    for e in REGISTRY_LIST_1C:
        if e["group"] == group and e["name"] == name:
            return float(e["true_val"])
    raise ValueError(f"Parameter {group}::{name} not found in REGISTRY_LIST_1C")

def ledger_snap_test(name, x_real, target_frac, band, N=20000, rng=None):
    """
    Simple ledger snap test:
      - x_real: real-world value
      - target_frac: Fraction p/q (ledger)
      - band: (lo, hi) for Uniform null
      - N: number of null samples
    Returns dict of summary stats.
    """
    if rng is None:
        rng = random

    t = float(target_frac)
    eps_real = abs(x_real - t)

    lo, hi = band
    eps_samples = []
    count_le = 0
    for _ in range(N):
        x_fake = lo + (hi - lo) * rng.random()
        eps = abs(x_fake - t)
        eps_samples.append(eps)
        if eps <= eps_real:
            count_le += 1

    eps_samples.sort()
    def pct(arr, p):
        idx = int(max(0, min(len(arr) - 1, round(p * (len(arr) - 1)))))
        return arr[idx]

    p_emp = count_le / N
    return {
        "name": name,
        "x_real": x_real,
        "target": t,
        "target_frac": target_frac,
        "eps_real": eps_real,
        "median_eps": pct(eps_samples, 0.5),
        "eps_5": pct(eps_samples, 0.05),
        "eps_95": pct(eps_samples, 0.95),
        "p_emp": p_emp,
        "N": N,
    }

# ----------------- 1. Compute real values & ledger targets -----------------

print("Computing real values for ρ², Koide Q, and sin²θW from registry...\n")

# (a) ρ² = (M_W/M_Z)²
MW_over_v = get_registry_value("EW", "MW_over_v")
MZ_over_v = get_registry_value("EW", "MZ_over_v")
rho2_real = (MW_over_v / MZ_over_v)**2

rho2_ledger = Fraction(655, 843)  # your custodial snap
rho2_band   = (0.60, 0.90)

# (b) Koide Q(e, μ, τ) using me_over_v, mmu_over_v, mtau_over_v
me_over_v   = get_registry_value("LEPTON_YUKAWA", "me_over_v")
mmu_over_v  = get_registry_value("LEPTON_YUKAWA", "mmu_over_v")
mtau_over_v = get_registry_value("LEPTON_YUKAWA", "mtau_over_v")

# Koide Q is homogeneous of degree 0 (scale cancels), so using *_over_v is fine
num_Q = me_over_v + mmu_over_v + mtau_over_v
den_Q = (math.sqrt(me_over_v) + math.sqrt(mmu_over_v) + math.sqrt(mtau_over_v))**2
Q_real = num_Q / den_Q

Q_ledger = Fraction(2, 3)
Q_band   = (0.40, 0.90)

# (c) sin²θW, with ledger tied to same ρ-snap: s² = 1 - 655/843 = 188/843
s2W_real = get_registry_value("COUPLINGS", "sin2_thetaW")
s2W_ledger = Fraction(188, 843)
s2W_band   = (0.15, 0.35)

print(f"Real ρ² from registry          : {rho2_real:.12f}")
print(f"Ledger ρ² target (655/843)     : {float(rho2_ledger):.12f}")
print(f"Real Koide Q(e,μ,τ)            : {Q_real:.12f}")
print(f"Ledger Koide target (2/3)      : {float(Q_ledger):.12f}")
print(f"Real sin²θW from registry      : {s2W_real:.12f}")
print(f"Ledger sin²θW target (188/843) : {float(s2W_ledger):.12f}")
print()

# ----------------- 2. Run single-ledger snap tests -----------------

N_LEDGER = 20000
random.seed(4242)

print(f"Running ledger snap tests with N={N_LEDGER} per quantity...\n")

res_rho2 = ledger_snap_test(
    name="ρ² = (M_W/M_Z)²",
    x_real=rho2_real,
    target_frac=rho2_ledger,
    band=rho2_band,
    N=N_LEDGER,
    rng=random
)

res_Q = ledger_snap_test(
    name="Koide Q(e,μ,τ)",
    x_real=Q_real,
    target_frac=Q_ledger,
    band=Q_band,
    N=N_LEDGER,
    rng=random
)

res_s2W = ledger_snap_test(
    name="sin²θW",
    x_real=s2W_real,
    target_frac=s2W_ledger,
    band=s2W_band,
    N=N_LEDGER,
    rng=random
)

def print_ledger_result(res):
    fr = res["target_frac"]
    bits = fr.numerator.bit_length() + fr.denominator.bit_length()
    print(f">>> LEDGER SNAP: {res['name']}")
    print(f"  target fraction           : {fr.numerator}/{fr.denominator}  (bits={bits})")
    print(f"  target value              : {res['target']:.12f}")
    print(f"  real value x_real         : {res['x_real']:.12f}")
    print(f"  real residual ε_real      : {res['eps_real']:.3e}")
    print(f"  null median(|x - target|) : {res['median_eps']:.3e}")
    print(f"  null 5th percentile       : {res['eps_5']:.3e}")
    print(f"  null 95th percentile      : {res['eps_95']:.3e}")
    print(f"  empirical p_ledger        : P(|x_fake - target| ≤ ε_real) ≈ {res['p_emp']:.4f}")
    print()

print_ledger_result(res_rho2)
print_ledger_result(res_Q)
print_ledger_result(res_s2W)

# ----------------- 3. Joint ledger test (ρ², Q, sin²θW simultaneously) -----------------

print("Running JOINT ledger snap test for (ρ², Q, sin²θW)...\n")

N_JOINT = 20000
random.seed(9999)

eps_rho2_real = res_rho2["eps_real"]
eps_Q_real    = res_Q["eps_real"]
eps_s2W_real  = res_s2W["eps_real"]

count_joint = 0
for _ in range(N_JOINT):
    # independent uniforms in their respective bands
    R_fake  = rho2_band[0] + (rho2_band[1] - rho2_band[0]) * random.random()
    Q_fake  = Q_band[0]    + (Q_band[1]    - Q_band[0])    * random.random()
    s2W_fake= s2W_band[0]  + (s2W_band[1]  - s2W_band[0])  * random.random()

    if (abs(R_fake - float(rho2_ledger))  <= eps_rho2_real and
        abs(Q_fake - float(Q_ledger))     <= eps_Q_real    and
        abs(s2W_fake - float(s2W_ledger)) <= eps_s2W_real):
        count_joint += 1

p_joint = count_joint / N_JOINT

print(">>> JOINT LEDGER SNAP (ρ², Koide Q, sin²θW):")
print(f"  Real residuals:")
print(f"    ε_real(ρ²)      = {eps_rho2_real:.3e}")
print(f"    ε_real(Q)       = {eps_Q_real:.3e}")
print(f"    ε_real(sin²θW)  = {eps_s2W_real:.3e}")
print(f"  Joint empirical p_joint ≈ {p_joint:.4f}  "
      f"(fraction of null triples with ALL three ε_fake ≤ ε_real)")
print()

print("Interpretation:")
print("  • Each single-ledger test shows how often a random value in a broad band would")
print("    be at least as close to that fixed rational as the real universe is.")
print("  • The joint p_joint says how often you’d get a universe where ρ², Koide Q, and")
print("    sin²θW are simultaneously as well-aligned with their ledger fractions as in")
print("    our universe, under a simple uniform null for each quantity.")
print("  • This drills into the specific fractions (655/843, 2/3, 188/843) you care about,")
print("    separate from the more generic 'best rational compression' MDL tests.")
print()
print("="*90)
print("END OF MODULE 7: LEDGER SNAP TESTS FOR SELECTED FRACTIONS")
print("="*90 + "\n")

# === QRLF v11-print — Master-List Prior + Rosetta Map (prints everything inline) ===
# One cell, self-contained. No reliance on prior runs.
# - Edits: prints CI+MDL summary, posterior summary, full Quantum Ledger,
#   full overlaps, full Rosetta map, Bayes stats, and shows plots inline.
# - Still writes artifacts to a run folder for convenience.


import sys, subprocess, importlib, os, json, math, time, csv, io
from fractions import Fraction
from dataclasses import dataclass
from typing import Dict, List, Tuple, Optional
from pathlib import Path


# ---------------- deps ----------------
def _need(pkg):
    try: importlib.import_module(pkg); return False
    except ImportError: return True
to_install=[p for p in ("pandas","numpy","requests","openpyxl","matplotlib","IPython") if _need(p)]
if to_install:
    subprocess.check_call([sys.executable,"-m","pip","install",*to_install])
import pandas as pd, numpy as np, requests, matplotlib.pyplot as plt
from IPython.display import display, Image, HTML


# ---------------- master ledger (editable) ----------------
MASTER_LEDGER = {
  "CKM": [
    "2/89","28/675","3/20","2/9","7/23","7/20","7/17","16/23","3/4","14/17",
    "49/289","58/338","79/81","87/89","119/169","609/2047","1392/2047"
  ],
  "RareDecay": ["169/4050"],
  "Cosmology": ["14/75","63/200"],
  "Neutrino": ["1/34","1/33","1/45","2/89","5/16","4/7","7/12","5/8","7/23"],
  "Ledger": [
    "63/200","137/200","211/400","95/173","105/196","117/490","663/1000",
    "466/973","416/729","543/814","6869/17983","21123/33512","22034/43315","24087/34343"
  ],
  "BlackHole": ["1/2","1/4","4/15","5/6","8/11","11/15"],
  "Other": [
    "3/761","4/453","1/45","8/193","33/782","9/77","31/209","1/6","24/107","63/103",
    "9/40","25/108","3/10","4/11","3/8","3/5","11/23","49/289","58/338","79/81",
    "95/173","105/196","117/490","137/200","180/803","188/843","211/400","350/1529","416/729",
    "466/973","543/814","554/569","650/667","655/843","663/1000","687/941","7852/33959",
    "6869/17983","9953/84419","999/1000","13482/60107","17807/54547","21123/33512",
    "22034/43315","24087/34343","26107/33959"
  ],
  "QuantumPowers": [f"1/{2**n}" for n in range(1,17)]
}
for override_path in ("/content/master_ledger.json","/mnt/data/master_ledger.json"):
    if os.path.exists(override_path):
        try:
            MASTER_LEDGER = json.load(open(override_path,"r"))
            print(f"Using uploaded master ledger: {override_path}")
            break
        except Exception as e:
            print("Failed to load uploaded JSON; using inline list. Error:", e)


# ---------------- run dirs ----------------
RUN_ID = time.strftime("v11print_%Y%m%d-%H%M%S")
BASE   = Path(f"qrlf_rosetta_{RUN_ID}"); BASE.mkdir(parents=True, exist_ok=True)
DATA_DIR = BASE/"datasets"; DATA_DIR.mkdir(exist_ok=True)


# ---------------- utilities ----------------
def mdl_bits(fr: Fraction) -> int:
    p,q = abs(fr.numerator), abs(fr.denominator)
    if p == 0: return 1 + (0 if q==1 else math.ceil(math.log2(q)))
    return (0 if p==1 else math.ceil(math.log2(p))) + (0 if q==1 else math.ceil(math.log2(q)))


def wilson_ci(k:int, n:int, z:float=1.96):
    if n==0: return 0.0,1.0
    phat = k/n
    denom = 1 + (z*z)/n
    center = phat + (z*z)/(2*n)
    rad = z*math.sqrt((phat*(1-phat) + (z*z)/(4*n))/n)
    lo=(center-rad)/denom; hi=(center+rad)/denom
    return max(0.0,lo), min(1.0,hi)


@dataclass
class Prob:
    phat: float; n: int; lo: float; hi: float; method: str="wilson"


def prob_from_counts(counts:Dict[str,int]) -> Prob:
    n = counts["0"] + counts["1"]; k = counts["1"]
    lo,hi = wilson_ci(k,n)
    return Prob(phat=(k/n if n else 0.0), n=n, lo=lo, hi=hi)


def continued_fraction_convergents(x: float, max_den: int = 4096) -> List[Fraction]:
    denoms=[1,2,3,4,5,6,7,8,9,10,12,16,20,24,32,40,48,64,80,96,128,160,192,256,384,512,768,1024,2048,4096]
    S=set(Fraction(x).limit_denominator(d) for d in denoms)
    S.add(Fraction(x).limit_denominator(max_den))
    return sorted(S, key=float)


@dataclass
class MatchCfg:
    max_den: int = 10000
    use_ci: bool = True
    prefer_min_mdl_in_ci: bool = True
    ci_expand: float = 1.0


def ci_mdl(ph: float, ci: Tuple[float,float], cfg: MatchCfg):
    convs = continued_fraction_convergents(ph, max_den=cfg.max_den)
    pool = [(f, abs(float(f)-ph), mdl_bits(f)) for f in convs]
    pool.sort(key=lambda t:(t[1],t[2]))
    if cfg.use_ci and ci:
        lo,hi = ci; width = (hi-lo)*cfg.ci_expand
        c = 0.5*(lo+hi); lo2=max(0.0,c-width/2); hi2=min(1.0,c+width/2)
        in_ci = [(f,e,m) for (f,e,m) in pool if lo2-1e-15 <= float(f) <= hi2+1e-15]
        if in_ci:
            in_ci.sort(key=(lambda t: (t[2],t[1])) if cfg.prefer_min_mdl_in_ci else (lambda t: (t[1],t[2])))
            f,e,m = in_ci[0]; return ("ci-mdl", f, e, m)
    f,e,m = pool[0]; return ("cf", f, e, m)


# ---------------- prior & posterior ----------------
class Prior:
    def __init__(self,
                 mdl_temp: float = 1.0,
                 half_boost: float = 6.0, half_win: float = 8e-4,
                 fam_boost: float = 1.5, fam_tau: float = 0.015,
                 fam_ks = (2,3,4,5,6),
                 xor_boost: float = 8.0, xor_win: float = 1e-3,
                 seed_weights: Optional[Dict[Fraction,float]] = None):
        self.mdl_temp=mdl_temp
        self.half_boost=half_boost; self.half_win=half_win
        self.fam_boost=fam_boost; self.fam_tau=fam_tau; self.fam_ks=tuple(int(k) for k in fam_ks)
        self.xor_boost=xor_boost; self.xor_win=xor_win
        self.seed_weights = seed_weights or {}


    def _family_anchors(self)->List[float]:
        A=[]
        for k in self.fam_ks:
            if k>=2:
                A.append((k-1)/k); A.append(k/(k+1))
        return A


    def weight(self, f: Fraction, channel: str)->float:
        x=float(f)
        w = 2.0 ** (- mdl_bits(f) / self.mdl_temp)   # MDL base
        if f in self.seed_weights: w *= (1.0 + self.seed_weights[f])
        if channel in ("A","B"):
            d = abs(x - 0.5)
            if d <= self.half_win:
                w *= (1.0 + self.half_boost*(1 - d/self.half_win))
        dmin = min(abs(x-a) for a in self._family_anchors())
        w *= (1.0 + self.fam_boost * math.exp(-dmin/self.fam_tau))
        if channel == "XOR":
            d = min(abs(x-0.0), abs(x-1.0))
            if d <= self.xor_win:
                w *= (1.0 + self.xor_boost*(1 - d/self.xor_win))
        return max(w, 1e-300)


def loglik_binom(k:int, n:int, x:float)->float:
    if x<=0.0: return 0.0 if k==0 else -1e300
    if x>=1.0: return 0.0 if k==n else -1e300
    return k*math.log(x) + (n-k)*math.log(1-x)


def dynamic_candidates(phat: float, channel: str, q_hint: int, master: Dict[str,List[str]])->List[Fraction]:
    S=set()
    for f in continued_fraction_convergents(phat, max_den=q_hint): S.add(f)
    for k in range(2,33): S.add(Fraction(k-1,k)); S.add(Fraction(k,k+1))
    for q in range(2,65):
        for p in range(0,q+1):
            if math.gcd(p,q)==1: S.add(Fraction(p,q))
    for anchors in ((0,1),(1,256)):
        S.add(Fraction(*anchors))
    for cat, arr in master.items():
        for s in arr:
            try:
                p,q = map(int, s.split("/"))
                if q>0 and 0<=p<=q: S.add(Fraction(p,q))
            except: pass
    return sorted(S, key=float)


def posterior_map(counts: Dict[str,int], channel: str, prior: Prior, master: Dict[str,List[str]]):
    n = counts["0"] + counts["1"]; k = counts["1"]
    phat = k/n if n else 0.5
    cands = dynamic_candidates(phat, channel, q_hint=1024, master=master)
    best=None; best_lp=-1e300; ladder=[]
    for f in cands:
        lp = loglik_binom(k,n,float(f)) + math.log(prior.weight(f, channel))
        ladder.append((f, lp, mdl_bits(f)))
        if lp>best_lp: best_lp=lp; best=f
    ladder.sort(key=lambda t:-t[1])
    top10=[(f"{t[0].numerator}/{t[0].denominator}", t[1], t[2]) for t in ladder[:10]]
    return best, best_lp, mdl_bits(best), top10, ladder


# ---------------- seed weights from master ----------------
cat_weight = {
    "CKM": 1.0, "Cosmology": 1.0, "RareDecay": 0.9, "BlackHole": 0.8,
    "Neutrino": 0.8, "Ledger": 0.7, "Muon": 0.7, "Other": 0.5, "QuantumPowers": 0.9
}
seed_weights={}; DEDUP_LEDGER={}
for cat, arr in MASTER_LEDGER.items():
    S=set()
    for s in arr:
        try:
            p,q = map(int, s.split("/"))
            if q>0 and 0<=p<=q:
                fr=Fraction(p,q); S.add(f"{p}/{q}")
                w = cat_weight.get(cat, 0.5)
                if q<=16: w += 0.3
                occur = sum(1 for c,A in MASTER_LEDGER.items() if s in A)
                w += 0.1*max(0, occur-1)
                seed_weights[fr] = max(seed_weights.get(fr,0.0), w)
        except: pass
    DEDUP_LEDGER[cat] = sorted(S, key=lambda t: Fraction(*map(int, t.split("/"))))
json.dump(DEDUP_LEDGER, open(BASE/"master_ledger_in_use.json","w"), indent=2)
print("Saved in-use ledger →", (BASE/"master_ledger_in_use.json").resolve())


# ---------------- NIST files ----------------
NIST_URLS = {
  "02_54_ALL.xlsx": "https://s3.amazonaws.com/nist-belltestdata/belldata/Peter%27s%20Data%20Calculations/First%203%20Runs/02_54_ALL.xlsx",
  "03_43_ALL.xlsx": "https://s3.amazonaws.com/nist-belltestdata/belldata/Peter%27s%20Data%20Calculations/First%203%20Runs/03_43_CH_pockel_100kHz.run4.afterTimingfix2_afterfixingModeLocking.dat.compressed.build.hdf5.v4pc_ALL.xlsx",
  "19_45_ALL.xlsx": "https://s3.amazonaws.com/nist-belltestdata/belldata/Peter%27s%20Data%20Calculations/First%203%20Runs/19_45_nolightconeshift_ALL%20(Autosaved).xlsx",
}
def download(name:str, outdir:Path)->Path:
    p=outdir/name; outdir.mkdir(parents=True, exist_ok=True)
    r=requests.get(NIST_URLS[name], timeout=90); r.raise_for_status(); p.write_bytes(r.content)
    return p


def find_labeled_header_row(df:pd.DataFrame):
    cands=[("c00","c01","c10","c11"),("n00","n01","n10","n11"),("00","01","10","11")]
    nrows=min(df.shape[0], 2000)
    for r in range(nrows):
        row=[str(x).strip().lower() for x in df.iloc[r,:].tolist()]
        for cand in cands:
            pos={}; ok=True
            for tok in cand:
                if tok in row: pos[tok]=row.index(tok)
                else: ok=False; break
            if ok: return r,pos
    return None,None


def sum_counts_under(df:pd.DataFrame, header_row:int, pos:Dict[str,int]):
    block=df.iloc[header_row+1:,:]; totals={}
    for lbl,cidx in pos.items():
        col=pd.to_numeric(block.iloc[:,cidx], errors='coerce').fillna(0.0)
        totals[lbl]=float(col.sum())
    C={"00":0,"01":0,"10":0,"11":0}
    for k,v in totals.items():
        kk=k[-2:]; 
        if kk in C: C[kk]+=int(round(v))
    return C, sum(C.values())


def score_count_column(series:pd.Series)->float:
    x=pd.to_numeric(series, errors='coerce'); x=x[~x.isna()]
    if len(x)==0: return 1e12
    med=float(x.median()); mx=float(x.max())
    if med<=0: med=1e-9
    penalty=0.0
    if mx>1e8 or med>1e7: penalty+=1e6
    if med<5 or med>1e6: penalty+=1e5
    ratio=(mx+1)/(med+1)
    return penalty+ratio


def discover_4col_candidates(df:pd.DataFrame, top_k:int=3):
    ncols=df.shape[1]
    scores=[score_count_column(df.iloc[:,c]) for c in range(ncols)]
    cands=[]
    for c0 in range(ncols):
        for skip in (0,1):
            c1,c2,c3=c0+1+skip, c0+2+skip, c0+3+skip
            if c3>=ncols: continue
            cols=(c0,c1,c2,c3)
            sc=sum(scores[c] for c in cols)
            cands.append((sc,cols))
    cands.sort(key=lambda t:t[0])
    out=[]
    for _,cols in cands[:100]:
        block=df.iloc[:, list(cols)]
        numblock=block.apply(pd.to_numeric, errors='coerce').fillna(0.0)
        bsum=numblock.sum(axis=0).to_numpy().astype(float)
        if (bsum<=1.0).any(): continue
        norm = bsum / max(1.0, bsum.sum())
        if norm.max()>0.97: continue
        C={"00":int(round(bsum[0])),"01":int(round(bsum[1])),"10":int(round(bsum[2])),"11":int(round(bsum[3]))}
        if (C["00"]==0 and C["11"]==0) or (C["01"]==0 and C["10"]==0): continue
        out.append((cols,C,sum(C.values())))
        if len(out)>=top_k: break
    return out


def collapse_channels(C:Dict[str,int])->Dict[str,Dict[str,int]]:
    A={"0": C["00"] + C["01"], "1": C["10"] + C["11"]}
    B={"0": C["00"] + C["10"], "1": C["01"] + C["11"]}
    XOR={"0": C["00"] + C["11"], "1": C["01"] + C["10"]}
    return {"A":A,"B":B,"XOR":XOR}


# ---------------- run ----------------
FILES = ["02_54_ALL.xlsx","03_43_ALL.xlsx","19_45_ALL.xlsx"]
paths=[download(n, DATA_DIR) for n in FILES]
print("Downloaded:", [p.name for p in paths])


cfg = MatchCfg()
prior = Prior(seed_weights=seed_weights)


records=[]; summary_ci={"A":{}, "B":{}, "XOR":{}}; summary_post={"A":{}, "B":{}, "XOR":{}}
bf_ab=[]  # ln Bayes factor advantage of 1/2 vs best alt for A/B


def bump(d,ch,key): d[ch][key]=d[ch].get(key,0)+1
def fstr(fr:Fraction)->str: return f"{fr.numerator}/{fr.denominator}"


def print_block_header(p_name, sh, kind, tag, C):
    print(f"\n[CAND] file={p_name} sheet={sh} tag={tag} C={C} tot={sum(C.values())}")


for p in paths:
    xl=pd.ExcelFile(p, engine="openpyxl"); print("\nSheets:", xl.sheet_names)
    for sh in xl.sheet_names:
        df = xl.parse(sh, header=None, dtype=object)
        blocks=[]
        r,pos=find_labeled_header_row(df)
        if r is not None:
            C, tot = sum_counts_under(df, r, pos)
            if tot>0: blocks.append(("HEADER", None, C, tot))
        for cols, C, tot in discover_4col_candidates(df, top_k=3):
            blocks.append(("CAND", cols, C, tot))
        if not blocks:
            print(f"[no-2bit] {p.name}/{sh}: skipped"); continue


        for kind, cols, C, tot in blocks:
            tag="header" if kind=="HEADER" else f"cols{cols[0]}_{cols[1]}_{cols[2]}_{cols[3]}"
            print_block_header(p.name, sh, kind, tag, C)
            chans=collapse_channels(C)
            for ch_name, counts in chans.items():
                prob = prob_from_counts(counts)
                mode, f_ci, err_ci, mdl_ci = ci_mdl(prob.phat, (prob.lo,prob.hi), cfg)
                f_post, lp_post, mdl_post, ladder, ladder_full = posterior_map(counts, ch_name, prior, DEDUP_LEDGER)
                print(f"  -> {ch_name}: p̂={prob.phat:.9f}  CI={prob.lo:.9f}..{prob.hi:.9f} | CI+MDL={fstr(f_ci)}(mdl={mdl_ci}, {mode}) || Posterior={fstr(f_post)}(mdl={mdl_post})")
                print("     Posterior top10:", ", ".join([f"{a} (mdl={m})" for a,_,m in ladder]))


                rec = {
                    "file": p.name, "sheet": sh, "kind": kind, "tag": tag, "channel": ch_name,
                    "counts": counts, "n": sum(counts.values()),
                    "phat": prob.phat, "ci": [prob.lo, prob.hi],
                    "ci_mdl": {"lock": fstr(f_ci), "mdl": mdl_ci, "mode": mode},
                    "posterior": {"lock": fstr(f_post), "mdl": mdl_post, "log_post": lp_post, "ladder_top10": ladder},
                }
                records.append(rec)
                if mdl_ci<=12: bump(summary_ci, ch_name, fstr(f_ci))
                bump(summary_post, ch_name, fstr(f_post))


                if ch_name in ("A","B"):
                    lp_half = next((lp for fr,lp,_ in ladder_full if fr==Fraction(1,2)), -1e300)
                    best_alt_lp = next((lp for fr,lp,_ in ladder_full if fr!=Fraction(1,2)), -1e300)
                    bf_ab.append(lp_half - best_alt_lp)


# Persist raw records
OUT_JSONL = BASE/"locks.jsonl"
with OUT_JSONL.open("w") as f:
    for r in records: f.write(json.dumps(r)+"\n")
print("\nJSONL →", OUT_JSONL.resolve())


# ---------------- build Quantum Ledger ----------------
def build_quantum_ledger(summary_post:Dict[str,Dict[str,int]], min_abs:int=3, min_frac:float=0.10, mdl_cap:int=16):
    ledger=[]
    for ch, counts in summary_post.items():
        total=sum(counts.values())
        for frac, support in sorted(counts.items(), key=lambda kv:(-kv[1], kv[0])):
            p,q=map(int, frac.split("/")); fr=Fraction(p,q)
            if support >= max(min_abs, int(math.ceil(min_frac*total))) and mdl_bits(fr)<=mdl_cap:
                ledger.append({"channel":ch,"fraction":frac,"mdl":mdl_bits(fr),"support":support,"total":total})
    agg={}
    for row in ledger:
        f=row["fraction"]
        if f not in agg:
            agg[f]={"fraction":f,"mdl":row["mdl"],"channels":set(),"support":0,"by_channel":{}}
        agg[f]["channels"].add(row["channel"])
        agg[f]["support"]+=row["support"]
        agg[f]["by_channel"][row["channel"]]=row["support"]
    out=[]
    for f,v in agg.items():
        v["channels"]="/".join(sorted(list(v["channels"]))); out.append(v)
    out.sort(key=lambda d:(-d["support"], d["fraction"]))
    return out


quantum_ledger = build_quantum_ledger(summary_post, min_abs=3, min_frac=0.10, mdl_cap=16)
json.dump(quantum_ledger, open(BASE/"quantum_ledger.json","w"), indent=2)
print("Quantum ledger saved →", (BASE/"quantum_ledger.json").resolve())


# ---------------- overlaps with master ----------------
def overlaps_per_category(qledger, master:Dict[str,List[str]]):
    qset={Fraction(*map(int, x["fraction"].split("/"))): x for x in qledger}
    rows=[]
    for cat, arr in master.items():
        for s in arr:
            try:
                p,q=map(int, s.split("/")); fr=Fraction(p,q)
                if fr in qset:
                    x=qset[fr]
                    rows.append({"ledger":cat,"fraction":x["fraction"],"mdl":x["mdl"],"channels":x["channels"],"support":x["support"]})
            except: pass
    return rows


overlaps = overlaps_per_category(quantum_ledger, DEDUP_LEDGER)
with (BASE/"overlaps.csv").open("w", newline="") as f:
    w=csv.DictWriter(f, fieldnames=["ledger","fraction","mdl","channels","support"])
    w.writeheader()
    for r in overlaps: w.writerow(r)
print("Overlaps CSV →", (BASE/"overlaps.csv").resolve())


# ---------------- Rosetta tagging ----------------
def classify_fraction(fr: Fraction):
    tags=[]
    n=fr.numerator; d=fr.denominator
    def is_pow2(x): return x>0 and (x & (x-1))==0
    if n==1 and is_pow2(d): tags.append(f"pow2(1/{d})")
    for k in range(2,65):
        if fr == Fraction(k-1,k): tags.append(f"(k-1)/k@{k}")
        if fr == Fraction(k, k+1): tags.append(f"k/(k+1)@{k}")
    x=float(fr); eps=1e-3
    if abs(x-0.5) < eps: tags.append("near(1/2)")
    for k in range(2,33):
        if abs(x - (k-1)/k) < eps: tags.append(f"near((k-1)/k@{k})")
        if abs(x - k/(k+1)) < eps: tags.append(f"near(k/(k+1)@{k})")
    return tags or ["—"]


def rosetta_rows(qledger, master:Dict[str,List[str]]):
    cat_by_frac={}
    for cat, arr in master.items():
        for s in arr:
            try:
                p,q=map(int, s.split("/")); fr=Fraction(p,q)
                cat_by_frac.setdefault(fr, set()).add(cat)
            except: pass
    rows=[]
    for item in qledger:
        p,q = map(int, item["fraction"].split("/")); fr=Fraction(p,q)
        cats = sorted(list(cat_by_frac.get(fr, set())))
        rows.append({
            "fraction": item["fraction"],
            "mdl": item["mdl"],
            "channels": item["channels"],
            "support": item["support"],
            "categories": ",".join(cats) if cats else "",
            "tags": ";".join(classify_fraction(fr))
        })
    return rows


ros = rosetta_rows(quantum_ledger, DEDUP_LEDGER)
with (BASE/"rosetta.csv").open("w", newline="") as f:
    w=csv.DictWriter(f, fieldnames=["fraction","mdl","channels","support","categories","tags"])
    w.writeheader()
    for r in ros: w.writerow(r)
json.dump(ros, open(BASE/"rosetta.json","w"), indent=2)
print("Rosetta saved →", (BASE/"rosetta.csv").resolve())


# ---------------- plots (also display inline) ----------------
if quantum_ledger:
    top = quantum_ledger[:15]
    labels=[x["fraction"] for x in top]
    values=[x["support"] for x in top]
    plt.figure()
    plt.bar(range(len(labels)), values)
    plt.xticks(range(len(labels)), labels, rotation=45, ha="right")
    plt.title("Quantum Ledger — Support (top 15)")
    plt.tight_layout()
    plot1 = BASE/"support_top15.png"
    plt.savefig(plot1, dpi=160)
    display(Image(filename=str(plot1)))
    plt.close()


if bf_ab:
    plt.figure()
    plt.hist(bf_ab, bins=30)
    plt.title("ln Bayes factor: 1/2 vs best alternative (A/B channels)")
    plt.xlabel("ln BF (positive ⇒ favors 1/2)"); plt.ylabel("count")
    plt.tight_layout()
    plot2 = BASE/"bf_hist.png"
    plt.savefig(plot2, dpi=160)
    display(Image(filename=str(plot2)))
    plt.close()


# ---------------- pretty printers ----------------
def print_kv_summary(title, d):
    print(f"\n=== {title} ===")
    for ch in ("A","B","XOR"):
        items = sorted(d[ch].items(), key=lambda kv:(-kv[1], kv[0]))
        if not items:
            print(f"- {ch}: (none)")
        else:
            s=", ".join([f"{k}×{v}" for k,v in items])
            print(f"- {ch}: {s}")


def print_table(rows, headers):
    # rows: list of dicts with headers keys; headers: list of (key, title)
    cols=[k for k,_ in headers]
    titles=[t for _,t in headers]
    data=[[str(r.get(k,"")) for k in cols] for r in rows]
    widths=[max(len(titles[i]), *(len(row[i]) for row in data)) for i in range(len(cols))]
    line="| " + " | ".join(titles[i].ljust(widths[i]) for i in range(len(cols))) + " |"
    sep ="|-" + "-|-".join("-"*widths[i] for i in range(len(cols))) + "-|"
    print("\n"+line); print(sep)
    for row in data:
        print("| " + " | ".join(row[i].ljust(widths[i]) for i in range(len(cols))) + " |")


# ---------------- print everything inline ----------------
# Master ledger summary
print("\n=== Master Ledger In Use ===")
for cat in sorted(DEDUP_LEDGER.keys()):
    print(f"- {cat}: {len(DEDUP_LEDGER[cat])} fractions")


# CI+MDL & Posterior summaries
print_kv_summary("CI+MDL Lock Summary (MDL ≤ 12)", summary_ci)
print_kv_summary("Generative Posterior Lock Summary (all MAPs)", summary_post)


# Quantum Ledger table
print("\n=== Quantum Ledger (posterior repeats; inclusion: ≥3 repeats or ≥10% blocks, MDL≤16) ===")
if quantum_ledger:
    print_table(
        [{"fraction":x["fraction"],"mdl":x["mdl"],"channels":x["channels"],"support":x["support"]} for x in quantum_ledger],
        [("fraction","Fraction"),("mdl","MDL"),("channels","Channels"),("support","Support")]
    )
else:
    print("(empty)")


# Overlaps table
print("\n=== Overlaps with Master Ledger ===")
if overlaps:
    print_table(
        overlaps,
        [("ledger","Ledger"),("fraction","Fraction"),("mdl","MDL"),("channels","Channels"),("support","Support")]
    )
else:
    print("(none)")


# Rosetta table
print("\n=== Rosetta Map (categories + tags) ===")
if ros:
    print_table(
        ros,
        [("fraction","Fraction"),("mdl","MDL"),("channels","Channels"),("support","Support"),("categories","Categories"),("tags","Tags")]
    )
else:
    print("(empty)")


# Bayes stats
def ln_to_log10(x): 
    try: return x/math.log(10)
    except Exception: return float('nan')
if bf_ab:
    mean_ln = sum(bf_ab)/len(bf_ab)
    q = np.quantile(np.array(bf_ab), [0.05,0.25,0.5,0.75,0.95])
    print("\n=== Evidence for 1/2 on A/B (Bayes factors) ===")
    print(f"- blocks: {len(bf_ab)}")
    print(f"- mean ln(BF): {mean_ln:.3f}  (~log10 {ln_to_log10(mean_ln):.3f})")
    print(f"- quantiles ln(BF): 5%={q[0]:.3f}, 25%={q[1]:.3f}, median={q[2]:.3f}, 75%={q[3]:.3f}, 95%={q[4]:.3f}")
else:
    print("\n=== Evidence for 1/2 on A/B (Bayes factors) ===\n- none tallied")


# Final artifact reminder
print("\nArtifacts saved in:", str(BASE.resolve()))
print("Files: master_ledger_in_use.json, locks.jsonl, quantum_ledger.json, overlaps.csv, rosetta.csv/json, support_top15.png, bf_hist.png")
print("\nDone ✓")